&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=yolov4-288.onnx --saveEngine=yolov4-288.trt --fp16 --dumpProfile --verbose --separateProfileRun --exportProfile=yolov4-288/recordProfile.json --exportOutput=yolov4-288/recordOutput.json --exportTimes=yolov4-288/recordTimes.json --exportLayerInfo=yolov4-288/recordLayer.json --workspace=512
[05/21/2022-02:47:10] [I] === Model Options ===
[05/21/2022-02:47:10] [I] Format: ONNX
[05/21/2022-02:47:10] [I] Model: yolov4-288.onnx
[05/21/2022-02:47:10] [I] Output:
[05/21/2022-02:47:10] [I] === Build Options ===
[05/21/2022-02:47:10] [I] Max batch: explicit batch
[05/21/2022-02:47:10] [I] Workspace: 512 MiB
[05/21/2022-02:47:10] [I] minTiming: 1
[05/21/2022-02:47:10] [I] avgTiming: 8
[05/21/2022-02:47:10] [I] Precision: FP32+FP16
[05/21/2022-02:47:10] [I] Calibration: 
[05/21/2022-02:47:10] [I] Refit: Disabled
[05/21/2022-02:47:10] [I] Sparsity: Disabled
[05/21/2022-02:47:10] [I] Safe mode: Disabled
[05/21/2022-02:47:10] [I] DirectIO mode: Disabled
[05/21/2022-02:47:10] [I] Restricted mode: Disabled
[05/21/2022-02:47:10] [I] Save engine: yolov4-288.trt
[05/21/2022-02:47:10] [I] Load engine: 
[05/21/2022-02:47:10] [I] Profiling verbosity: 0
[05/21/2022-02:47:10] [I] Tactic sources: Using default tactic sources
[05/21/2022-02:47:10] [I] timingCacheMode: local
[05/21/2022-02:47:10] [I] timingCacheFile: 
[05/21/2022-02:47:10] [I] Input(s)s format: fp32:CHW
[05/21/2022-02:47:10] [I] Output(s)s format: fp32:CHW
[05/21/2022-02:47:10] [I] Input build shapes: model
[05/21/2022-02:47:10] [I] Input calibration shapes: model
[05/21/2022-02:47:10] [I] === System Options ===
[05/21/2022-02:47:10] [I] Device: 0
[05/21/2022-02:47:10] [I] DLACore: 
[05/21/2022-02:47:10] [I] Plugins:
[05/21/2022-02:47:10] [I] === Inference Options ===
[05/21/2022-02:47:10] [I] Batch: Explicit
[05/21/2022-02:47:10] [I] Input inference shapes: model
[05/21/2022-02:47:10] [I] Iterations: 10
[05/21/2022-02:47:10] [I] Duration: 3s (+ 200ms warm up)
[05/21/2022-02:47:10] [I] Sleep time: 0ms
[05/21/2022-02:47:10] [I] Idle time: 0ms
[05/21/2022-02:47:10] [I] Streams: 1
[05/21/2022-02:47:10] [I] ExposeDMA: Disabled
[05/21/2022-02:47:10] [I] Data transfers: Enabled
[05/21/2022-02:47:10] [I] Spin-wait: Disabled
[05/21/2022-02:47:10] [I] Multithreading: Disabled
[05/21/2022-02:47:10] [I] CUDA Graph: Disabled
[05/21/2022-02:47:10] [I] Separate profiling: Enabled
[05/21/2022-02:47:10] [I] Time Deserialize: Disabled
[05/21/2022-02:47:10] [I] Time Refit: Disabled
[05/21/2022-02:47:10] [I] Skip inference: Disabled
[05/21/2022-02:47:10] [I] Inputs:
[05/21/2022-02:47:10] [I] === Reporting Options ===
[05/21/2022-02:47:10] [I] Verbose: Enabled
[05/21/2022-02:47:10] [I] Averages: 10 inferences
[05/21/2022-02:47:10] [I] Percentile: 99
[05/21/2022-02:47:10] [I] Dump refittable layers:Disabled
[05/21/2022-02:47:10] [I] Dump output: Disabled
[05/21/2022-02:47:10] [I] Profile: Enabled
[05/21/2022-02:47:10] [I] Export timing to JSON file: yolov4-288/recordTimes.json
[05/21/2022-02:47:10] [I] Export output to JSON file: yolov4-288/recordOutput.json
[05/21/2022-02:47:10] [I] Export profile to JSON file: yolov4-288/recordProfile.json
[05/21/2022-02:47:10] [I] 
[05/21/2022-02:47:10] [I] === Device Information ===
[05/21/2022-02:47:10] [I] Selected Device: NVIDIA Tegra X1
[05/21/2022-02:47:10] [I] Compute Capability: 5.3
[05/21/2022-02:47:10] [I] SMs: 1
[05/21/2022-02:47:10] [I] Compute Clock Rate: 0.9216 GHz
[05/21/2022-02:47:10] [I] Device Global Memory: 3964 MiB
[05/21/2022-02:47:10] [I] Shared Memory per SM: 64 KiB
[05/21/2022-02:47:10] [I] Memory Bus Width: 64 bits (ECC disabled)
[05/21/2022-02:47:10] [I] Memory Clock Rate: 0.01275 GHz
[05/21/2022-02:47:10] [I] 
[05/21/2022-02:47:10] [I] TensorRT version: 8.2.1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::EfficientNMS_TFTRT_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::Proposal version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::Split version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[05/21/2022-02:47:10] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[05/21/2022-02:47:12] [I] [TRT] [MemUsageChange] Init CUDA: CPU +230, GPU +0, now: CPU 248, GPU 2615 (MiB)
[05/21/2022-02:47:13] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 2618 MiB
[05/21/2022-02:47:13] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 278 MiB, GPU 2648 MiB
[05/21/2022-02:47:13] [I] Start parsing network model
[05/21/2022-02:47:13] [I] [TRT] ----------------------------------------------------------------
[05/21/2022-02:47:13] [I] [TRT] Input filename:   yolov4-288.onnx
[05/21/2022-02:47:13] [I] [TRT] ONNX IR version:  0.0.4
[05/21/2022-02:47:13] [I] [TRT] Opset version:    9
[05/21/2022-02:47:13] [I] [TRT] Producer name:    NVIDIA TensorRT sample
[05/21/2022-02:47:13] [I] [TRT] Producer version: 
[05/21/2022-02:47:13] [I] [TRT] Domain:           
[05/21/2022-02:47:13] [I] [TRT] Model version:    0
[05/21/2022-02:47:13] [I] [TRT] Doc string:       
[05/21/2022-02:47:13] [I] [TRT] ----------------------------------------------------------------
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TFTRT_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::Split version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[05/21/2022-02:47:14] [V] [TRT] Adding network input: 000_net with dtype: float32, dimensions: (1, 3, 288, 288)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 000_net for ONNX tensor: 000_net
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 001_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 001_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 001_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 001_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 001_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 002_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 002_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 002_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 002_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 002_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 003_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 003_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 003_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 003_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 003_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 005_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 005_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 005_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 005_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 005_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 006_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 006_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 006_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 006_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 006_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 007_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 007_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 007_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 007_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 007_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 009_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 009_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 009_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 009_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 009_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 011_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 011_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 011_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 011_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 011_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 012_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 012_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 012_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 012_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 012_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 013_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 013_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 013_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 013_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 013_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 015_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 015_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 015_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 015_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 015_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 016_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 016_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 016_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 016_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 016_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 017_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 017_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 017_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 017_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 017_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 019_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 019_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 019_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 019_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 019_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 020_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 020_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 020_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 020_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 020_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 022_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 022_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 022_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 022_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 022_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 024_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 024_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 024_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 024_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 024_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 025_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 025_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 025_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 025_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 025_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 026_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 026_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 026_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 026_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 026_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 028_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 028_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 028_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 028_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 028_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 029_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 029_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 029_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 029_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 029_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 030_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 030_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 030_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 030_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 030_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 032_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 032_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 032_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 032_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 032_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 033_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 033_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 033_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 033_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 033_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 035_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 035_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 035_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 035_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 035_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 036_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 036_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 036_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 036_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 036_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 038_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 038_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 038_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 038_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 038_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 039_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 039_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 039_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 039_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 039_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 041_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 041_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 041_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 041_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 041_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 042_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 042_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 042_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 042_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 042_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 044_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 044_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 044_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 044_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 044_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 045_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 045_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 045_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 045_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 045_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 047_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 047_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 047_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 047_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 047_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 048_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 048_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 048_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 048_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 048_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 050_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 050_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 050_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 050_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 050_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 051_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 051_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 051_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 051_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 051_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 053_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 053_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 053_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 053_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 053_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 055_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 055_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 055_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 055_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 055_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 056_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 056_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 056_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 056_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 056_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 057_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 057_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 057_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 057_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 057_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 059_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 059_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 059_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 059_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 059_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 060_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 060_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 060_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 060_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 060_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 061_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 061_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 061_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 061_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 061_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 063_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 063_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 063_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 063_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 063_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 064_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 064_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 064_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 064_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 064_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 066_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 066_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 066_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 066_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 066_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 067_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 067_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 067_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 067_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 067_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 069_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 069_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 069_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 069_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 069_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 070_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 070_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 070_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 070_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 070_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 072_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 072_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 072_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 072_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 072_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 073_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 073_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 073_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 073_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 073_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 075_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 075_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 075_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 075_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 075_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 076_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 076_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 076_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 076_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 076_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 078_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 078_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 078_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 078_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 078_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 079_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 079_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 079_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 079_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 079_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 081_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 081_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 081_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 081_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 081_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 082_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 082_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 082_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 082_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 082_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 084_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 084_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 084_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 084_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 084_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 086_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 086_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 086_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 086_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 086_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 087_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 087_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 087_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 087_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 087_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 088_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 088_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 088_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 088_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 088_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 090_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 090_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 090_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 090_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 090_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 091_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 091_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 091_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 091_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 091_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 092_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 092_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 092_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 092_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 092_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 094_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 094_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 094_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 094_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 094_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 095_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 095_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 095_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 095_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 095_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 097_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 097_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 097_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 097_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 097_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 098_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 098_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 098_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 098_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 098_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 100_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 100_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 100_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 100_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 100_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 101_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 101_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 101_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 101_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 101_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 103_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 103_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 103_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 103_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 103_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 105_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 105_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 105_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 105_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 105_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 106_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 106_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 106_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 106_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 106_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 107_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 107_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 107_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 107_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 107_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 108_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 108_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 108_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 108_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 108_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 115_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 115_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 115_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 115_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 115_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 116_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 116_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 116_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 116_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 116_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 117_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 117_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 117_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 117_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 117_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 118_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 118_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 118_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 118_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 118_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 119_upsample_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 121_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 121_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 121_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 121_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 121_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 123_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 123_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 123_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 123_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 123_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 124_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 124_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 124_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 124_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 124_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 125_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 125_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 125_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 125_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 125_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 126_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 126_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 126_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 126_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 126_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 127_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 127_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 127_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 127_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 127_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 128_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 128_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 128_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 128_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 128_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 129_upsample_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 131_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 131_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 131_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 131_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 131_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 133_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 133_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 133_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 133_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 133_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 134_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 134_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 134_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 134_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 134_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 135_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 135_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 135_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 135_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 135_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 136_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 136_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 136_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 136_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 136_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 137_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 137_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 137_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 137_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 137_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 138_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 138_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 138_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 138_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 138_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 139_convolutional_conv_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 139_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 142_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 142_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 142_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 142_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 142_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 144_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 144_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 144_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 144_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 144_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 145_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 145_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 145_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 145_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 145_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 146_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 146_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 146_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 146_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 146_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 147_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 147_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 147_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 147_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 147_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 148_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 148_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 148_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 148_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 148_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 149_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 149_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 149_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 149_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 149_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 150_convolutional_conv_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 150_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 153_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 153_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 153_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 153_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 153_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 155_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 155_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 155_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 155_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 155_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 156_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 156_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 156_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 156_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 156_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 157_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 157_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 157_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 157_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 157_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 158_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 158_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 158_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 158_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 158_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 159_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 159_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 159_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 159_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 159_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 160_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 160_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 160_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 160_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 160_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 161_convolutional_conv_bias
[05/21/2022-02:47:14] [V] [TRT] Importing initializer: 161_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 001_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 000_net
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional [Conv] inputs: [000_net -> (1, 3, 288, 288)[FLOAT]], [001_convolutional_conv_weights -> (32, 3, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 3, 288, 288)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 001_convolutional for ONNX node: 001_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 32
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 32, 288, 288)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 001_convolutional for ONNX tensor: 001_convolutional
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional [Conv] outputs: [001_convolutional -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 001_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_bn [BatchNormalization] inputs: [001_convolutional -> (1, 32, 288, 288)[FLOAT]], [001_convolutional_bn_scale -> (32)[FLOAT]], [001_convolutional_bn_bias -> (32)[FLOAT]], [001_convolutional_bn_mean -> (32)[FLOAT]], [001_convolutional_bn_var -> (32)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 001_convolutional_bn for ONNX node: 001_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 001_convolutional_bn for ONNX tensor: 001_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_bn [BatchNormalization] outputs: [001_convolutional_bn -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 001_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_softplus [Softplus] inputs: [001_convolutional_bn -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 001_convolutional_softplus for ONNX node: 001_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 001_convolutional_softplus for ONNX tensor: 001_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_softplus [Softplus] outputs: [001_convolutional_softplus -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 001_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_tanh [Tanh] inputs: [001_convolutional_softplus -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 001_convolutional_tanh for ONNX node: 001_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 001_convolutional_tanh for ONNX tensor: 001_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_tanh [Tanh] outputs: [001_convolutional_tanh -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 001_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_mish [Mul] inputs: [001_convolutional_bn -> (1, 32, 288, 288)[FLOAT]], [001_convolutional_tanh -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 001_convolutional_mish for ONNX node: 001_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 001_convolutional_mish for ONNX tensor: 001_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 001_convolutional_mish [Mul] outputs: [001_convolutional_mish -> (1, 32, 288, 288)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 002_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 001_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional [Conv] inputs: [001_convolutional_mish -> (1, 32, 288, 288)[FLOAT]], [002_convolutional_conv_weights -> (64, 32, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 32, 288, 288)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 002_convolutional for ONNX node: 002_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 002_convolutional for ONNX tensor: 002_convolutional
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional [Conv] outputs: [002_convolutional -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 002_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_bn [BatchNormalization] inputs: [002_convolutional -> (1, 64, 144, 144)[FLOAT]], [002_convolutional_bn_scale -> (64)[FLOAT]], [002_convolutional_bn_bias -> (64)[FLOAT]], [002_convolutional_bn_mean -> (64)[FLOAT]], [002_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 002_convolutional_bn for ONNX node: 002_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 002_convolutional_bn for ONNX tensor: 002_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_bn [BatchNormalization] outputs: [002_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 002_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_softplus [Softplus] inputs: [002_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 002_convolutional_softplus for ONNX node: 002_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 002_convolutional_softplus for ONNX tensor: 002_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_softplus [Softplus] outputs: [002_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 002_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_tanh [Tanh] inputs: [002_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 002_convolutional_tanh for ONNX node: 002_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 002_convolutional_tanh for ONNX tensor: 002_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_tanh [Tanh] outputs: [002_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 002_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_mish [Mul] inputs: [002_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], [002_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 002_convolutional_mish for ONNX node: 002_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 002_convolutional_mish for ONNX tensor: 002_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 002_convolutional_mish [Mul] outputs: [002_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 003_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional [Conv] inputs: [002_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], [003_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 003_convolutional for ONNX node: 003_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 003_convolutional for ONNX tensor: 003_convolutional
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional [Conv] outputs: [003_convolutional -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 003_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_bn [BatchNormalization] inputs: [003_convolutional -> (1, 64, 144, 144)[FLOAT]], [003_convolutional_bn_scale -> (64)[FLOAT]], [003_convolutional_bn_bias -> (64)[FLOAT]], [003_convolutional_bn_mean -> (64)[FLOAT]], [003_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 003_convolutional_bn for ONNX node: 003_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 003_convolutional_bn for ONNX tensor: 003_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_bn [BatchNormalization] outputs: [003_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 003_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_softplus [Softplus] inputs: [003_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 003_convolutional_softplus for ONNX node: 003_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 003_convolutional_softplus for ONNX tensor: 003_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_softplus [Softplus] outputs: [003_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 003_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_tanh [Tanh] inputs: [003_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 003_convolutional_tanh for ONNX node: 003_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 003_convolutional_tanh for ONNX tensor: 003_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_tanh [Tanh] outputs: [003_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 003_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_mish [Mul] inputs: [003_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], [003_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 003_convolutional_mish for ONNX node: 003_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 003_convolutional_mish for ONNX tensor: 003_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 003_convolutional_mish [Mul] outputs: [003_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 005_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 002_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional [Conv] inputs: [002_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], [005_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 005_convolutional for ONNX node: 005_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 005_convolutional for ONNX tensor: 005_convolutional
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional [Conv] outputs: [005_convolutional -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 005_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_bn [BatchNormalization] inputs: [005_convolutional -> (1, 64, 144, 144)[FLOAT]], [005_convolutional_bn_scale -> (64)[FLOAT]], [005_convolutional_bn_bias -> (64)[FLOAT]], [005_convolutional_bn_mean -> (64)[FLOAT]], [005_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 005_convolutional_bn for ONNX node: 005_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 005_convolutional_bn for ONNX tensor: 005_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_bn [BatchNormalization] outputs: [005_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 005_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_softplus [Softplus] inputs: [005_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 005_convolutional_softplus for ONNX node: 005_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 005_convolutional_softplus for ONNX tensor: 005_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_softplus [Softplus] outputs: [005_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 005_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_tanh [Tanh] inputs: [005_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 005_convolutional_tanh for ONNX node: 005_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 005_convolutional_tanh for ONNX tensor: 005_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_tanh [Tanh] outputs: [005_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 005_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_mish [Mul] inputs: [005_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], [005_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 005_convolutional_mish for ONNX node: 005_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 005_convolutional_mish for ONNX tensor: 005_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 005_convolutional_mish [Mul] outputs: [005_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 006_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional [Conv] inputs: [005_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], [006_convolutional_conv_weights -> (32, 64, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 006_convolutional for ONNX node: 006_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 32
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 32, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 006_convolutional for ONNX tensor: 006_convolutional
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional [Conv] outputs: [006_convolutional -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 006_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_bn [BatchNormalization] inputs: [006_convolutional -> (1, 32, 144, 144)[FLOAT]], [006_convolutional_bn_scale -> (32)[FLOAT]], [006_convolutional_bn_bias -> (32)[FLOAT]], [006_convolutional_bn_mean -> (32)[FLOAT]], [006_convolutional_bn_var -> (32)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 006_convolutional_bn for ONNX node: 006_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 006_convolutional_bn for ONNX tensor: 006_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_bn [BatchNormalization] outputs: [006_convolutional_bn -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 006_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_softplus [Softplus] inputs: [006_convolutional_bn -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 006_convolutional_softplus for ONNX node: 006_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 006_convolutional_softplus for ONNX tensor: 006_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_softplus [Softplus] outputs: [006_convolutional_softplus -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 006_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_tanh [Tanh] inputs: [006_convolutional_softplus -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 006_convolutional_tanh for ONNX node: 006_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 006_convolutional_tanh for ONNX tensor: 006_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_tanh [Tanh] outputs: [006_convolutional_tanh -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 006_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_mish [Mul] inputs: [006_convolutional_bn -> (1, 32, 144, 144)[FLOAT]], [006_convolutional_tanh -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 006_convolutional_mish for ONNX node: 006_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 006_convolutional_mish for ONNX tensor: 006_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 006_convolutional_mish [Mul] outputs: [006_convolutional_mish -> (1, 32, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 007_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 006_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional [Conv] inputs: [006_convolutional_mish -> (1, 32, 144, 144)[FLOAT]], [007_convolutional_conv_weights -> (64, 32, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 32, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 007_convolutional for ONNX node: 007_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 007_convolutional for ONNX tensor: 007_convolutional
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional [Conv] outputs: [007_convolutional -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 007_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_bn [BatchNormalization] inputs: [007_convolutional -> (1, 64, 144, 144)[FLOAT]], [007_convolutional_bn_scale -> (64)[FLOAT]], [007_convolutional_bn_bias -> (64)[FLOAT]], [007_convolutional_bn_mean -> (64)[FLOAT]], [007_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 007_convolutional_bn for ONNX node: 007_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 007_convolutional_bn for ONNX tensor: 007_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_bn [BatchNormalization] outputs: [007_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 007_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_softplus [Softplus] inputs: [007_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 007_convolutional_softplus for ONNX node: 007_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 007_convolutional_softplus for ONNX tensor: 007_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_softplus [Softplus] outputs: [007_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 007_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_tanh [Tanh] inputs: [007_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 007_convolutional_tanh for ONNX node: 007_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 007_convolutional_tanh for ONNX tensor: 007_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_tanh [Tanh] outputs: [007_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 007_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_mish [Mul] inputs: [007_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], [007_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 007_convolutional_mish for ONNX node: 007_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 007_convolutional_mish for ONNX tensor: 007_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 007_convolutional_mish [Mul] outputs: [007_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 008_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 007_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 005_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 008_shortcut [Add] inputs: [007_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], [005_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 008_shortcut for ONNX node: 008_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 008_shortcut for ONNX tensor: 008_shortcut
[05/21/2022-02:47:14] [V] [TRT] 008_shortcut [Add] outputs: [008_shortcut -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 009_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 008_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional [Conv] inputs: [008_shortcut -> (1, 64, 144, 144)[FLOAT]], [009_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 009_convolutional for ONNX node: 009_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 009_convolutional for ONNX tensor: 009_convolutional
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional [Conv] outputs: [009_convolutional -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 009_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_bn [BatchNormalization] inputs: [009_convolutional -> (1, 64, 144, 144)[FLOAT]], [009_convolutional_bn_scale -> (64)[FLOAT]], [009_convolutional_bn_bias -> (64)[FLOAT]], [009_convolutional_bn_mean -> (64)[FLOAT]], [009_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 009_convolutional_bn for ONNX node: 009_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 009_convolutional_bn for ONNX tensor: 009_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_bn [BatchNormalization] outputs: [009_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 009_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_softplus [Softplus] inputs: [009_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 009_convolutional_softplus for ONNX node: 009_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 009_convolutional_softplus for ONNX tensor: 009_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_softplus [Softplus] outputs: [009_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 009_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_tanh [Tanh] inputs: [009_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 009_convolutional_tanh for ONNX node: 009_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 009_convolutional_tanh for ONNX tensor: 009_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_tanh [Tanh] outputs: [009_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 009_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_mish [Mul] inputs: [009_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], [009_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 009_convolutional_mish for ONNX node: 009_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 009_convolutional_mish for ONNX tensor: 009_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 009_convolutional_mish [Mul] outputs: [009_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 010_route [Concat]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 009_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 003_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 010_route [Concat] inputs: [009_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], [003_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 010_route for ONNX node: 010_route
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 010_route for ONNX tensor: 010_route
[05/21/2022-02:47:14] [V] [TRT] 010_route [Concat] outputs: [010_route -> (1, 128, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 011_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 010_route
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional [Conv] inputs: [010_route -> (1, 128, 144, 144)[FLOAT]], [011_convolutional_conv_weights -> (64, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 011_convolutional for ONNX node: 011_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 011_convolutional for ONNX tensor: 011_convolutional
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional [Conv] outputs: [011_convolutional -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 011_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_bn [BatchNormalization] inputs: [011_convolutional -> (1, 64, 144, 144)[FLOAT]], [011_convolutional_bn_scale -> (64)[FLOAT]], [011_convolutional_bn_bias -> (64)[FLOAT]], [011_convolutional_bn_mean -> (64)[FLOAT]], [011_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 011_convolutional_bn for ONNX node: 011_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 011_convolutional_bn for ONNX tensor: 011_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_bn [BatchNormalization] outputs: [011_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 011_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_softplus [Softplus] inputs: [011_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 011_convolutional_softplus for ONNX node: 011_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 011_convolutional_softplus for ONNX tensor: 011_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_softplus [Softplus] outputs: [011_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 011_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_tanh [Tanh] inputs: [011_convolutional_softplus -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 011_convolutional_tanh for ONNX node: 011_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 011_convolutional_tanh for ONNX tensor: 011_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_tanh [Tanh] outputs: [011_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 011_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_mish [Mul] inputs: [011_convolutional_bn -> (1, 64, 144, 144)[FLOAT]], [011_convolutional_tanh -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 011_convolutional_mish for ONNX node: 011_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 011_convolutional_mish for ONNX tensor: 011_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 011_convolutional_mish [Mul] outputs: [011_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 012_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 011_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional [Conv] inputs: [011_convolutional_mish -> (1, 64, 144, 144)[FLOAT]], [012_convolutional_conv_weights -> (128, 64, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 144, 144)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 012_convolutional for ONNX node: 012_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 012_convolutional for ONNX tensor: 012_convolutional
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional [Conv] outputs: [012_convolutional -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 012_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_bn [BatchNormalization] inputs: [012_convolutional -> (1, 128, 72, 72)[FLOAT]], [012_convolutional_bn_scale -> (128)[FLOAT]], [012_convolutional_bn_bias -> (128)[FLOAT]], [012_convolutional_bn_mean -> (128)[FLOAT]], [012_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 012_convolutional_bn for ONNX node: 012_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 012_convolutional_bn for ONNX tensor: 012_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_bn [BatchNormalization] outputs: [012_convolutional_bn -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 012_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_softplus [Softplus] inputs: [012_convolutional_bn -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 012_convolutional_softplus for ONNX node: 012_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 012_convolutional_softplus for ONNX tensor: 012_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_softplus [Softplus] outputs: [012_convolutional_softplus -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 012_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_tanh [Tanh] inputs: [012_convolutional_softplus -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 012_convolutional_tanh for ONNX node: 012_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 012_convolutional_tanh for ONNX tensor: 012_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_tanh [Tanh] outputs: [012_convolutional_tanh -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 012_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_mish [Mul] inputs: [012_convolutional_bn -> (1, 128, 72, 72)[FLOAT]], [012_convolutional_tanh -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 012_convolutional_mish for ONNX node: 012_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 012_convolutional_mish for ONNX tensor: 012_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 012_convolutional_mish [Mul] outputs: [012_convolutional_mish -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 013_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional [Conv] inputs: [012_convolutional_mish -> (1, 128, 72, 72)[FLOAT]], [013_convolutional_conv_weights -> (64, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 013_convolutional for ONNX node: 013_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 013_convolutional for ONNX tensor: 013_convolutional
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional [Conv] outputs: [013_convolutional -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 013_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_bn [BatchNormalization] inputs: [013_convolutional -> (1, 64, 72, 72)[FLOAT]], [013_convolutional_bn_scale -> (64)[FLOAT]], [013_convolutional_bn_bias -> (64)[FLOAT]], [013_convolutional_bn_mean -> (64)[FLOAT]], [013_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 013_convolutional_bn for ONNX node: 013_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 013_convolutional_bn for ONNX tensor: 013_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_bn [BatchNormalization] outputs: [013_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 013_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_softplus [Softplus] inputs: [013_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 013_convolutional_softplus for ONNX node: 013_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 013_convolutional_softplus for ONNX tensor: 013_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_softplus [Softplus] outputs: [013_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 013_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_tanh [Tanh] inputs: [013_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 013_convolutional_tanh for ONNX node: 013_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 013_convolutional_tanh for ONNX tensor: 013_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_tanh [Tanh] outputs: [013_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 013_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_mish [Mul] inputs: [013_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], [013_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 013_convolutional_mish for ONNX node: 013_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 013_convolutional_mish for ONNX tensor: 013_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 013_convolutional_mish [Mul] outputs: [013_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 015_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 012_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional [Conv] inputs: [012_convolutional_mish -> (1, 128, 72, 72)[FLOAT]], [015_convolutional_conv_weights -> (64, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 015_convolutional for ONNX node: 015_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 015_convolutional for ONNX tensor: 015_convolutional
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional [Conv] outputs: [015_convolutional -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 015_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_bn [BatchNormalization] inputs: [015_convolutional -> (1, 64, 72, 72)[FLOAT]], [015_convolutional_bn_scale -> (64)[FLOAT]], [015_convolutional_bn_bias -> (64)[FLOAT]], [015_convolutional_bn_mean -> (64)[FLOAT]], [015_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 015_convolutional_bn for ONNX node: 015_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 015_convolutional_bn for ONNX tensor: 015_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_bn [BatchNormalization] outputs: [015_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 015_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_softplus [Softplus] inputs: [015_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 015_convolutional_softplus for ONNX node: 015_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 015_convolutional_softplus for ONNX tensor: 015_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_softplus [Softplus] outputs: [015_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 015_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_tanh [Tanh] inputs: [015_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 015_convolutional_tanh for ONNX node: 015_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 015_convolutional_tanh for ONNX tensor: 015_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_tanh [Tanh] outputs: [015_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 015_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_mish [Mul] inputs: [015_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], [015_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 015_convolutional_mish for ONNX node: 015_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 015_convolutional_mish for ONNX tensor: 015_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 015_convolutional_mish [Mul] outputs: [015_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 016_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional [Conv] inputs: [015_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], [016_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 016_convolutional for ONNX node: 016_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 016_convolutional for ONNX tensor: 016_convolutional
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional [Conv] outputs: [016_convolutional -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 016_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_bn [BatchNormalization] inputs: [016_convolutional -> (1, 64, 72, 72)[FLOAT]], [016_convolutional_bn_scale -> (64)[FLOAT]], [016_convolutional_bn_bias -> (64)[FLOAT]], [016_convolutional_bn_mean -> (64)[FLOAT]], [016_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 016_convolutional_bn for ONNX node: 016_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 016_convolutional_bn for ONNX tensor: 016_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_bn [BatchNormalization] outputs: [016_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 016_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_softplus [Softplus] inputs: [016_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 016_convolutional_softplus for ONNX node: 016_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 016_convolutional_softplus for ONNX tensor: 016_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_softplus [Softplus] outputs: [016_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 016_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_tanh [Tanh] inputs: [016_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 016_convolutional_tanh for ONNX node: 016_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 016_convolutional_tanh for ONNX tensor: 016_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_tanh [Tanh] outputs: [016_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 016_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_mish [Mul] inputs: [016_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], [016_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 016_convolutional_mish for ONNX node: 016_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 016_convolutional_mish for ONNX tensor: 016_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 016_convolutional_mish [Mul] outputs: [016_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 017_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 016_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional [Conv] inputs: [016_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], [017_convolutional_conv_weights -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 017_convolutional for ONNX node: 017_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 017_convolutional for ONNX tensor: 017_convolutional
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional [Conv] outputs: [017_convolutional -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 017_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_bn [BatchNormalization] inputs: [017_convolutional -> (1, 64, 72, 72)[FLOAT]], [017_convolutional_bn_scale -> (64)[FLOAT]], [017_convolutional_bn_bias -> (64)[FLOAT]], [017_convolutional_bn_mean -> (64)[FLOAT]], [017_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 017_convolutional_bn for ONNX node: 017_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 017_convolutional_bn for ONNX tensor: 017_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_bn [BatchNormalization] outputs: [017_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 017_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_softplus [Softplus] inputs: [017_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 017_convolutional_softplus for ONNX node: 017_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 017_convolutional_softplus for ONNX tensor: 017_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_softplus [Softplus] outputs: [017_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 017_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_tanh [Tanh] inputs: [017_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 017_convolutional_tanh for ONNX node: 017_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 017_convolutional_tanh for ONNX tensor: 017_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_tanh [Tanh] outputs: [017_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 017_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_mish [Mul] inputs: [017_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], [017_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 017_convolutional_mish for ONNX node: 017_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 017_convolutional_mish for ONNX tensor: 017_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 017_convolutional_mish [Mul] outputs: [017_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 018_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 017_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 015_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 018_shortcut [Add] inputs: [017_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], [015_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 018_shortcut for ONNX node: 018_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 018_shortcut for ONNX tensor: 018_shortcut
[05/21/2022-02:47:14] [V] [TRT] 018_shortcut [Add] outputs: [018_shortcut -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 019_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 018_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional [Conv] inputs: [018_shortcut -> (1, 64, 72, 72)[FLOAT]], [019_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 019_convolutional for ONNX node: 019_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 019_convolutional for ONNX tensor: 019_convolutional
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional [Conv] outputs: [019_convolutional -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 019_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_bn [BatchNormalization] inputs: [019_convolutional -> (1, 64, 72, 72)[FLOAT]], [019_convolutional_bn_scale -> (64)[FLOAT]], [019_convolutional_bn_bias -> (64)[FLOAT]], [019_convolutional_bn_mean -> (64)[FLOAT]], [019_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 019_convolutional_bn for ONNX node: 019_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 019_convolutional_bn for ONNX tensor: 019_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_bn [BatchNormalization] outputs: [019_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 019_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_softplus [Softplus] inputs: [019_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 019_convolutional_softplus for ONNX node: 019_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 019_convolutional_softplus for ONNX tensor: 019_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_softplus [Softplus] outputs: [019_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 019_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_tanh [Tanh] inputs: [019_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 019_convolutional_tanh for ONNX node: 019_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 019_convolutional_tanh for ONNX tensor: 019_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_tanh [Tanh] outputs: [019_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 019_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_mish [Mul] inputs: [019_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], [019_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 019_convolutional_mish for ONNX node: 019_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 019_convolutional_mish for ONNX tensor: 019_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 019_convolutional_mish [Mul] outputs: [019_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 020_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 019_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional [Conv] inputs: [019_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], [020_convolutional_conv_weights -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 020_convolutional for ONNX node: 020_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 020_convolutional for ONNX tensor: 020_convolutional
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional [Conv] outputs: [020_convolutional -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 020_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_bn [BatchNormalization] inputs: [020_convolutional -> (1, 64, 72, 72)[FLOAT]], [020_convolutional_bn_scale -> (64)[FLOAT]], [020_convolutional_bn_bias -> (64)[FLOAT]], [020_convolutional_bn_mean -> (64)[FLOAT]], [020_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 020_convolutional_bn for ONNX node: 020_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 020_convolutional_bn for ONNX tensor: 020_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_bn [BatchNormalization] outputs: [020_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 020_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_softplus [Softplus] inputs: [020_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 020_convolutional_softplus for ONNX node: 020_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 020_convolutional_softplus for ONNX tensor: 020_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_softplus [Softplus] outputs: [020_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 020_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_tanh [Tanh] inputs: [020_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 020_convolutional_tanh for ONNX node: 020_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 020_convolutional_tanh for ONNX tensor: 020_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_tanh [Tanh] outputs: [020_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 020_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_mish [Mul] inputs: [020_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], [020_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 020_convolutional_mish for ONNX node: 020_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 020_convolutional_mish for ONNX tensor: 020_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 020_convolutional_mish [Mul] outputs: [020_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 021_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 020_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 018_shortcut
[05/21/2022-02:47:14] [V] [TRT] 021_shortcut [Add] inputs: [020_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], [018_shortcut -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 021_shortcut for ONNX node: 021_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 021_shortcut for ONNX tensor: 021_shortcut
[05/21/2022-02:47:14] [V] [TRT] 021_shortcut [Add] outputs: [021_shortcut -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 022_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 021_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional [Conv] inputs: [021_shortcut -> (1, 64, 72, 72)[FLOAT]], [022_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 022_convolutional for ONNX node: 022_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 64, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 022_convolutional for ONNX tensor: 022_convolutional
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional [Conv] outputs: [022_convolutional -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 022_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_bn [BatchNormalization] inputs: [022_convolutional -> (1, 64, 72, 72)[FLOAT]], [022_convolutional_bn_scale -> (64)[FLOAT]], [022_convolutional_bn_bias -> (64)[FLOAT]], [022_convolutional_bn_mean -> (64)[FLOAT]], [022_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 022_convolutional_bn for ONNX node: 022_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 022_convolutional_bn for ONNX tensor: 022_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_bn [BatchNormalization] outputs: [022_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 022_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_softplus [Softplus] inputs: [022_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 022_convolutional_softplus for ONNX node: 022_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 022_convolutional_softplus for ONNX tensor: 022_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_softplus [Softplus] outputs: [022_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 022_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_tanh [Tanh] inputs: [022_convolutional_softplus -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 022_convolutional_tanh for ONNX node: 022_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 022_convolutional_tanh for ONNX tensor: 022_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_tanh [Tanh] outputs: [022_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 022_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_mish [Mul] inputs: [022_convolutional_bn -> (1, 64, 72, 72)[FLOAT]], [022_convolutional_tanh -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 022_convolutional_mish for ONNX node: 022_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 022_convolutional_mish for ONNX tensor: 022_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 022_convolutional_mish [Mul] outputs: [022_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 023_route [Concat]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 022_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 013_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 023_route [Concat] inputs: [022_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], [013_convolutional_mish -> (1, 64, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 023_route for ONNX node: 023_route
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 023_route for ONNX tensor: 023_route
[05/21/2022-02:47:14] [V] [TRT] 023_route [Concat] outputs: [023_route -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 024_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 023_route
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional [Conv] inputs: [023_route -> (1, 128, 72, 72)[FLOAT]], [024_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 024_convolutional for ONNX node: 024_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 024_convolutional for ONNX tensor: 024_convolutional
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional [Conv] outputs: [024_convolutional -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 024_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_bn [BatchNormalization] inputs: [024_convolutional -> (1, 128, 72, 72)[FLOAT]], [024_convolutional_bn_scale -> (128)[FLOAT]], [024_convolutional_bn_bias -> (128)[FLOAT]], [024_convolutional_bn_mean -> (128)[FLOAT]], [024_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 024_convolutional_bn for ONNX node: 024_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 024_convolutional_bn for ONNX tensor: 024_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_bn [BatchNormalization] outputs: [024_convolutional_bn -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 024_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_softplus [Softplus] inputs: [024_convolutional_bn -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 024_convolutional_softplus for ONNX node: 024_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 024_convolutional_softplus for ONNX tensor: 024_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_softplus [Softplus] outputs: [024_convolutional_softplus -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 024_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_tanh [Tanh] inputs: [024_convolutional_softplus -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 024_convolutional_tanh for ONNX node: 024_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 024_convolutional_tanh for ONNX tensor: 024_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_tanh [Tanh] outputs: [024_convolutional_tanh -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 024_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_mish [Mul] inputs: [024_convolutional_bn -> (1, 128, 72, 72)[FLOAT]], [024_convolutional_tanh -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 024_convolutional_mish for ONNX node: 024_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 024_convolutional_mish for ONNX tensor: 024_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 024_convolutional_mish [Mul] outputs: [024_convolutional_mish -> (1, 128, 72, 72)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 025_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 024_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional [Conv] inputs: [024_convolutional_mish -> (1, 128, 72, 72)[FLOAT]], [025_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 72, 72)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 025_convolutional for ONNX node: 025_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 025_convolutional for ONNX tensor: 025_convolutional
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional [Conv] outputs: [025_convolutional -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 025_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_bn [BatchNormalization] inputs: [025_convolutional -> (1, 256, 36, 36)[FLOAT]], [025_convolutional_bn_scale -> (256)[FLOAT]], [025_convolutional_bn_bias -> (256)[FLOAT]], [025_convolutional_bn_mean -> (256)[FLOAT]], [025_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 025_convolutional_bn for ONNX node: 025_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 025_convolutional_bn for ONNX tensor: 025_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_bn [BatchNormalization] outputs: [025_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 025_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_softplus [Softplus] inputs: [025_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 025_convolutional_softplus for ONNX node: 025_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 025_convolutional_softplus for ONNX tensor: 025_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_softplus [Softplus] outputs: [025_convolutional_softplus -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 025_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_tanh [Tanh] inputs: [025_convolutional_softplus -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 025_convolutional_tanh for ONNX node: 025_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 025_convolutional_tanh for ONNX tensor: 025_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_tanh [Tanh] outputs: [025_convolutional_tanh -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 025_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_mish [Mul] inputs: [025_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], [025_convolutional_tanh -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 025_convolutional_mish for ONNX node: 025_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 025_convolutional_mish for ONNX tensor: 025_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 025_convolutional_mish [Mul] outputs: [025_convolutional_mish -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 026_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional [Conv] inputs: [025_convolutional_mish -> (1, 256, 36, 36)[FLOAT]], [026_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 026_convolutional for ONNX node: 026_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 026_convolutional for ONNX tensor: 026_convolutional
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional [Conv] outputs: [026_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 026_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_bn [BatchNormalization] inputs: [026_convolutional -> (1, 128, 36, 36)[FLOAT]], [026_convolutional_bn_scale -> (128)[FLOAT]], [026_convolutional_bn_bias -> (128)[FLOAT]], [026_convolutional_bn_mean -> (128)[FLOAT]], [026_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 026_convolutional_bn for ONNX node: 026_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 026_convolutional_bn for ONNX tensor: 026_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_bn [BatchNormalization] outputs: [026_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 026_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_softplus [Softplus] inputs: [026_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 026_convolutional_softplus for ONNX node: 026_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 026_convolutional_softplus for ONNX tensor: 026_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_softplus [Softplus] outputs: [026_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 026_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_tanh [Tanh] inputs: [026_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 026_convolutional_tanh for ONNX node: 026_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 026_convolutional_tanh for ONNX tensor: 026_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_tanh [Tanh] outputs: [026_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 026_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_mish [Mul] inputs: [026_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [026_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 026_convolutional_mish for ONNX node: 026_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 026_convolutional_mish for ONNX tensor: 026_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 026_convolutional_mish [Mul] outputs: [026_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 028_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 025_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional [Conv] inputs: [025_convolutional_mish -> (1, 256, 36, 36)[FLOAT]], [028_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 028_convolutional for ONNX node: 028_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 028_convolutional for ONNX tensor: 028_convolutional
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional [Conv] outputs: [028_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 028_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_bn [BatchNormalization] inputs: [028_convolutional -> (1, 128, 36, 36)[FLOAT]], [028_convolutional_bn_scale -> (128)[FLOAT]], [028_convolutional_bn_bias -> (128)[FLOAT]], [028_convolutional_bn_mean -> (128)[FLOAT]], [028_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 028_convolutional_bn for ONNX node: 028_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 028_convolutional_bn for ONNX tensor: 028_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_bn [BatchNormalization] outputs: [028_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 028_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_softplus [Softplus] inputs: [028_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 028_convolutional_softplus for ONNX node: 028_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 028_convolutional_softplus for ONNX tensor: 028_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_softplus [Softplus] outputs: [028_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 028_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_tanh [Tanh] inputs: [028_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 028_convolutional_tanh for ONNX node: 028_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 028_convolutional_tanh for ONNX tensor: 028_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_tanh [Tanh] outputs: [028_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 028_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_mish [Mul] inputs: [028_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [028_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 028_convolutional_mish for ONNX node: 028_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 028_convolutional_mish for ONNX tensor: 028_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 028_convolutional_mish [Mul] outputs: [028_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 029_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional [Conv] inputs: [028_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [029_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 029_convolutional for ONNX node: 029_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 029_convolutional for ONNX tensor: 029_convolutional
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional [Conv] outputs: [029_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 029_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_bn [BatchNormalization] inputs: [029_convolutional -> (1, 128, 36, 36)[FLOAT]], [029_convolutional_bn_scale -> (128)[FLOAT]], [029_convolutional_bn_bias -> (128)[FLOAT]], [029_convolutional_bn_mean -> (128)[FLOAT]], [029_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 029_convolutional_bn for ONNX node: 029_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 029_convolutional_bn for ONNX tensor: 029_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_bn [BatchNormalization] outputs: [029_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 029_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_softplus [Softplus] inputs: [029_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 029_convolutional_softplus for ONNX node: 029_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 029_convolutional_softplus for ONNX tensor: 029_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_softplus [Softplus] outputs: [029_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 029_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_tanh [Tanh] inputs: [029_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 029_convolutional_tanh for ONNX node: 029_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 029_convolutional_tanh for ONNX tensor: 029_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_tanh [Tanh] outputs: [029_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 029_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_mish [Mul] inputs: [029_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [029_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 029_convolutional_mish for ONNX node: 029_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 029_convolutional_mish for ONNX tensor: 029_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 029_convolutional_mish [Mul] outputs: [029_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 030_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 029_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional [Conv] inputs: [029_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [030_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 030_convolutional for ONNX node: 030_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 030_convolutional for ONNX tensor: 030_convolutional
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional [Conv] outputs: [030_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 030_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_bn [BatchNormalization] inputs: [030_convolutional -> (1, 128, 36, 36)[FLOAT]], [030_convolutional_bn_scale -> (128)[FLOAT]], [030_convolutional_bn_bias -> (128)[FLOAT]], [030_convolutional_bn_mean -> (128)[FLOAT]], [030_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 030_convolutional_bn for ONNX node: 030_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 030_convolutional_bn for ONNX tensor: 030_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_bn [BatchNormalization] outputs: [030_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 030_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_softplus [Softplus] inputs: [030_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 030_convolutional_softplus for ONNX node: 030_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 030_convolutional_softplus for ONNX tensor: 030_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_softplus [Softplus] outputs: [030_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 030_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_tanh [Tanh] inputs: [030_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 030_convolutional_tanh for ONNX node: 030_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 030_convolutional_tanh for ONNX tensor: 030_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_tanh [Tanh] outputs: [030_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 030_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_mish [Mul] inputs: [030_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [030_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 030_convolutional_mish for ONNX node: 030_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 030_convolutional_mish for ONNX tensor: 030_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 030_convolutional_mish [Mul] outputs: [030_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 031_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 030_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 028_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 031_shortcut [Add] inputs: [030_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [028_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 031_shortcut for ONNX node: 031_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 031_shortcut for ONNX tensor: 031_shortcut
[05/21/2022-02:47:14] [V] [TRT] 031_shortcut [Add] outputs: [031_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 032_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 031_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional [Conv] inputs: [031_shortcut -> (1, 128, 36, 36)[FLOAT]], [032_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 032_convolutional for ONNX node: 032_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 032_convolutional for ONNX tensor: 032_convolutional
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional [Conv] outputs: [032_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 032_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_bn [BatchNormalization] inputs: [032_convolutional -> (1, 128, 36, 36)[FLOAT]], [032_convolutional_bn_scale -> (128)[FLOAT]], [032_convolutional_bn_bias -> (128)[FLOAT]], [032_convolutional_bn_mean -> (128)[FLOAT]], [032_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 032_convolutional_bn for ONNX node: 032_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 032_convolutional_bn for ONNX tensor: 032_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_bn [BatchNormalization] outputs: [032_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 032_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_softplus [Softplus] inputs: [032_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 032_convolutional_softplus for ONNX node: 032_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 032_convolutional_softplus for ONNX tensor: 032_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_softplus [Softplus] outputs: [032_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 032_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_tanh [Tanh] inputs: [032_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 032_convolutional_tanh for ONNX node: 032_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 032_convolutional_tanh for ONNX tensor: 032_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_tanh [Tanh] outputs: [032_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 032_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_mish [Mul] inputs: [032_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [032_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 032_convolutional_mish for ONNX node: 032_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 032_convolutional_mish for ONNX tensor: 032_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 032_convolutional_mish [Mul] outputs: [032_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 033_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 032_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional [Conv] inputs: [032_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [033_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 033_convolutional for ONNX node: 033_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 033_convolutional for ONNX tensor: 033_convolutional
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional [Conv] outputs: [033_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 033_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_bn [BatchNormalization] inputs: [033_convolutional -> (1, 128, 36, 36)[FLOAT]], [033_convolutional_bn_scale -> (128)[FLOAT]], [033_convolutional_bn_bias -> (128)[FLOAT]], [033_convolutional_bn_mean -> (128)[FLOAT]], [033_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 033_convolutional_bn for ONNX node: 033_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 033_convolutional_bn for ONNX tensor: 033_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_bn [BatchNormalization] outputs: [033_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 033_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_softplus [Softplus] inputs: [033_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 033_convolutional_softplus for ONNX node: 033_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 033_convolutional_softplus for ONNX tensor: 033_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_softplus [Softplus] outputs: [033_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 033_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_tanh [Tanh] inputs: [033_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 033_convolutional_tanh for ONNX node: 033_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 033_convolutional_tanh for ONNX tensor: 033_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_tanh [Tanh] outputs: [033_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 033_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_mish [Mul] inputs: [033_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [033_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 033_convolutional_mish for ONNX node: 033_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 033_convolutional_mish for ONNX tensor: 033_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 033_convolutional_mish [Mul] outputs: [033_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 034_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 033_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 031_shortcut
[05/21/2022-02:47:14] [V] [TRT] 034_shortcut [Add] inputs: [033_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [031_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 034_shortcut for ONNX node: 034_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 034_shortcut for ONNX tensor: 034_shortcut
[05/21/2022-02:47:14] [V] [TRT] 034_shortcut [Add] outputs: [034_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 035_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 034_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional [Conv] inputs: [034_shortcut -> (1, 128, 36, 36)[FLOAT]], [035_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 035_convolutional for ONNX node: 035_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 035_convolutional for ONNX tensor: 035_convolutional
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional [Conv] outputs: [035_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 035_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_bn [BatchNormalization] inputs: [035_convolutional -> (1, 128, 36, 36)[FLOAT]], [035_convolutional_bn_scale -> (128)[FLOAT]], [035_convolutional_bn_bias -> (128)[FLOAT]], [035_convolutional_bn_mean -> (128)[FLOAT]], [035_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 035_convolutional_bn for ONNX node: 035_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 035_convolutional_bn for ONNX tensor: 035_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_bn [BatchNormalization] outputs: [035_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 035_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_softplus [Softplus] inputs: [035_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 035_convolutional_softplus for ONNX node: 035_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 035_convolutional_softplus for ONNX tensor: 035_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_softplus [Softplus] outputs: [035_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 035_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_tanh [Tanh] inputs: [035_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 035_convolutional_tanh for ONNX node: 035_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 035_convolutional_tanh for ONNX tensor: 035_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_tanh [Tanh] outputs: [035_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 035_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_mish [Mul] inputs: [035_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [035_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 035_convolutional_mish for ONNX node: 035_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 035_convolutional_mish for ONNX tensor: 035_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 035_convolutional_mish [Mul] outputs: [035_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 036_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 035_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional [Conv] inputs: [035_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [036_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 036_convolutional for ONNX node: 036_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 036_convolutional for ONNX tensor: 036_convolutional
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional [Conv] outputs: [036_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 036_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_bn [BatchNormalization] inputs: [036_convolutional -> (1, 128, 36, 36)[FLOAT]], [036_convolutional_bn_scale -> (128)[FLOAT]], [036_convolutional_bn_bias -> (128)[FLOAT]], [036_convolutional_bn_mean -> (128)[FLOAT]], [036_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 036_convolutional_bn for ONNX node: 036_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 036_convolutional_bn for ONNX tensor: 036_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_bn [BatchNormalization] outputs: [036_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 036_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_softplus [Softplus] inputs: [036_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 036_convolutional_softplus for ONNX node: 036_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 036_convolutional_softplus for ONNX tensor: 036_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_softplus [Softplus] outputs: [036_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 036_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_tanh [Tanh] inputs: [036_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 036_convolutional_tanh for ONNX node: 036_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 036_convolutional_tanh for ONNX tensor: 036_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_tanh [Tanh] outputs: [036_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 036_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_mish [Mul] inputs: [036_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [036_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 036_convolutional_mish for ONNX node: 036_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 036_convolutional_mish for ONNX tensor: 036_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 036_convolutional_mish [Mul] outputs: [036_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 037_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 036_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 034_shortcut
[05/21/2022-02:47:14] [V] [TRT] 037_shortcut [Add] inputs: [036_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [034_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 037_shortcut for ONNX node: 037_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 037_shortcut for ONNX tensor: 037_shortcut
[05/21/2022-02:47:14] [V] [TRT] 037_shortcut [Add] outputs: [037_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 038_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 037_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional [Conv] inputs: [037_shortcut -> (1, 128, 36, 36)[FLOAT]], [038_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 038_convolutional for ONNX node: 038_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 038_convolutional for ONNX tensor: 038_convolutional
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional [Conv] outputs: [038_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 038_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_bn [BatchNormalization] inputs: [038_convolutional -> (1, 128, 36, 36)[FLOAT]], [038_convolutional_bn_scale -> (128)[FLOAT]], [038_convolutional_bn_bias -> (128)[FLOAT]], [038_convolutional_bn_mean -> (128)[FLOAT]], [038_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 038_convolutional_bn for ONNX node: 038_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 038_convolutional_bn for ONNX tensor: 038_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_bn [BatchNormalization] outputs: [038_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 038_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_softplus [Softplus] inputs: [038_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 038_convolutional_softplus for ONNX node: 038_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 038_convolutional_softplus for ONNX tensor: 038_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_softplus [Softplus] outputs: [038_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 038_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_tanh [Tanh] inputs: [038_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 038_convolutional_tanh for ONNX node: 038_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 038_convolutional_tanh for ONNX tensor: 038_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_tanh [Tanh] outputs: [038_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 038_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_mish [Mul] inputs: [038_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [038_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 038_convolutional_mish for ONNX node: 038_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 038_convolutional_mish for ONNX tensor: 038_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 038_convolutional_mish [Mul] outputs: [038_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 039_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 038_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional [Conv] inputs: [038_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [039_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 039_convolutional for ONNX node: 039_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 039_convolutional for ONNX tensor: 039_convolutional
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional [Conv] outputs: [039_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 039_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_bn [BatchNormalization] inputs: [039_convolutional -> (1, 128, 36, 36)[FLOAT]], [039_convolutional_bn_scale -> (128)[FLOAT]], [039_convolutional_bn_bias -> (128)[FLOAT]], [039_convolutional_bn_mean -> (128)[FLOAT]], [039_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 039_convolutional_bn for ONNX node: 039_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 039_convolutional_bn for ONNX tensor: 039_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_bn [BatchNormalization] outputs: [039_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 039_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_softplus [Softplus] inputs: [039_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 039_convolutional_softplus for ONNX node: 039_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 039_convolutional_softplus for ONNX tensor: 039_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_softplus [Softplus] outputs: [039_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 039_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_tanh [Tanh] inputs: [039_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 039_convolutional_tanh for ONNX node: 039_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 039_convolutional_tanh for ONNX tensor: 039_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_tanh [Tanh] outputs: [039_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 039_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_mish [Mul] inputs: [039_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [039_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 039_convolutional_mish for ONNX node: 039_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 039_convolutional_mish for ONNX tensor: 039_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 039_convolutional_mish [Mul] outputs: [039_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 040_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 039_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 037_shortcut
[05/21/2022-02:47:14] [V] [TRT] 040_shortcut [Add] inputs: [039_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [037_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 040_shortcut for ONNX node: 040_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 040_shortcut for ONNX tensor: 040_shortcut
[05/21/2022-02:47:14] [V] [TRT] 040_shortcut [Add] outputs: [040_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 041_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 040_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional [Conv] inputs: [040_shortcut -> (1, 128, 36, 36)[FLOAT]], [041_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 041_convolutional for ONNX node: 041_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 041_convolutional for ONNX tensor: 041_convolutional
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional [Conv] outputs: [041_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 041_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_bn [BatchNormalization] inputs: [041_convolutional -> (1, 128, 36, 36)[FLOAT]], [041_convolutional_bn_scale -> (128)[FLOAT]], [041_convolutional_bn_bias -> (128)[FLOAT]], [041_convolutional_bn_mean -> (128)[FLOAT]], [041_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 041_convolutional_bn for ONNX node: 041_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 041_convolutional_bn for ONNX tensor: 041_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_bn [BatchNormalization] outputs: [041_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 041_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_softplus [Softplus] inputs: [041_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 041_convolutional_softplus for ONNX node: 041_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 041_convolutional_softplus for ONNX tensor: 041_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_softplus [Softplus] outputs: [041_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 041_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_tanh [Tanh] inputs: [041_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 041_convolutional_tanh for ONNX node: 041_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 041_convolutional_tanh for ONNX tensor: 041_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_tanh [Tanh] outputs: [041_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 041_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_mish [Mul] inputs: [041_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [041_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 041_convolutional_mish for ONNX node: 041_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 041_convolutional_mish for ONNX tensor: 041_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 041_convolutional_mish [Mul] outputs: [041_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 042_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 041_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional [Conv] inputs: [041_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [042_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 042_convolutional for ONNX node: 042_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 042_convolutional for ONNX tensor: 042_convolutional
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional [Conv] outputs: [042_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 042_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_bn [BatchNormalization] inputs: [042_convolutional -> (1, 128, 36, 36)[FLOAT]], [042_convolutional_bn_scale -> (128)[FLOAT]], [042_convolutional_bn_bias -> (128)[FLOAT]], [042_convolutional_bn_mean -> (128)[FLOAT]], [042_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 042_convolutional_bn for ONNX node: 042_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 042_convolutional_bn for ONNX tensor: 042_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_bn [BatchNormalization] outputs: [042_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 042_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_softplus [Softplus] inputs: [042_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 042_convolutional_softplus for ONNX node: 042_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 042_convolutional_softplus for ONNX tensor: 042_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_softplus [Softplus] outputs: [042_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 042_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_tanh [Tanh] inputs: [042_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 042_convolutional_tanh for ONNX node: 042_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 042_convolutional_tanh for ONNX tensor: 042_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_tanh [Tanh] outputs: [042_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 042_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_mish [Mul] inputs: [042_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [042_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 042_convolutional_mish for ONNX node: 042_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 042_convolutional_mish for ONNX tensor: 042_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 042_convolutional_mish [Mul] outputs: [042_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 043_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 042_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 040_shortcut
[05/21/2022-02:47:14] [V] [TRT] 043_shortcut [Add] inputs: [042_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [040_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 043_shortcut for ONNX node: 043_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 043_shortcut for ONNX tensor: 043_shortcut
[05/21/2022-02:47:14] [V] [TRT] 043_shortcut [Add] outputs: [043_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 044_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 043_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional [Conv] inputs: [043_shortcut -> (1, 128, 36, 36)[FLOAT]], [044_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 044_convolutional for ONNX node: 044_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 044_convolutional for ONNX tensor: 044_convolutional
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional [Conv] outputs: [044_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 044_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_bn [BatchNormalization] inputs: [044_convolutional -> (1, 128, 36, 36)[FLOAT]], [044_convolutional_bn_scale -> (128)[FLOAT]], [044_convolutional_bn_bias -> (128)[FLOAT]], [044_convolutional_bn_mean -> (128)[FLOAT]], [044_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 044_convolutional_bn for ONNX node: 044_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 044_convolutional_bn for ONNX tensor: 044_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_bn [BatchNormalization] outputs: [044_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 044_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_softplus [Softplus] inputs: [044_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 044_convolutional_softplus for ONNX node: 044_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 044_convolutional_softplus for ONNX tensor: 044_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_softplus [Softplus] outputs: [044_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 044_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_tanh [Tanh] inputs: [044_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 044_convolutional_tanh for ONNX node: 044_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 044_convolutional_tanh for ONNX tensor: 044_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_tanh [Tanh] outputs: [044_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 044_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_mish [Mul] inputs: [044_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [044_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 044_convolutional_mish for ONNX node: 044_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 044_convolutional_mish for ONNX tensor: 044_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 044_convolutional_mish [Mul] outputs: [044_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 045_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 044_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional [Conv] inputs: [044_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [045_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 045_convolutional for ONNX node: 045_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 045_convolutional for ONNX tensor: 045_convolutional
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional [Conv] outputs: [045_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 045_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_bn [BatchNormalization] inputs: [045_convolutional -> (1, 128, 36, 36)[FLOAT]], [045_convolutional_bn_scale -> (128)[FLOAT]], [045_convolutional_bn_bias -> (128)[FLOAT]], [045_convolutional_bn_mean -> (128)[FLOAT]], [045_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 045_convolutional_bn for ONNX node: 045_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 045_convolutional_bn for ONNX tensor: 045_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_bn [BatchNormalization] outputs: [045_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 045_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_softplus [Softplus] inputs: [045_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 045_convolutional_softplus for ONNX node: 045_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 045_convolutional_softplus for ONNX tensor: 045_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_softplus [Softplus] outputs: [045_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 045_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_tanh [Tanh] inputs: [045_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 045_convolutional_tanh for ONNX node: 045_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 045_convolutional_tanh for ONNX tensor: 045_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_tanh [Tanh] outputs: [045_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 045_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_mish [Mul] inputs: [045_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [045_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 045_convolutional_mish for ONNX node: 045_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 045_convolutional_mish for ONNX tensor: 045_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 045_convolutional_mish [Mul] outputs: [045_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 046_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 045_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 043_shortcut
[05/21/2022-02:47:14] [V] [TRT] 046_shortcut [Add] inputs: [045_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [043_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 046_shortcut for ONNX node: 046_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 046_shortcut for ONNX tensor: 046_shortcut
[05/21/2022-02:47:14] [V] [TRT] 046_shortcut [Add] outputs: [046_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 047_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 046_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional [Conv] inputs: [046_shortcut -> (1, 128, 36, 36)[FLOAT]], [047_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 047_convolutional for ONNX node: 047_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 047_convolutional for ONNX tensor: 047_convolutional
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional [Conv] outputs: [047_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 047_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_bn [BatchNormalization] inputs: [047_convolutional -> (1, 128, 36, 36)[FLOAT]], [047_convolutional_bn_scale -> (128)[FLOAT]], [047_convolutional_bn_bias -> (128)[FLOAT]], [047_convolutional_bn_mean -> (128)[FLOAT]], [047_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 047_convolutional_bn for ONNX node: 047_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 047_convolutional_bn for ONNX tensor: 047_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_bn [BatchNormalization] outputs: [047_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 047_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_softplus [Softplus] inputs: [047_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 047_convolutional_softplus for ONNX node: 047_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 047_convolutional_softplus for ONNX tensor: 047_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_softplus [Softplus] outputs: [047_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 047_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_tanh [Tanh] inputs: [047_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 047_convolutional_tanh for ONNX node: 047_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 047_convolutional_tanh for ONNX tensor: 047_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_tanh [Tanh] outputs: [047_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 047_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_mish [Mul] inputs: [047_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [047_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 047_convolutional_mish for ONNX node: 047_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 047_convolutional_mish for ONNX tensor: 047_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 047_convolutional_mish [Mul] outputs: [047_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 048_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 047_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional [Conv] inputs: [047_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [048_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 048_convolutional for ONNX node: 048_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 048_convolutional for ONNX tensor: 048_convolutional
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional [Conv] outputs: [048_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 048_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_bn [BatchNormalization] inputs: [048_convolutional -> (1, 128, 36, 36)[FLOAT]], [048_convolutional_bn_scale -> (128)[FLOAT]], [048_convolutional_bn_bias -> (128)[FLOAT]], [048_convolutional_bn_mean -> (128)[FLOAT]], [048_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 048_convolutional_bn for ONNX node: 048_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 048_convolutional_bn for ONNX tensor: 048_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_bn [BatchNormalization] outputs: [048_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 048_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_softplus [Softplus] inputs: [048_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 048_convolutional_softplus for ONNX node: 048_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 048_convolutional_softplus for ONNX tensor: 048_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_softplus [Softplus] outputs: [048_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 048_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_tanh [Tanh] inputs: [048_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 048_convolutional_tanh for ONNX node: 048_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 048_convolutional_tanh for ONNX tensor: 048_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_tanh [Tanh] outputs: [048_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 048_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_mish [Mul] inputs: [048_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [048_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 048_convolutional_mish for ONNX node: 048_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 048_convolutional_mish for ONNX tensor: 048_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 048_convolutional_mish [Mul] outputs: [048_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 049_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 048_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 046_shortcut
[05/21/2022-02:47:14] [V] [TRT] 049_shortcut [Add] inputs: [048_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [046_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 049_shortcut for ONNX node: 049_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 049_shortcut for ONNX tensor: 049_shortcut
[05/21/2022-02:47:14] [V] [TRT] 049_shortcut [Add] outputs: [049_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 050_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 049_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional [Conv] inputs: [049_shortcut -> (1, 128, 36, 36)[FLOAT]], [050_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 050_convolutional for ONNX node: 050_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 050_convolutional for ONNX tensor: 050_convolutional
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional [Conv] outputs: [050_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 050_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_bn [BatchNormalization] inputs: [050_convolutional -> (1, 128, 36, 36)[FLOAT]], [050_convolutional_bn_scale -> (128)[FLOAT]], [050_convolutional_bn_bias -> (128)[FLOAT]], [050_convolutional_bn_mean -> (128)[FLOAT]], [050_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 050_convolutional_bn for ONNX node: 050_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 050_convolutional_bn for ONNX tensor: 050_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_bn [BatchNormalization] outputs: [050_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 050_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_softplus [Softplus] inputs: [050_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 050_convolutional_softplus for ONNX node: 050_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 050_convolutional_softplus for ONNX tensor: 050_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_softplus [Softplus] outputs: [050_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 050_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_tanh [Tanh] inputs: [050_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 050_convolutional_tanh for ONNX node: 050_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 050_convolutional_tanh for ONNX tensor: 050_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_tanh [Tanh] outputs: [050_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 050_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_mish [Mul] inputs: [050_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [050_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 050_convolutional_mish for ONNX node: 050_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 050_convolutional_mish for ONNX tensor: 050_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 050_convolutional_mish [Mul] outputs: [050_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 051_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 050_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional [Conv] inputs: [050_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [051_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 051_convolutional for ONNX node: 051_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 051_convolutional for ONNX tensor: 051_convolutional
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional [Conv] outputs: [051_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 051_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_bn [BatchNormalization] inputs: [051_convolutional -> (1, 128, 36, 36)[FLOAT]], [051_convolutional_bn_scale -> (128)[FLOAT]], [051_convolutional_bn_bias -> (128)[FLOAT]], [051_convolutional_bn_mean -> (128)[FLOAT]], [051_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 051_convolutional_bn for ONNX node: 051_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 051_convolutional_bn for ONNX tensor: 051_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_bn [BatchNormalization] outputs: [051_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 051_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_softplus [Softplus] inputs: [051_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 051_convolutional_softplus for ONNX node: 051_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 051_convolutional_softplus for ONNX tensor: 051_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_softplus [Softplus] outputs: [051_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 051_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_tanh [Tanh] inputs: [051_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 051_convolutional_tanh for ONNX node: 051_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 051_convolutional_tanh for ONNX tensor: 051_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_tanh [Tanh] outputs: [051_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 051_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_mish [Mul] inputs: [051_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [051_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 051_convolutional_mish for ONNX node: 051_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 051_convolutional_mish for ONNX tensor: 051_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 051_convolutional_mish [Mul] outputs: [051_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 052_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 051_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 049_shortcut
[05/21/2022-02:47:14] [V] [TRT] 052_shortcut [Add] inputs: [051_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [049_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 052_shortcut for ONNX node: 052_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 052_shortcut for ONNX tensor: 052_shortcut
[05/21/2022-02:47:14] [V] [TRT] 052_shortcut [Add] outputs: [052_shortcut -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 053_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 052_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional [Conv] inputs: [052_shortcut -> (1, 128, 36, 36)[FLOAT]], [053_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 053_convolutional for ONNX node: 053_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 053_convolutional for ONNX tensor: 053_convolutional
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional [Conv] outputs: [053_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 053_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_bn [BatchNormalization] inputs: [053_convolutional -> (1, 128, 36, 36)[FLOAT]], [053_convolutional_bn_scale -> (128)[FLOAT]], [053_convolutional_bn_bias -> (128)[FLOAT]], [053_convolutional_bn_mean -> (128)[FLOAT]], [053_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 053_convolutional_bn for ONNX node: 053_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 053_convolutional_bn for ONNX tensor: 053_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_bn [BatchNormalization] outputs: [053_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 053_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_softplus [Softplus] inputs: [053_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 053_convolutional_softplus for ONNX node: 053_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 053_convolutional_softplus for ONNX tensor: 053_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_softplus [Softplus] outputs: [053_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 053_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_tanh [Tanh] inputs: [053_convolutional_softplus -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 053_convolutional_tanh for ONNX node: 053_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 053_convolutional_tanh for ONNX tensor: 053_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_tanh [Tanh] outputs: [053_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 053_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_mish [Mul] inputs: [053_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], [053_convolutional_tanh -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 053_convolutional_mish for ONNX node: 053_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 053_convolutional_mish for ONNX tensor: 053_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 053_convolutional_mish [Mul] outputs: [053_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 054_route [Concat]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 053_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 026_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 054_route [Concat] inputs: [053_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], [026_convolutional_mish -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 054_route for ONNX node: 054_route
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 054_route for ONNX tensor: 054_route
[05/21/2022-02:47:14] [V] [TRT] 054_route [Concat] outputs: [054_route -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 055_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 054_route
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional [Conv] inputs: [054_route -> (1, 256, 36, 36)[FLOAT]], [055_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 055_convolutional for ONNX node: 055_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 055_convolutional for ONNX tensor: 055_convolutional
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional [Conv] outputs: [055_convolutional -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 055_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_bn [BatchNormalization] inputs: [055_convolutional -> (1, 256, 36, 36)[FLOAT]], [055_convolutional_bn_scale -> (256)[FLOAT]], [055_convolutional_bn_bias -> (256)[FLOAT]], [055_convolutional_bn_mean -> (256)[FLOAT]], [055_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 055_convolutional_bn for ONNX node: 055_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 055_convolutional_bn for ONNX tensor: 055_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_bn [BatchNormalization] outputs: [055_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 055_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_softplus [Softplus] inputs: [055_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 055_convolutional_softplus for ONNX node: 055_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 055_convolutional_softplus for ONNX tensor: 055_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_softplus [Softplus] outputs: [055_convolutional_softplus -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 055_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_tanh [Tanh] inputs: [055_convolutional_softplus -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 055_convolutional_tanh for ONNX node: 055_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 055_convolutional_tanh for ONNX tensor: 055_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_tanh [Tanh] outputs: [055_convolutional_tanh -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 055_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_mish [Mul] inputs: [055_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], [055_convolutional_tanh -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 055_convolutional_mish for ONNX node: 055_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 055_convolutional_mish for ONNX tensor: 055_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 055_convolutional_mish [Mul] outputs: [055_convolutional_mish -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 056_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 055_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional [Conv] inputs: [055_convolutional_mish -> (1, 256, 36, 36)[FLOAT]], [056_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 056_convolutional for ONNX node: 056_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 056_convolutional for ONNX tensor: 056_convolutional
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional [Conv] outputs: [056_convolutional -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 056_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_bn [BatchNormalization] inputs: [056_convolutional -> (1, 512, 18, 18)[FLOAT]], [056_convolutional_bn_scale -> (512)[FLOAT]], [056_convolutional_bn_bias -> (512)[FLOAT]], [056_convolutional_bn_mean -> (512)[FLOAT]], [056_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 056_convolutional_bn for ONNX node: 056_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 056_convolutional_bn for ONNX tensor: 056_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_bn [BatchNormalization] outputs: [056_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 056_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_softplus [Softplus] inputs: [056_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 056_convolutional_softplus for ONNX node: 056_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 056_convolutional_softplus for ONNX tensor: 056_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_softplus [Softplus] outputs: [056_convolutional_softplus -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 056_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_tanh [Tanh] inputs: [056_convolutional_softplus -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 056_convolutional_tanh for ONNX node: 056_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 056_convolutional_tanh for ONNX tensor: 056_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_tanh [Tanh] outputs: [056_convolutional_tanh -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 056_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_mish [Mul] inputs: [056_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], [056_convolutional_tanh -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 056_convolutional_mish for ONNX node: 056_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 056_convolutional_mish for ONNX tensor: 056_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 056_convolutional_mish [Mul] outputs: [056_convolutional_mish -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 057_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional [Conv] inputs: [056_convolutional_mish -> (1, 512, 18, 18)[FLOAT]], [057_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 057_convolutional for ONNX node: 057_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 057_convolutional for ONNX tensor: 057_convolutional
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional [Conv] outputs: [057_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 057_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_bn [BatchNormalization] inputs: [057_convolutional -> (1, 256, 18, 18)[FLOAT]], [057_convolutional_bn_scale -> (256)[FLOAT]], [057_convolutional_bn_bias -> (256)[FLOAT]], [057_convolutional_bn_mean -> (256)[FLOAT]], [057_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 057_convolutional_bn for ONNX node: 057_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 057_convolutional_bn for ONNX tensor: 057_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_bn [BatchNormalization] outputs: [057_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 057_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_softplus [Softplus] inputs: [057_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 057_convolutional_softplus for ONNX node: 057_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 057_convolutional_softplus for ONNX tensor: 057_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_softplus [Softplus] outputs: [057_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 057_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_tanh [Tanh] inputs: [057_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 057_convolutional_tanh for ONNX node: 057_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 057_convolutional_tanh for ONNX tensor: 057_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_tanh [Tanh] outputs: [057_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 057_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_mish [Mul] inputs: [057_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [057_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 057_convolutional_mish for ONNX node: 057_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 057_convolutional_mish for ONNX tensor: 057_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 057_convolutional_mish [Mul] outputs: [057_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 059_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 056_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional [Conv] inputs: [056_convolutional_mish -> (1, 512, 18, 18)[FLOAT]], [059_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 059_convolutional for ONNX node: 059_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 059_convolutional for ONNX tensor: 059_convolutional
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional [Conv] outputs: [059_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 059_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_bn [BatchNormalization] inputs: [059_convolutional -> (1, 256, 18, 18)[FLOAT]], [059_convolutional_bn_scale -> (256)[FLOAT]], [059_convolutional_bn_bias -> (256)[FLOAT]], [059_convolutional_bn_mean -> (256)[FLOAT]], [059_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 059_convolutional_bn for ONNX node: 059_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 059_convolutional_bn for ONNX tensor: 059_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_bn [BatchNormalization] outputs: [059_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 059_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_softplus [Softplus] inputs: [059_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 059_convolutional_softplus for ONNX node: 059_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 059_convolutional_softplus for ONNX tensor: 059_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_softplus [Softplus] outputs: [059_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 059_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_tanh [Tanh] inputs: [059_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 059_convolutional_tanh for ONNX node: 059_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 059_convolutional_tanh for ONNX tensor: 059_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_tanh [Tanh] outputs: [059_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 059_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_mish [Mul] inputs: [059_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [059_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 059_convolutional_mish for ONNX node: 059_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 059_convolutional_mish for ONNX tensor: 059_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 059_convolutional_mish [Mul] outputs: [059_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 060_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional [Conv] inputs: [059_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [060_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 060_convolutional for ONNX node: 060_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 060_convolutional for ONNX tensor: 060_convolutional
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional [Conv] outputs: [060_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 060_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_bn [BatchNormalization] inputs: [060_convolutional -> (1, 256, 18, 18)[FLOAT]], [060_convolutional_bn_scale -> (256)[FLOAT]], [060_convolutional_bn_bias -> (256)[FLOAT]], [060_convolutional_bn_mean -> (256)[FLOAT]], [060_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 060_convolutional_bn for ONNX node: 060_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 060_convolutional_bn for ONNX tensor: 060_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_bn [BatchNormalization] outputs: [060_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 060_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_softplus [Softplus] inputs: [060_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 060_convolutional_softplus for ONNX node: 060_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 060_convolutional_softplus for ONNX tensor: 060_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_softplus [Softplus] outputs: [060_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 060_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_tanh [Tanh] inputs: [060_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 060_convolutional_tanh for ONNX node: 060_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 060_convolutional_tanh for ONNX tensor: 060_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_tanh [Tanh] outputs: [060_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 060_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_mish [Mul] inputs: [060_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [060_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 060_convolutional_mish for ONNX node: 060_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 060_convolutional_mish for ONNX tensor: 060_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 060_convolutional_mish [Mul] outputs: [060_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 061_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 060_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional [Conv] inputs: [060_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [061_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 061_convolutional for ONNX node: 061_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 061_convolutional for ONNX tensor: 061_convolutional
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional [Conv] outputs: [061_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 061_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_bn [BatchNormalization] inputs: [061_convolutional -> (1, 256, 18, 18)[FLOAT]], [061_convolutional_bn_scale -> (256)[FLOAT]], [061_convolutional_bn_bias -> (256)[FLOAT]], [061_convolutional_bn_mean -> (256)[FLOAT]], [061_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 061_convolutional_bn for ONNX node: 061_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 061_convolutional_bn for ONNX tensor: 061_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_bn [BatchNormalization] outputs: [061_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 061_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_softplus [Softplus] inputs: [061_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 061_convolutional_softplus for ONNX node: 061_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 061_convolutional_softplus for ONNX tensor: 061_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_softplus [Softplus] outputs: [061_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 061_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_tanh [Tanh] inputs: [061_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 061_convolutional_tanh for ONNX node: 061_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 061_convolutional_tanh for ONNX tensor: 061_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_tanh [Tanh] outputs: [061_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 061_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_mish [Mul] inputs: [061_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [061_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 061_convolutional_mish for ONNX node: 061_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 061_convolutional_mish for ONNX tensor: 061_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 061_convolutional_mish [Mul] outputs: [061_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 062_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 061_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 059_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 062_shortcut [Add] inputs: [061_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [059_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 062_shortcut for ONNX node: 062_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 062_shortcut for ONNX tensor: 062_shortcut
[05/21/2022-02:47:14] [V] [TRT] 062_shortcut [Add] outputs: [062_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 063_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 062_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional [Conv] inputs: [062_shortcut -> (1, 256, 18, 18)[FLOAT]], [063_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 063_convolutional for ONNX node: 063_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 063_convolutional for ONNX tensor: 063_convolutional
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional [Conv] outputs: [063_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 063_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_bn [BatchNormalization] inputs: [063_convolutional -> (1, 256, 18, 18)[FLOAT]], [063_convolutional_bn_scale -> (256)[FLOAT]], [063_convolutional_bn_bias -> (256)[FLOAT]], [063_convolutional_bn_mean -> (256)[FLOAT]], [063_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 063_convolutional_bn for ONNX node: 063_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 063_convolutional_bn for ONNX tensor: 063_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_bn [BatchNormalization] outputs: [063_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 063_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_softplus [Softplus] inputs: [063_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 063_convolutional_softplus for ONNX node: 063_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 063_convolutional_softplus for ONNX tensor: 063_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_softplus [Softplus] outputs: [063_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 063_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_tanh [Tanh] inputs: [063_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 063_convolutional_tanh for ONNX node: 063_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 063_convolutional_tanh for ONNX tensor: 063_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_tanh [Tanh] outputs: [063_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 063_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_mish [Mul] inputs: [063_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [063_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 063_convolutional_mish for ONNX node: 063_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 063_convolutional_mish for ONNX tensor: 063_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 063_convolutional_mish [Mul] outputs: [063_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 064_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 063_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional [Conv] inputs: [063_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [064_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 064_convolutional for ONNX node: 064_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 064_convolutional for ONNX tensor: 064_convolutional
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional [Conv] outputs: [064_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 064_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_bn [BatchNormalization] inputs: [064_convolutional -> (1, 256, 18, 18)[FLOAT]], [064_convolutional_bn_scale -> (256)[FLOAT]], [064_convolutional_bn_bias -> (256)[FLOAT]], [064_convolutional_bn_mean -> (256)[FLOAT]], [064_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 064_convolutional_bn for ONNX node: 064_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 064_convolutional_bn for ONNX tensor: 064_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_bn [BatchNormalization] outputs: [064_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 064_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_softplus [Softplus] inputs: [064_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 064_convolutional_softplus for ONNX node: 064_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 064_convolutional_softplus for ONNX tensor: 064_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_softplus [Softplus] outputs: [064_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 064_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_tanh [Tanh] inputs: [064_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 064_convolutional_tanh for ONNX node: 064_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 064_convolutional_tanh for ONNX tensor: 064_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_tanh [Tanh] outputs: [064_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 064_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_mish [Mul] inputs: [064_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [064_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 064_convolutional_mish for ONNX node: 064_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 064_convolutional_mish for ONNX tensor: 064_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 064_convolutional_mish [Mul] outputs: [064_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 065_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 064_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 062_shortcut
[05/21/2022-02:47:14] [V] [TRT] 065_shortcut [Add] inputs: [064_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [062_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 065_shortcut for ONNX node: 065_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 065_shortcut for ONNX tensor: 065_shortcut
[05/21/2022-02:47:14] [V] [TRT] 065_shortcut [Add] outputs: [065_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 066_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 065_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional [Conv] inputs: [065_shortcut -> (1, 256, 18, 18)[FLOAT]], [066_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 066_convolutional for ONNX node: 066_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 066_convolutional for ONNX tensor: 066_convolutional
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional [Conv] outputs: [066_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 066_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_bn [BatchNormalization] inputs: [066_convolutional -> (1, 256, 18, 18)[FLOAT]], [066_convolutional_bn_scale -> (256)[FLOAT]], [066_convolutional_bn_bias -> (256)[FLOAT]], [066_convolutional_bn_mean -> (256)[FLOAT]], [066_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 066_convolutional_bn for ONNX node: 066_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 066_convolutional_bn for ONNX tensor: 066_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_bn [BatchNormalization] outputs: [066_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 066_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_softplus [Softplus] inputs: [066_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 066_convolutional_softplus for ONNX node: 066_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 066_convolutional_softplus for ONNX tensor: 066_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_softplus [Softplus] outputs: [066_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 066_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_tanh [Tanh] inputs: [066_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 066_convolutional_tanh for ONNX node: 066_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 066_convolutional_tanh for ONNX tensor: 066_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_tanh [Tanh] outputs: [066_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 066_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_mish [Mul] inputs: [066_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [066_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 066_convolutional_mish for ONNX node: 066_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 066_convolutional_mish for ONNX tensor: 066_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 066_convolutional_mish [Mul] outputs: [066_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 067_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 066_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional [Conv] inputs: [066_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [067_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 067_convolutional for ONNX node: 067_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 067_convolutional for ONNX tensor: 067_convolutional
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional [Conv] outputs: [067_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 067_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_bn [BatchNormalization] inputs: [067_convolutional -> (1, 256, 18, 18)[FLOAT]], [067_convolutional_bn_scale -> (256)[FLOAT]], [067_convolutional_bn_bias -> (256)[FLOAT]], [067_convolutional_bn_mean -> (256)[FLOAT]], [067_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 067_convolutional_bn for ONNX node: 067_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 067_convolutional_bn for ONNX tensor: 067_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_bn [BatchNormalization] outputs: [067_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 067_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_softplus [Softplus] inputs: [067_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 067_convolutional_softplus for ONNX node: 067_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 067_convolutional_softplus for ONNX tensor: 067_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_softplus [Softplus] outputs: [067_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 067_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_tanh [Tanh] inputs: [067_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 067_convolutional_tanh for ONNX node: 067_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 067_convolutional_tanh for ONNX tensor: 067_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_tanh [Tanh] outputs: [067_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 067_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_mish [Mul] inputs: [067_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [067_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 067_convolutional_mish for ONNX node: 067_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 067_convolutional_mish for ONNX tensor: 067_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 067_convolutional_mish [Mul] outputs: [067_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 068_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 067_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 065_shortcut
[05/21/2022-02:47:14] [V] [TRT] 068_shortcut [Add] inputs: [067_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [065_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 068_shortcut for ONNX node: 068_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 068_shortcut for ONNX tensor: 068_shortcut
[05/21/2022-02:47:14] [V] [TRT] 068_shortcut [Add] outputs: [068_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 069_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 068_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional [Conv] inputs: [068_shortcut -> (1, 256, 18, 18)[FLOAT]], [069_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 069_convolutional for ONNX node: 069_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 069_convolutional for ONNX tensor: 069_convolutional
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional [Conv] outputs: [069_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 069_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_bn [BatchNormalization] inputs: [069_convolutional -> (1, 256, 18, 18)[FLOAT]], [069_convolutional_bn_scale -> (256)[FLOAT]], [069_convolutional_bn_bias -> (256)[FLOAT]], [069_convolutional_bn_mean -> (256)[FLOAT]], [069_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 069_convolutional_bn for ONNX node: 069_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 069_convolutional_bn for ONNX tensor: 069_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_bn [BatchNormalization] outputs: [069_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 069_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_softplus [Softplus] inputs: [069_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 069_convolutional_softplus for ONNX node: 069_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 069_convolutional_softplus for ONNX tensor: 069_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_softplus [Softplus] outputs: [069_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 069_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_tanh [Tanh] inputs: [069_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 069_convolutional_tanh for ONNX node: 069_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 069_convolutional_tanh for ONNX tensor: 069_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_tanh [Tanh] outputs: [069_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 069_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_mish [Mul] inputs: [069_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [069_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 069_convolutional_mish for ONNX node: 069_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 069_convolutional_mish for ONNX tensor: 069_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 069_convolutional_mish [Mul] outputs: [069_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 070_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 069_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional [Conv] inputs: [069_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [070_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 070_convolutional for ONNX node: 070_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 070_convolutional for ONNX tensor: 070_convolutional
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional [Conv] outputs: [070_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 070_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_bn [BatchNormalization] inputs: [070_convolutional -> (1, 256, 18, 18)[FLOAT]], [070_convolutional_bn_scale -> (256)[FLOAT]], [070_convolutional_bn_bias -> (256)[FLOAT]], [070_convolutional_bn_mean -> (256)[FLOAT]], [070_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 070_convolutional_bn for ONNX node: 070_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 070_convolutional_bn for ONNX tensor: 070_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_bn [BatchNormalization] outputs: [070_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 070_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_softplus [Softplus] inputs: [070_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 070_convolutional_softplus for ONNX node: 070_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 070_convolutional_softplus for ONNX tensor: 070_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_softplus [Softplus] outputs: [070_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 070_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_tanh [Tanh] inputs: [070_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 070_convolutional_tanh for ONNX node: 070_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 070_convolutional_tanh for ONNX tensor: 070_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_tanh [Tanh] outputs: [070_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 070_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_mish [Mul] inputs: [070_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [070_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 070_convolutional_mish for ONNX node: 070_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 070_convolutional_mish for ONNX tensor: 070_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 070_convolutional_mish [Mul] outputs: [070_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 071_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 070_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 068_shortcut
[05/21/2022-02:47:14] [V] [TRT] 071_shortcut [Add] inputs: [070_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [068_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 071_shortcut for ONNX node: 071_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 071_shortcut for ONNX tensor: 071_shortcut
[05/21/2022-02:47:14] [V] [TRT] 071_shortcut [Add] outputs: [071_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 072_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 071_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional [Conv] inputs: [071_shortcut -> (1, 256, 18, 18)[FLOAT]], [072_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 072_convolutional for ONNX node: 072_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 072_convolutional for ONNX tensor: 072_convolutional
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional [Conv] outputs: [072_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 072_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_bn [BatchNormalization] inputs: [072_convolutional -> (1, 256, 18, 18)[FLOAT]], [072_convolutional_bn_scale -> (256)[FLOAT]], [072_convolutional_bn_bias -> (256)[FLOAT]], [072_convolutional_bn_mean -> (256)[FLOAT]], [072_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 072_convolutional_bn for ONNX node: 072_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 072_convolutional_bn for ONNX tensor: 072_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_bn [BatchNormalization] outputs: [072_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 072_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_softplus [Softplus] inputs: [072_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 072_convolutional_softplus for ONNX node: 072_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 072_convolutional_softplus for ONNX tensor: 072_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_softplus [Softplus] outputs: [072_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 072_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_tanh [Tanh] inputs: [072_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 072_convolutional_tanh for ONNX node: 072_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 072_convolutional_tanh for ONNX tensor: 072_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_tanh [Tanh] outputs: [072_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 072_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_mish [Mul] inputs: [072_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [072_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 072_convolutional_mish for ONNX node: 072_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 072_convolutional_mish for ONNX tensor: 072_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 072_convolutional_mish [Mul] outputs: [072_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 073_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 072_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional [Conv] inputs: [072_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [073_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 073_convolutional for ONNX node: 073_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 073_convolutional for ONNX tensor: 073_convolutional
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional [Conv] outputs: [073_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 073_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_bn [BatchNormalization] inputs: [073_convolutional -> (1, 256, 18, 18)[FLOAT]], [073_convolutional_bn_scale -> (256)[FLOAT]], [073_convolutional_bn_bias -> (256)[FLOAT]], [073_convolutional_bn_mean -> (256)[FLOAT]], [073_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 073_convolutional_bn for ONNX node: 073_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 073_convolutional_bn for ONNX tensor: 073_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_bn [BatchNormalization] outputs: [073_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 073_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_softplus [Softplus] inputs: [073_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 073_convolutional_softplus for ONNX node: 073_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 073_convolutional_softplus for ONNX tensor: 073_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_softplus [Softplus] outputs: [073_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 073_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_tanh [Tanh] inputs: [073_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 073_convolutional_tanh for ONNX node: 073_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 073_convolutional_tanh for ONNX tensor: 073_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_tanh [Tanh] outputs: [073_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 073_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_mish [Mul] inputs: [073_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [073_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 073_convolutional_mish for ONNX node: 073_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 073_convolutional_mish for ONNX tensor: 073_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 073_convolutional_mish [Mul] outputs: [073_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 074_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 073_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 071_shortcut
[05/21/2022-02:47:14] [V] [TRT] 074_shortcut [Add] inputs: [073_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [071_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 074_shortcut for ONNX node: 074_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 074_shortcut for ONNX tensor: 074_shortcut
[05/21/2022-02:47:14] [V] [TRT] 074_shortcut [Add] outputs: [074_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 075_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 074_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional [Conv] inputs: [074_shortcut -> (1, 256, 18, 18)[FLOAT]], [075_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 075_convolutional for ONNX node: 075_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 075_convolutional for ONNX tensor: 075_convolutional
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional [Conv] outputs: [075_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 075_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_bn [BatchNormalization] inputs: [075_convolutional -> (1, 256, 18, 18)[FLOAT]], [075_convolutional_bn_scale -> (256)[FLOAT]], [075_convolutional_bn_bias -> (256)[FLOAT]], [075_convolutional_bn_mean -> (256)[FLOAT]], [075_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 075_convolutional_bn for ONNX node: 075_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 075_convolutional_bn for ONNX tensor: 075_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_bn [BatchNormalization] outputs: [075_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 075_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_softplus [Softplus] inputs: [075_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 075_convolutional_softplus for ONNX node: 075_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 075_convolutional_softplus for ONNX tensor: 075_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_softplus [Softplus] outputs: [075_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 075_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_tanh [Tanh] inputs: [075_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 075_convolutional_tanh for ONNX node: 075_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 075_convolutional_tanh for ONNX tensor: 075_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_tanh [Tanh] outputs: [075_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 075_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_mish [Mul] inputs: [075_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [075_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 075_convolutional_mish for ONNX node: 075_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 075_convolutional_mish for ONNX tensor: 075_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 075_convolutional_mish [Mul] outputs: [075_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 076_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 075_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional [Conv] inputs: [075_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [076_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 076_convolutional for ONNX node: 076_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 076_convolutional for ONNX tensor: 076_convolutional
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional [Conv] outputs: [076_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 076_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_bn [BatchNormalization] inputs: [076_convolutional -> (1, 256, 18, 18)[FLOAT]], [076_convolutional_bn_scale -> (256)[FLOAT]], [076_convolutional_bn_bias -> (256)[FLOAT]], [076_convolutional_bn_mean -> (256)[FLOAT]], [076_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 076_convolutional_bn for ONNX node: 076_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 076_convolutional_bn for ONNX tensor: 076_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_bn [BatchNormalization] outputs: [076_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 076_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_softplus [Softplus] inputs: [076_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 076_convolutional_softplus for ONNX node: 076_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 076_convolutional_softplus for ONNX tensor: 076_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_softplus [Softplus] outputs: [076_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 076_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_tanh [Tanh] inputs: [076_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 076_convolutional_tanh for ONNX node: 076_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 076_convolutional_tanh for ONNX tensor: 076_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_tanh [Tanh] outputs: [076_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 076_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_mish [Mul] inputs: [076_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [076_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 076_convolutional_mish for ONNX node: 076_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 076_convolutional_mish for ONNX tensor: 076_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 076_convolutional_mish [Mul] outputs: [076_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 077_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 076_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 074_shortcut
[05/21/2022-02:47:14] [V] [TRT] 077_shortcut [Add] inputs: [076_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [074_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 077_shortcut for ONNX node: 077_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 077_shortcut for ONNX tensor: 077_shortcut
[05/21/2022-02:47:14] [V] [TRT] 077_shortcut [Add] outputs: [077_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 078_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 077_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional [Conv] inputs: [077_shortcut -> (1, 256, 18, 18)[FLOAT]], [078_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 078_convolutional for ONNX node: 078_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 078_convolutional for ONNX tensor: 078_convolutional
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional [Conv] outputs: [078_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 078_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_bn [BatchNormalization] inputs: [078_convolutional -> (1, 256, 18, 18)[FLOAT]], [078_convolutional_bn_scale -> (256)[FLOAT]], [078_convolutional_bn_bias -> (256)[FLOAT]], [078_convolutional_bn_mean -> (256)[FLOAT]], [078_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 078_convolutional_bn for ONNX node: 078_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 078_convolutional_bn for ONNX tensor: 078_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_bn [BatchNormalization] outputs: [078_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 078_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_softplus [Softplus] inputs: [078_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 078_convolutional_softplus for ONNX node: 078_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 078_convolutional_softplus for ONNX tensor: 078_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_softplus [Softplus] outputs: [078_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 078_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_tanh [Tanh] inputs: [078_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 078_convolutional_tanh for ONNX node: 078_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 078_convolutional_tanh for ONNX tensor: 078_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_tanh [Tanh] outputs: [078_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 078_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_mish [Mul] inputs: [078_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [078_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 078_convolutional_mish for ONNX node: 078_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 078_convolutional_mish for ONNX tensor: 078_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 078_convolutional_mish [Mul] outputs: [078_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 079_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 078_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional [Conv] inputs: [078_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [079_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 079_convolutional for ONNX node: 079_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 079_convolutional for ONNX tensor: 079_convolutional
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional [Conv] outputs: [079_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 079_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_bn [BatchNormalization] inputs: [079_convolutional -> (1, 256, 18, 18)[FLOAT]], [079_convolutional_bn_scale -> (256)[FLOAT]], [079_convolutional_bn_bias -> (256)[FLOAT]], [079_convolutional_bn_mean -> (256)[FLOAT]], [079_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 079_convolutional_bn for ONNX node: 079_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 079_convolutional_bn for ONNX tensor: 079_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_bn [BatchNormalization] outputs: [079_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 079_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_softplus [Softplus] inputs: [079_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 079_convolutional_softplus for ONNX node: 079_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 079_convolutional_softplus for ONNX tensor: 079_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_softplus [Softplus] outputs: [079_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 079_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_tanh [Tanh] inputs: [079_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 079_convolutional_tanh for ONNX node: 079_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 079_convolutional_tanh for ONNX tensor: 079_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_tanh [Tanh] outputs: [079_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 079_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_mish [Mul] inputs: [079_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [079_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 079_convolutional_mish for ONNX node: 079_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 079_convolutional_mish for ONNX tensor: 079_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 079_convolutional_mish [Mul] outputs: [079_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 080_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 079_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 077_shortcut
[05/21/2022-02:47:14] [V] [TRT] 080_shortcut [Add] inputs: [079_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [077_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 080_shortcut for ONNX node: 080_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 080_shortcut for ONNX tensor: 080_shortcut
[05/21/2022-02:47:14] [V] [TRT] 080_shortcut [Add] outputs: [080_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 081_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 080_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional [Conv] inputs: [080_shortcut -> (1, 256, 18, 18)[FLOAT]], [081_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 081_convolutional for ONNX node: 081_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 081_convolutional for ONNX tensor: 081_convolutional
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional [Conv] outputs: [081_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 081_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_bn [BatchNormalization] inputs: [081_convolutional -> (1, 256, 18, 18)[FLOAT]], [081_convolutional_bn_scale -> (256)[FLOAT]], [081_convolutional_bn_bias -> (256)[FLOAT]], [081_convolutional_bn_mean -> (256)[FLOAT]], [081_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 081_convolutional_bn for ONNX node: 081_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 081_convolutional_bn for ONNX tensor: 081_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_bn [BatchNormalization] outputs: [081_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 081_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_softplus [Softplus] inputs: [081_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 081_convolutional_softplus for ONNX node: 081_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 081_convolutional_softplus for ONNX tensor: 081_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_softplus [Softplus] outputs: [081_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 081_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_tanh [Tanh] inputs: [081_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 081_convolutional_tanh for ONNX node: 081_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 081_convolutional_tanh for ONNX tensor: 081_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_tanh [Tanh] outputs: [081_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 081_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_mish [Mul] inputs: [081_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [081_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 081_convolutional_mish for ONNX node: 081_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 081_convolutional_mish for ONNX tensor: 081_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 081_convolutional_mish [Mul] outputs: [081_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 082_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 081_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional [Conv] inputs: [081_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [082_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 082_convolutional for ONNX node: 082_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 082_convolutional for ONNX tensor: 082_convolutional
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional [Conv] outputs: [082_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 082_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_bn [BatchNormalization] inputs: [082_convolutional -> (1, 256, 18, 18)[FLOAT]], [082_convolutional_bn_scale -> (256)[FLOAT]], [082_convolutional_bn_bias -> (256)[FLOAT]], [082_convolutional_bn_mean -> (256)[FLOAT]], [082_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 082_convolutional_bn for ONNX node: 082_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 082_convolutional_bn for ONNX tensor: 082_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_bn [BatchNormalization] outputs: [082_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 082_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_softplus [Softplus] inputs: [082_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 082_convolutional_softplus for ONNX node: 082_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 082_convolutional_softplus for ONNX tensor: 082_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_softplus [Softplus] outputs: [082_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 082_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_tanh [Tanh] inputs: [082_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 082_convolutional_tanh for ONNX node: 082_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 082_convolutional_tanh for ONNX tensor: 082_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_tanh [Tanh] outputs: [082_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 082_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_mish [Mul] inputs: [082_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [082_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 082_convolutional_mish for ONNX node: 082_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 082_convolutional_mish for ONNX tensor: 082_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 082_convolutional_mish [Mul] outputs: [082_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 083_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 082_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 080_shortcut
[05/21/2022-02:47:14] [V] [TRT] 083_shortcut [Add] inputs: [082_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [080_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 083_shortcut for ONNX node: 083_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 083_shortcut for ONNX tensor: 083_shortcut
[05/21/2022-02:47:14] [V] [TRT] 083_shortcut [Add] outputs: [083_shortcut -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 084_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 083_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional [Conv] inputs: [083_shortcut -> (1, 256, 18, 18)[FLOAT]], [084_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 084_convolutional for ONNX node: 084_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 084_convolutional for ONNX tensor: 084_convolutional
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional [Conv] outputs: [084_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 084_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_bn [BatchNormalization] inputs: [084_convolutional -> (1, 256, 18, 18)[FLOAT]], [084_convolutional_bn_scale -> (256)[FLOAT]], [084_convolutional_bn_bias -> (256)[FLOAT]], [084_convolutional_bn_mean -> (256)[FLOAT]], [084_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 084_convolutional_bn for ONNX node: 084_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 084_convolutional_bn for ONNX tensor: 084_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_bn [BatchNormalization] outputs: [084_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 084_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_softplus [Softplus] inputs: [084_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 084_convolutional_softplus for ONNX node: 084_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 084_convolutional_softplus for ONNX tensor: 084_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_softplus [Softplus] outputs: [084_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 084_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_tanh [Tanh] inputs: [084_convolutional_softplus -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 084_convolutional_tanh for ONNX node: 084_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 084_convolutional_tanh for ONNX tensor: 084_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_tanh [Tanh] outputs: [084_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 084_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_mish [Mul] inputs: [084_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], [084_convolutional_tanh -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 084_convolutional_mish for ONNX node: 084_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 084_convolutional_mish for ONNX tensor: 084_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 084_convolutional_mish [Mul] outputs: [084_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 085_route [Concat]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 084_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 057_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 085_route [Concat] inputs: [084_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], [057_convolutional_mish -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 085_route for ONNX node: 085_route
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 085_route for ONNX tensor: 085_route
[05/21/2022-02:47:14] [V] [TRT] 085_route [Concat] outputs: [085_route -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 086_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 085_route
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional [Conv] inputs: [085_route -> (1, 512, 18, 18)[FLOAT]], [086_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 086_convolutional for ONNX node: 086_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 086_convolutional for ONNX tensor: 086_convolutional
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional [Conv] outputs: [086_convolutional -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 086_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_bn [BatchNormalization] inputs: [086_convolutional -> (1, 512, 18, 18)[FLOAT]], [086_convolutional_bn_scale -> (512)[FLOAT]], [086_convolutional_bn_bias -> (512)[FLOAT]], [086_convolutional_bn_mean -> (512)[FLOAT]], [086_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 086_convolutional_bn for ONNX node: 086_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 086_convolutional_bn for ONNX tensor: 086_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_bn [BatchNormalization] outputs: [086_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 086_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_softplus [Softplus] inputs: [086_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 086_convolutional_softplus for ONNX node: 086_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 086_convolutional_softplus for ONNX tensor: 086_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_softplus [Softplus] outputs: [086_convolutional_softplus -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 086_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_tanh [Tanh] inputs: [086_convolutional_softplus -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 086_convolutional_tanh for ONNX node: 086_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 086_convolutional_tanh for ONNX tensor: 086_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_tanh [Tanh] outputs: [086_convolutional_tanh -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 086_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_mish [Mul] inputs: [086_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], [086_convolutional_tanh -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 086_convolutional_mish for ONNX node: 086_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 086_convolutional_mish for ONNX tensor: 086_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 086_convolutional_mish [Mul] outputs: [086_convolutional_mish -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 087_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 086_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional [Conv] inputs: [086_convolutional_mish -> (1, 512, 18, 18)[FLOAT]], [087_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 087_convolutional for ONNX node: 087_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 087_convolutional for ONNX tensor: 087_convolutional
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional [Conv] outputs: [087_convolutional -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 087_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_bn [BatchNormalization] inputs: [087_convolutional -> (1, 1024, 9, 9)[FLOAT]], [087_convolutional_bn_scale -> (1024)[FLOAT]], [087_convolutional_bn_bias -> (1024)[FLOAT]], [087_convolutional_bn_mean -> (1024)[FLOAT]], [087_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 087_convolutional_bn for ONNX node: 087_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 087_convolutional_bn for ONNX tensor: 087_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_bn [BatchNormalization] outputs: [087_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 087_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_softplus [Softplus] inputs: [087_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 087_convolutional_softplus for ONNX node: 087_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 087_convolutional_softplus for ONNX tensor: 087_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_softplus [Softplus] outputs: [087_convolutional_softplus -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 087_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_tanh [Tanh] inputs: [087_convolutional_softplus -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 087_convolutional_tanh for ONNX node: 087_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 087_convolutional_tanh for ONNX tensor: 087_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_tanh [Tanh] outputs: [087_convolutional_tanh -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 087_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_mish [Mul] inputs: [087_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], [087_convolutional_tanh -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 087_convolutional_mish for ONNX node: 087_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 087_convolutional_mish for ONNX tensor: 087_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 087_convolutional_mish [Mul] outputs: [087_convolutional_mish -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 088_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional [Conv] inputs: [087_convolutional_mish -> (1, 1024, 9, 9)[FLOAT]], [088_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 088_convolutional for ONNX node: 088_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 088_convolutional for ONNX tensor: 088_convolutional
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional [Conv] outputs: [088_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 088_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_bn [BatchNormalization] inputs: [088_convolutional -> (1, 512, 9, 9)[FLOAT]], [088_convolutional_bn_scale -> (512)[FLOAT]], [088_convolutional_bn_bias -> (512)[FLOAT]], [088_convolutional_bn_mean -> (512)[FLOAT]], [088_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 088_convolutional_bn for ONNX node: 088_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 088_convolutional_bn for ONNX tensor: 088_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_bn [BatchNormalization] outputs: [088_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 088_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_softplus [Softplus] inputs: [088_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 088_convolutional_softplus for ONNX node: 088_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 088_convolutional_softplus for ONNX tensor: 088_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_softplus [Softplus] outputs: [088_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 088_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_tanh [Tanh] inputs: [088_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 088_convolutional_tanh for ONNX node: 088_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 088_convolutional_tanh for ONNX tensor: 088_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_tanh [Tanh] outputs: [088_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 088_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_mish [Mul] inputs: [088_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [088_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 088_convolutional_mish for ONNX node: 088_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 088_convolutional_mish for ONNX tensor: 088_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 088_convolutional_mish [Mul] outputs: [088_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 090_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 087_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional [Conv] inputs: [087_convolutional_mish -> (1, 1024, 9, 9)[FLOAT]], [090_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 090_convolutional for ONNX node: 090_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 090_convolutional for ONNX tensor: 090_convolutional
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional [Conv] outputs: [090_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 090_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_bn [BatchNormalization] inputs: [090_convolutional -> (1, 512, 9, 9)[FLOAT]], [090_convolutional_bn_scale -> (512)[FLOAT]], [090_convolutional_bn_bias -> (512)[FLOAT]], [090_convolutional_bn_mean -> (512)[FLOAT]], [090_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 090_convolutional_bn for ONNX node: 090_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 090_convolutional_bn for ONNX tensor: 090_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_bn [BatchNormalization] outputs: [090_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 090_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_softplus [Softplus] inputs: [090_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 090_convolutional_softplus for ONNX node: 090_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 090_convolutional_softplus for ONNX tensor: 090_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_softplus [Softplus] outputs: [090_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 090_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_tanh [Tanh] inputs: [090_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 090_convolutional_tanh for ONNX node: 090_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 090_convolutional_tanh for ONNX tensor: 090_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_tanh [Tanh] outputs: [090_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 090_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_mish [Mul] inputs: [090_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [090_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 090_convolutional_mish for ONNX node: 090_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 090_convolutional_mish for ONNX tensor: 090_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 090_convolutional_mish [Mul] outputs: [090_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 091_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional [Conv] inputs: [090_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [091_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 091_convolutional for ONNX node: 091_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 091_convolutional for ONNX tensor: 091_convolutional
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional [Conv] outputs: [091_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 091_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_bn [BatchNormalization] inputs: [091_convolutional -> (1, 512, 9, 9)[FLOAT]], [091_convolutional_bn_scale -> (512)[FLOAT]], [091_convolutional_bn_bias -> (512)[FLOAT]], [091_convolutional_bn_mean -> (512)[FLOAT]], [091_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 091_convolutional_bn for ONNX node: 091_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 091_convolutional_bn for ONNX tensor: 091_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_bn [BatchNormalization] outputs: [091_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 091_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_softplus [Softplus] inputs: [091_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 091_convolutional_softplus for ONNX node: 091_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 091_convolutional_softplus for ONNX tensor: 091_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_softplus [Softplus] outputs: [091_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 091_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_tanh [Tanh] inputs: [091_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 091_convolutional_tanh for ONNX node: 091_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 091_convolutional_tanh for ONNX tensor: 091_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_tanh [Tanh] outputs: [091_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 091_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_mish [Mul] inputs: [091_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [091_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 091_convolutional_mish for ONNX node: 091_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 091_convolutional_mish for ONNX tensor: 091_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 091_convolutional_mish [Mul] outputs: [091_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 092_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 091_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional [Conv] inputs: [091_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [092_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 092_convolutional for ONNX node: 092_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 092_convolutional for ONNX tensor: 092_convolutional
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional [Conv] outputs: [092_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 092_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_bn [BatchNormalization] inputs: [092_convolutional -> (1, 512, 9, 9)[FLOAT]], [092_convolutional_bn_scale -> (512)[FLOAT]], [092_convolutional_bn_bias -> (512)[FLOAT]], [092_convolutional_bn_mean -> (512)[FLOAT]], [092_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 092_convolutional_bn for ONNX node: 092_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 092_convolutional_bn for ONNX tensor: 092_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_bn [BatchNormalization] outputs: [092_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 092_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_softplus [Softplus] inputs: [092_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 092_convolutional_softplus for ONNX node: 092_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 092_convolutional_softplus for ONNX tensor: 092_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_softplus [Softplus] outputs: [092_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 092_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_tanh [Tanh] inputs: [092_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 092_convolutional_tanh for ONNX node: 092_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 092_convolutional_tanh for ONNX tensor: 092_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_tanh [Tanh] outputs: [092_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 092_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_mish [Mul] inputs: [092_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [092_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 092_convolutional_mish for ONNX node: 092_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 092_convolutional_mish for ONNX tensor: 092_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 092_convolutional_mish [Mul] outputs: [092_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 093_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 092_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 090_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 093_shortcut [Add] inputs: [092_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [090_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 093_shortcut for ONNX node: 093_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 093_shortcut for ONNX tensor: 093_shortcut
[05/21/2022-02:47:14] [V] [TRT] 093_shortcut [Add] outputs: [093_shortcut -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 094_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 093_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional [Conv] inputs: [093_shortcut -> (1, 512, 9, 9)[FLOAT]], [094_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 094_convolutional for ONNX node: 094_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 094_convolutional for ONNX tensor: 094_convolutional
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional [Conv] outputs: [094_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 094_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_bn [BatchNormalization] inputs: [094_convolutional -> (1, 512, 9, 9)[FLOAT]], [094_convolutional_bn_scale -> (512)[FLOAT]], [094_convolutional_bn_bias -> (512)[FLOAT]], [094_convolutional_bn_mean -> (512)[FLOAT]], [094_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 094_convolutional_bn for ONNX node: 094_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 094_convolutional_bn for ONNX tensor: 094_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_bn [BatchNormalization] outputs: [094_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 094_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_softplus [Softplus] inputs: [094_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 094_convolutional_softplus for ONNX node: 094_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 094_convolutional_softplus for ONNX tensor: 094_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_softplus [Softplus] outputs: [094_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 094_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_tanh [Tanh] inputs: [094_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 094_convolutional_tanh for ONNX node: 094_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 094_convolutional_tanh for ONNX tensor: 094_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_tanh [Tanh] outputs: [094_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 094_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_mish [Mul] inputs: [094_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [094_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 094_convolutional_mish for ONNX node: 094_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 094_convolutional_mish for ONNX tensor: 094_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 094_convolutional_mish [Mul] outputs: [094_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 095_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 094_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional [Conv] inputs: [094_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [095_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 095_convolutional for ONNX node: 095_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 095_convolutional for ONNX tensor: 095_convolutional
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional [Conv] outputs: [095_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 095_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_bn [BatchNormalization] inputs: [095_convolutional -> (1, 512, 9, 9)[FLOAT]], [095_convolutional_bn_scale -> (512)[FLOAT]], [095_convolutional_bn_bias -> (512)[FLOAT]], [095_convolutional_bn_mean -> (512)[FLOAT]], [095_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 095_convolutional_bn for ONNX node: 095_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 095_convolutional_bn for ONNX tensor: 095_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_bn [BatchNormalization] outputs: [095_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 095_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_softplus [Softplus] inputs: [095_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 095_convolutional_softplus for ONNX node: 095_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 095_convolutional_softplus for ONNX tensor: 095_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_softplus [Softplus] outputs: [095_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 095_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_tanh [Tanh] inputs: [095_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 095_convolutional_tanh for ONNX node: 095_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 095_convolutional_tanh for ONNX tensor: 095_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_tanh [Tanh] outputs: [095_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 095_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_mish [Mul] inputs: [095_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [095_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 095_convolutional_mish for ONNX node: 095_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 095_convolutional_mish for ONNX tensor: 095_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 095_convolutional_mish [Mul] outputs: [095_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 096_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 095_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 093_shortcut
[05/21/2022-02:47:14] [V] [TRT] 096_shortcut [Add] inputs: [095_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [093_shortcut -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 096_shortcut for ONNX node: 096_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 096_shortcut for ONNX tensor: 096_shortcut
[05/21/2022-02:47:14] [V] [TRT] 096_shortcut [Add] outputs: [096_shortcut -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 097_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 096_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional [Conv] inputs: [096_shortcut -> (1, 512, 9, 9)[FLOAT]], [097_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 097_convolutional for ONNX node: 097_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 097_convolutional for ONNX tensor: 097_convolutional
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional [Conv] outputs: [097_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 097_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_bn [BatchNormalization] inputs: [097_convolutional -> (1, 512, 9, 9)[FLOAT]], [097_convolutional_bn_scale -> (512)[FLOAT]], [097_convolutional_bn_bias -> (512)[FLOAT]], [097_convolutional_bn_mean -> (512)[FLOAT]], [097_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 097_convolutional_bn for ONNX node: 097_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 097_convolutional_bn for ONNX tensor: 097_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_bn [BatchNormalization] outputs: [097_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 097_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_softplus [Softplus] inputs: [097_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 097_convolutional_softplus for ONNX node: 097_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 097_convolutional_softplus for ONNX tensor: 097_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_softplus [Softplus] outputs: [097_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 097_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_tanh [Tanh] inputs: [097_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 097_convolutional_tanh for ONNX node: 097_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 097_convolutional_tanh for ONNX tensor: 097_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_tanh [Tanh] outputs: [097_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 097_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_mish [Mul] inputs: [097_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [097_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 097_convolutional_mish for ONNX node: 097_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 097_convolutional_mish for ONNX tensor: 097_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 097_convolutional_mish [Mul] outputs: [097_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 098_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 097_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional [Conv] inputs: [097_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [098_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 098_convolutional for ONNX node: 098_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 098_convolutional for ONNX tensor: 098_convolutional
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional [Conv] outputs: [098_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 098_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_bn [BatchNormalization] inputs: [098_convolutional -> (1, 512, 9, 9)[FLOAT]], [098_convolutional_bn_scale -> (512)[FLOAT]], [098_convolutional_bn_bias -> (512)[FLOAT]], [098_convolutional_bn_mean -> (512)[FLOAT]], [098_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 098_convolutional_bn for ONNX node: 098_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 098_convolutional_bn for ONNX tensor: 098_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_bn [BatchNormalization] outputs: [098_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 098_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_softplus [Softplus] inputs: [098_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 098_convolutional_softplus for ONNX node: 098_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 098_convolutional_softplus for ONNX tensor: 098_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_softplus [Softplus] outputs: [098_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 098_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_tanh [Tanh] inputs: [098_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 098_convolutional_tanh for ONNX node: 098_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 098_convolutional_tanh for ONNX tensor: 098_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_tanh [Tanh] outputs: [098_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 098_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_mish [Mul] inputs: [098_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [098_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 098_convolutional_mish for ONNX node: 098_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 098_convolutional_mish for ONNX tensor: 098_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 098_convolutional_mish [Mul] outputs: [098_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 099_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 098_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 096_shortcut
[05/21/2022-02:47:14] [V] [TRT] 099_shortcut [Add] inputs: [098_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [096_shortcut -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 099_shortcut for ONNX node: 099_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 099_shortcut for ONNX tensor: 099_shortcut
[05/21/2022-02:47:14] [V] [TRT] 099_shortcut [Add] outputs: [099_shortcut -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 100_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 099_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional [Conv] inputs: [099_shortcut -> (1, 512, 9, 9)[FLOAT]], [100_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 100_convolutional for ONNX node: 100_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 100_convolutional for ONNX tensor: 100_convolutional
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional [Conv] outputs: [100_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 100_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_bn [BatchNormalization] inputs: [100_convolutional -> (1, 512, 9, 9)[FLOAT]], [100_convolutional_bn_scale -> (512)[FLOAT]], [100_convolutional_bn_bias -> (512)[FLOAT]], [100_convolutional_bn_mean -> (512)[FLOAT]], [100_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 100_convolutional_bn for ONNX node: 100_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 100_convolutional_bn for ONNX tensor: 100_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_bn [BatchNormalization] outputs: [100_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 100_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_softplus [Softplus] inputs: [100_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 100_convolutional_softplus for ONNX node: 100_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 100_convolutional_softplus for ONNX tensor: 100_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_softplus [Softplus] outputs: [100_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 100_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_tanh [Tanh] inputs: [100_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 100_convolutional_tanh for ONNX node: 100_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 100_convolutional_tanh for ONNX tensor: 100_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_tanh [Tanh] outputs: [100_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 100_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_mish [Mul] inputs: [100_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [100_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 100_convolutional_mish for ONNX node: 100_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 100_convolutional_mish for ONNX tensor: 100_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 100_convolutional_mish [Mul] outputs: [100_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 101_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 100_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional [Conv] inputs: [100_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [101_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 101_convolutional for ONNX node: 101_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 101_convolutional for ONNX tensor: 101_convolutional
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional [Conv] outputs: [101_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 101_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_bn [BatchNormalization] inputs: [101_convolutional -> (1, 512, 9, 9)[FLOAT]], [101_convolutional_bn_scale -> (512)[FLOAT]], [101_convolutional_bn_bias -> (512)[FLOAT]], [101_convolutional_bn_mean -> (512)[FLOAT]], [101_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 101_convolutional_bn for ONNX node: 101_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 101_convolutional_bn for ONNX tensor: 101_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_bn [BatchNormalization] outputs: [101_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 101_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_softplus [Softplus] inputs: [101_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 101_convolutional_softplus for ONNX node: 101_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 101_convolutional_softplus for ONNX tensor: 101_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_softplus [Softplus] outputs: [101_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 101_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_tanh [Tanh] inputs: [101_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 101_convolutional_tanh for ONNX node: 101_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 101_convolutional_tanh for ONNX tensor: 101_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_tanh [Tanh] outputs: [101_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 101_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_mish [Mul] inputs: [101_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [101_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 101_convolutional_mish for ONNX node: 101_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 101_convolutional_mish for ONNX tensor: 101_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 101_convolutional_mish [Mul] outputs: [101_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 102_shortcut [Add]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 101_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 099_shortcut
[05/21/2022-02:47:14] [V] [TRT] 102_shortcut [Add] inputs: [101_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [099_shortcut -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 102_shortcut for ONNX node: 102_shortcut
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 102_shortcut for ONNX tensor: 102_shortcut
[05/21/2022-02:47:14] [V] [TRT] 102_shortcut [Add] outputs: [102_shortcut -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 103_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 102_shortcut
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional [Conv] inputs: [102_shortcut -> (1, 512, 9, 9)[FLOAT]], [103_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 103_convolutional for ONNX node: 103_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 103_convolutional for ONNX tensor: 103_convolutional
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional [Conv] outputs: [103_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 103_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_bn [BatchNormalization] inputs: [103_convolutional -> (1, 512, 9, 9)[FLOAT]], [103_convolutional_bn_scale -> (512)[FLOAT]], [103_convolutional_bn_bias -> (512)[FLOAT]], [103_convolutional_bn_mean -> (512)[FLOAT]], [103_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 103_convolutional_bn for ONNX node: 103_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 103_convolutional_bn for ONNX tensor: 103_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_bn [BatchNormalization] outputs: [103_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 103_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_softplus [Softplus] inputs: [103_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 103_convolutional_softplus for ONNX node: 103_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 103_convolutional_softplus for ONNX tensor: 103_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_softplus [Softplus] outputs: [103_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 103_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_tanh [Tanh] inputs: [103_convolutional_softplus -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 103_convolutional_tanh for ONNX node: 103_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 103_convolutional_tanh for ONNX tensor: 103_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_tanh [Tanh] outputs: [103_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 103_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_mish [Mul] inputs: [103_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], [103_convolutional_tanh -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 103_convolutional_mish for ONNX node: 103_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 103_convolutional_mish for ONNX tensor: 103_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 103_convolutional_mish [Mul] outputs: [103_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 104_route [Concat]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 103_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 088_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 104_route [Concat] inputs: [103_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], [088_convolutional_mish -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 104_route for ONNX node: 104_route
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 104_route for ONNX tensor: 104_route
[05/21/2022-02:47:14] [V] [TRT] 104_route [Concat] outputs: [104_route -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 105_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 104_route
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional [Conv] inputs: [104_route -> (1, 1024, 9, 9)[FLOAT]], [105_convolutional_conv_weights -> (1024, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 105_convolutional for ONNX node: 105_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 105_convolutional for ONNX tensor: 105_convolutional
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional [Conv] outputs: [105_convolutional -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 105_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_bn [BatchNormalization] inputs: [105_convolutional -> (1, 1024, 9, 9)[FLOAT]], [105_convolutional_bn_scale -> (1024)[FLOAT]], [105_convolutional_bn_bias -> (1024)[FLOAT]], [105_convolutional_bn_mean -> (1024)[FLOAT]], [105_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 105_convolutional_bn for ONNX node: 105_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 105_convolutional_bn for ONNX tensor: 105_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_bn [BatchNormalization] outputs: [105_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 105_convolutional_softplus [Softplus]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_softplus [Softplus] inputs: [105_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 105_convolutional_softplus for ONNX node: 105_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 105_convolutional_softplus for ONNX tensor: 105_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_softplus [Softplus] outputs: [105_convolutional_softplus -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 105_convolutional_tanh [Tanh]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_softplus
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_tanh [Tanh] inputs: [105_convolutional_softplus -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 105_convolutional_tanh for ONNX node: 105_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 105_convolutional_tanh for ONNX tensor: 105_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_tanh [Tanh] outputs: [105_convolutional_tanh -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 105_convolutional_mish [Mul]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_tanh
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_mish [Mul] inputs: [105_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], [105_convolutional_tanh -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 105_convolutional_mish for ONNX node: 105_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 105_convolutional_mish for ONNX tensor: 105_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] 105_convolutional_mish [Mul] outputs: [105_convolutional_mish -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 106_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 105_convolutional_mish
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 106_convolutional [Conv] inputs: [105_convolutional_mish -> (1, 1024, 9, 9)[FLOAT]], [106_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 106_convolutional for ONNX node: 106_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 106_convolutional for ONNX tensor: 106_convolutional
[05/21/2022-02:47:14] [V] [TRT] 106_convolutional [Conv] outputs: [106_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 106_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 106_convolutional_bn [BatchNormalization] inputs: [106_convolutional -> (1, 512, 9, 9)[FLOAT]], [106_convolutional_bn_scale -> (512)[FLOAT]], [106_convolutional_bn_bias -> (512)[FLOAT]], [106_convolutional_bn_mean -> (512)[FLOAT]], [106_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 106_convolutional_bn for ONNX node: 106_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 106_convolutional_bn for ONNX tensor: 106_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 106_convolutional_bn [BatchNormalization] outputs: [106_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 106_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 106_convolutional_lrelu [LeakyRelu] inputs: [106_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 106_convolutional_lrelu for ONNX node: 106_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 106_convolutional_lrelu for ONNX tensor: 106_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 106_convolutional_lrelu [LeakyRelu] outputs: [106_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 107_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 106_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 107_convolutional [Conv] inputs: [106_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], [107_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 107_convolutional for ONNX node: 107_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 107_convolutional for ONNX tensor: 107_convolutional
[05/21/2022-02:47:14] [V] [TRT] 107_convolutional [Conv] outputs: [107_convolutional -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 107_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 107_convolutional_bn [BatchNormalization] inputs: [107_convolutional -> (1, 1024, 9, 9)[FLOAT]], [107_convolutional_bn_scale -> (1024)[FLOAT]], [107_convolutional_bn_bias -> (1024)[FLOAT]], [107_convolutional_bn_mean -> (1024)[FLOAT]], [107_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 107_convolutional_bn for ONNX node: 107_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 107_convolutional_bn for ONNX tensor: 107_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 107_convolutional_bn [BatchNormalization] outputs: [107_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 107_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 107_convolutional_lrelu [LeakyRelu] inputs: [107_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 107_convolutional_lrelu for ONNX node: 107_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 107_convolutional_lrelu for ONNX tensor: 107_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 107_convolutional_lrelu [LeakyRelu] outputs: [107_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 108_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 107_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 108_convolutional [Conv] inputs: [107_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], [108_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 108_convolutional for ONNX node: 108_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 108_convolutional for ONNX tensor: 108_convolutional
[05/21/2022-02:47:14] [V] [TRT] 108_convolutional [Conv] outputs: [108_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 108_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 108_convolutional_bn [BatchNormalization] inputs: [108_convolutional -> (1, 512, 9, 9)[FLOAT]], [108_convolutional_bn_scale -> (512)[FLOAT]], [108_convolutional_bn_bias -> (512)[FLOAT]], [108_convolutional_bn_mean -> (512)[FLOAT]], [108_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 108_convolutional_bn for ONNX node: 108_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 108_convolutional_bn for ONNX tensor: 108_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 108_convolutional_bn [BatchNormalization] outputs: [108_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 108_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 108_convolutional_lrelu [LeakyRelu] inputs: [108_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 108_convolutional_lrelu for ONNX node: 108_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 108_convolutional_lrelu for ONNX tensor: 108_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 108_convolutional_lrelu [LeakyRelu] outputs: [108_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 109_maxpool [MaxPool]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 109_maxpool [MaxPool] inputs: [108_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 109_maxpool for ONNX node: 109_maxpool
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 109_maxpool for ONNX tensor: 109_maxpool
[05/21/2022-02:47:14] [V] [TRT] 109_maxpool [MaxPool] outputs: [109_maxpool -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 111_maxpool [MaxPool]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 111_maxpool [MaxPool] inputs: [108_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 111_maxpool for ONNX node: 111_maxpool
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 111_maxpool for ONNX tensor: 111_maxpool
[05/21/2022-02:47:14] [V] [TRT] 111_maxpool [MaxPool] outputs: [111_maxpool -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 113_maxpool [MaxPool]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 113_maxpool [MaxPool] inputs: [108_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 113_maxpool for ONNX node: 113_maxpool
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 113_maxpool for ONNX tensor: 113_maxpool
[05/21/2022-02:47:14] [V] [TRT] 113_maxpool [MaxPool] outputs: [113_maxpool -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 114_route [Concat]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 113_maxpool
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 111_maxpool
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 109_maxpool
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 114_route [Concat] inputs: [113_maxpool -> (1, 512, 9, 9)[FLOAT]], [111_maxpool -> (1, 512, 9, 9)[FLOAT]], [109_maxpool -> (1, 512, 9, 9)[FLOAT]], [108_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 114_route for ONNX node: 114_route
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 114_route for ONNX tensor: 114_route
[05/21/2022-02:47:14] [V] [TRT] 114_route [Concat] outputs: [114_route -> (1, 2048, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 115_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 114_route
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 115_convolutional [Conv] inputs: [114_route -> (1, 2048, 9, 9)[FLOAT]], [115_convolutional_conv_weights -> (512, 2048, 1, 1)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 2048, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 115_convolutional for ONNX node: 115_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 115_convolutional for ONNX tensor: 115_convolutional
[05/21/2022-02:47:14] [V] [TRT] 115_convolutional [Conv] outputs: [115_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 115_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 115_convolutional_bn [BatchNormalization] inputs: [115_convolutional -> (1, 512, 9, 9)[FLOAT]], [115_convolutional_bn_scale -> (512)[FLOAT]], [115_convolutional_bn_bias -> (512)[FLOAT]], [115_convolutional_bn_mean -> (512)[FLOAT]], [115_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 115_convolutional_bn for ONNX node: 115_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 115_convolutional_bn for ONNX tensor: 115_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 115_convolutional_bn [BatchNormalization] outputs: [115_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 115_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] 115_convolutional_lrelu [LeakyRelu] inputs: [115_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 115_convolutional_lrelu for ONNX node: 115_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 115_convolutional_lrelu for ONNX tensor: 115_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] 115_convolutional_lrelu [LeakyRelu] outputs: [115_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 116_convolutional [Conv]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 115_convolutional_lrelu
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 116_convolutional_conv_weights
[05/21/2022-02:47:14] [V] [TRT] 116_convolutional [Conv] inputs: [115_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], [116_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 116_convolutional for ONNX node: 116_convolutional
[05/21/2022-02:47:14] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-02:47:14] [V] [TRT] Convolution output dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 116_convolutional for ONNX tensor: 116_convolutional
[05/21/2022-02:47:14] [V] [TRT] 116_convolutional [Conv] outputs: [116_convolutional -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Parsing node: 116_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 116_convolutional
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 116_convolutional_bn_scale
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 116_convolutional_bn_bias
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 116_convolutional_bn_mean
[05/21/2022-02:47:14] [V] [TRT] Searching for input: 116_convolutional_bn_var
[05/21/2022-02:47:14] [V] [TRT] 116_convolutional_bn [BatchNormalization] inputs: [116_convolutional -> (1, 1024, 9, 9)[FLOAT]], [116_convolutional_bn_scale -> (1024)[FLOAT]], [116_convolutional_bn_bias -> (1024)[FLOAT]], [116_convolutional_bn_mean -> (1024)[FLOAT]], [116_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-02:47:14] [V] [TRT] Registering layer: 116_convolutional_bn for ONNX node: 116_convolutional_bn
[05/21/2022-02:47:14] [V] [TRT] Registering tensor: 116_convolutional_bn for ONNX tensor: 116_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 116_convolutional_bn [BatchNormalization] outputs: [116_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 116_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 116_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 116_convolutional_lrelu [LeakyRelu] inputs: [116_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 116_convolutional_lrelu for ONNX node: 116_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 116_convolutional_lrelu for ONNX tensor: 116_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 116_convolutional_lrelu [LeakyRelu] outputs: [116_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 117_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 116_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 117_convolutional [Conv] inputs: [116_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], [117_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 117_convolutional for ONNX node: 117_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 117_convolutional for ONNX tensor: 117_convolutional
[05/21/2022-02:47:15] [V] [TRT] 117_convolutional [Conv] outputs: [117_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 117_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 117_convolutional_bn [BatchNormalization] inputs: [117_convolutional -> (1, 512, 9, 9)[FLOAT]], [117_convolutional_bn_scale -> (512)[FLOAT]], [117_convolutional_bn_bias -> (512)[FLOAT]], [117_convolutional_bn_mean -> (512)[FLOAT]], [117_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 117_convolutional_bn for ONNX node: 117_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 117_convolutional_bn for ONNX tensor: 117_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 117_convolutional_bn [BatchNormalization] outputs: [117_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 117_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 117_convolutional_lrelu [LeakyRelu] inputs: [117_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 117_convolutional_lrelu for ONNX node: 117_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 117_convolutional_lrelu for ONNX tensor: 117_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 117_convolutional_lrelu [LeakyRelu] outputs: [117_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 118_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 118_convolutional [Conv] inputs: [117_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], [118_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 118_convolutional for ONNX node: 118_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 118_convolutional for ONNX tensor: 118_convolutional
[05/21/2022-02:47:15] [V] [TRT] 118_convolutional [Conv] outputs: [118_convolutional -> (1, 256, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 118_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 118_convolutional_bn [BatchNormalization] inputs: [118_convolutional -> (1, 256, 9, 9)[FLOAT]], [118_convolutional_bn_scale -> (256)[FLOAT]], [118_convolutional_bn_bias -> (256)[FLOAT]], [118_convolutional_bn_mean -> (256)[FLOAT]], [118_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 118_convolutional_bn for ONNX node: 118_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 118_convolutional_bn for ONNX tensor: 118_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 118_convolutional_bn [BatchNormalization] outputs: [118_convolutional_bn -> (1, 256, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 118_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 118_convolutional_lrelu [LeakyRelu] inputs: [118_convolutional_bn -> (1, 256, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 118_convolutional_lrelu for ONNX node: 118_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 118_convolutional_lrelu for ONNX tensor: 118_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 118_convolutional_lrelu [LeakyRelu] outputs: [118_convolutional_lrelu -> (1, 256, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 119_upsample [Upsample]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 118_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 119_upsample_scale
[05/21/2022-02:47:15] [V] [TRT] 119_upsample [Upsample] inputs: [118_convolutional_lrelu -> (1, 256, 9, 9)[FLOAT]], [119_upsample_scale -> (4)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 119_upsample for ONNX node: 119_upsample
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 119_upsample for ONNX tensor: 119_upsample
[05/21/2022-02:47:15] [V] [TRT] 119_upsample [Upsample] outputs: [119_upsample -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 121_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 086_convolutional_mish
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 121_convolutional [Conv] inputs: [086_convolutional_mish -> (1, 512, 18, 18)[FLOAT]], [121_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 121_convolutional for ONNX node: 121_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 121_convolutional for ONNX tensor: 121_convolutional
[05/21/2022-02:47:15] [V] [TRT] 121_convolutional [Conv] outputs: [121_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 121_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 121_convolutional_bn [BatchNormalization] inputs: [121_convolutional -> (1, 256, 18, 18)[FLOAT]], [121_convolutional_bn_scale -> (256)[FLOAT]], [121_convolutional_bn_bias -> (256)[FLOAT]], [121_convolutional_bn_mean -> (256)[FLOAT]], [121_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 121_convolutional_bn for ONNX node: 121_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 121_convolutional_bn for ONNX tensor: 121_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 121_convolutional_bn [BatchNormalization] outputs: [121_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 121_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 121_convolutional_lrelu [LeakyRelu] inputs: [121_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 121_convolutional_lrelu for ONNX node: 121_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 121_convolutional_lrelu for ONNX tensor: 121_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 121_convolutional_lrelu [LeakyRelu] outputs: [121_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 122_route [Concat]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 121_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 119_upsample
[05/21/2022-02:47:15] [V] [TRT] 122_route [Concat] inputs: [121_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [119_upsample -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 122_route for ONNX node: 122_route
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 122_route for ONNX tensor: 122_route
[05/21/2022-02:47:15] [V] [TRT] 122_route [Concat] outputs: [122_route -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 123_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 122_route
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 123_convolutional [Conv] inputs: [122_route -> (1, 512, 18, 18)[FLOAT]], [123_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 123_convolutional for ONNX node: 123_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 123_convolutional for ONNX tensor: 123_convolutional
[05/21/2022-02:47:15] [V] [TRT] 123_convolutional [Conv] outputs: [123_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 123_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 123_convolutional_bn [BatchNormalization] inputs: [123_convolutional -> (1, 256, 18, 18)[FLOAT]], [123_convolutional_bn_scale -> (256)[FLOAT]], [123_convolutional_bn_bias -> (256)[FLOAT]], [123_convolutional_bn_mean -> (256)[FLOAT]], [123_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 123_convolutional_bn for ONNX node: 123_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 123_convolutional_bn for ONNX tensor: 123_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 123_convolutional_bn [BatchNormalization] outputs: [123_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 123_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 123_convolutional_lrelu [LeakyRelu] inputs: [123_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 123_convolutional_lrelu for ONNX node: 123_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 123_convolutional_lrelu for ONNX tensor: 123_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 123_convolutional_lrelu [LeakyRelu] outputs: [123_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 124_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 123_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 124_convolutional [Conv] inputs: [123_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [124_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 124_convolutional for ONNX node: 124_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 124_convolutional for ONNX tensor: 124_convolutional
[05/21/2022-02:47:15] [V] [TRT] 124_convolutional [Conv] outputs: [124_convolutional -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 124_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 124_convolutional_bn [BatchNormalization] inputs: [124_convolutional -> (1, 512, 18, 18)[FLOAT]], [124_convolutional_bn_scale -> (512)[FLOAT]], [124_convolutional_bn_bias -> (512)[FLOAT]], [124_convolutional_bn_mean -> (512)[FLOAT]], [124_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 124_convolutional_bn for ONNX node: 124_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 124_convolutional_bn for ONNX tensor: 124_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 124_convolutional_bn [BatchNormalization] outputs: [124_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 124_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 124_convolutional_lrelu [LeakyRelu] inputs: [124_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 124_convolutional_lrelu for ONNX node: 124_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 124_convolutional_lrelu for ONNX tensor: 124_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 124_convolutional_lrelu [LeakyRelu] outputs: [124_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 125_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 124_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 125_convolutional [Conv] inputs: [124_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], [125_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 125_convolutional for ONNX node: 125_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 125_convolutional for ONNX tensor: 125_convolutional
[05/21/2022-02:47:15] [V] [TRT] 125_convolutional [Conv] outputs: [125_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 125_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 125_convolutional_bn [BatchNormalization] inputs: [125_convolutional -> (1, 256, 18, 18)[FLOAT]], [125_convolutional_bn_scale -> (256)[FLOAT]], [125_convolutional_bn_bias -> (256)[FLOAT]], [125_convolutional_bn_mean -> (256)[FLOAT]], [125_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 125_convolutional_bn for ONNX node: 125_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 125_convolutional_bn for ONNX tensor: 125_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 125_convolutional_bn [BatchNormalization] outputs: [125_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 125_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 125_convolutional_lrelu [LeakyRelu] inputs: [125_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 125_convolutional_lrelu for ONNX node: 125_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 125_convolutional_lrelu for ONNX tensor: 125_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 125_convolutional_lrelu [LeakyRelu] outputs: [125_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 126_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 125_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 126_convolutional [Conv] inputs: [125_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [126_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 126_convolutional for ONNX node: 126_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 126_convolutional for ONNX tensor: 126_convolutional
[05/21/2022-02:47:15] [V] [TRT] 126_convolutional [Conv] outputs: [126_convolutional -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 126_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 126_convolutional_bn [BatchNormalization] inputs: [126_convolutional -> (1, 512, 18, 18)[FLOAT]], [126_convolutional_bn_scale -> (512)[FLOAT]], [126_convolutional_bn_bias -> (512)[FLOAT]], [126_convolutional_bn_mean -> (512)[FLOAT]], [126_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 126_convolutional_bn for ONNX node: 126_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 126_convolutional_bn for ONNX tensor: 126_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 126_convolutional_bn [BatchNormalization] outputs: [126_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 126_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 126_convolutional_lrelu [LeakyRelu] inputs: [126_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 126_convolutional_lrelu for ONNX node: 126_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 126_convolutional_lrelu for ONNX tensor: 126_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 126_convolutional_lrelu [LeakyRelu] outputs: [126_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 127_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 126_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 127_convolutional [Conv] inputs: [126_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], [127_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 127_convolutional for ONNX node: 127_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 127_convolutional for ONNX tensor: 127_convolutional
[05/21/2022-02:47:15] [V] [TRT] 127_convolutional [Conv] outputs: [127_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 127_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 127_convolutional_bn [BatchNormalization] inputs: [127_convolutional -> (1, 256, 18, 18)[FLOAT]], [127_convolutional_bn_scale -> (256)[FLOAT]], [127_convolutional_bn_bias -> (256)[FLOAT]], [127_convolutional_bn_mean -> (256)[FLOAT]], [127_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 127_convolutional_bn for ONNX node: 127_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 127_convolutional_bn for ONNX tensor: 127_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 127_convolutional_bn [BatchNormalization] outputs: [127_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 127_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 127_convolutional_lrelu [LeakyRelu] inputs: [127_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 127_convolutional_lrelu for ONNX node: 127_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 127_convolutional_lrelu for ONNX tensor: 127_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 127_convolutional_lrelu [LeakyRelu] outputs: [127_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 128_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 128_convolutional [Conv] inputs: [127_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [128_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 128_convolutional for ONNX node: 128_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 128, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 128_convolutional for ONNX tensor: 128_convolutional
[05/21/2022-02:47:15] [V] [TRT] 128_convolutional [Conv] outputs: [128_convolutional -> (1, 128, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 128_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 128_convolutional_bn [BatchNormalization] inputs: [128_convolutional -> (1, 128, 18, 18)[FLOAT]], [128_convolutional_bn_scale -> (128)[FLOAT]], [128_convolutional_bn_bias -> (128)[FLOAT]], [128_convolutional_bn_mean -> (128)[FLOAT]], [128_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 128_convolutional_bn for ONNX node: 128_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 128_convolutional_bn for ONNX tensor: 128_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 128_convolutional_bn [BatchNormalization] outputs: [128_convolutional_bn -> (1, 128, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 128_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 128_convolutional_lrelu [LeakyRelu] inputs: [128_convolutional_bn -> (1, 128, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 128_convolutional_lrelu for ONNX node: 128_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 128_convolutional_lrelu for ONNX tensor: 128_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 128_convolutional_lrelu [LeakyRelu] outputs: [128_convolutional_lrelu -> (1, 128, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 129_upsample [Upsample]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 128_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 129_upsample_scale
[05/21/2022-02:47:15] [V] [TRT] 129_upsample [Upsample] inputs: [128_convolutional_lrelu -> (1, 128, 18, 18)[FLOAT]], [129_upsample_scale -> (4)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 129_upsample for ONNX node: 129_upsample
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 129_upsample for ONNX tensor: 129_upsample
[05/21/2022-02:47:15] [V] [TRT] 129_upsample [Upsample] outputs: [129_upsample -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 131_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 055_convolutional_mish
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 131_convolutional [Conv] inputs: [055_convolutional_mish -> (1, 256, 36, 36)[FLOAT]], [131_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 131_convolutional for ONNX node: 131_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 131_convolutional for ONNX tensor: 131_convolutional
[05/21/2022-02:47:15] [V] [TRT] 131_convolutional [Conv] outputs: [131_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 131_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 131_convolutional_bn [BatchNormalization] inputs: [131_convolutional -> (1, 128, 36, 36)[FLOAT]], [131_convolutional_bn_scale -> (128)[FLOAT]], [131_convolutional_bn_bias -> (128)[FLOAT]], [131_convolutional_bn_mean -> (128)[FLOAT]], [131_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 131_convolutional_bn for ONNX node: 131_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 131_convolutional_bn for ONNX tensor: 131_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 131_convolutional_bn [BatchNormalization] outputs: [131_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 131_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 131_convolutional_lrelu [LeakyRelu] inputs: [131_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 131_convolutional_lrelu for ONNX node: 131_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 131_convolutional_lrelu for ONNX tensor: 131_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 131_convolutional_lrelu [LeakyRelu] outputs: [131_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 132_route [Concat]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 131_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 129_upsample
[05/21/2022-02:47:15] [V] [TRT] 132_route [Concat] inputs: [131_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], [129_upsample -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 132_route for ONNX node: 132_route
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 132_route for ONNX tensor: 132_route
[05/21/2022-02:47:15] [V] [TRT] 132_route [Concat] outputs: [132_route -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 133_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 132_route
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 133_convolutional [Conv] inputs: [132_route -> (1, 256, 36, 36)[FLOAT]], [133_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 133_convolutional for ONNX node: 133_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 133_convolutional for ONNX tensor: 133_convolutional
[05/21/2022-02:47:15] [V] [TRT] 133_convolutional [Conv] outputs: [133_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 133_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 133_convolutional_bn [BatchNormalization] inputs: [133_convolutional -> (1, 128, 36, 36)[FLOAT]], [133_convolutional_bn_scale -> (128)[FLOAT]], [133_convolutional_bn_bias -> (128)[FLOAT]], [133_convolutional_bn_mean -> (128)[FLOAT]], [133_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 133_convolutional_bn for ONNX node: 133_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 133_convolutional_bn for ONNX tensor: 133_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 133_convolutional_bn [BatchNormalization] outputs: [133_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 133_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 133_convolutional_lrelu [LeakyRelu] inputs: [133_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 133_convolutional_lrelu for ONNX node: 133_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 133_convolutional_lrelu for ONNX tensor: 133_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 133_convolutional_lrelu [LeakyRelu] outputs: [133_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 134_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 133_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 134_convolutional [Conv] inputs: [133_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], [134_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 134_convolutional for ONNX node: 134_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 134_convolutional for ONNX tensor: 134_convolutional
[05/21/2022-02:47:15] [V] [TRT] 134_convolutional [Conv] outputs: [134_convolutional -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 134_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 134_convolutional_bn [BatchNormalization] inputs: [134_convolutional -> (1, 256, 36, 36)[FLOAT]], [134_convolutional_bn_scale -> (256)[FLOAT]], [134_convolutional_bn_bias -> (256)[FLOAT]], [134_convolutional_bn_mean -> (256)[FLOAT]], [134_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 134_convolutional_bn for ONNX node: 134_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 134_convolutional_bn for ONNX tensor: 134_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 134_convolutional_bn [BatchNormalization] outputs: [134_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 134_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 134_convolutional_lrelu [LeakyRelu] inputs: [134_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 134_convolutional_lrelu for ONNX node: 134_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 134_convolutional_lrelu for ONNX tensor: 134_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 134_convolutional_lrelu [LeakyRelu] outputs: [134_convolutional_lrelu -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 135_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 134_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 135_convolutional [Conv] inputs: [134_convolutional_lrelu -> (1, 256, 36, 36)[FLOAT]], [135_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 135_convolutional for ONNX node: 135_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 135_convolutional for ONNX tensor: 135_convolutional
[05/21/2022-02:47:15] [V] [TRT] 135_convolutional [Conv] outputs: [135_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 135_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 135_convolutional_bn [BatchNormalization] inputs: [135_convolutional -> (1, 128, 36, 36)[FLOAT]], [135_convolutional_bn_scale -> (128)[FLOAT]], [135_convolutional_bn_bias -> (128)[FLOAT]], [135_convolutional_bn_mean -> (128)[FLOAT]], [135_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 135_convolutional_bn for ONNX node: 135_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 135_convolutional_bn for ONNX tensor: 135_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 135_convolutional_bn [BatchNormalization] outputs: [135_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 135_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 135_convolutional_lrelu [LeakyRelu] inputs: [135_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 135_convolutional_lrelu for ONNX node: 135_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 135_convolutional_lrelu for ONNX tensor: 135_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 135_convolutional_lrelu [LeakyRelu] outputs: [135_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 136_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 135_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 136_convolutional [Conv] inputs: [135_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], [136_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 136_convolutional for ONNX node: 136_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 136_convolutional for ONNX tensor: 136_convolutional
[05/21/2022-02:47:15] [V] [TRT] 136_convolutional [Conv] outputs: [136_convolutional -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 136_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 136_convolutional_bn [BatchNormalization] inputs: [136_convolutional -> (1, 256, 36, 36)[FLOAT]], [136_convolutional_bn_scale -> (256)[FLOAT]], [136_convolutional_bn_bias -> (256)[FLOAT]], [136_convolutional_bn_mean -> (256)[FLOAT]], [136_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 136_convolutional_bn for ONNX node: 136_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 136_convolutional_bn for ONNX tensor: 136_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 136_convolutional_bn [BatchNormalization] outputs: [136_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 136_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 136_convolutional_lrelu [LeakyRelu] inputs: [136_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 136_convolutional_lrelu for ONNX node: 136_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 136_convolutional_lrelu for ONNX tensor: 136_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 136_convolutional_lrelu [LeakyRelu] outputs: [136_convolutional_lrelu -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 137_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 136_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 137_convolutional [Conv] inputs: [136_convolutional_lrelu -> (1, 256, 36, 36)[FLOAT]], [137_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 137_convolutional for ONNX node: 137_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 137_convolutional for ONNX tensor: 137_convolutional
[05/21/2022-02:47:15] [V] [TRT] 137_convolutional [Conv] outputs: [137_convolutional -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 137_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 137_convolutional_bn [BatchNormalization] inputs: [137_convolutional -> (1, 128, 36, 36)[FLOAT]], [137_convolutional_bn_scale -> (128)[FLOAT]], [137_convolutional_bn_bias -> (128)[FLOAT]], [137_convolutional_bn_mean -> (128)[FLOAT]], [137_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 137_convolutional_bn for ONNX node: 137_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 137_convolutional_bn for ONNX tensor: 137_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 137_convolutional_bn [BatchNormalization] outputs: [137_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 137_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 137_convolutional_lrelu [LeakyRelu] inputs: [137_convolutional_bn -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 137_convolutional_lrelu for ONNX node: 137_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 137_convolutional_lrelu for ONNX tensor: 137_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 137_convolutional_lrelu [LeakyRelu] outputs: [137_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 138_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 138_convolutional [Conv] inputs: [137_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], [138_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 138_convolutional for ONNX node: 138_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 138_convolutional for ONNX tensor: 138_convolutional
[05/21/2022-02:47:15] [V] [TRT] 138_convolutional [Conv] outputs: [138_convolutional -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 138_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 138_convolutional_bn [BatchNormalization] inputs: [138_convolutional -> (1, 256, 36, 36)[FLOAT]], [138_convolutional_bn_scale -> (256)[FLOAT]], [138_convolutional_bn_bias -> (256)[FLOAT]], [138_convolutional_bn_mean -> (256)[FLOAT]], [138_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 138_convolutional_bn for ONNX node: 138_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 138_convolutional_bn for ONNX tensor: 138_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 138_convolutional_bn [BatchNormalization] outputs: [138_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 138_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 138_convolutional_lrelu [LeakyRelu] inputs: [138_convolutional_bn -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 138_convolutional_lrelu for ONNX node: 138_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 138_convolutional_lrelu for ONNX tensor: 138_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 138_convolutional_lrelu [LeakyRelu] outputs: [138_convolutional_lrelu -> (1, 256, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 139_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 138_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 139_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 139_convolutional_conv_bias
[05/21/2022-02:47:15] [V] [TRT] 139_convolutional [Conv] inputs: [138_convolutional_lrelu -> (1, 256, 36, 36)[FLOAT]], [139_convolutional_conv_weights -> (255, 256, 1, 1)[FLOAT]], [139_convolutional_conv_bias -> (255)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 139_convolutional for ONNX node: 139_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 255
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 255, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 139_convolutional_543 for ONNX tensor: 139_convolutional
[05/21/2022-02:47:15] [V] [TRT] 139_convolutional [Conv] outputs: [139_convolutional -> (1, 255, 36, 36)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 142_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 137_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 142_convolutional [Conv] inputs: [137_convolutional_lrelu -> (1, 128, 36, 36)[FLOAT]], [142_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 128, 36, 36)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 142_convolutional for ONNX node: 142_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 142_convolutional for ONNX tensor: 142_convolutional
[05/21/2022-02:47:15] [V] [TRT] 142_convolutional [Conv] outputs: [142_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 142_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 142_convolutional_bn [BatchNormalization] inputs: [142_convolutional -> (1, 256, 18, 18)[FLOAT]], [142_convolutional_bn_scale -> (256)[FLOAT]], [142_convolutional_bn_bias -> (256)[FLOAT]], [142_convolutional_bn_mean -> (256)[FLOAT]], [142_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 142_convolutional_bn for ONNX node: 142_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 142_convolutional_bn for ONNX tensor: 142_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 142_convolutional_bn [BatchNormalization] outputs: [142_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 142_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 142_convolutional_lrelu [LeakyRelu] inputs: [142_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 142_convolutional_lrelu for ONNX node: 142_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 142_convolutional_lrelu for ONNX tensor: 142_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 142_convolutional_lrelu [LeakyRelu] outputs: [142_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 143_route [Concat]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 142_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 127_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 143_route [Concat] inputs: [142_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [127_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 143_route for ONNX node: 143_route
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 143_route for ONNX tensor: 143_route
[05/21/2022-02:47:15] [V] [TRT] 143_route [Concat] outputs: [143_route -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 144_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 143_route
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 144_convolutional [Conv] inputs: [143_route -> (1, 512, 18, 18)[FLOAT]], [144_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 144_convolutional for ONNX node: 144_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 144_convolutional for ONNX tensor: 144_convolutional
[05/21/2022-02:47:15] [V] [TRT] 144_convolutional [Conv] outputs: [144_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 144_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 144_convolutional_bn [BatchNormalization] inputs: [144_convolutional -> (1, 256, 18, 18)[FLOAT]], [144_convolutional_bn_scale -> (256)[FLOAT]], [144_convolutional_bn_bias -> (256)[FLOAT]], [144_convolutional_bn_mean -> (256)[FLOAT]], [144_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 144_convolutional_bn for ONNX node: 144_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 144_convolutional_bn for ONNX tensor: 144_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 144_convolutional_bn [BatchNormalization] outputs: [144_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 144_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 144_convolutional_lrelu [LeakyRelu] inputs: [144_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 144_convolutional_lrelu for ONNX node: 144_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 144_convolutional_lrelu for ONNX tensor: 144_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 144_convolutional_lrelu [LeakyRelu] outputs: [144_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 145_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 144_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 145_convolutional [Conv] inputs: [144_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [145_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 145_convolutional for ONNX node: 145_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 145_convolutional for ONNX tensor: 145_convolutional
[05/21/2022-02:47:15] [V] [TRT] 145_convolutional [Conv] outputs: [145_convolutional -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 145_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 145_convolutional_bn [BatchNormalization] inputs: [145_convolutional -> (1, 512, 18, 18)[FLOAT]], [145_convolutional_bn_scale -> (512)[FLOAT]], [145_convolutional_bn_bias -> (512)[FLOAT]], [145_convolutional_bn_mean -> (512)[FLOAT]], [145_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 145_convolutional_bn for ONNX node: 145_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 145_convolutional_bn for ONNX tensor: 145_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 145_convolutional_bn [BatchNormalization] outputs: [145_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 145_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 145_convolutional_lrelu [LeakyRelu] inputs: [145_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 145_convolutional_lrelu for ONNX node: 145_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 145_convolutional_lrelu for ONNX tensor: 145_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 145_convolutional_lrelu [LeakyRelu] outputs: [145_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 146_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 145_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 146_convolutional [Conv] inputs: [145_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], [146_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 146_convolutional for ONNX node: 146_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 146_convolutional for ONNX tensor: 146_convolutional
[05/21/2022-02:47:15] [V] [TRT] 146_convolutional [Conv] outputs: [146_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 146_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 146_convolutional_bn [BatchNormalization] inputs: [146_convolutional -> (1, 256, 18, 18)[FLOAT]], [146_convolutional_bn_scale -> (256)[FLOAT]], [146_convolutional_bn_bias -> (256)[FLOAT]], [146_convolutional_bn_mean -> (256)[FLOAT]], [146_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 146_convolutional_bn for ONNX node: 146_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 146_convolutional_bn for ONNX tensor: 146_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 146_convolutional_bn [BatchNormalization] outputs: [146_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 146_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 146_convolutional_lrelu [LeakyRelu] inputs: [146_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 146_convolutional_lrelu for ONNX node: 146_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 146_convolutional_lrelu for ONNX tensor: 146_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 146_convolutional_lrelu [LeakyRelu] outputs: [146_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 147_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 146_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 147_convolutional [Conv] inputs: [146_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [147_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 147_convolutional for ONNX node: 147_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 147_convolutional for ONNX tensor: 147_convolutional
[05/21/2022-02:47:15] [V] [TRT] 147_convolutional [Conv] outputs: [147_convolutional -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 147_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 147_convolutional_bn [BatchNormalization] inputs: [147_convolutional -> (1, 512, 18, 18)[FLOAT]], [147_convolutional_bn_scale -> (512)[FLOAT]], [147_convolutional_bn_bias -> (512)[FLOAT]], [147_convolutional_bn_mean -> (512)[FLOAT]], [147_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 147_convolutional_bn for ONNX node: 147_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 147_convolutional_bn for ONNX tensor: 147_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 147_convolutional_bn [BatchNormalization] outputs: [147_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 147_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 147_convolutional_lrelu [LeakyRelu] inputs: [147_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 147_convolutional_lrelu for ONNX node: 147_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 147_convolutional_lrelu for ONNX tensor: 147_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 147_convolutional_lrelu [LeakyRelu] outputs: [147_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 148_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 147_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 148_convolutional [Conv] inputs: [147_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], [148_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 148_convolutional for ONNX node: 148_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 148_convolutional for ONNX tensor: 148_convolutional
[05/21/2022-02:47:15] [V] [TRT] 148_convolutional [Conv] outputs: [148_convolutional -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 148_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 148_convolutional_bn [BatchNormalization] inputs: [148_convolutional -> (1, 256, 18, 18)[FLOAT]], [148_convolutional_bn_scale -> (256)[FLOAT]], [148_convolutional_bn_bias -> (256)[FLOAT]], [148_convolutional_bn_mean -> (256)[FLOAT]], [148_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 148_convolutional_bn for ONNX node: 148_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 148_convolutional_bn for ONNX tensor: 148_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 148_convolutional_bn [BatchNormalization] outputs: [148_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 148_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 148_convolutional_lrelu [LeakyRelu] inputs: [148_convolutional_bn -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 148_convolutional_lrelu for ONNX node: 148_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 148_convolutional_lrelu for ONNX tensor: 148_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 148_convolutional_lrelu [LeakyRelu] outputs: [148_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 149_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 149_convolutional [Conv] inputs: [148_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [149_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 149_convolutional for ONNX node: 149_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 149_convolutional for ONNX tensor: 149_convolutional
[05/21/2022-02:47:15] [V] [TRT] 149_convolutional [Conv] outputs: [149_convolutional -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 149_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 149_convolutional_bn [BatchNormalization] inputs: [149_convolutional -> (1, 512, 18, 18)[FLOAT]], [149_convolutional_bn_scale -> (512)[FLOAT]], [149_convolutional_bn_bias -> (512)[FLOAT]], [149_convolutional_bn_mean -> (512)[FLOAT]], [149_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 149_convolutional_bn for ONNX node: 149_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 149_convolutional_bn for ONNX tensor: 149_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 149_convolutional_bn [BatchNormalization] outputs: [149_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 149_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 149_convolutional_lrelu [LeakyRelu] inputs: [149_convolutional_bn -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 149_convolutional_lrelu for ONNX node: 149_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 149_convolutional_lrelu for ONNX tensor: 149_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 149_convolutional_lrelu [LeakyRelu] outputs: [149_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 150_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 149_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 150_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 150_convolutional_conv_bias
[05/21/2022-02:47:15] [V] [TRT] 150_convolutional [Conv] inputs: [149_convolutional_lrelu -> (1, 512, 18, 18)[FLOAT]], [150_convolutional_conv_weights -> (255, 512, 1, 1)[FLOAT]], [150_convolutional_conv_bias -> (255)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 150_convolutional for ONNX node: 150_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 255
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 255, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 150_convolutional_544 for ONNX tensor: 150_convolutional
[05/21/2022-02:47:15] [V] [TRT] 150_convolutional [Conv] outputs: [150_convolutional -> (1, 255, 18, 18)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 153_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 148_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 153_convolutional [Conv] inputs: [148_convolutional_lrelu -> (1, 256, 18, 18)[FLOAT]], [153_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 256, 18, 18)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 153_convolutional for ONNX node: 153_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 153_convolutional for ONNX tensor: 153_convolutional
[05/21/2022-02:47:15] [V] [TRT] 153_convolutional [Conv] outputs: [153_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 153_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 153_convolutional_bn [BatchNormalization] inputs: [153_convolutional -> (1, 512, 9, 9)[FLOAT]], [153_convolutional_bn_scale -> (512)[FLOAT]], [153_convolutional_bn_bias -> (512)[FLOAT]], [153_convolutional_bn_mean -> (512)[FLOAT]], [153_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 153_convolutional_bn for ONNX node: 153_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 153_convolutional_bn for ONNX tensor: 153_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 153_convolutional_bn [BatchNormalization] outputs: [153_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 153_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 153_convolutional_lrelu [LeakyRelu] inputs: [153_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 153_convolutional_lrelu for ONNX node: 153_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 153_convolutional_lrelu for ONNX tensor: 153_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 153_convolutional_lrelu [LeakyRelu] outputs: [153_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 154_route [Concat]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 153_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 117_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 154_route [Concat] inputs: [153_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], [117_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 154_route for ONNX node: 154_route
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 154_route for ONNX tensor: 154_route
[05/21/2022-02:47:15] [V] [TRT] 154_route [Concat] outputs: [154_route -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 155_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 154_route
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 155_convolutional [Conv] inputs: [154_route -> (1, 1024, 9, 9)[FLOAT]], [155_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 155_convolutional for ONNX node: 155_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 155_convolutional for ONNX tensor: 155_convolutional
[05/21/2022-02:47:15] [V] [TRT] 155_convolutional [Conv] outputs: [155_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 155_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 155_convolutional_bn [BatchNormalization] inputs: [155_convolutional -> (1, 512, 9, 9)[FLOAT]], [155_convolutional_bn_scale -> (512)[FLOAT]], [155_convolutional_bn_bias -> (512)[FLOAT]], [155_convolutional_bn_mean -> (512)[FLOAT]], [155_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 155_convolutional_bn for ONNX node: 155_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 155_convolutional_bn for ONNX tensor: 155_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 155_convolutional_bn [BatchNormalization] outputs: [155_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 155_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 155_convolutional_lrelu [LeakyRelu] inputs: [155_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 155_convolutional_lrelu for ONNX node: 155_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 155_convolutional_lrelu for ONNX tensor: 155_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 155_convolutional_lrelu [LeakyRelu] outputs: [155_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 156_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 155_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 156_convolutional [Conv] inputs: [155_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], [156_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 156_convolutional for ONNX node: 156_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 156_convolutional for ONNX tensor: 156_convolutional
[05/21/2022-02:47:15] [V] [TRT] 156_convolutional [Conv] outputs: [156_convolutional -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 156_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 156_convolutional_bn [BatchNormalization] inputs: [156_convolutional -> (1, 1024, 9, 9)[FLOAT]], [156_convolutional_bn_scale -> (1024)[FLOAT]], [156_convolutional_bn_bias -> (1024)[FLOAT]], [156_convolutional_bn_mean -> (1024)[FLOAT]], [156_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 156_convolutional_bn for ONNX node: 156_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 156_convolutional_bn for ONNX tensor: 156_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 156_convolutional_bn [BatchNormalization] outputs: [156_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 156_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 156_convolutional_lrelu [LeakyRelu] inputs: [156_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 156_convolutional_lrelu for ONNX node: 156_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 156_convolutional_lrelu for ONNX tensor: 156_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 156_convolutional_lrelu [LeakyRelu] outputs: [156_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 157_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 156_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 157_convolutional [Conv] inputs: [156_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], [157_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 157_convolutional for ONNX node: 157_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 157_convolutional for ONNX tensor: 157_convolutional
[05/21/2022-02:47:15] [V] [TRT] 157_convolutional [Conv] outputs: [157_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 157_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 157_convolutional_bn [BatchNormalization] inputs: [157_convolutional -> (1, 512, 9, 9)[FLOAT]], [157_convolutional_bn_scale -> (512)[FLOAT]], [157_convolutional_bn_bias -> (512)[FLOAT]], [157_convolutional_bn_mean -> (512)[FLOAT]], [157_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 157_convolutional_bn for ONNX node: 157_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 157_convolutional_bn for ONNX tensor: 157_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 157_convolutional_bn [BatchNormalization] outputs: [157_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 157_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 157_convolutional_lrelu [LeakyRelu] inputs: [157_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 157_convolutional_lrelu for ONNX node: 157_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 157_convolutional_lrelu for ONNX tensor: 157_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 157_convolutional_lrelu [LeakyRelu] outputs: [157_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 158_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 157_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 158_convolutional [Conv] inputs: [157_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], [158_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 158_convolutional for ONNX node: 158_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 158_convolutional for ONNX tensor: 158_convolutional
[05/21/2022-02:47:15] [V] [TRT] 158_convolutional [Conv] outputs: [158_convolutional -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 158_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 158_convolutional_bn [BatchNormalization] inputs: [158_convolutional -> (1, 1024, 9, 9)[FLOAT]], [158_convolutional_bn_scale -> (1024)[FLOAT]], [158_convolutional_bn_bias -> (1024)[FLOAT]], [158_convolutional_bn_mean -> (1024)[FLOAT]], [158_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 158_convolutional_bn for ONNX node: 158_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 158_convolutional_bn for ONNX tensor: 158_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 158_convolutional_bn [BatchNormalization] outputs: [158_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 158_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 158_convolutional_lrelu [LeakyRelu] inputs: [158_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 158_convolutional_lrelu for ONNX node: 158_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 158_convolutional_lrelu for ONNX tensor: 158_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 158_convolutional_lrelu [LeakyRelu] outputs: [158_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 159_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 158_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 159_convolutional [Conv] inputs: [158_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], [159_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 159_convolutional for ONNX node: 159_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 159_convolutional for ONNX tensor: 159_convolutional
[05/21/2022-02:47:15] [V] [TRT] 159_convolutional [Conv] outputs: [159_convolutional -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 159_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 159_convolutional_bn [BatchNormalization] inputs: [159_convolutional -> (1, 512, 9, 9)[FLOAT]], [159_convolutional_bn_scale -> (512)[FLOAT]], [159_convolutional_bn_bias -> (512)[FLOAT]], [159_convolutional_bn_mean -> (512)[FLOAT]], [159_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 159_convolutional_bn for ONNX node: 159_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 159_convolutional_bn for ONNX tensor: 159_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 159_convolutional_bn [BatchNormalization] outputs: [159_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 159_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 159_convolutional_lrelu [LeakyRelu] inputs: [159_convolutional_bn -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 159_convolutional_lrelu for ONNX node: 159_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 159_convolutional_lrelu for ONNX tensor: 159_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 159_convolutional_lrelu [LeakyRelu] outputs: [159_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 160_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 159_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] 160_convolutional [Conv] inputs: [159_convolutional_lrelu -> (1, 512, 9, 9)[FLOAT]], [160_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 512, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 160_convolutional for ONNX node: 160_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 160_convolutional for ONNX tensor: 160_convolutional
[05/21/2022-02:47:15] [V] [TRT] 160_convolutional [Conv] outputs: [160_convolutional -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 160_convolutional_bn [BatchNormalization]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional_bn_scale
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional_bn_bias
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional_bn_mean
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional_bn_var
[05/21/2022-02:47:15] [V] [TRT] 160_convolutional_bn [BatchNormalization] inputs: [160_convolutional -> (1, 1024, 9, 9)[FLOAT]], [160_convolutional_bn_scale -> (1024)[FLOAT]], [160_convolutional_bn_bias -> (1024)[FLOAT]], [160_convolutional_bn_mean -> (1024)[FLOAT]], [160_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 160_convolutional_bn for ONNX node: 160_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 160_convolutional_bn for ONNX tensor: 160_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 160_convolutional_bn [BatchNormalization] outputs: [160_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 160_convolutional_lrelu [LeakyRelu]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] 160_convolutional_lrelu [LeakyRelu] inputs: [160_convolutional_bn -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 160_convolutional_lrelu for ONNX node: 160_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 160_convolutional_lrelu for ONNX tensor: 160_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] 160_convolutional_lrelu [LeakyRelu] outputs: [160_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Parsing node: 161_convolutional [Conv]
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 160_convolutional_lrelu
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 161_convolutional_conv_weights
[05/21/2022-02:47:15] [V] [TRT] Searching for input: 161_convolutional_conv_bias
[05/21/2022-02:47:15] [V] [TRT] 161_convolutional [Conv] inputs: [160_convolutional_lrelu -> (1, 1024, 9, 9)[FLOAT]], [161_convolutional_conv_weights -> (255, 1024, 1, 1)[FLOAT]], [161_convolutional_conv_bias -> (255)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Convolution input dimensions: (1, 1024, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering layer: 161_convolutional for ONNX node: 161_convolutional
[05/21/2022-02:47:15] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 255
[05/21/2022-02:47:15] [V] [TRT] Convolution output dimensions: (1, 255, 9, 9)
[05/21/2022-02:47:15] [V] [TRT] Registering tensor: 161_convolutional_545 for ONNX tensor: 161_convolutional
[05/21/2022-02:47:15] [V] [TRT] 161_convolutional [Conv] outputs: [161_convolutional -> (1, 255, 9, 9)[FLOAT]], 
[05/21/2022-02:47:15] [V] [TRT] Marking 139_convolutional_543 as output: 139_convolutional
[05/21/2022-02:47:15] [V] [TRT] Marking 150_convolutional_544 as output: 150_convolutional
[05/21/2022-02:47:15] [V] [TRT] Marking 161_convolutional_545 as output: 161_convolutional
[05/21/2022-02:47:15] [I] Finish parsing network model
[05/21/2022-02:47:15] [V] [TRT] Applying generic optimizations to the graph for inference.
[05/21/2022-02:47:15] [V] [TRT] Original: 506 layers
[05/21/2022-02:47:15] [V] [TRT] After dead-layer removal: 506 layers
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 001_convolutional with 001_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 002_convolutional with 002_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 003_convolutional with 003_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 005_convolutional with 005_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 006_convolutional with 006_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 007_convolutional with 007_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 009_convolutional with 009_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 011_convolutional with 011_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 012_convolutional with 012_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 013_convolutional with 013_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 015_convolutional with 015_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 016_convolutional with 016_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 017_convolutional with 017_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 019_convolutional with 019_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 020_convolutional with 020_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 022_convolutional with 022_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 024_convolutional with 024_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 025_convolutional with 025_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 026_convolutional with 026_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 028_convolutional with 028_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 029_convolutional with 029_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 030_convolutional with 030_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 032_convolutional with 032_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 033_convolutional with 033_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 035_convolutional with 035_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 036_convolutional with 036_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 038_convolutional with 038_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 039_convolutional with 039_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 041_convolutional with 041_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 042_convolutional with 042_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 044_convolutional with 044_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 045_convolutional with 045_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 047_convolutional with 047_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 048_convolutional with 048_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 050_convolutional with 050_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 051_convolutional with 051_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 053_convolutional with 053_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 055_convolutional with 055_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 056_convolutional with 056_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 057_convolutional with 057_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 059_convolutional with 059_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 060_convolutional with 060_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 061_convolutional with 061_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 063_convolutional with 063_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 064_convolutional with 064_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 066_convolutional with 066_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 067_convolutional with 067_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 069_convolutional with 069_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 070_convolutional with 070_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 072_convolutional with 072_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 073_convolutional with 073_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 075_convolutional with 075_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 076_convolutional with 076_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 078_convolutional with 078_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 079_convolutional with 079_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 081_convolutional with 081_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 082_convolutional with 082_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 084_convolutional with 084_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 086_convolutional with 086_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 087_convolutional with 087_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 088_convolutional with 088_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 090_convolutional with 090_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 091_convolutional with 091_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 092_convolutional with 092_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 094_convolutional with 094_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 095_convolutional with 095_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 097_convolutional with 097_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 098_convolutional with 098_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 100_convolutional with 100_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 101_convolutional with 101_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 103_convolutional with 103_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 105_convolutional with 105_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 106_convolutional with 106_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 107_convolutional with 107_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 108_convolutional with 108_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 115_convolutional with 115_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 116_convolutional with 116_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 117_convolutional with 117_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 118_convolutional with 118_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 121_convolutional with 121_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 123_convolutional with 123_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 124_convolutional with 124_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 125_convolutional with 125_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 126_convolutional with 126_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 127_convolutional with 127_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 128_convolutional with 128_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 131_convolutional with 131_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 133_convolutional with 133_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 134_convolutional with 134_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 135_convolutional with 135_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 136_convolutional with 136_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 137_convolutional with 137_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 138_convolutional with 138_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 142_convolutional with 142_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 144_convolutional with 144_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 145_convolutional with 145_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 146_convolutional with 146_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 147_convolutional with 147_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 148_convolutional with 148_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 149_convolutional with 149_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 153_convolutional with 153_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 155_convolutional with 155_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 156_convolutional with 156_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 157_convolutional with 157_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 158_convolutional with 158_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 159_convolutional with 159_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-02:47:15] [V] [TRT] ConvScaleFusion: Fusing 160_convolutional with 160_convolutional_bn
[05/21/2022-02:47:15] [V] [TRT] After Myelin optimization: 399 layers
[05/21/2022-02:47:15] [V] [TRT] Applying ScaleNodes fusions.
[05/21/2022-02:47:15] [V] [TRT] After scale fusion: 399 layers
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 001_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 001_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 002_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 002_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 003_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 003_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 005_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 005_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 006_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 006_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 007_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 007_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 009_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 009_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 011_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 011_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 012_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 012_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 013_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 013_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 015_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 015_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 016_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 016_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 017_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 017_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 019_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 019_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 020_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 020_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 022_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 022_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 024_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 024_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 025_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 025_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 026_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 026_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 028_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 028_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 029_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 029_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 030_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 030_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 032_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 032_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 033_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 033_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 035_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 035_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 036_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 036_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 038_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 038_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 039_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 039_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 041_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 041_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 042_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 042_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 044_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 044_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 045_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 045_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 047_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 047_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 048_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 048_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 050_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 050_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 051_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 051_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 053_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 053_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 055_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 055_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 056_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 056_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 057_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 057_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 059_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 059_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 060_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 060_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 061_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 061_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 063_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 063_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 064_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 064_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 066_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 066_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 067_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 067_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 069_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 069_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 070_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 070_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 072_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 072_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 073_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 073_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 075_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 075_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 076_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 076_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 078_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 078_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 079_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 079_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 081_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 081_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 082_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 082_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 084_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 084_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 086_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 086_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 087_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 087_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 088_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 088_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 090_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 090_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 091_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 091_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 092_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 092_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 094_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 094_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 095_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 095_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 097_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 097_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 098_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 098_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 100_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 100_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 101_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:15] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:15] [V] [TRT] Swap the layer type of 101_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 103_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 103_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 105_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 105_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 106_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 107_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 108_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 115_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 116_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 117_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 118_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 121_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 123_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 124_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 125_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 126_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 127_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 128_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 131_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 133_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 134_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 135_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 136_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 137_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 138_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 142_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 144_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 145_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 146_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 147_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 148_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 149_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 153_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 155_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 156_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 157_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 158_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 159_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-02:47:16] [V] [TRT] Swap the layer type of 160_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(001_convolutional_softplus) with PWN(001_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)) with 001_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(002_convolutional_softplus) with PWN(002_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)) with 002_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(003_convolutional_softplus) with PWN(003_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)) with 003_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(005_convolutional_softplus) with PWN(005_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)) with 005_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(006_convolutional_softplus) with PWN(006_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)) with 006_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(007_convolutional_softplus) with PWN(007_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)) with 007_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish) with 008_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(009_convolutional_softplus) with PWN(009_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)) with 009_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(011_convolutional_softplus) with PWN(011_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)) with 011_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(012_convolutional_softplus) with PWN(012_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)) with 012_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(013_convolutional_softplus) with PWN(013_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)) with 013_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(015_convolutional_softplus) with PWN(015_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)) with 015_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(016_convolutional_softplus) with PWN(016_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)) with 016_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(017_convolutional_softplus) with PWN(017_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)) with 017_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish) with 018_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(019_convolutional_softplus) with PWN(019_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)) with 019_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(020_convolutional_softplus) with PWN(020_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)) with 020_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish) with 021_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(022_convolutional_softplus) with PWN(022_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)) with 022_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(024_convolutional_softplus) with PWN(024_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)) with 024_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(025_convolutional_softplus) with PWN(025_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)) with 025_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(026_convolutional_softplus) with PWN(026_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)) with 026_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(028_convolutional_softplus) with PWN(028_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)) with 028_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(029_convolutional_softplus) with PWN(029_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)) with 029_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(030_convolutional_softplus) with PWN(030_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)) with 030_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish) with 031_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(032_convolutional_softplus) with PWN(032_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)) with 032_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(033_convolutional_softplus) with PWN(033_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)) with 033_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish) with 034_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(035_convolutional_softplus) with PWN(035_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)) with 035_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(036_convolutional_softplus) with PWN(036_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)) with 036_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish) with 037_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(038_convolutional_softplus) with PWN(038_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)) with 038_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(039_convolutional_softplus) with PWN(039_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)) with 039_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish) with 040_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(041_convolutional_softplus) with PWN(041_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)) with 041_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(042_convolutional_softplus) with PWN(042_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)) with 042_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish) with 043_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(044_convolutional_softplus) with PWN(044_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)) with 044_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(045_convolutional_softplus) with PWN(045_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)) with 045_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish) with 046_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(047_convolutional_softplus) with PWN(047_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)) with 047_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(048_convolutional_softplus) with PWN(048_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)) with 048_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish) with 049_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(050_convolutional_softplus) with PWN(050_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)) with 050_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(051_convolutional_softplus) with PWN(051_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)) with 051_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish) with 052_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(053_convolutional_softplus) with PWN(053_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)) with 053_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(055_convolutional_softplus) with PWN(055_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)) with 055_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(056_convolutional_softplus) with PWN(056_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)) with 056_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(057_convolutional_softplus) with PWN(057_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)) with 057_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(059_convolutional_softplus) with PWN(059_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)) with 059_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(060_convolutional_softplus) with PWN(060_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)) with 060_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(061_convolutional_softplus) with PWN(061_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)) with 061_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish) with 062_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(063_convolutional_softplus) with PWN(063_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)) with 063_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(064_convolutional_softplus) with PWN(064_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)) with 064_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish) with 065_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(066_convolutional_softplus) with PWN(066_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)) with 066_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(067_convolutional_softplus) with PWN(067_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)) with 067_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish) with 068_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(069_convolutional_softplus) with PWN(069_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)) with 069_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(070_convolutional_softplus) with PWN(070_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)) with 070_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish) with 071_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(072_convolutional_softplus) with PWN(072_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)) with 072_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(073_convolutional_softplus) with PWN(073_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)) with 073_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish) with 074_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(075_convolutional_softplus) with PWN(075_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)) with 075_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(076_convolutional_softplus) with PWN(076_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)) with 076_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish) with 077_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(078_convolutional_softplus) with PWN(078_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)) with 078_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(079_convolutional_softplus) with PWN(079_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)) with 079_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish) with 080_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(081_convolutional_softplus) with PWN(081_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)) with 081_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(082_convolutional_softplus) with PWN(082_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)) with 082_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish) with 083_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(084_convolutional_softplus) with PWN(084_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)) with 084_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(086_convolutional_softplus) with PWN(086_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)) with 086_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(087_convolutional_softplus) with PWN(087_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)) with 087_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(088_convolutional_softplus) with PWN(088_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)) with 088_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(090_convolutional_softplus) with PWN(090_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)) with 090_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(091_convolutional_softplus) with PWN(091_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)) with 091_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(092_convolutional_softplus) with PWN(092_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)) with 092_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish) with 093_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(094_convolutional_softplus) with PWN(094_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)) with 094_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(095_convolutional_softplus) with PWN(095_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)) with 095_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish) with 096_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(097_convolutional_softplus) with PWN(097_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)) with 097_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(098_convolutional_softplus) with PWN(098_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)) with 098_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish) with 099_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(100_convolutional_softplus) with PWN(100_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)) with 100_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(101_convolutional_softplus) with PWN(101_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)) with 101_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish) with 102_shortcut
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(103_convolutional_softplus) with PWN(103_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)) with 103_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(105_convolutional_softplus) with PWN(105_convolutional_tanh)
[05/21/2022-02:47:16] [V] [TRT] Running: PointWiseFusion
[05/21/2022-02:47:16] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)) with 105_convolutional_mish
[05/21/2022-02:47:16] [V] [TRT] After vertical fusions: 232 layers
[05/21/2022-02:47:16] [V] [TRT] After dupe layer removal: 232 layers
[05/21/2022-02:47:16] [V] [TRT] After final dead-layer removal: 232 layers
[05/21/2022-02:47:16] [V] [TRT] Merging layers: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn
[05/21/2022-02:47:16] [V] [TRT] Merging layers: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn
[05/21/2022-02:47:16] [V] [TRT] Merging layers: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn
[05/21/2022-02:47:16] [V] [TRT] Merging layers: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn
[05/21/2022-02:47:16] [V] [TRT] Merging layers: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn
[05/21/2022-02:47:16] [V] [TRT] After tensor merging: 227 layers
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 154_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 153_convolutional_lrelu to 154_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 117_convolutional_lrelu to 154_route
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 143_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 142_convolutional_lrelu to 143_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 127_convolutional_lrelu to 143_route
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 132_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 131_convolutional_lrelu to 132_route
[05/21/2022-02:47:16] [V] [TRT] Generating copy for 129_upsample to 132_route because input does not support striding.
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 122_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 121_convolutional_lrelu to 122_route
[05/21/2022-02:47:16] [V] [TRT] Generating copy for 119_upsample to 122_route because input does not support striding.
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 114_route
[05/21/2022-02:47:16] [V] [TRT] Generating copy for 113_maxpool to 114_route because input does not support striding.
[05/21/2022-02:47:16] [V] [TRT] Generating copy for 111_maxpool to 114_route because input does not support striding.
[05/21/2022-02:47:16] [V] [TRT] Generating copy for 109_maxpool to 114_route because input does not support striding.
[05/21/2022-02:47:16] [V] [TRT] Generating copy for 108_convolutional_lrelu to 114_route because input does not support striding.
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 104_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 103_convolutional_mish to 104_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 088_convolutional_mish to 104_route
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 085_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 084_convolutional_mish to 085_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 057_convolutional_mish to 085_route
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 054_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 053_convolutional_mish to 054_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 026_convolutional_mish to 054_route
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 023_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 022_convolutional_mish to 023_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 013_convolutional_mish to 023_route
[05/21/2022-02:47:16] [V] [TRT] Eliminating concatenation 010_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 009_convolutional_mish to 010_route
[05/21/2022-02:47:16] [V] [TRT] Retargeting 003_convolutional_mish to 010_route
[05/21/2022-02:47:16] [V] [TRT] After concat removal: 223 layers
[05/21/2022-02:47:16] [V] [TRT] Graph construction and optimization completed in 1.63944 seconds.
[05/21/2022-02:47:16] [I] [TRT] ---------- Layers Running on DLA ----------
[05/21/2022-02:47:16] [I] [TRT] ---------- Layers Running on GPU ----------
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 001_convolutional + 001_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 002_convolutional + 002_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 006_convolutional + 006_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 007_convolutional + 007_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 009_convolutional + 009_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 011_convolutional + 011_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 012_convolutional + 012_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 016_convolutional + 016_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 017_convolutional + 017_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 019_convolutional + 019_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 020_convolutional + 020_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 022_convolutional + 022_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 024_convolutional + 024_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 025_convolutional + 025_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 029_convolutional + 029_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 030_convolutional + 030_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 032_convolutional + 032_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 033_convolutional + 033_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 035_convolutional + 035_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 036_convolutional + 036_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 038_convolutional + 038_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 039_convolutional + 039_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 041_convolutional + 041_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 042_convolutional + 042_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 044_convolutional + 044_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 045_convolutional + 045_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 047_convolutional + 047_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 048_convolutional + 048_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 050_convolutional + 050_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 051_convolutional + 051_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 053_convolutional + 053_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 055_convolutional + 055_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 056_convolutional + 056_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 060_convolutional + 060_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 061_convolutional + 061_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 063_convolutional + 063_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 064_convolutional + 064_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 066_convolutional + 066_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 067_convolutional + 067_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 069_convolutional + 069_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 070_convolutional + 070_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 072_convolutional + 072_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 073_convolutional + 073_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 075_convolutional + 075_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 076_convolutional + 076_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 078_convolutional + 078_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 079_convolutional + 079_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 081_convolutional + 081_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 082_convolutional + 082_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 084_convolutional + 084_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 086_convolutional + 086_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 087_convolutional + 087_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 091_convolutional + 091_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 092_convolutional + 092_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 094_convolutional + 094_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 095_convolutional + 095_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 097_convolutional + 097_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 098_convolutional + 098_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 100_convolutional + 100_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 101_convolutional + 101_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 103_convolutional + 103_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 105_convolutional + 105_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 106_convolutional + 106_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(106_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 107_convolutional + 107_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(107_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 108_convolutional + 108_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(108_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 109_maxpool
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 111_maxpool
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 113_maxpool
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 113_maxpool copy
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 111_maxpool copy
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 109_maxpool copy
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 108_convolutional_lrelu copy
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 115_convolutional + 115_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(115_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 116_convolutional + 116_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(116_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 117_convolutional + 117_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(117_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 118_convolutional + 118_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(118_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 119_upsample
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 121_convolutional + 121_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(121_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 119_upsample copy
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 123_convolutional + 123_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(123_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 124_convolutional + 124_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(124_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 125_convolutional + 125_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(125_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 126_convolutional + 126_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(126_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 127_convolutional + 127_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(127_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 128_convolutional + 128_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(128_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 129_upsample
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 131_convolutional + 131_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(131_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 129_upsample copy
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 133_convolutional + 133_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(133_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 134_convolutional + 134_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(134_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 135_convolutional + 135_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(135_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 136_convolutional + 136_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(136_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 137_convolutional + 137_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(137_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 138_convolutional + 138_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(138_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 139_convolutional
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 142_convolutional + 142_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(142_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 144_convolutional + 144_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(144_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 145_convolutional + 145_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(145_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 146_convolutional + 146_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(146_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 147_convolutional + 147_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(147_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 148_convolutional + 148_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(148_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 149_convolutional + 149_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(149_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 150_convolutional
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 153_convolutional + 153_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(153_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 155_convolutional + 155_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(155_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 156_convolutional + 156_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(156_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 157_convolutional + 157_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(157_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 158_convolutional + 158_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(158_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 159_convolutional + 159_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(159_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 160_convolutional + 160_convolutional_bn
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] PWN(160_convolutional_lrelu)
[05/21/2022-02:47:16] [I] [TRT] [GpuLayer] 161_convolutional
[05/21/2022-02:47:18] [V] [TRT] Using cublas as a tactic source
[05/21/2022-02:47:18] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +144, now: CPU 928, GPU 3310 (MiB)
[05/21/2022-02:47:18] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-02:47:20] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +245, now: CPU 1169, GPU 3555 (MiB)
[05/21/2022-02:47:20] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/21/2022-02:47:20] [V] [TRT] Constructing optimization profile number 0 [1/1].
[05/21/2022-02:47:20] [V] [TRT] Reserving memory for activation tensors. Host: 0 bytes Device: 2730348 bytes
[05/21/2022-02:47:20] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:20] [V] [TRT] *************** Autotuning Reformat: Float(248832,82944,288,1) -> Float(248832,1,864,3) ***************
[05/21/2022-02:47:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(000_net -> <out>) (Reformat)
[05/21/2022-02:47:20] [V] [TRT] Tactic: 1002 Time: 3.12235
[05/21/2022-02:47:20] [V] [TRT] Tactic: 0 Time: 1.45171
[05/21/2022-02:47:20] [V] [TRT] Fastest Tactic: 0 Time: 1.45171
[05/21/2022-02:47:20] [V] [TRT] *************** Autotuning Reformat: Float(248832,82944,288,1) -> Half(248832,82944,288,1) ***************
[05/21/2022-02:47:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(000_net -> <out>) (Reformat)
[05/21/2022-02:47:20] [V] [TRT] Tactic: 1002 Time: 1.29409
[05/21/2022-02:47:20] [V] [TRT] Tactic: 0 Time: 1.00798
[05/21/2022-02:47:20] [V] [TRT] Fastest Tactic: 0 Time: 1.00798
[05/21/2022-02:47:20] [V] [TRT] *************** Autotuning Reformat: Float(248832,82944,288,1) -> Half(165888,82944:2,288,1) ***************
[05/21/2022-02:47:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(000_net -> <out>) (Reformat)
[05/21/2022-02:47:20] [V] [TRT] Tactic: 1002 Time: 2.9154
[05/21/2022-02:47:20] [V] [TRT] Tactic: 0 Time: 0.85709
[05/21/2022-02:47:20] [V] [TRT] Fastest Tactic: 0 Time: 0.85709
[05/21/2022-02:47:20] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:20] [V] [TRT] *************** Autotuning Reformat: Float(2654208,82944,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:21] [V] [TRT] Tactic: 1002 Time: 7.54348
[05/21/2022-02:47:21] [V] [TRT] Tactic: 0 Time: 5.14411
[05/21/2022-02:47:21] [V] [TRT] Fastest Tactic: 0 Time: 5.14411
[05/21/2022-02:47:21] [V] [TRT] *************** Autotuning Reformat: Float(2654208,82944,288,1) -> Float(82944,82944:32,288,1) ***************
[05/21/2022-02:47:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:21] [V] [TRT] Tactic: 1002 Time: 6.26122
[05/21/2022-02:47:21] [V] [TRT] Tactic: 0 Time: 9.00736
[05/21/2022-02:47:21] [V] [TRT] Fastest Tactic: 1002 Time: 6.26122
[05/21/2022-02:47:21] [V] [TRT] *************** Autotuning Reformat: Float(2654208,82944,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:21] [V] [TRT] Tactic: 1002 Time: 3.30898
[05/21/2022-02:47:21] [V] [TRT] Tactic: 0 Time: 2.71581
[05/21/2022-02:47:21] [V] [TRT] Fastest Tactic: 0 Time: 2.71581
[05/21/2022-02:47:21] [V] [TRT] *************** Autotuning Reformat: Float(2654208,82944,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:21] [V] [TRT] Tactic: 1002 Time: 3.96329
[05/21/2022-02:47:21] [V] [TRT] Tactic: 0 Time: 2.16433
[05/21/2022-02:47:21] [V] [TRT] Fastest Tactic: 0 Time: 2.16433
[05/21/2022-02:47:21] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,9216,32) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:21] [V] [TRT] Tactic: 1002 Time: 6.19695
[05/21/2022-02:47:22] [V] [TRT] Tactic: 0 Time: 9.30439
[05/21/2022-02:47:22] [V] [TRT] Fastest Tactic: 1002 Time: 6.19695
[05/21/2022-02:47:22] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,9216,32) -> Float(82944,82944:32,288,1) ***************
[05/21/2022-02:47:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:22] [V] [TRT] Tactic: 1002 Time: 6.07658
[05/21/2022-02:47:22] [V] [TRT] Tactic: 0 Time: 18.0141
[05/21/2022-02:47:22] [V] [TRT] Fastest Tactic: 1002 Time: 6.07658
[05/21/2022-02:47:22] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,9216,32) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:22] [V] [TRT] Tactic: 1002 Time: 2.51458
[05/21/2022-02:47:22] [V] [TRT] Tactic: 0 Time: 9.29507
[05/21/2022-02:47:22] [V] [TRT] Fastest Tactic: 1002 Time: 2.51458
[05/21/2022-02:47:22] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,9216,32) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:22] [V] [TRT] Tactic: 1002 Time: 3.33768
[05/21/2022-02:47:23] [V] [TRT] Tactic: 0 Time: 10.1519
[05/21/2022-02:47:23] [V] [TRT] Fastest Tactic: 1002 Time: 3.33768
[05/21/2022-02:47:23] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:23] [V] [TRT] Tactic: 1002 Time: 6.12635
[05/21/2022-02:47:23] [V] [TRT] Tactic: 0 Time: 9.19747
[05/21/2022-02:47:23] [V] [TRT] Fastest Tactic: 1002 Time: 6.12635
[05/21/2022-02:47:23] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:23] [V] [TRT] Tactic: 1002 Time: 5.98432
[05/21/2022-02:47:23] [V] [TRT] Tactic: 0 Time: 4.56329
[05/21/2022-02:47:23] [V] [TRT] Fastest Tactic: 0 Time: 4.56329
[05/21/2022-02:47:23] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:23] [V] [TRT] Tactic: 1002 Time: 2.7827
[05/21/2022-02:47:23] [V] [TRT] Tactic: 0 Time: 9.153
[05/21/2022-02:47:23] [V] [TRT] Fastest Tactic: 1002 Time: 2.7827
[05/21/2022-02:47:23] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:23] [V] [TRT] Tactic: 1002 Time: 3.37762
[05/21/2022-02:47:24] [V] [TRT] Tactic: 0 Time: 10.0504
[05/21/2022-02:47:24] [V] [TRT] Fastest Tactic: 1002 Time: 3.37762
[05/21/2022-02:47:24] [V] [TRT] *************** Autotuning Reformat: Half(2654208,82944,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:24] [V] [TRT] Tactic: 1002 Time: 3.34592
[05/21/2022-02:47:24] [V] [TRT] Tactic: 0 Time: 2.33152
[05/21/2022-02:47:24] [V] [TRT] Fastest Tactic: 0 Time: 2.33152
[05/21/2022-02:47:24] [V] [TRT] *************** Autotuning Reformat: Half(2654208,82944,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:24] [V] [TRT] Tactic: 1002 Time: 2.49311
[05/21/2022-02:47:24] [V] [TRT] Tactic: 0 Time: 4.30934
[05/21/2022-02:47:24] [V] [TRT] Fastest Tactic: 1002 Time: 2.49311
[05/21/2022-02:47:24] [V] [TRT] *************** Autotuning Reformat: Half(2654208,82944,288,1) -> Float(82944,82944:32,288,1) ***************
[05/21/2022-02:47:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:24] [V] [TRT] Tactic: 1002 Time: 2.43928
[05/21/2022-02:47:24] [V] [TRT] Tactic: 0 Time: 9.26505
[05/21/2022-02:47:24] [V] [TRT] Fastest Tactic: 1002 Time: 2.43928
[05/21/2022-02:47:24] [V] [TRT] *************** Autotuning Reformat: Half(2654208,82944,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:24] [V] [TRT] Tactic: 1002 Time: 2.49718
[05/21/2022-02:47:24] [V] [TRT] Tactic: 0 Time: 2.16016
[05/21/2022-02:47:24] [V] [TRT] Fastest Tactic: 0 Time: 2.16016
[05/21/2022-02:47:24] [V] [TRT] *************** Autotuning Reformat: Half(1327104,82944:2,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:24] [V] [TRT] Tactic: 1002 Time: 3.17727
[05/21/2022-02:47:25] [V] [TRT] Tactic: 0 Time: 1.87901
[05/21/2022-02:47:25] [V] [TRT] Fastest Tactic: 0 Time: 1.87901
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(1327104,82944:2,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:25] [V] [TRT] Tactic: 1002 Time: 2.49763
[05/21/2022-02:47:25] [V] [TRT] Tactic: 0 Time: 4.62891
[05/21/2022-02:47:25] [V] [TRT] Fastest Tactic: 1002 Time: 2.49763
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(1327104,82944:2,288,1) -> Float(82944,82944:32,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:25] [V] [TRT] Tactic: 1002 Time: 2.47795
[05/21/2022-02:47:25] [V] [TRT] Tactic: 0 Time: 9.33277
[05/21/2022-02:47:25] [V] [TRT] Fastest Tactic: 1002 Time: 2.47795
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(1327104,82944:2,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:25] [V] [TRT] Tactic: 1002 Time: 8.54505
[05/21/2022-02:47:25] [V] [TRT] Tactic: 0 Time: 1.87221
[05/21/2022-02:47:25] [V] [TRT] Fastest Tactic: 0 Time: 1.87221
[05/21/2022-02:47:25] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(2654208,82944,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(2654208,82944,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(2654208,82944,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,9216,32) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,9216,32) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,9216,32) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(82944,82944:32,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(2654208,82944,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(2654208,82944,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(2654208,82944,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(1327104,82944:2,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(1327104,82944:2,288,1) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Half(1327104,82944:2,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:47:25] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:25] [V] [TRT] Tactic: 1002 Time: 1.43094
[05/21/2022-02:47:25] [V] [TRT] Tactic: 0 Time: 2.53533
[05/21/2022-02:47:25] [V] [TRT] Fastest Tactic: 1002 Time: 1.43094
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:25] [V] [TRT] Tactic: 1002 Time: 1.40859
[05/21/2022-02:47:25] [V] [TRT] Tactic: 0 Time: 4.22542
[05/21/2022-02:47:25] [V] [TRT] Fastest Tactic: 1002 Time: 1.40859
[05/21/2022-02:47:25] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:25] [V] [TRT] Tactic: 1002 Time: 1.68071
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 1.35304
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 0 Time: 1.35304
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:26] [V] [TRT] Tactic: 1002 Time: 2.01253
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 1.08291
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 0 Time: 1.08291
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:26] [V] [TRT] Tactic: 1002 Time: 1.5641
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 4.54522
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 1002 Time: 1.5641
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:26] [V] [TRT] Tactic: 1002 Time: 1.14898
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 9.40942
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 1002 Time: 1.14898
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:26] [V] [TRT] Tactic: 1002 Time: 1.25644
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 4.71033
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 1002 Time: 1.25644
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:26] [V] [TRT] Tactic: 1002 Time: 1.76527
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 4.85665
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 1002 Time: 1.76527
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:26] [V] [TRT] Tactic: 1002 Time: 1.57993
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 4.50458
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 1002 Time: 1.57993
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:26] [V] [TRT] Tactic: 1002 Time: 1.20328
[05/21/2022-02:47:26] [V] [TRT] Tactic: 0 Time: 2.32286
[05/21/2022-02:47:26] [V] [TRT] Fastest Tactic: 1002 Time: 1.20328
[05/21/2022-02:47:26] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.38025
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 4.62587
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 1002 Time: 1.38025
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.73742
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 4.89529
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 1002 Time: 1.73742
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.75284
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 1.1557
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 0 Time: 1.1557
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.22395
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 2.24344
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 1002 Time: 1.22395
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.22529
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 4.65249
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 1002 Time: 1.22529
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.34355
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 1.07273
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 0 Time: 1.07273
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.5968
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 0.941074
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 0 Time: 0.941074
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:27] [V] [TRT] Tactic: 1002 Time: 1.23947
[05/21/2022-02:47:27] [V] [TRT] Tactic: 0 Time: 2.31727
[05/21/2022-02:47:27] [V] [TRT] Fastest Tactic: 1002 Time: 1.23947
[05/21/2022-02:47:27] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:28] [V] [TRT] Tactic: 1002 Time: 1.23859
[05/21/2022-02:47:28] [V] [TRT] Tactic: 0 Time: 4.29349
[05/21/2022-02:47:28] [V] [TRT] Fastest Tactic: 1002 Time: 1.23859
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:28] [V] [TRT] Tactic: 1002 Time: 2.76569
[05/21/2022-02:47:28] [V] [TRT] Tactic: 0 Time: 0.914766
[05/21/2022-02:47:28] [V] [TRT] Fastest Tactic: 0 Time: 0.914766
[05/21/2022-02:47:28] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:28] [V] [TRT] Tactic: 1002 Time: 2.87716
[05/21/2022-02:47:28] [V] [TRT] Tactic: 0 Time: 5.20463
[05/21/2022-02:47:28] [V] [TRT] Fastest Tactic: 1002 Time: 2.87716
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:28] [V] [TRT] Tactic: 1002 Time: 2.82554
[05/21/2022-02:47:28] [V] [TRT] Tactic: 0 Time: 9.08024
[05/21/2022-02:47:28] [V] [TRT] Fastest Tactic: 1002 Time: 2.82554
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:28] [V] [TRT] Tactic: 1002 Time: 3.36415
[05/21/2022-02:47:28] [V] [TRT] Tactic: 0 Time: 2.71046
[05/21/2022-02:47:28] [V] [TRT] Fastest Tactic: 0 Time: 2.71046
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:28] [V] [TRT] Tactic: 1002 Time: 3.98747
[05/21/2022-02:47:28] [V] [TRT] Tactic: 0 Time: 2.19067
[05/21/2022-02:47:28] [V] [TRT] Fastest Tactic: 0 Time: 2.19067
[05/21/2022-02:47:28] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:28] [V] [TRT] Tactic: 1002 Time: 3.14307
[05/21/2022-02:47:29] [V] [TRT] Tactic: 0 Time: 9.96875
[05/21/2022-02:47:29] [V] [TRT] Fastest Tactic: 1002 Time: 3.14307
[05/21/2022-02:47:29] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:29] [V] [TRT] Tactic: 1002 Time: 2.3671
[05/21/2022-02:47:29] [V] [TRT] Tactic: 0 Time: 18.6581
[05/21/2022-02:47:29] [V] [TRT] Fastest Tactic: 1002 Time: 2.3671
[05/21/2022-02:47:29] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:29] [V] [TRT] Tactic: 1002 Time: 2.51434
[05/21/2022-02:47:29] [V] [TRT] Tactic: 0 Time: 9.93919
[05/21/2022-02:47:29] [V] [TRT] Fastest Tactic: 1002 Time: 2.51434
[05/21/2022-02:47:29] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:30] [V] [TRT] Tactic: 1002 Time: 3.54114
[05/21/2022-02:47:30] [V] [TRT] Tactic: 0 Time: 10.6111
[05/21/2022-02:47:30] [V] [TRT] Fastest Tactic: 1002 Time: 3.54114
[05/21/2022-02:47:30] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:30] [V] [TRT] Tactic: 1002 Time: 3.43572
[05/21/2022-02:47:30] [V] [TRT] Tactic: 0 Time: 2.36557
[05/21/2022-02:47:30] [V] [TRT] Fastest Tactic: 0 Time: 2.36557
[05/21/2022-02:47:30] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:30] [V] [TRT] Tactic: 1002 Time: 2.47454
[05/21/2022-02:47:30] [V] [TRT] Tactic: 0 Time: 4.59569
[05/21/2022-02:47:30] [V] [TRT] Fastest Tactic: 1002 Time: 2.47454
[05/21/2022-02:47:30] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:30] [V] [TRT] Tactic: 1002 Time: 2.78426
[05/21/2022-02:47:30] [V] [TRT] Tactic: 0 Time: 9.19839
[05/21/2022-02:47:30] [V] [TRT] Fastest Tactic: 1002 Time: 2.78426
[05/21/2022-02:47:30] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:30] [V] [TRT] Tactic: 1002 Time: 2.49139
[05/21/2022-02:47:30] [V] [TRT] Tactic: 0 Time: 2.1883
[05/21/2022-02:47:30] [V] [TRT] Fastest Tactic: 0 Time: 2.1883
[05/21/2022-02:47:30] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:31] [V] [TRT] Tactic: 1002 Time: 3.25251
[05/21/2022-02:47:31] [V] [TRT] Tactic: 0 Time: 1.88267
[05/21/2022-02:47:31] [V] [TRT] Fastest Tactic: 0 Time: 1.88267
[05/21/2022-02:47:31] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:31] [V] [TRT] Tactic: 1002 Time: 2.49694
[05/21/2022-02:47:31] [V] [TRT] Tactic: 0 Time: 4.64217
[05/21/2022-02:47:31] [V] [TRT] Fastest Tactic: 1002 Time: 2.49694
[05/21/2022-02:47:31] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:31] [V] [TRT] Tactic: 1002 Time: 2.47989
[05/21/2022-02:47:31] [V] [TRT] Tactic: 0 Time: 9.09605
[05/21/2022-02:47:31] [V] [TRT] Fastest Tactic: 1002 Time: 2.47989
[05/21/2022-02:47:31] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-02:47:31] [V] [TRT] Tactic: 1002 Time: 4.88035
[05/21/2022-02:47:31] [V] [TRT] Tactic: 0 Time: 1.91044
[05/21/2022-02:47:31] [V] [TRT] Fastest Tactic: 0 Time: 1.91044
[05/21/2022-02:47:31] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:31] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:31] [V] [TRT] Tactic: 1002 Time: 1.43349
[05/21/2022-02:47:31] [V] [TRT] Tactic: 0 Time: 2.57683
[05/21/2022-02:47:31] [V] [TRT] Fastest Tactic: 1002 Time: 1.43349
[05/21/2022-02:47:31] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:31] [V] [TRT] Tactic: 1002 Time: 1.40706
[05/21/2022-02:47:31] [V] [TRT] Tactic: 0 Time: 4.23461
[05/21/2022-02:47:31] [V] [TRT] Fastest Tactic: 1002 Time: 1.40706
[05/21/2022-02:47:31] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:32] [V] [TRT] Tactic: 1002 Time: 2.00449
[05/21/2022-02:47:32] [V] [TRT] Tactic: 0 Time: 1.85173
[05/21/2022-02:47:32] [V] [TRT] Fastest Tactic: 0 Time: 1.85173
[05/21/2022-02:47:32] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:32] [V] [TRT] Tactic: 1002 Time: 2.01155
[05/21/2022-02:47:32] [V] [TRT] Tactic: 0 Time: 2.17894
[05/21/2022-02:47:32] [V] [TRT] Fastest Tactic: 1002 Time: 2.01155
[05/21/2022-02:47:32] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:32] [V] [TRT] Tactic: 1002 Time: 1.58403
[05/21/2022-02:47:32] [V] [TRT] Tactic: 0 Time: 4.95536
[05/21/2022-02:47:32] [V] [TRT] Fastest Tactic: 1002 Time: 1.58403
[05/21/2022-02:47:32] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:32] [V] [TRT] Tactic: 1002 Time: 1.1682
[05/21/2022-02:47:32] [V] [TRT] Tactic: 0 Time: 9.56773
[05/21/2022-02:47:32] [V] [TRT] Fastest Tactic: 1002 Time: 1.1682
[05/21/2022-02:47:32] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:32] [V] [TRT] Tactic: 1002 Time: 1.25505
[05/21/2022-02:47:32] [V] [TRT] Tactic: 0 Time: 4.86927
[05/21/2022-02:47:32] [V] [TRT] Fastest Tactic: 1002 Time: 1.25505
[05/21/2022-02:47:32] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:32] [V] [TRT] Tactic: 1002 Time: 1.70303
[05/21/2022-02:47:32] [V] [TRT] Tactic: 0 Time: 5.22071
[05/21/2022-02:47:32] [V] [TRT] Fastest Tactic: 1002 Time: 1.70303
[05/21/2022-02:47:32] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:32] [V] [TRT] Tactic: 1002 Time: 1.58417
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 4.57441
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 1002 Time: 1.58417
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:33] [V] [TRT] Tactic: 1002 Time: 1.14138
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 2.28036
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 1002 Time: 1.14138
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:33] [V] [TRT] Tactic: 1002 Time: 1.31804
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 4.37613
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 1002 Time: 1.31804
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:33] [V] [TRT] Tactic: 1002 Time: 1.8038
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 4.73792
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 1002 Time: 1.8038
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:33] [V] [TRT] Tactic: 1002 Time: 2.00798
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 1.83354
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 0 Time: 1.83354
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:33] [V] [TRT] Tactic: 1002 Time: 1.24035
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 2.26303
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 1002 Time: 1.24035
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:33] [V] [TRT] Tactic: 1002 Time: 1.22551
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 4.76049
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 1002 Time: 1.22551
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:33] [V] [TRT] Tactic: 1002 Time: 1.37782
[05/21/2022-02:47:33] [V] [TRT] Tactic: 0 Time: 1.94544
[05/21/2022-02:47:33] [V] [TRT] Fastest Tactic: 1002 Time: 1.37782
[05/21/2022-02:47:33] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:34] [V] [TRT] Tactic: 1002 Time: 1.71169
[05/21/2022-02:47:34] [V] [TRT] Tactic: 0 Time: 0.947715
[05/21/2022-02:47:34] [V] [TRT] Fastest Tactic: 0 Time: 0.947715
[05/21/2022-02:47:34] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:34] [V] [TRT] Tactic: 1002 Time: 1.23773
[05/21/2022-02:47:34] [V] [TRT] Tactic: 0 Time: 2.45434
[05/21/2022-02:47:34] [V] [TRT] Fastest Tactic: 1002 Time: 1.23773
[05/21/2022-02:47:34] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:34] [V] [TRT] Tactic: 1002 Time: 1.28818
[05/21/2022-02:47:34] [V] [TRT] Tactic: 0 Time: 4.929
[05/21/2022-02:47:34] [V] [TRT] Fastest Tactic: 1002 Time: 1.28818
[05/21/2022-02:47:34] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:34] [V] [TRT] Tactic: 1002 Time: 2.86956
[05/21/2022-02:47:34] [V] [TRT] Tactic: 0 Time: 0.919681
[05/21/2022-02:47:34] [V] [TRT] Fastest Tactic: 0 Time: 0.919681
[05/21/2022-02:47:34] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:34] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:34] [V] [TRT] Tactic: 1002 Time: 1.51863
[05/21/2022-02:47:34] [V] [TRT] Tactic: 0 Time: 2.70557
[05/21/2022-02:47:34] [V] [TRT] Fastest Tactic: 1002 Time: 1.51863
[05/21/2022-02:47:34] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:34] [V] [TRT] Tactic: 1002 Time: 1.49278
[05/21/2022-02:47:34] [V] [TRT] Tactic: 0 Time: 4.80687
[05/21/2022-02:47:34] [V] [TRT] Fastest Tactic: 1002 Time: 1.49278
[05/21/2022-02:47:34] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:34] [V] [TRT] Tactic: 1002 Time: 2.0118
[05/21/2022-02:47:35] [V] [TRT] Tactic: 0 Time: 1.84876
[05/21/2022-02:47:35] [V] [TRT] Fastest Tactic: 0 Time: 1.84876
[05/21/2022-02:47:35] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:35] [V] [TRT] Tactic: 1002 Time: 2.0685
[05/21/2022-02:47:35] [V] [TRT] Tactic: 0 Time: 1.09307
[05/21/2022-02:47:35] [V] [TRT] Fastest Tactic: 0 Time: 1.09307
[05/21/2022-02:47:35] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:35] [V] [TRT] Tactic: 1002 Time: 1.59132
[05/21/2022-02:47:35] [V] [TRT] Tactic: 0 Time: 5.06196
[05/21/2022-02:47:35] [V] [TRT] Fastest Tactic: 1002 Time: 1.59132
[05/21/2022-02:47:35] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:35] [V] [TRT] Tactic: 1002 Time: 1.16595
[05/21/2022-02:47:35] [V] [TRT] Tactic: 0 Time: 10.317
[05/21/2022-02:47:35] [V] [TRT] Fastest Tactic: 1002 Time: 1.16595
[05/21/2022-02:47:35] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:35] [V] [TRT] Tactic: 1002 Time: 1.25619
[05/21/2022-02:47:35] [V] [TRT] Tactic: 0 Time: 4.98264
[05/21/2022-02:47:35] [V] [TRT] Fastest Tactic: 1002 Time: 1.25619
[05/21/2022-02:47:35] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:35] [V] [TRT] Tactic: 1002 Time: 1.75387
[05/21/2022-02:47:35] [V] [TRT] Tactic: 0 Time: 5.32014
[05/21/2022-02:47:35] [V] [TRT] Fastest Tactic: 1002 Time: 1.75387
[05/21/2022-02:47:35] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:35] [V] [TRT] Tactic: 1002 Time: 1.60389
[05/21/2022-02:47:36] [V] [TRT] Tactic: 0 Time: 4.95204
[05/21/2022-02:47:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.60389
[05/21/2022-02:47:36] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:36] [V] [TRT] Tactic: 1002 Time: 1.1759
[05/21/2022-02:47:36] [V] [TRT] Tactic: 0 Time: 2.37985
[05/21/2022-02:47:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.1759
[05/21/2022-02:47:36] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:36] [V] [TRT] Tactic: 1002 Time: 1.34695
[05/21/2022-02:47:36] [V] [TRT] Tactic: 0 Time: 4.93939
[05/21/2022-02:47:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.34695
[05/21/2022-02:47:36] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:36] [V] [TRT] Tactic: 1002 Time: 1.78693
[05/21/2022-02:47:36] [V] [TRT] Tactic: 0 Time: 5.14835
[05/21/2022-02:47:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.78693
[05/21/2022-02:47:36] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:36] [V] [TRT] Tactic: 1002 Time: 2.0566
[05/21/2022-02:47:36] [V] [TRT] Tactic: 0 Time: 1.8648
[05/21/2022-02:47:36] [V] [TRT] Fastest Tactic: 0 Time: 1.8648
[05/21/2022-02:47:36] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:36] [V] [TRT] Tactic: 1002 Time: 1.2996
[05/21/2022-02:47:36] [V] [TRT] Tactic: 0 Time: 2.32421
[05/21/2022-02:47:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.2996
[05/21/2022-02:47:36] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:36] [V] [TRT] Tactic: 1002 Time: 1.226
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 4.6099
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.226
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 1.25557
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 1.09269
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 0 Time: 1.09269
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 1.62761
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 2.24601
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.62761
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 1.23986
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 2.33268
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.23986
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 1.30482
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 4.74646
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.30482
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 2.67315
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 1.99765
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 0 Time: 1.99765
[05/21/2022-02:47:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 1.41672
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 2.64932
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.41672
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 1.42943
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 4.752
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.42943
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:37] [V] [TRT] Tactic: 1002 Time: 1.83042
[05/21/2022-02:47:37] [V] [TRT] Tactic: 0 Time: 1.35372
[05/21/2022-02:47:37] [V] [TRT] Fastest Tactic: 0 Time: 1.35372
[05/21/2022-02:47:37] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:38] [V] [TRT] Tactic: 1002 Time: 2.0588
[05/21/2022-02:47:38] [V] [TRT] Tactic: 0 Time: 1.08391
[05/21/2022-02:47:38] [V] [TRT] Fastest Tactic: 0 Time: 1.08391
[05/21/2022-02:47:38] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:38] [V] [TRT] Tactic: 1002 Time: 1.58463
[05/21/2022-02:47:38] [V] [TRT] Tactic: 0 Time: 4.92502
[05/21/2022-02:47:38] [V] [TRT] Fastest Tactic: 1002 Time: 1.58463
[05/21/2022-02:47:38] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:38] [V] [TRT] Tactic: 1002 Time: 1.12752
[05/21/2022-02:47:38] [V] [TRT] Tactic: 0 Time: 9.27124
[05/21/2022-02:47:38] [V] [TRT] Fastest Tactic: 1002 Time: 1.12752
[05/21/2022-02:47:38] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:38] [V] [TRT] Tactic: 1002 Time: 1.25534
[05/21/2022-02:47:38] [V] [TRT] Tactic: 0 Time: 4.69424
[05/21/2022-02:47:38] [V] [TRT] Fastest Tactic: 1002 Time: 1.25534
[05/21/2022-02:47:38] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:38] [V] [TRT] Tactic: 1002 Time: 1.7657
[05/21/2022-02:47:38] [V] [TRT] Tactic: 0 Time: 5.28638
[05/21/2022-02:47:38] [V] [TRT] Fastest Tactic: 1002 Time: 1.7657
[05/21/2022-02:47:38] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:38] [V] [TRT] Tactic: 1002 Time: 1.62527
[05/21/2022-02:47:38] [V] [TRT] Tactic: 0 Time: 4.91635
[05/21/2022-02:47:38] [V] [TRT] Fastest Tactic: 1002 Time: 1.62527
[05/21/2022-02:47:38] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:38] [V] [TRT] Tactic: 1002 Time: 1.16168
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 2.38548
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.16168
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.31818
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 4.75091
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.31818
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.83398
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 5.23132
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.83398
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.70193
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 1.16365
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 0 Time: 1.16365
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.22913
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 2.16776
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.22913
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.227
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 4.17345
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.227
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.25221
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 1.07148
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 0 Time: 1.07148
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.59273
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 0.941921
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 0 Time: 0.941921
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.23902
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 2.41917
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.23902
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:39] [V] [TRT] Tactic: 1002 Time: 1.2726
[05/21/2022-02:47:39] [V] [TRT] Tactic: 0 Time: 4.3426
[05/21/2022-02:47:39] [V] [TRT] Fastest Tactic: 1002 Time: 1.2726
[05/21/2022-02:47:39] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 2.65249
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 0.914987
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 0 Time: 0.914987
[05/21/2022-02:47:40] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,20736,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 1.54049
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 1.25656
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 0 Time: 1.25656
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,20736,144,1) -> Float(20736,20736:32,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 1.53928
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 2.09826
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 1.53928
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,20736,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 0.845944
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 0.681992
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 0 Time: 0.681992
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,20736,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 0.995059
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 0.546849
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 0 Time: 0.546849
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,4608,32) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 1.53167
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 2.2335
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 1.53167
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,4608,32) -> Float(20736,20736:32,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 1.48666
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 4.54329
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 1.48666
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,4608,32) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 0.635221
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 2.19577
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.635221
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,4608,32) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 0.84541
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 2.36119
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.84541
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 1.53134
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 2.2559
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 1.53134
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 1.48602
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 1.14609
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 0 Time: 1.14609
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 0.674551
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 2.26461
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.674551
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 0.845788
[05/21/2022-02:47:40] [V] [TRT] Tactic: 0 Time: 2.35165
[05/21/2022-02:47:40] [V] [TRT] Fastest Tactic: 1002 Time: 0.845788
[05/21/2022-02:47:40] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:40] [V] [TRT] Tactic: 1002 Time: 0.856315
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 0.582142
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 0 Time: 0.582142
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 0.620567
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 1.03704
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.620567
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736,144,1) -> Float(20736,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 0.620111
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 2.2336
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.620111
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 0.682539
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 0.541673
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 0 Time: 0.541673
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(331776,20736:2,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 0.815977
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 0.474766
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 0 Time: 0.474766
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(331776,20736:2,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 0.647995
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 1.16464
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.647995
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(331776,20736:2,144,1) -> Float(20736,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 0.626282
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 2.18749
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 1002 Time: 0.626282
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(331776,20736:2,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 2.13729
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 0.462832
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 0 Time: 0.462832
[05/21/2022-02:47:41] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(663552,20736,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(663552,20736,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(663552,20736,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,4608,32) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,4608,32) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,4608,32) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(20736,20736:32,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(331776,20736:2,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(331776,20736:2,144,1) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(331776,20736:2,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 2.8081
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 5.16892
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 1002 Time: 2.8081
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 3.39352
[05/21/2022-02:47:41] [V] [TRT] Tactic: 0 Time: 2.80141
[05/21/2022-02:47:41] [V] [TRT] Fastest Tactic: 0 Time: 2.80141
[05/21/2022-02:47:41] [V] [TRT] *************** Autotuning Reformat: Float(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:41] [V] [TRT] Tactic: 1002 Time: 4.24641
[05/21/2022-02:47:42] [V] [TRT] Tactic: 0 Time: 2.24764
[05/21/2022-02:47:42] [V] [TRT] Fastest Tactic: 0 Time: 2.24764
[05/21/2022-02:47:42] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:42] [V] [TRT] Tactic: 1002 Time: 3.26449
[05/21/2022-02:47:42] [V] [TRT] Tactic: 0 Time: 10.2043
[05/21/2022-02:47:42] [V] [TRT] Fastest Tactic: 1002 Time: 3.26449
[05/21/2022-02:47:42] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:42] [V] [TRT] Tactic: 1002 Time: 2.51533
[05/21/2022-02:47:42] [V] [TRT] Tactic: 0 Time: 10.0805
[05/21/2022-02:47:42] [V] [TRT] Fastest Tactic: 1002 Time: 2.51533
[05/21/2022-02:47:42] [V] [TRT] *************** Autotuning Reformat: Float(2654208,1,18432,128) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:42] [V] [TRT] Tactic: 1002 Time: 3.50669
[05/21/2022-02:47:42] [V] [TRT] Tactic: 0 Time: 10.5079
[05/21/2022-02:47:42] [V] [TRT] Fastest Tactic: 1002 Time: 3.50669
[05/21/2022-02:47:42] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:42] [V] [TRT] Tactic: 1002 Time: 3.25458
[05/21/2022-02:47:43] [V] [TRT] Tactic: 0 Time: 9.5918
[05/21/2022-02:47:43] [V] [TRT] Fastest Tactic: 1002 Time: 3.25458
[05/21/2022-02:47:43] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:43] [V] [TRT] Tactic: 1002 Time: 2.49798
[05/21/2022-02:47:43] [V] [TRT] Tactic: 0 Time: 4.58375
[05/21/2022-02:47:43] [V] [TRT] Fastest Tactic: 1002 Time: 2.49798
[05/21/2022-02:47:43] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:43] [V] [TRT] Tactic: 1002 Time: 2.62651
[05/21/2022-02:47:43] [V] [TRT] Tactic: 0 Time: 8.86365
[05/21/2022-02:47:43] [V] [TRT] Fastest Tactic: 1002 Time: 2.62651
[05/21/2022-02:47:43] [V] [TRT] *************** Autotuning Reformat: Float(82944,20736:32,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:43] [V] [TRT] Tactic: 1002 Time: 3.40153
[05/21/2022-02:47:43] [V] [TRT] Tactic: 0 Time: 9.43731
[05/21/2022-02:47:43] [V] [TRT] Fastest Tactic: 1002 Time: 3.40153
[05/21/2022-02:47:43] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:43] [V] [TRT] Tactic: 1002 Time: 3.41415
[05/21/2022-02:47:43] [V] [TRT] Tactic: 0 Time: 2.304
[05/21/2022-02:47:43] [V] [TRT] Fastest Tactic: 0 Time: 2.304
[05/21/2022-02:47:43] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 2.45408
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 4.81378
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 1002 Time: 2.45408
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(2654208,20736,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 2.56373
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 2.13454
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 0 Time: 2.13454
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 3.16472
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 1.86713
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 0 Time: 1.86713
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 2.47743
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 4.73839
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 1002 Time: 2.47743
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736:2,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 4.86149
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 1.8187
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 0 Time: 1.8187
[05/21/2022-02:47:44] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(1327104,1,9216,64) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(41472,20736:32,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(1327104,20736,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:47:44] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 0.702519
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 1.22447
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.702519
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 0.711231
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 2.1143
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 1002 Time: 0.711231
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 0.905944
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 0.683646
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 0 Time: 0.683646
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 0.997031
[05/21/2022-02:47:44] [V] [TRT] Tactic: 0 Time: 0.547819
[05/21/2022-02:47:44] [V] [TRT] Fastest Tactic: 0 Time: 0.547819
[05/21/2022-02:47:44] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:44] [V] [TRT] Tactic: 1002 Time: 0.803717
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.5102
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.803717
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.574382
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 4.44063
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.574382
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.633034
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.40555
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.633034
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.85431
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.7207
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.85431
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.817481
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.24946
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.817481
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.573952
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 1.14626
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.573952
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.665
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.17398
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.665
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.854205
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.34034
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.854205
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.915059
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 0.581673
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 0 Time: 0.581673
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.620378
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 1.04013
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.620378
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.619688
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.09304
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.619688
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.62582
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 0.540827
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 0 Time: 0.540827
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.78832
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 0.471803
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 0 Time: 0.471803
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.626465
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 1.16313
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.626465
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 0.625124
[05/21/2022-02:47:45] [V] [TRT] Tactic: 0 Time: 2.04718
[05/21/2022-02:47:45] [V] [TRT] Fastest Tactic: 1002 Time: 0.625124
[05/21/2022-02:47:45] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:45] [V] [TRT] Tactic: 1002 Time: 1.20458
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 0.462096
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 0 Time: 0.462096
[05/21/2022-02:47:46] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.703874
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 1.20833
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.703874
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.704766
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 2.10374
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.704766
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.906302
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 0.682578
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 0 Time: 0.682578
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.998737
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 0.546465
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 0 Time: 0.546465
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.803001
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 2.41515
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.803001
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.579674
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 4.50819
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.579674
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.633177
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 2.3814
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.633177
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.853398
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 2.52855
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.853398
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.915299
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 0.582076
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 0 Time: 0.582076
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.620332
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 1.04314
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.620332
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.620319
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 2.10518
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.620319
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.627598
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 0.541517
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 0 Time: 0.541517
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.789069
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 0.472357
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 0 Time: 0.472357
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.625495
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 1.16366
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.625495
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 0.626028
[05/21/2022-02:47:46] [V] [TRT] Tactic: 0 Time: 2.0973
[05/21/2022-02:47:46] [V] [TRT] Fastest Tactic: 1002 Time: 0.626028
[05/21/2022-02:47:46] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-02:47:46] [V] [TRT] Tactic: 1002 Time: 1.20911
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.462109
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 0 Time: 0.462109
[05/21/2022-02:47:47] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.35724
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.575703
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.35724
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.357826
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.06193
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.357826
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.541836
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.463125
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 0 Time: 0.463125
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.50263
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.553281
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.50263
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.412018
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.20191
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.412018
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.292754
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 2.16437
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.292754
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.32332
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.19346
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.32332
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.443249
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.2566
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.443249
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.405925
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.11521
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.405925
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.292494
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.579128
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.292494
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.338841
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.09042
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.338841
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.421647
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.17105
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.421647
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.546764
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.466731
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 0 Time: 0.466731
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.316159
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.507858
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.316159
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.316497
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.04828
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.316497
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.317383
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.494701
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.317383
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.401953
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.240794
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 0 Time: 0.240794
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.318978
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.587331
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.318978
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.31888
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.03548
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.31888
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.670886
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.23612
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 0 Time: 0.23612
[05/21/2022-02:47:47] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.360345
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.591126
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.360345
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.364557
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 1.06563
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 1002 Time: 0.364557
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.542806
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.463515
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 0 Time: 0.463515
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:47] [V] [TRT] Tactic: 1002 Time: 0.50651
[05/21/2022-02:47:47] [V] [TRT] Tactic: 0 Time: 0.278555
[05/21/2022-02:47:47] [V] [TRT] Fastest Tactic: 0 Time: 0.278555
[05/21/2022-02:47:47] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.403392
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.13807
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.403392
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.293874
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 2.49546
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.293874
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.340488
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.1691
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.340488
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.424635
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.21135
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.424635
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.408952
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.11335
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.408952
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.294551
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 0.578437
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.294551
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.33989
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.1024
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.33989
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.423503
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.20616
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.423503
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.547734
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 0.467051
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 0 Time: 0.467051
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.31571
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 0.534128
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.31571
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.340612
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.09702
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.340612
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.319701
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 0.27724
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 0 Time: 0.27724
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.415293
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 0.54595
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.415293
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.326901
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 0.587272
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.326901
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.318665
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 1.16301
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.318665
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.86207
[05/21/2022-02:47:48] [V] [TRT] Tactic: 0 Time: 0.493717
[05/21/2022-02:47:48] [V] [TRT] Fastest Tactic: 0 Time: 0.493717
[05/21/2022-02:47:48] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:48] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:48] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:48] [V] [TRT] Tactic: 1002 Time: 0.358848
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.597891
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.358848
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.393203
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.16384
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.393203
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.524694
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.34778
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 0 Time: 0.34778
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.505202
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.278216
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 0 Time: 0.278216
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.404128
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.17863
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.404128
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.294564
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 2.45092
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.294564
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.322494
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.16427
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.322494
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.421562
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.23874
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.421562
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.415924
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.17346
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.415924
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.299277
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.579388
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.299277
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.340521
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.16776
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.340521
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.422364
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.24819
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.422364
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.463294
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.29636
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 0 Time: 0.29636
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.316537
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.522149
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.316537
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.317018
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.19377
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.317018
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.325807
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.275462
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 0 Time: 0.275462
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.402943
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.240606
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 0 Time: 0.240606
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.319467
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 0.586999
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.319467
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:49] [V] [TRT] Tactic: 1002 Time: 0.320234
[05/21/2022-02:47:49] [V] [TRT] Tactic: 0 Time: 1.03698
[05/21/2022-02:47:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.320234
[05/21/2022-02:47:49] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.670605
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.235078
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 0 Time: 0.235078
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.35569
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.56541
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.35569
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.45776
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.346621
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 0 Time: 0.346621
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.502825
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.278503
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 0 Time: 0.278503
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.403887
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.13452
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.403887
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.323952
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.11889
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.323952
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.421523
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.21904
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.421523
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.413639
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.15916
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.413639
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.294297
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.578828
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.294297
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.339994
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.09915
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.339994
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.426439
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.24822
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.426439
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.465084
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.295742
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 0 Time: 0.295742
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.335157
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.534453
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.335157
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.315716
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.275963
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 0 Time: 0.275963
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.41776
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.242122
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 0 Time: 0.242122
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.318991
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.586947
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.318991
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.698841
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.236309
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 0 Time: 0.236309
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.356563
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.16304
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.356563
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.29444
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 2.42987
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.29444
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.316784
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.07856
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.316784
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.332851
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 1.07531
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.332851
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,4608,64) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(10368,5184:32,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(663552,1,9216,128) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(20736,5184:32,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(663552,5184,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:47:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:50] [V] [TRT] Tactic: 1002 Time: 0.370651
[05/21/2022-02:47:50] [V] [TRT] Tactic: 0 Time: 0.601849
[05/21/2022-02:47:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.370651
[05/21/2022-02:47:50] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.376745
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.780879
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.376745
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.499831
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.347318
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.347318
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.497265
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.278236
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.278236
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.418093
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.532012
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.418093
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.309629
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 1.44122
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.309629
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.326289
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.532832
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.326289
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.422702
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.61233
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.422702
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.413249
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.597461
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.413249
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.30722
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.578796
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.30722
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.342617
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.600951
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.342617
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.424974
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.680872
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.424974
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.505651
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.29543
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.29543
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.320651
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.508197
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.320651
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.319837
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.781973
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.319837
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.334948
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.275644
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.275644
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.402487
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.240521
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.240521
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.322363
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.586758
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.322363
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.322513
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.777572
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.322513
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.604837
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.235247
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.235247
[05/21/2022-02:47:51] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.370254
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.585391
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.370254
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.370482
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.780169
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.370482
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.498835
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.346523
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.346523
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.496934
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.278385
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.278385
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.418106
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.531882
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.418106
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.305911
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 1.4255
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.305911
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.326797
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.532637
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.326797
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.422298
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.61179
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.422298
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.504486
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.295384
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.295384
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.320078
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.508112
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.320078
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.320345
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.780872
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.320345
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:51] [V] [TRT] Tactic: 1002 Time: 0.336094
[05/21/2022-02:47:51] [V] [TRT] Tactic: 0 Time: 0.275403
[05/21/2022-02:47:51] [V] [TRT] Fastest Tactic: 0 Time: 0.275403
[05/21/2022-02:47:51] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.401133
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.240872
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.240872
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.322064
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.586842
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.322064
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.322018
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.778151
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.322018
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.596882
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.235722
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.235722
[05/21/2022-02:47:52] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.187285
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.283926
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.187285
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.188236
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.394368
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.188236
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.300853
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.236602
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.236602
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.253926
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.281667
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.253926
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.219538
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.271549
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.219538
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.157741
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.720215
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.157741
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.168756
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.272012
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.168756
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.218509
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.31183
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.218509
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.218724
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.305267
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.218724
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.15558
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.294661
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.15558
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.176966
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.305847
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.176966
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.218118
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.346452
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.218118
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.303431
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.237962
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.237962
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.16571
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.258157
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.16571
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.165436
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.395612
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.165436
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.173158
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.252402
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.173158
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.20849
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.123952
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.123952
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.166159
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.2989
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.166159
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.165833
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.39403
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.165833
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.307799
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.121706
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.121706
[05/21/2022-02:47:52] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.188157
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.287897
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.188157
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.187357
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.395045
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.187357
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.300541
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.236979
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.236979
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.254388
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.143138
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.143138
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.216816
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.271426
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.216816
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.154746
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.722291
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.154746
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.168464
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.271647
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.168464
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.217943
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.310924
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.217943
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.214407
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.304147
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.214407
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.156823
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.294219
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.156823
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.176569
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.305859
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.176569
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.21819
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.345833
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.21819
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.302877
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.237513
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.237513
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.165729
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.257793
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.165729
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.166002
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.3975
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.166002
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.17388
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.142214
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 0 Time: 0.142214
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.208125
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.277467
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.208125
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.167494
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.298796
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.167494
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.165833
[05/21/2022-02:47:52] [V] [TRT] Tactic: 0 Time: 0.396953
[05/21/2022-02:47:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.165833
[05/21/2022-02:47:52] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-02:47:52] [V] [TRT] Tactic: 1002 Time: 0.307826
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.251491
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.251491
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.187552
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.287194
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.187552
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.188548
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.392591
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.188548
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.254707
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.178906
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.178906
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.253796
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.143301
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.143301
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.219251
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.269844
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.219251
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.154316
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.733047
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.154316
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.168477
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.271426
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.168477
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.218769
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.31123
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.218769
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.216146
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.302969
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.216146
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.156934
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.29431
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.156934
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.176745
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.305645
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.176745
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.217747
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.34584
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.217747
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.257969
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.151888
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.151888
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.165827
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.257865
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.165827
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.165462
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.39431
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.165462
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.174095
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.141986
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.141986
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.20748
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.124505
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.124505
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.165827
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.29888
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.165827
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.16571
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.39569
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.16571
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.309518
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.121751
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.121751
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.189909
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.286465
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.189909
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.254681
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.179232
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.179232
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.253112
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.143093
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.143093
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.218978
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.269987
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.218978
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.16808
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.270853
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.16808
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.218184
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.310996
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.218184
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.216725
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.303841
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.216725
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.15582
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.294317
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.15582
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.176354
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.305085
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.176354
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.218131
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.345755
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.218131
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.258008
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.152116
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.152116
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.165977
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.257623
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.165977
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.174837
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.141627
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.141627
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.20778
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.124102
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.124102
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.165677
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.29834
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.165677
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.306582
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.121309
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 0 Time: 0.121309
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.186823
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.393366
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.186823
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.153516
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.730586
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.153516
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.165879
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.395846
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.165879
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.165833
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.394023
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.165833
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.410905
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.597793
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.410905
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.303307
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.578646
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.303307
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-02:47:53] [V] [TRT] Tactic: 1002 Time: 0.342363
[05/21/2022-02:47:53] [V] [TRT] Tactic: 0 Time: 0.600469
[05/21/2022-02:47:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.342363
[05/21/2022-02:47:53] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.424902
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.680521
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.424902
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:47:54] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.218874
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.257415
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.218874
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.219642
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.380378
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.219642
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 4.99159
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.179004
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.179004
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.267012
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.143307
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.143307
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.264056
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.256888
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.256888
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.179388
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.532565
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.179388
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.184538
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.253457
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.184538
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.228815
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.285911
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.228815
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.260442
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.283848
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.260442
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.181452
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.294433
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.181452
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.192272
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.280508
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.192272
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.228522
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.324889
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.228522
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 5.19909
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.152103
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.152103
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.178184
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.257415
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.178184
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.17849
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.384459
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.17849
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.192923
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.142038
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.142038
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.249772
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.124297
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.124297
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.179486
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.298568
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.179486
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.179395
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.38543
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.179395
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.361445
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.121959
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.121959
[05/21/2022-02:47:54] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.215807
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.256966
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.215807
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.218704
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.380794
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.218704
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 4.99266
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.178157
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.178157
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.266569
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.143112
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.143112
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.262188
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.257884
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 0 Time: 0.257884
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.180501
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.533516
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.180501
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.184694
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.256101
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.184694
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 0.228528
[05/21/2022-02:47:54] [V] [TRT] Tactic: 0 Time: 0.286855
[05/21/2022-02:47:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.228528
[05/21/2022-02:47:54] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:54] [V] [TRT] Tactic: 1002 Time: 5.20107
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.152364
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.152364
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.17821
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.257357
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.17821
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.178392
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.384798
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.178392
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.194518
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.142096
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.142096
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.249805
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.124492
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.124492
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.178718
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.29862
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.178718
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.178919
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.385781
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.178919
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.362272
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.121933
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.121933
[05/21/2022-02:47:55] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.111413
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.135593
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.111413
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.111042
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.195032
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.111042
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 2.9234
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.122175
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.122175
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.137656
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.144694
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.137656
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.14015
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.133197
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.133197
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0936653
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.270286
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0936653
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0977731
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.130755
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0977731
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.119147
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.14806
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.119147
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.139141
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.14711
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.139141
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0951429
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.151601
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0951429
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.10071
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.145241
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.10071
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.118626
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.167278
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.118626
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 3.0279
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.122708
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.122708
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0932291
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.133359
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0932291
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0932815
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.197272
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0932815
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.102598
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.130137
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.102598
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.131237
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.0646612
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.0646612
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0934635
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.15345
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0934635
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0937695
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.199108
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0937695
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.188281
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.0635939
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.0635939
[05/21/2022-02:47:55] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.111256
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.134896
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.111256
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.11054
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.195586
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.11054
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 2.92331
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.122578
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.122578
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.137761
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.074707
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.074707
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.142819
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.132383
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.132383
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0950069
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.257422
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0950069
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0980275
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.132422
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0980275
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.118463
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.149271
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.118463
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.140989
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.146842
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.140989
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0958268
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.151263
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0958268
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.100697
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.144316
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.100697
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.119128
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.167975
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.119128
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 3.02747
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.12278
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.12278
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0933596
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.132891
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0933596
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.0931445
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.197292
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.0931445
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.102168
[05/21/2022-02:47:55] [V] [TRT] Tactic: 0 Time: 0.073978
[05/21/2022-02:47:55] [V] [TRT] Fastest Tactic: 0 Time: 0.073978
[05/21/2022-02:47:55] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:55] [V] [TRT] Tactic: 1002 Time: 0.132643
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.142956
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.132643
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0935741
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.153835
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0935741
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0936196
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.19819
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0936196
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.186146
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.129831
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.129831
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.110039
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.134323
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.110039
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.109746
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.195403
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.109746
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 2.52963
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0928581
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0928581
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.138014
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0746548
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0746548
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.140033
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.135371
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.135371
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0946094
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.262148
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0946094
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0977215
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.13054
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0977215
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.118965
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.14845
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.118965
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.142663
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.147109
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.142663
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0944859
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.151973
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0944859
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.102318
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.145417
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.102318
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.118874
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.16707
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.118874
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 2.60694
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0787302
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0787302
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0949933
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.133444
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0949933
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0939908
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.197253
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0939908
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.103555
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0739126
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0739126
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.131706
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0645962
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0645962
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0938541
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.153242
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0938541
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0936005
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.198002
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0936005
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.188105
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0636979
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0636979
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.110833
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.134161
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.110833
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 2.50043
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0939258
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0939258
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.137741
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0749934
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0749934
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.137709
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.135794
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.135794
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.097663
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.130352
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.097663
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.118919
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.14888
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.118919
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.142246
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.146491
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.142246
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0959896
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.151328
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0959896
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.100872
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.14528
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.100872
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.119036
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.167005
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.119036
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 2.60631
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0788869
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0788869
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.093698
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.132949
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.093698
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.103027
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0741795
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0741795
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.131777
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0650129
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0650129
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0937306
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.153516
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0937306
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.186719
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.0636001
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 0 Time: 0.0636001
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.109941
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.194798
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.109941
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0952734
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.261739
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0952734
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0930597
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.19748
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0930597
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.0936718
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.197806
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.0936718
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.262904
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.28528
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.262904
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.181074
[05/21/2022-02:47:56] [V] [TRT] Tactic: 0 Time: 0.294323
[05/21/2022-02:47:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.181074
[05/21/2022-02:47:56] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-02:47:56] [V] [TRT] Tactic: 1002 Time: 0.191237
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.280384
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.191237
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.228327
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.325091
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.228327
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:47:57] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.145834
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.132709
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.132709
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.145599
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.195319
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.145599
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 2.72673
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0934375
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0934375
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.146823
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.074987
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.074987
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.155671
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.120794
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.120794
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.128021
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.218001
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.128021
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.106152
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.121836
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.106152
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.130846
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.145072
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.130846
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.156179
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.141126
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.141126
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.126803
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.151797
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.126803
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.109889
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.142038
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.109889
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.128568
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.166016
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.128568
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 2.84203
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0787045
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0787045
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.102695
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.133249
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.102695
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.103105
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.196218
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.103105
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.122748
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.074212
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.074212
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.134167
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0650131
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0650131
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.103099
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.154193
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.103099
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.102884
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.197774
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.102884
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.186361
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0635742
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0635742
[05/21/2022-02:47:57] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.145365
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.131413
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.131413
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.144127
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.194857
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.144127
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 2.72773
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0939129
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0939129
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.14696
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0749739
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0749739
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.157363
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.12054
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.12054
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.127682
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.218789
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.127682
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.105853
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.122272
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.105853
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.129837
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.144883
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.129837
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 2.84242
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0787565
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0787565
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.103633
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.133021
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.103633
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.102988
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.196009
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.102988
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.121426
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0739845
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0739845
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.134089
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0647138
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0647138
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.103516
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.153822
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.103516
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.103294
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.197969
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.103294
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.18582
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0637111
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0637111
[05/21/2022-02:47:57] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0768034
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0694012
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0694012
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0755991
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.101419
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0755991
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 1.59917
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0635091
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0635091
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0758726
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.075228
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.075228
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0863217
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0635221
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0635221
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0692384
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.113001
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0692384
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0563999
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0635939
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0563999
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0678385
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.075254
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0678385
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0855208
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0733982
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0733982
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0688084
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.079017
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0688084
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0574808
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0738736
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0574808
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0671481
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0858659
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0671481
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 1.65694
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0636525
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 0 Time: 0.0636525
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0548175
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.0696939
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0548175
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:57] [V] [TRT] Tactic: 1002 Time: 0.0547526
[05/21/2022-02:47:57] [V] [TRT] Tactic: 0 Time: 0.100957
[05/21/2022-02:47:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.0547526
[05/21/2022-02:47:57] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0609764
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0674348
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0609764
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0730664
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0341211
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0341211
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0543425
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0800326
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0543425
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.054212
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.102851
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.054212
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0956968
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0337044
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0337044
[05/21/2022-02:47:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0766796
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0686717
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0686717
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0758725
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.101146
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0758725
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 1.59873
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0641211
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0641211
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0759896
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0393165
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0393165
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0864649
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.063164
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.063164
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0689061
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.112331
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0689061
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0561325
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0637757
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0561325
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0676757
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.075293
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0676757
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0863283
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0735157
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0735157
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.069043
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0788671
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.069043
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0579685
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0739127
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0579685
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0677996
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0857745
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0677996
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 1.65635
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0634762
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0634762
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0551172
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0697264
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0551172
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0538149
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.100827
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0538149
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.061289
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.038828
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.038828
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.072754
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0740234
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.072754
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0544466
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0801626
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0544466
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.054948
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.102187
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.054948
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0960545
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0671484
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0671484
[05/21/2022-02:47:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0773114
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0690104
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0690104
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0756771
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.101426
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0756771
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 1.36805
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0476364
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0476364
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0761199
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0390755
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0390755
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0865887
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0634374
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0634374
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0694534
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.112513
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0694534
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0564518
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0637435
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0564518
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0678256
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0754362
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0678256
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0856706
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0734897
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0734897
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0690105
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0791409
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0690105
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0575846
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.073926
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0575846
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0675523
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0862435
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0675523
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 1.42628
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0414711
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0414711
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0544726
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.069707
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0544726
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0547459
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.101237
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0547459
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0612305
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0385287
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0385287
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0728644
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0339778
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0339778
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.054642
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0800716
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.054642
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0542902
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.102611
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0542902
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0958201
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0337174
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0337174
[05/21/2022-02:47:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0767644
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0689191
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0689191
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 1.36786
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0473634
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0473634
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0758204
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.039655
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.039655
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0860028
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0635028
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0635028
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0559245
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0642185
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0559245
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.067949
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.075814
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.067949
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0876171
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0732489
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0732489
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0684829
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0788999
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0684829
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0580859
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0743685
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0580859
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0676823
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0860609
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0676823
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 1.42553
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0412761
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0412761
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.0547265
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.069245
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.0547265
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.061322
[05/21/2022-02:47:58] [V] [TRT] Tactic: 0 Time: 0.0383009
[05/21/2022-02:47:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0383009
[05/21/2022-02:47:58] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:58] [V] [TRT] Tactic: 1002 Time: 0.072806
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0339973
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0339973
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0546288
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0801496
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0546288
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0958465
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0333071
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0333071
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0762435
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.101354
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0762435
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0700194
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.112825
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0700194
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0542904
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.101536
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0542904
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0543096
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.10209
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0543096
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 4.14004
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0242189
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0242189
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0764909
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0688411
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0688411
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 1.59826
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0636067
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0636067
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0763803
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0388673
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0388673
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 1.65585
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0640102
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0640102
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0541211
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0693684
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0541211
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 1.62725
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.00804025
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.00804025
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0636458
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0384961
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0384961
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0738084
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.073991
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0738084
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0541214
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.079668
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0541214
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0957358
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0673437
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0673437
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0766799
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.00800138
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.00800138
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 4.14113
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0246286
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0246286
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.076341
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0692514
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0692514
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 1.59862
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0635938
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0635938
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.076569
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0396745
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0396745
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 1.65588
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0634701
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0634701
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0547461
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.069629
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0547461
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 1.6263
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.00792313
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.00792313
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0616212
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0383526
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0383526
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.072233
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0740106
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.072233
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0548046
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.080013
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.0548046
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0956701
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0672266
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0672266
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.076341
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.00798825
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.00798825
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 4.14312
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0246745
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0246745
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0772985
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0691798
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0691798
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 1.60074
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0631575
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0631575
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:47:59] [V] [TRT] Tactic: 1002 Time: 0.0755729
[05/21/2022-02:47:59] [V] [TRT] Tactic: 0 Time: 0.0391471
[05/21/2022-02:47:59] [V] [TRT] Fastest Tactic: 0 Time: 0.0391471
[05/21/2022-02:47:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:47:59] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:47:59] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 1.65679
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0640625
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0640625
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0539256
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0688023
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0539256
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 1.627
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.00800787
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.00800787
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0614517
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0384116
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0384116
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0721746
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0741535
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0721746
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0546939
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0804689
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0546939
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0957551
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0672851
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0672851
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0761721
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.00800138
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.00800138
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 4.14348
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0244922
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0244922
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0766341
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0687698
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0687698
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 1.59896
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0637434
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0637434
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0766214
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0393359
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0393359
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0866928
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0632421
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0632421
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0583984
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0675131
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0583984
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0557226
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0633527
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0557226
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.067298
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0751044
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.067298
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0858529
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0735221
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0735221
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0687305
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0790299
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0687305
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0579885
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0738607
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0579885
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0674805
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0857618
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0674805
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 1.65521
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0639256
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0639256
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0546943
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0692187
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0546943
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 1.62608
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.00795588
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.00795588
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0610483
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0385872
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.0385872
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0731575
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.0744595
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0731575
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0550389
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.080625
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.0550389
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.0962241
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.067207
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.067207
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.076621
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.00791625
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.00791625
[05/21/2022-02:48:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:00] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(165888,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.283926
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.460358
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.283926
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(165888,81,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 5.44147
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.179421
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.179421
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(165888,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.281647
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.143229
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.143229
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,18432,2048) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.299538
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.233607
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 0 Time: 0.233607
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,18432,2048) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.201022
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.236693
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.201022
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,18432,2048) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:00] [V] [TRT] Tactic: 1002 Time: 0.25015
[05/21/2022-02:48:00] [V] [TRT] Tactic: 0 Time: 0.282285
[05/21/2022-02:48:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.25015
[05/21/2022-02:48:00] [V] [TRT] *************** Autotuning Reformat: Half(165888,81,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 5.68656
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.151608
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.151608
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,81,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.196465
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.421869
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.196465
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,81,9,1) -> Half(82944,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.230228
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.141589
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.141589
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81:2,9,1) -> Float(165888,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.255273
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.124688
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.124688
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81:2,9,1) -> Float(165888,1,18432,2048) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.197435
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.298945
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.197435
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81:2,9,1) -> Half(165888,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.359024
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.122123
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.122123
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,81,9,1) -> Float(20736,1,2304,256) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0382747
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0364127
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0364127
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,81,9,1) -> Float(648,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0383333
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0523308
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0383333
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,81,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.688659
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.025397
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.025397
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,81,9,1) -> Half(10368,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0409375
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0213019
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0213019
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,1,2304,256) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0457029
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0333331
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0333331
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,1,2304,256) -> Float(648,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0335546
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0575584
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0335546
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,1,2304,256) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.030124
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0337629
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.030124
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,1,2304,256) -> Half(10368,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0363869
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0388995
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0363869
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(648,81:32,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0452409
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0386001
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0386001
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(648,81:32,9,1) -> Float(20736,1,2304,256) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0336261
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0408138
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0336261
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(648,81:32,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0318359
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0383266
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0318359
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(648,81:32,9,1) -> Half(10368,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0361002
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0451171
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0361002
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.717481
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0220314
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0220314
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81,9,1) -> Float(20736,1,2304,256) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0290104
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0368881
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0290104
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81,9,1) -> Float(648,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0295377
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0523178
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0295377
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81,9,1) -> Half(10368,81:2,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.034707
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0211395
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0211395
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(10368,81:2,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0406381
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.018815
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.018815
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(10368,81:2,9,1) -> Float(20736,1,2304,256) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.029219
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0413543
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.029219
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(10368,81:2,9,1) -> Float(648,81:32,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0290888
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0535289
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.0290888
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(10368,81:2,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0515884
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0179364
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0179364
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,81,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,1,2304,256) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(20736,1,2304,256) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(648,81:32,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(648,81:32,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(20736,81,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(10368,81:2,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(10368,81:2,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.20541
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0474805
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0474805
[05/21/2022-02:48:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.146992
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.16082
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.146992
[05/21/2022-02:48:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.113464
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.195436
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.113464
[05/21/2022-02:48:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 3.0187
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.122643
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.122643
[05/21/2022-02:48:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.13905
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.0756445
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.0756445
[05/21/2022-02:48:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 3.11939
[05/21/2022-02:48:01] [V] [TRT] Tactic: 0 Time: 0.122884
[05/21/2022-02:48:01] [V] [TRT] Fastest Tactic: 0 Time: 0.122884
[05/21/2022-02:48:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:01] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:01] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:01] [V] [TRT] Tactic: 1002 Time: 0.0937696
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.134108
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0937696
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0931383
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.197676
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0931383
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 2.97792
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0245184
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0245184
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.103945
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.073841
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.073841
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,324,18,1) -> Float(41472,1,2304,128) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0593229
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.070625
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0593229
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,324,18,1) -> Float(1296,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0573504
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.101133
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0573504
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,324,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 1.27857
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0478254
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0478254
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,324,18,1) -> Half(20736,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0741211
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0389647
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0389647
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,2304,128) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0839714
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0690691
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0690691
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,2304,128) -> Float(1296,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.052116
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.135098
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.052116
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,2304,128) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0527735
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0653906
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0527735
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,2304,128) -> Half(20736,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0641078
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.07625
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0641078
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(1296,324:32,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0814454
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0766404
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0766404
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(1296,324:32,18,1) -> Float(41472,1,2304,128) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0500523
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.079499
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0500523
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(1296,324:32,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.058789
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0763348
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.058789
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(1296,324:32,18,1) -> Half(20736,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0711456
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0870053
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0711456
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 1.35768
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0412825
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0412825
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324,18,1) -> Float(41472,1,2304,128) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0511003
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0755341
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0511003
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324,18,1) -> Float(1296,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.107656
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.102676
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.102676
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324,18,1) -> Half(20736,324:2,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0521745
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0561913
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0521745
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(20736,324:2,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0711264
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.034336
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.034336
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(20736,324:2,18,1) -> Float(41472,1,2304,128) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0494402
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0800064
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0494402
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(20736,324:2,18,1) -> Float(1296,324:32,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.0500716
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.102493
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.0500716
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(20736,324:2,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.093568
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0336
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0336
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,324,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,2304,128) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,2304,128) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(1296,324:32,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(1296,324:32,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(41472,324,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(20736,324:2,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(20736,324:2,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.302656
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.089948
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.089948
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.191504
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.296015
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.191504
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.19181
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.395514
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.19181
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.300677
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.236601
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.236601
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.255059
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.143698
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.143698
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.303138
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.238796
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.238796
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.182025
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.264792
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.182025
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.165612
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.400723
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.165612
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.20914
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.0463934
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.0463934
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-02:48:02] [V] [TRT] Tactic: 1002 Time: 0.173704
[05/21/2022-02:48:02] [V] [TRT] Tactic: 0 Time: 0.141804
[05/21/2022-02:48:02] [V] [TRT] Fastest Tactic: 0 Time: 0.141804
[05/21/2022-02:48:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(331776,1,9216,256) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(10368,1296:32,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(331776,1296,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(330480,1,9180,255) -> Float(330480,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 139_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.475534
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.496257
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.475534
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(330480,1296,36,1) -> Float(330480,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 139_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.504603
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.294883
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.294883
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296:2,36,1) -> Float(330480,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 139_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.400274
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.2397
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.2397
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,4608,128) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,1296:32,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,1296,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(165888,1,9216,512) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(5184,324:32,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(165888,324,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82620,1,4590,255) -> Float(82620,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 150_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.154759
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.122122
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.122122
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82620,324,18,1) -> Float(82620,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 150_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 2.59579
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.0791993
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0791993
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82620,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 150_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.132337
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.0650586
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0650586
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,4608,256) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,324:32,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,324,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(41472,1,4608,512) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(1296,81:32,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(82944,1,9216,1024) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(2592,81:32,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(82944,81,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Float(20655,1,2295,255) -> Float(20655,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 161_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.0491995
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.0334699
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0334699
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(20655,81,9,1) -> Float(20655,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 161_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.715163
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.022552
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.022552
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning Reformat: Half(10368,81:2,9,1) -> Float(20655,81,9,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 161_convolutional) (Reformat)
[05/21/2022-02:48:03] [V] [TRT] Tactic: 1002 Time: 0.0404751
[05/21/2022-02:48:03] [V] [TRT] Tactic: 0 Time: 0.0187435
[05/21/2022-02:48:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0187435
[05/21/2022-02:48:03] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:48:03] [V] [TRT] *************** Autotuning format combination: Float(248832,82944,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:48:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:48:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:48:03] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-02:48:08] [V] [TRT] Tactic: 0 Time: 5.45841
[05/21/2022-02:48:08] [V] [TRT] Tactic: 1 Time: 4.39087
[05/21/2022-02:48:08] [V] [TRT] Tactic: 2 Time: 9.274
[05/21/2022-02:48:09] [V] [TRT] Tactic: 5 Time: 66.4815
[05/21/2022-02:48:09] [V] [TRT] Tactic: 6 Time: 4.68562
[05/21/2022-02:48:09] [V] [TRT] Fastest Tactic: 1 Time: 4.39087
[05/21/2022-02:48:09] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-02:48:09] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:48:09] [V] [TRT] Tactic: 1062367460111450758 Time: 2.22997
[05/21/2022-02:48:09] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:48:09] [V] [TRT] Tactic: 1754984623894446479 Time: 2.12407
[05/21/2022-02:48:09] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:48:09] [V] [TRT] Tactic: 3611739942397549984 Time: 7.19322
[05/21/2022-02:48:09] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:48:09] [V] [TRT] Tactic: 3827454225649558724 Time: 5.30412
[05/21/2022-02:48:09] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:48:10] [V] [TRT] Tactic: 4337000649858996379 Time: 3.37852
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:48:10] [V] [TRT] Tactic: 4501471010995462441 Time: 6.68408
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:48:10] [V] [TRT] Tactic: 5137655947464784826 Time: 3.23899
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:48:10] [V] [TRT] Tactic: 5288347012147084929 Time: 7.04477
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:48:10] [V] [TRT] Tactic: 5921334924264294896 Time: 3.49325
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:48:10] [V] [TRT] Tactic: 6645123197870846056 Time: 3.33386
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:48:10] [V] [TRT] Tactic: 7144526460361122478 Time: 2.04724
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:48:10] [V] [TRT] Tactic: 7852627285308570038 Time: 5.55202
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:48:10] [V] [TRT] Tactic: -9137461792520977713 Time: 6.75123
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:48:10] [V] [TRT] Tactic: -8776506421218919509 Time: 5.17491
[05/21/2022-02:48:10] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:48:11] [V] [TRT] Tactic: -8262349710178828730 Time: 7.32756
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:48:11] [V] [TRT] Tactic: -8133971918129952780 Time: 3.5334
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:48:11] [V] [TRT] Tactic: -6092040395344634144 Time: 2.2973
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:48:11] [V] [TRT] Tactic: -4787320710726427159 Time: 2.14464
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:48:11] [V] [TRT] Tactic: -3456450830548107839 Time: 2.11471
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:48:11] [V] [TRT] Tactic: -2318106587342035239 Time: 5.30516
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:48:11] [V] [TRT] Tactic: -1343271414618805657 Time: 3.4161
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:48:11] [V] [TRT] Tactic: -1218658103698133241 Time: 3.35379
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:48:11] [V] [TRT] Tactic: -836875257600482091 Time: 3.29646
[05/21/2022-02:48:11] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:48:11] [V] [TRT] Tactic: -410470605513481746 Time: 6.59563
[05/21/2022-02:48:11] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 2.04724
[05/21/2022-02:48:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7144526460361122478
[05/21/2022-02:48:11] [V] [TRT] *************** Autotuning format combination: Float(248832,1,864,3) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:48:11] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-02:48:11] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:48:11] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-02:48:11] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:48:11] [V] [TRT] *************** Autotuning format combination: Half(248832,82944,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:48:11] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-02:48:11] [V] [TRT] Tactic: 0 Time: 4.10504
[05/21/2022-02:48:12] [V] [TRT] Tactic: 1 Time: 4.14027
[05/21/2022-02:48:12] [V] [TRT] Tactic: 2 Time: 9.09469
[05/21/2022-02:48:13] [V] [TRT] Tactic: 5 Time: 65.8969
[05/21/2022-02:48:13] [V] [TRT] Tactic: 6 Time: 6.49585
[05/21/2022-02:48:13] [V] [TRT] Fastest Tactic: 0 Time: 4.10504
[05/21/2022-02:48:13] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-02:48:13] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:48:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0
[05/21/2022-02:48:13] [V] [TRT] *************** Autotuning format combination: Half(165888,82944:2,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:48:13] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:48:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:48:13] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-02:48:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:48:13] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:48:13] [V] [TRT] Tactic: 3564772625446233998 Time: 1.65637
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:48:13] [V] [TRT] Tactic: 3650389455493082349 Time: 1.70532
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:48:13] [V] [TRT] Tactic: 4772821744921268633 Time: 2.82335
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:48:13] [V] [TRT] Tactic: 5319956359050645452 Time: 1.59669
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:48:13] [V] [TRT] Tactic: 7205456024582378848 Time: 2.46221
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:48:13] [V] [TRT] Tactic: -6490690591794140522 Time: 2.50505
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:48:13] [V] [TRT] Tactic: -4686027666808657977 Time: 4.9329
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:48:13] [V] [TRT] Tactic: -4212163711445252890 Time: 4.92044
[05/21/2022-02:48:13] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:48:14] [V] [TRT] Tactic: -3898373634979201110 Time: 4.88844
[05/21/2022-02:48:14] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:48:14] [V] [TRT] Tactic: -2409163523992614473 Time: 2.39143
[05/21/2022-02:48:14] [V] [TRT] Fastest Tactic: 5319956359050645452 Time: 1.59669
[05/21/2022-02:48:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452
[05/21/2022-02:48:14] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:48:14] [V] [TRT] *************** Autotuning format combination: Float(2654208,82944,288,1) -> Float(2654208,82944,288,1) ***************
[05/21/2022-02:48:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-02:48:15] [V] [TRT] Tactic: 0 Time: 4.83593
[05/21/2022-02:48:16] [V] [TRT] Tactic: 1 Time: 5.06835
[05/21/2022-02:48:17] [V] [TRT] Tactic: 2 Time: 6.08626
[05/21/2022-02:48:18] [V] [TRT] Tactic: 3 Time: 3.04943
[05/21/2022-02:48:19] [V] [TRT] Tactic: 4 Time: 3.52824
[05/21/2022-02:48:20] [V] [TRT] Tactic: 5 Time: 3.85003
[05/21/2022-02:48:21] [V] [TRT] Tactic: 6 Time: 2.21046
[05/21/2022-02:48:22] [V] [TRT] Tactic: 7 Time: 3.06865
[05/21/2022-02:48:23] [V] [TRT] Tactic: 8 Time: 2.88589
[05/21/2022-02:48:24] [V] [TRT] Tactic: 9 Time: 4.77482
[05/21/2022-02:48:25] [V] [TRT] Tactic: 28 Time: 4.65602
[05/21/2022-02:48:25] [V] [TRT] Fastest Tactic: 6 Time: 2.21046
[05/21/2022-02:48:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-02:48:25] [V] [TRT] Tactic: 128 Time: 10.9168
[05/21/2022-02:48:25] [V] [TRT] Tactic: 256 Time: 10.6713
[05/21/2022-02:48:26] [V] [TRT] Tactic: 512 Time: 10.6922
[05/21/2022-02:48:26] [V] [TRT] Tactic: -32 Time: 11.0248
[05/21/2022-02:48:26] [V] [TRT] Tactic: -64 Time: 10.9977
[05/21/2022-02:48:26] [V] [TRT] Tactic: -128 Time: 11.0695
[05/21/2022-02:48:26] [V] [TRT] Fastest Tactic: 256 Time: 10.6713
[05/21/2022-02:48:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 6
[05/21/2022-02:48:26] [V] [TRT] *************** Autotuning format combination: Float(2654208,1,9216,32) -> Float(2654208,1,9216,32) ***************
[05/21/2022-02:48:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-02:48:26] [V] [TRT] Tactic: 0 Time: 2.87041
[05/21/2022-02:48:26] [V] [TRT] Tactic: 1 Time: 2.12092
[05/21/2022-02:48:26] [V] [TRT] Tactic: 2 Time: 2.00769
[05/21/2022-02:48:26] [V] [TRT] Tactic: 3 Time: 1.76008
[05/21/2022-02:48:27] [V] [TRT] Tactic: 4 Time: 1.49911
[05/21/2022-02:48:27] [V] [TRT] Tactic: 5 Time: 1.54809
[05/21/2022-02:48:27] [V] [TRT] Tactic: 6 Time: 1.60247
[05/21/2022-02:48:27] [V] [TRT] Tactic: 7 Time: 1.30664
[05/21/2022-02:48:27] [V] [TRT] Tactic: 8 Time: 1.22764
[05/21/2022-02:48:27] [V] [TRT] Tactic: 9 Time: 1.31525
[05/21/2022-02:48:27] [V] [TRT] Tactic: 28 Time: 2.8223
[05/21/2022-02:48:27] [V] [TRT] Fastest Tactic: 8 Time: 1.22764
[05/21/2022-02:48:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-02:48:27] [V] [TRT] Tactic: 128 Time: 10.6452
[05/21/2022-02:48:27] [V] [TRT] Tactic: 256 Time: 10.6762
[05/21/2022-02:48:27] [V] [TRT] Tactic: 512 Time: 10.6897
[05/21/2022-02:48:28] [V] [TRT] Tactic: -32 Time: 10.9858
[05/21/2022-02:48:28] [V] [TRT] Tactic: -64 Time: 10.9939
[05/21/2022-02:48:28] [V] [TRT] Tactic: -128 Time: 11.065
[05/21/2022-02:48:28] [V] [TRT] Fastest Tactic: 128 Time: 10.6452
[05/21/2022-02:48:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:48:28] [V] [TRT] *************** Autotuning format combination: Float(82944,82944:32,288,1) -> Float(82944,82944:32,288,1) ***************
[05/21/2022-02:48:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-02:48:29] [V] [TRT] Tactic: 24 Time: 3.69625
[05/21/2022-02:48:30] [V] [TRT] Tactic: 25 Time: 4.59549
[05/21/2022-02:48:31] [V] [TRT] Tactic: 26 Time: 2.61635
[05/21/2022-02:48:32] [V] [TRT] Tactic: 27 Time: 2.05639
[05/21/2022-02:48:33] [V] [TRT] Tactic: 31 Time: 4.04617
[05/21/2022-02:48:33] [V] [TRT] Fastest Tactic: 27 Time: 2.05639
[05/21/2022-02:48:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-02:48:33] [V] [TRT] Tactic: 128 Time: 10.6432
[05/21/2022-02:48:34] [V] [TRT] Tactic: 256 Time: 10.6713
[05/21/2022-02:48:34] [V] [TRT] Tactic: 512 Time: 10.6883
[05/21/2022-02:48:34] [V] [TRT] Tactic: -32 Time: 11.0621
[05/21/2022-02:48:34] [V] [TRT] Tactic: -64 Time: 10.9925
[05/21/2022-02:48:35] [V] [TRT] Tactic: -128 Time: 11.0609
[05/21/2022-02:48:35] [V] [TRT] Fastest Tactic: 128 Time: 10.6432
[05/21/2022-02:48:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:48:35] [V] [TRT] *************** Autotuning format combination: Half(2654208,82944,288,1) -> Half(2654208,82944,288,1) ***************
[05/21/2022-02:48:35] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-02:48:36] [V] [TRT] Tactic: 0 Time: 7.31247
[05/21/2022-02:48:37] [V] [TRT] Tactic: 1 Time: 5.22052
[05/21/2022-02:48:38] [V] [TRT] Tactic: 2 Time: 4.32383
[05/21/2022-02:48:39] [V] [TRT] Tactic: 3 Time: 4.32777
[05/21/2022-02:48:40] [V] [TRT] Tactic: 4 Time: 4.19881
[05/21/2022-02:48:41] [V] [TRT] Tactic: 5 Time: 4.15664
[05/21/2022-02:48:42] [V] [TRT] Tactic: 6 Time: 3.73283
[05/21/2022-02:48:43] [V] [TRT] Tactic: 7 Time: 3.2476
[05/21/2022-02:48:44] [V] [TRT] Tactic: 8 Time: 3.21366
[05/21/2022-02:48:45] [V] [TRT] Tactic: 9 Time: 3.62253
[05/21/2022-02:48:46] [V] [TRT] Tactic: 28 Time: 4.68688
[05/21/2022-02:48:46] [V] [TRT] Fastest Tactic: 8 Time: 3.21366
[05/21/2022-02:48:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-02:48:46] [V] [TRT] Tactic: 128 Time: 11.0788
[05/21/2022-02:48:46] [V] [TRT] Tactic: 256 Time: 10.8218
[05/21/2022-02:48:46] [V] [TRT] Tactic: 512 Time: 10.1672
[05/21/2022-02:48:47] [V] [TRT] Tactic: -32 Time: 11.0124
[05/21/2022-02:48:47] [V] [TRT] Tactic: -64 Time: 10.9938
[05/21/2022-02:48:47] [V] [TRT] Tactic: -128 Time: 10.9734
[05/21/2022-02:48:47] [V] [TRT] Fastest Tactic: 512 Time: 10.1672
[05/21/2022-02:48:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:48:47] [V] [TRT] *************** Autotuning format combination: Half(1327104,82944:2,288,1) -> Half(1327104,82944:2,288,1) ***************
[05/21/2022-02:48:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-02:48:48] [V] [TRT] Tactic: 0 Time: 2.23816
[05/21/2022-02:48:49] [V] [TRT] Tactic: 1 Time: 4.01099
[05/21/2022-02:48:50] [V] [TRT] Tactic: 2 Time: 4.72411
[05/21/2022-02:48:51] [V] [TRT] Tactic: 3 Time: 3.03039
[05/21/2022-02:48:52] [V] [TRT] Tactic: 4 Time: 3.53658
[05/21/2022-02:48:53] [V] [TRT] Tactic: 5 Time: 3.77802
[05/21/2022-02:48:54] [V] [TRT] Tactic: 6 Time: 2.70811
[05/21/2022-02:48:55] [V] [TRT] Tactic: 7 Time: 3.02933
[05/21/2022-02:48:56] [V] [TRT] Tactic: 8 Time: 3.45151
[05/21/2022-02:48:57] [V] [TRT] Tactic: 9 Time: 4.43798
[05/21/2022-02:48:58] [V] [TRT] Tactic: 10 Time: 4.44339
[05/21/2022-02:48:59] [V] [TRT] Tactic: 11 Time: 5.83391
[05/21/2022-02:49:00] [V] [TRT] Tactic: 12 Time: 5.35663
[05/21/2022-02:49:01] [V] [TRT] Tactic: 13 Time: 2.72611
[05/21/2022-02:49:02] [V] [TRT] Tactic: 14 Time: 2.20923
[05/21/2022-02:49:03] [V] [TRT] Tactic: 15 Time: 4.02497
[05/21/2022-02:49:04] [V] [TRT] Tactic: 16 Time: 4.11967
[05/21/2022-02:49:05] [V] [TRT] Tactic: 17 Time: 3.47354
[05/21/2022-02:49:06] [V] [TRT] Tactic: 18 Time: 3.26037
[05/21/2022-02:49:07] [V] [TRT] Tactic: 19 Time: 2.5214
[05/21/2022-02:49:08] [V] [TRT] Tactic: 28 Time: 3.78744
[05/21/2022-02:49:09] [V] [TRT] Tactic: 29 Time: 3.92219
[05/21/2022-02:49:09] [V] [TRT] Fastest Tactic: 14 Time: 2.20923
[05/21/2022-02:49:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-02:49:09] [V] [TRT] Tactic: 128 Time: 11.0255
[05/21/2022-02:49:09] [V] [TRT] Tactic: 256 Time: 10.8259
[05/21/2022-02:49:10] [V] [TRT] Tactic: 512 Time: 10.1767
[05/21/2022-02:49:10] [V] [TRT] Tactic: -32 Time: 10.9954
[05/21/2022-02:49:10] [V] [TRT] Tactic: -64 Time: 10.9714
[05/21/2022-02:49:10] [V] [TRT] Tactic: -128 Time: 10.9588
[05/21/2022-02:49:10] [V] [TRT] Fastest Tactic: 512 Time: 10.1767
[05/21/2022-02:49:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 14
[05/21/2022-02:49:10] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:49:10] [V] [TRT] *************** Autotuning format combination: Float(2654208,82944,288,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:49:10] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:49:10] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:10] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:49:10] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:10] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:11] [V] [TRT] Tactic: 0 Time: 16.5692
[05/21/2022-02:49:11] [V] [TRT] Tactic: 1 Time: 7.14615
[05/21/2022-02:49:11] [V] [TRT] Tactic: 2 Time: 16.7519
[05/21/2022-02:49:14] [V] [TRT] Tactic: 5 Time: 184.95
[05/21/2022-02:49:14] [V] [TRT] Fastest Tactic: 1 Time: 7.14615
[05/21/2022-02:49:14] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:14] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:49:14] [V] [TRT] Tactic: 1062367460111450758 Time: 5.34025
[05/21/2022-02:49:14] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:49:14] [V] [TRT] Tactic: 1754984623894446479 Time: 5.92798
[05/21/2022-02:49:14] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:49:15] [V] [TRT] Tactic: 3611739942397549984 Time: 8.56369
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:49:15] [V] [TRT] Tactic: 4337000649858996379 Time: 4.34383
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:49:15] [V] [TRT] Tactic: 4501471010995462441 Time: 8.4117
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:49:15] [V] [TRT] Tactic: 5137655947464784826 Time: 4.14068
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:49:15] [V] [TRT] Tactic: 5288347012147084929 Time: 8.37671
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:49:15] [V] [TRT] Tactic: 6645123197870846056 Time: 4.23751
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:49:15] [V] [TRT] Tactic: 7144526460361122478 Time: 5.5924
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:49:15] [V] [TRT] Tactic: -9137461792520977713 Time: 8.60577
[05/21/2022-02:49:15] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:49:16] [V] [TRT] Tactic: -8262349710178828730 Time: 8.51797
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:49:16] [V] [TRT] Tactic: -8133971918129952780 Time: 4.80363
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:49:16] [V] [TRT] Tactic: -6092040395344634144 Time: 5.56732
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:49:16] [V] [TRT] Tactic: -4787320710726427159 Time: 5.89004
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:49:16] [V] [TRT] Tactic: -3456450830548107839 Time: 4.97488
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:49:16] [V] [TRT] Tactic: -1218658103698133241 Time: 4.73894
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:49:16] [V] [TRT] Tactic: -836875257600482091 Time: 4.57868
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:49:16] [V] [TRT] Tactic: -410470605513481746 Time: 8.36387
[05/21/2022-02:49:16] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 4.14068
[05/21/2022-02:49:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-02:49:16] [V] [TRT] *************** Autotuning format combination: Float(2654208,1,9216,32) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:49:16] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:16] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:16] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:16] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:49:17] [V] [TRT] Tactic: -9153228964338181824 Time: 7.37984
[05/21/2022-02:49:17] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:49:17] [V] [TRT] Tactic: -7394439838318485025 Time: 4.3021
[05/21/2022-02:49:17] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.3021
[05/21/2022-02:49:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:49:17] [V] [TRT] *************** Autotuning format combination: Half(2654208,82944,288,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:49:17] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:17] [V] [TRT] Tactic: 0 Time: 17.0563
[05/21/2022-02:49:17] [V] [TRT] Tactic: 1 Time: 7.36238
[05/21/2022-02:49:17] [V] [TRT] Tactic: 2 Time: 16.2174
[05/21/2022-02:49:20] [V] [TRT] Tactic: 5 Time: 183.948
[05/21/2022-02:49:20] [V] [TRT] Fastest Tactic: 1 Time: 7.36238
[05/21/2022-02:49:20] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:49:20] [V] [TRT] *************** Autotuning format combination: Half(1327104,82944:2,288,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:49:20] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:49:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:20] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:20] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:20] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:49:21] [V] [TRT] Tactic: 3564772625446233998 Time: 2.80441
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:49:21] [V] [TRT] Tactic: 3650389455493082349 Time: 2.91308
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:49:21] [V] [TRT] Tactic: 5319956359050645452 Time: 2.59732
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:49:21] [V] [TRT] Tactic: 7205456024582378848 Time: 2.22023
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:49:21] [V] [TRT] Tactic: -6490690591794140522 Time: 2.22954
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:49:21] [V] [TRT] Tactic: -4686027666808657977 Time: 4.47557
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:49:21] [V] [TRT] Tactic: -4212163711445252890 Time: 4.26231
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:49:21] [V] [TRT] Tactic: -3898373634979201110 Time: 4.37596
[05/21/2022-02:49:21] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:49:21] [V] [TRT] Tactic: -2409163523992614473 Time: 2.15443
[05/21/2022-02:49:21] [V] [TRT] Fastest Tactic: -2409163523992614473 Time: 2.15443
[05/21/2022-02:49:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -2409163523992614473
[05/21/2022-02:49:21] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:49:21] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:49:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:21] [V] [TRT] Tactic: 0 Time: 1.43826
[05/21/2022-02:49:21] [V] [TRT] Tactic: 1 Time: 1.06177
[05/21/2022-02:49:21] [V] [TRT] Tactic: 2 Time: 1.00578
[05/21/2022-02:49:21] [V] [TRT] Tactic: 3 Time: 0.883132
[05/21/2022-02:49:21] [V] [TRT] Tactic: 4 Time: 0.753939
[05/21/2022-02:49:21] [V] [TRT] Tactic: 5 Time: 0.778613
[05/21/2022-02:49:21] [V] [TRT] Tactic: 6 Time: 0.804805
[05/21/2022-02:49:21] [V] [TRT] Tactic: 7 Time: 0.650449
[05/21/2022-02:49:21] [V] [TRT] Tactic: 8 Time: 0.61778
[05/21/2022-02:49:21] [V] [TRT] Tactic: 9 Time: 0.662747
[05/21/2022-02:49:21] [V] [TRT] Tactic: 28 Time: 1.4143
[05/21/2022-02:49:21] [V] [TRT] Fastest Tactic: 8 Time: 0.61778
[05/21/2022-02:49:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-02:49:22] [V] [TRT] Tactic: 128 Time: 5.32538
[05/21/2022-02:49:22] [V] [TRT] Tactic: 256 Time: 5.33904
[05/21/2022-02:49:22] [V] [TRT] Tactic: 512 Time: 5.34816
[05/21/2022-02:49:22] [V] [TRT] Tactic: -32 Time: 5.51661
[05/21/2022-02:49:22] [V] [TRT] Tactic: -64 Time: 5.52145
[05/21/2022-02:49:22] [V] [TRT] Tactic: -128 Time: 5.53981
[05/21/2022-02:49:22] [V] [TRT] Fastest Tactic: 128 Time: 5.32538
[05/21/2022-02:49:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:49:22] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:49:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:22] [V] [TRT] Tactic: 0 Time: 1.43919
[05/21/2022-02:49:22] [V] [TRT] Tactic: 1 Time: 1.06357
[05/21/2022-02:49:22] [V] [TRT] Tactic: 2 Time: 1.00702
[05/21/2022-02:49:22] [V] [TRT] Tactic: 3 Time: 0.883425
[05/21/2022-02:49:22] [V] [TRT] Tactic: 4 Time: 0.753893
[05/21/2022-02:49:22] [V] [TRT] Tactic: 5 Time: 0.77888
[05/21/2022-02:49:22] [V] [TRT] Tactic: 6 Time: 0.806257
[05/21/2022-02:49:22] [V] [TRT] Tactic: 7 Time: 0.650951
[05/21/2022-02:49:22] [V] [TRT] Tactic: 8 Time: 0.618249
[05/21/2022-02:49:22] [V] [TRT] Tactic: 9 Time: 0.66291
[05/21/2022-02:49:23] [V] [TRT] Tactic: 28 Time: 1.41539
[05/21/2022-02:49:23] [V] [TRT] Fastest Tactic: 8 Time: 0.618249
[05/21/2022-02:49:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-02:49:23] [V] [TRT] Tactic: 128 Time: 5.3258
[05/21/2022-02:49:23] [V] [TRT] Tactic: 256 Time: 5.33747
[05/21/2022-02:49:23] [V] [TRT] Tactic: 512 Time: 5.3554
[05/21/2022-02:49:23] [V] [TRT] Tactic: -32 Time: 5.51811
[05/21/2022-02:49:23] [V] [TRT] Tactic: -64 Time: 5.51002
[05/21/2022-02:49:23] [V] [TRT] Tactic: -128 Time: 5.53761
[05/21/2022-02:49:23] [V] [TRT] Fastest Tactic: 128 Time: 5.3258
[05/21/2022-02:49:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:49:23] [V] [TRT] *************** Autotuning format combination: Float(41472,20736:32,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:49:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:23] [V] [TRT] Tactic: 24 Time: 0.985579
[05/21/2022-02:49:23] [V] [TRT] Tactic: 25 Time: 0.896693
[05/21/2022-02:49:23] [V] [TRT] Tactic: 26 Time: 0.884271
[05/21/2022-02:49:23] [V] [TRT] Tactic: 27 Time: 0.855762
[05/21/2022-02:49:23] [V] [TRT] Tactic: 31 Time: 0.982058
[05/21/2022-02:49:23] [V] [TRT] Fastest Tactic: 27 Time: 0.855762
[05/21/2022-02:49:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-02:49:23] [V] [TRT] Tactic: 128 Time: 5.3249
[05/21/2022-02:49:24] [V] [TRT] Tactic: 256 Time: 5.33855
[05/21/2022-02:49:24] [V] [TRT] Tactic: 512 Time: 5.34756
[05/21/2022-02:49:24] [V] [TRT] Tactic: -32 Time: 5.5215
[05/21/2022-02:49:24] [V] [TRT] Tactic: -64 Time: 5.51432
[05/21/2022-02:49:24] [V] [TRT] Tactic: -128 Time: 5.57322
[05/21/2022-02:49:24] [V] [TRT] Fastest Tactic: 128 Time: 5.3249
[05/21/2022-02:49:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:49:24] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:49:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:24] [V] [TRT] Tactic: 0 Time: 1.46694
[05/21/2022-02:49:24] [V] [TRT] Tactic: 1 Time: 1.10946
[05/21/2022-02:49:24] [V] [TRT] Tactic: 2 Time: 1.03189
[05/21/2022-02:49:24] [V] [TRT] Tactic: 3 Time: 0.879434
[05/21/2022-02:49:24] [V] [TRT] Tactic: 4 Time: 0.801276
[05/21/2022-02:49:24] [V] [TRT] Tactic: 5 Time: 0.820482
[05/21/2022-02:49:24] [V] [TRT] Tactic: 6 Time: 0.78334
[05/21/2022-02:49:24] [V] [TRT] Tactic: 7 Time: 0.682214
[05/21/2022-02:49:24] [V] [TRT] Tactic: 8 Time: 0.683646
[05/21/2022-02:49:24] [V] [TRT] Tactic: 9 Time: 0.706029
[05/21/2022-02:49:24] [V] [TRT] Tactic: 28 Time: 1.47055
[05/21/2022-02:49:24] [V] [TRT] Fastest Tactic: 7 Time: 0.682214
[05/21/2022-02:49:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-02:49:25] [V] [TRT] Tactic: 128 Time: 5.47554
[05/21/2022-02:49:25] [V] [TRT] Tactic: 256 Time: 5.42019
[05/21/2022-02:49:25] [V] [TRT] Tactic: 512 Time: 5.08941
[05/21/2022-02:49:25] [V] [TRT] Tactic: -32 Time: 5.51147
[05/21/2022-02:49:25] [V] [TRT] Tactic: -64 Time: 5.47413
[05/21/2022-02:49:25] [V] [TRT] Tactic: -128 Time: 5.49042
[05/21/2022-02:49:25] [V] [TRT] Fastest Tactic: 512 Time: 5.08941
[05/21/2022-02:49:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:49:25] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:49:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:25] [V] [TRT] Tactic: 0 Time: 1.12278
[05/21/2022-02:49:25] [V] [TRT] Tactic: 1 Time: 0.908672
[05/21/2022-02:49:25] [V] [TRT] Tactic: 2 Time: 0.911237
[05/21/2022-02:49:25] [V] [TRT] Tactic: 3 Time: 0.833144
[05/21/2022-02:49:25] [V] [TRT] Tactic: 4 Time: 0.809772
[05/21/2022-02:49:25] [V] [TRT] Tactic: 5 Time: 0.823079
[05/21/2022-02:49:25] [V] [TRT] Tactic: 6 Time: 0.793235
[05/21/2022-02:49:25] [V] [TRT] Tactic: 7 Time: 0.771302
[05/21/2022-02:49:25] [V] [TRT] Tactic: 8 Time: 0.754453
[05/21/2022-02:49:25] [V] [TRT] Tactic: 9 Time: 0.802227
[05/21/2022-02:49:25] [V] [TRT] Tactic: 10 Time: 1.54551
[05/21/2022-02:49:25] [V] [TRT] Tactic: 11 Time: 1.14674
[05/21/2022-02:49:25] [V] [TRT] Tactic: 12 Time: 1.08982
[05/21/2022-02:49:25] [V] [TRT] Tactic: 13 Time: 0.900306
[05/21/2022-02:49:26] [V] [TRT] Tactic: 14 Time: 0.833717
[05/21/2022-02:49:26] [V] [TRT] Tactic: 15 Time: 0.856257
[05/21/2022-02:49:26] [V] [TRT] Tactic: 16 Time: 0.793672
[05/21/2022-02:49:26] [V] [TRT] Tactic: 17 Time: 0.697064
[05/21/2022-02:49:26] [V] [TRT] Tactic: 18 Time: 0.694219
[05/21/2022-02:49:26] [V] [TRT] Tactic: 19 Time: 0.75181
[05/21/2022-02:49:26] [V] [TRT] Tactic: 28 Time: 1.10402
[05/21/2022-02:49:26] [V] [TRT] Tactic: 29 Time: 1.51887
[05/21/2022-02:49:26] [V] [TRT] Fastest Tactic: 18 Time: 0.694219
[05/21/2022-02:49:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-02:49:26] [V] [TRT] Tactic: 128 Time: 5.47856
[05/21/2022-02:49:26] [V] [TRT] Tactic: 256 Time: 5.43532
[05/21/2022-02:49:26] [V] [TRT] Tactic: 512 Time: 5.09916
[05/21/2022-02:49:26] [V] [TRT] Tactic: -32 Time: 5.51432
[05/21/2022-02:49:26] [V] [TRT] Tactic: -64 Time: 5.48212
[05/21/2022-02:49:26] [V] [TRT] Tactic: -128 Time: 5.48841
[05/21/2022-02:49:26] [V] [TRT] Fastest Tactic: 512 Time: 5.09916
[05/21/2022-02:49:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:49:26] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:49:26] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:49:26] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:49:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:26] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:49:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:26] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:27] [V] [TRT] Tactic: 0 Time: 5.55904
[05/21/2022-02:49:27] [V] [TRT] Tactic: 1 Time: 3.92721
[05/21/2022-02:49:27] [V] [TRT] Tactic: 2 Time: 5.94055
[05/21/2022-02:49:27] [V] [TRT] Tactic: 5 Time: 10.8935
[05/21/2022-02:49:27] [V] [TRT] Fastest Tactic: 1 Time: 3.92721
[05/21/2022-02:49:27] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-02:49:27] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:27] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:49:27] [V] [TRT] Tactic: 1062367460111450758 Time: 3.50822
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:49:27] [V] [TRT] Tactic: 1698681053543049347 Time: 3.18094
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:49:27] [V] [TRT] Tactic: 4501471010995462441 Time: 2.70497
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:49:27] [V] [TRT] Tactic: 5137655947464784826 Time: 2.52772
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:49:27] [V] [TRT] Tactic: 5288347012147084929 Time: 2.73582
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:49:27] [V] [TRT] Tactic: 5326823351883942011 Time: 2.56173
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:49:27] [V] [TRT] Tactic: 5500448035057547314 Time: 2.88003
[05/21/2022-02:49:27] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:49:28] [V] [TRT] Tactic: 6645123197870846056 Time: 2.5884
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:49:28] [V] [TRT] Tactic: 7144526460361122478 Time: 3.57014
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:49:28] [V] [TRT] Tactic: -8262349710178828730 Time: 2.78429
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:49:28] [V] [TRT] Tactic: -6576203419454146580 Time: 3.30563
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:49:28] [V] [TRT] Tactic: -4787320710726427159 Time: 3.699
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:49:28] [V] [TRT] Tactic: -3456450830548107839 Time: 3.39212
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:49:28] [V] [TRT] Tactic: -1218658103698133241 Time: 3.09265
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:49:28] [V] [TRT] Tactic: -836875257600482091 Time: 2.9921
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:49:28] [V] [TRT] Tactic: -410470605513481746 Time: 2.59522
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:49:28] [V] [TRT] Tactic: -377491875521947884 Time: 2.71878
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:49:28] [V] [TRT] Tactic: -37215280111360163 Time: 2.50924
[05/21/2022-02:49:28] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 2.50924
[05/21/2022-02:49:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-02:49:28] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:49:28] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:28] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:28] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-02:49:28] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:28] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:49:28] [V] [TRT] Tactic: 3886731678879822788 Time: 3.07688
[05/21/2022-02:49:28] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:49:28] [V] [TRT] Tactic: 6629944304117643200 Time: 7.97766
[05/21/2022-02:49:29] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:49:29] [V] [TRT] Tactic: -9153228964338181824 Time: 8.02742
[05/21/2022-02:49:29] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:49:29] [V] [TRT] Tactic: -7394439838318485025 Time: 3.06111
[05/21/2022-02:49:29] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 3.06111
[05/21/2022-02:49:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:49:29] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:29] [V] [TRT] Tactic: 0 Time: 5.07142
[05/21/2022-02:49:29] [V] [TRT] Tactic: 1 Time: 3.75459
[05/21/2022-02:49:29] [V] [TRT] Tactic: 2 Time: 5.05291
[05/21/2022-02:49:29] [V] [TRT] Tactic: 5 Time: 10.4509
[05/21/2022-02:49:29] [V] [TRT] Fastest Tactic: 1 Time: 3.75459
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-02:49:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:29] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:49:29] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:29] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:29] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:49:29] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-02:49:29] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-02:49:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:49:29] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-02:49:29] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:49:29] [V] [TRT] Tactic: 3066127711859985668 Time: 1.8922
[05/21/2022-02:49:29] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:49:29] [V] [TRT] Tactic: 3564772625446233998 Time: 2.02523
[05/21/2022-02:49:29] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:49:29] [V] [TRT] Tactic: 5319956359050645452 Time: 1.92926
[05/21/2022-02:49:29] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:49:29] [V] [TRT] Tactic: 7205456024582378848 Time: 1.48177
[05/21/2022-02:49:29] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:49:29] [V] [TRT] Tactic: 8163473458334948789 Time: 1.46685
[05/21/2022-02:49:30] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:49:30] [V] [TRT] Tactic: -4212163711445252890 Time: 1.50973
[05/21/2022-02:49:30] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:49:30] [V] [TRT] Tactic: -3898373634979201110 Time: 1.50047
[05/21/2022-02:49:30] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:49:30] [V] [TRT] Tactic: -2409163523992614473 Time: 1.44414
[05/21/2022-02:49:30] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:49:30] [V] [TRT] Tactic: -1716393687483585322 Time: 1.46872
[05/21/2022-02:49:30] [V] [TRT] Fastest Tactic: -2409163523992614473 Time: 1.44414
[05/21/2022-02:49:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -2409163523992614473
[05/21/2022-02:49:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:49:30] [V] [TRT] *************** Autotuning format combination: Float(2654208,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:49:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:31] [V] [TRT] Tactic: 0 Time: 4.32758
[05/21/2022-02:49:32] [V] [TRT] Tactic: 1 Time: 2.99443
[05/21/2022-02:49:33] [V] [TRT] Tactic: 2 Time: 2.34411
[05/21/2022-02:49:33] [V] [TRT] Tactic: 3 Time: 1.54798
[05/21/2022-02:49:34] [V] [TRT] Tactic: 4 Time: 1.31003
[05/21/2022-02:49:35] [V] [TRT] Tactic: 5 Time: 2.23085
[05/21/2022-02:49:36] [V] [TRT] Tactic: 6 Time: 1.79406
[05/21/2022-02:49:37] [V] [TRT] Tactic: 7 Time: 1.85582
[05/21/2022-02:49:38] [V] [TRT] Tactic: 8 Time: 1.63878
[05/21/2022-02:49:39] [V] [TRT] Tactic: 9 Time: 1.69572
[05/21/2022-02:49:40] [V] [TRT] Tactic: 28 Time: 2.64773
[05/21/2022-02:49:40] [V] [TRT] Fastest Tactic: 4 Time: 1.31003
[05/21/2022-02:49:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-02:49:40] [V] [TRT] Tactic: 128 Time: 6.00372
[05/21/2022-02:49:41] [V] [TRT] Tactic: 256 Time: 6.00801
[05/21/2022-02:49:41] [V] [TRT] Tactic: 512 Time: 6.01555
[05/21/2022-02:49:41] [V] [TRT] Tactic: -32 Time: 5.53855
[05/21/2022-02:49:41] [V] [TRT] Tactic: -64 Time: 5.54645
[05/21/2022-02:49:41] [V] [TRT] Tactic: -128 Time: 5.61665
[05/21/2022-02:49:41] [V] [TRT] Fastest Tactic: -32 Time: 5.53855
[05/21/2022-02:49:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4
[05/21/2022-02:49:41] [V] [TRT] *************** Autotuning format combination: Float(2654208,1,18432,128) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:49:41] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:41] [V] [TRT] Tactic: 0 Time: 1.82786
[05/21/2022-02:49:41] [V] [TRT] Tactic: 1 Time: 1.27085
[05/21/2022-02:49:41] [V] [TRT] Tactic: 2 Time: 1.20024
[05/21/2022-02:49:41] [V] [TRT] Tactic: 3 Time: 1.52259
[05/21/2022-02:49:41] [V] [TRT] Tactic: 4 Time: 1.41393
[05/21/2022-02:49:41] [V] [TRT] Tactic: 5 Time: 1.27939
[05/21/2022-02:49:41] [V] [TRT] Tactic: 6 Time: 2.0846
[05/21/2022-02:49:41] [V] [TRT] Tactic: 7 Time: 1.73197
[05/21/2022-02:49:41] [V] [TRT] Tactic: 8 Time: 1.6913
[05/21/2022-02:49:42] [V] [TRT] Tactic: 9 Time: 1.48303
[05/21/2022-02:49:42] [V] [TRT] Tactic: 28 Time: 1.80945
[05/21/2022-02:49:42] [V] [TRT] Fastest Tactic: 2 Time: 1.20024
[05/21/2022-02:49:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-02:49:42] [V] [TRT] Tactic: 128 Time: 6.00936
[05/21/2022-02:49:42] [V] [TRT] Tactic: 256 Time: 6.00926
[05/21/2022-02:49:42] [V] [TRT] Tactic: 512 Time: 6.01651
[05/21/2022-02:49:42] [V] [TRT] Tactic: -32 Time: 6.06792
[05/21/2022-02:49:42] [V] [TRT] Tactic: -64 Time: 6.64513
[05/21/2022-02:49:42] [V] [TRT] Tactic: -128 Time: 6.63313
[05/21/2022-02:49:42] [V] [TRT] Fastest Tactic: 256 Time: 6.00926
[05/21/2022-02:49:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:49:42] [V] [TRT] *************** Autotuning format combination: Float(82944,20736:32,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:49:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:43] [V] [TRT] Tactic: 24 Time: 2.01559
[05/21/2022-02:49:44] [V] [TRT] Tactic: 25 Time: 1.63581
[05/21/2022-02:49:45] [V] [TRT] Tactic: 26 Time: 1.51481
[05/21/2022-02:49:46] [V] [TRT] Tactic: 27 Time: 1.74783
[05/21/2022-02:49:47] [V] [TRT] Tactic: 31 Time: 2.54562
[05/21/2022-02:49:47] [V] [TRT] Fastest Tactic: 26 Time: 1.51481
[05/21/2022-02:49:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-02:49:47] [V] [TRT] Tactic: 128 Time: 6.94944
[05/21/2022-02:49:48] [V] [TRT] Tactic: 256 Time: 6.14529
[05/21/2022-02:49:48] [V] [TRT] Tactic: 512 Time: 6.01531
[05/21/2022-02:49:48] [V] [TRT] Tactic: -32 Time: 5.53458
[05/21/2022-02:49:48] [V] [TRT] Tactic: -64 Time: 5.54707
[05/21/2022-02:49:48] [V] [TRT] Tactic: -128 Time: 5.61499
[05/21/2022-02:49:48] [V] [TRT] Fastest Tactic: -32 Time: 5.53458
[05/21/2022-02:49:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:49:48] [V] [TRT] *************** Autotuning format combination: Half(2654208,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:49:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-02:49:49] [V] [TRT] Tactic: 0 Time: 4.48016
[05/21/2022-02:49:50] [V] [TRT] Tactic: 1 Time: 3.23271
[05/21/2022-02:49:51] [V] [TRT] Tactic: 2 Time: 2.43393
[05/21/2022-02:49:52] [V] [TRT] Tactic: 3 Time: 2.30248
[05/21/2022-02:49:53] [V] [TRT] Tactic: 4 Time: 2.18574
[05/21/2022-02:49:54] [V] [TRT] Tactic: 5 Time: 2.37279
[05/21/2022-02:49:55] [V] [TRT] Tactic: 6 Time: 1.89507
[05/21/2022-02:49:56] [V] [TRT] Tactic: 7 Time: 1.8165
[05/21/2022-02:49:57] [V] [TRT] Tactic: 8 Time: 1.91139
[05/21/2022-02:49:58] [V] [TRT] Tactic: 9 Time: 2.19742
[05/21/2022-02:49:59] [V] [TRT] Tactic: 28 Time: 3.17232
[05/21/2022-02:49:59] [V] [TRT] Fastest Tactic: 7 Time: 1.8165
[05/21/2022-02:49:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-02:49:59] [V] [TRT] Tactic: 128 Time: 6.18975
[05/21/2022-02:49:59] [V] [TRT] Tactic: 256 Time: 5.69207
[05/21/2022-02:49:59] [V] [TRT] Tactic: 512 Time: 5.33286
[05/21/2022-02:49:59] [V] [TRT] Tactic: -32 Time: 5.55038
[05/21/2022-02:49:59] [V] [TRT] Tactic: -64 Time: 5.52861
[05/21/2022-02:49:59] [V] [TRT] Tactic: -128 Time: 5.58551
[05/21/2022-02:49:59] [V] [TRT] Fastest Tactic: 512 Time: 5.33286
[05/21/2022-02:49:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:49:59] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736:2,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:49:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:00] [V] [TRT] Tactic: 0 Time: 3.1815
[05/21/2022-02:50:01] [V] [TRT] Tactic: 1 Time: 1.58046
[05/21/2022-02:50:02] [V] [TRT] Tactic: 2 Time: 2.71434
[05/21/2022-02:50:03] [V] [TRT] Tactic: 3 Time: 2.09154
[05/21/2022-02:50:04] [V] [TRT] Tactic: 4 Time: 1.77044
[05/21/2022-02:50:05] [V] [TRT] Tactic: 5 Time: 1.83114
[05/21/2022-02:50:06] [V] [TRT] Tactic: 6 Time: 1.64461
[05/21/2022-02:50:07] [V] [TRT] Tactic: 7 Time: 1.57107
[05/21/2022-02:50:08] [V] [TRT] Tactic: 8 Time: 2.15227
[05/21/2022-02:50:10] [V] [TRT] Tactic: 9 Time: 4.86466
[05/21/2022-02:50:11] [V] [TRT] Tactic: 10 Time: 3.8323
[05/21/2022-02:50:12] [V] [TRT] Tactic: 11 Time: 2.0599
[05/21/2022-02:50:13] [V] [TRT] Tactic: 12 Time: 3.17637
[05/21/2022-02:50:14] [V] [TRT] Tactic: 13 Time: 2.3966
[05/21/2022-02:50:15] [V] [TRT] Tactic: 14 Time: 2.27771
[05/21/2022-02:50:16] [V] [TRT] Tactic: 15 Time: 2.8913
[05/21/2022-02:50:16] [V] [TRT] Tactic: 16 Time: 2.76126
[05/21/2022-02:50:17] [V] [TRT] Tactic: 17 Time: 1.85535
[05/21/2022-02:50:19] [V] [TRT] Tactic: 18 Time: 2.82633
[05/21/2022-02:50:20] [V] [TRT] Tactic: 19 Time: 2.37505
[05/21/2022-02:50:21] [V] [TRT] Tactic: 28 Time: 2.99136
[05/21/2022-02:50:22] [V] [TRT] Tactic: 29 Time: 4.62478
[05/21/2022-02:50:22] [V] [TRT] Fastest Tactic: 7 Time: 1.57107
[05/21/2022-02:50:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-02:50:22] [V] [TRT] Tactic: 128 Time: 7.79071
[05/21/2022-02:50:22] [V] [TRT] Tactic: 256 Time: 5.69382
[05/21/2022-02:50:22] [V] [TRT] Tactic: 512 Time: 5.30746
[05/21/2022-02:50:22] [V] [TRT] Tactic: -32 Time: 5.54973
[05/21/2022-02:50:22] [V] [TRT] Tactic: -64 Time: 5.53099
[05/21/2022-02:50:22] [V] [TRT] Tactic: -128 Time: 5.58609
[05/21/2022-02:50:22] [V] [TRT] Fastest Tactic: 512 Time: 5.30746
[05/21/2022-02:50:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:50:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:50:22] [V] [TRT] *************** Autotuning format combination: Float(2654208,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:50:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:22] [V] [TRT] Tactic: 0 Time: 1.82618
[05/21/2022-02:50:22] [V] [TRT] Tactic: 1 Time: 1.26933
[05/21/2022-02:50:22] [V] [TRT] Tactic: 2 Time: 1.19871
[05/21/2022-02:50:22] [V] [TRT] Tactic: 3 Time: 0.956543
[05/21/2022-02:50:22] [V] [TRT] Tactic: 4 Time: 0.88528
[05/21/2022-02:50:23] [V] [TRT] Tactic: 5 Time: 0.875228
[05/21/2022-02:50:23] [V] [TRT] Tactic: 6 Time: 0.831764
[05/21/2022-02:50:23] [V] [TRT] Tactic: 7 Time: 0.706321
[05/21/2022-02:50:23] [V] [TRT] Tactic: 8 Time: 0.698327
[05/21/2022-02:50:23] [V] [TRT] Tactic: 9 Time: 0.719772
[05/21/2022-02:50:23] [V] [TRT] Tactic: 28 Time: 1.8085
[05/21/2022-02:50:23] [V] [TRT] Fastest Tactic: 8 Time: 0.698327
[05/21/2022-02:50:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-02:50:23] [V] [TRT] Tactic: 128 Time: 6.00582
[05/21/2022-02:50:23] [V] [TRT] Tactic: 256 Time: 6.00932
[05/21/2022-02:50:23] [V] [TRT] Tactic: 512 Time: 6.01454
[05/21/2022-02:50:23] [V] [TRT] Tactic: -32 Time: 5.5384
[05/21/2022-02:50:23] [V] [TRT] Tactic: -64 Time: 5.54887
[05/21/2022-02:50:23] [V] [TRT] Tactic: -128 Time: 5.61754
[05/21/2022-02:50:23] [V] [TRT] Fastest Tactic: -32 Time: 5.5384
[05/21/2022-02:50:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:50:23] [V] [TRT] *************** Autotuning format combination: Float(2654208,1,18432,128) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:50:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:23] [V] [TRT] Tactic: 0 Time: 1.82815
[05/21/2022-02:50:24] [V] [TRT] Tactic: 1 Time: 1.26997
[05/21/2022-02:50:24] [V] [TRT] Tactic: 2 Time: 1.19942
[05/21/2022-02:50:24] [V] [TRT] Tactic: 3 Time: 1.52139
[05/21/2022-02:50:24] [V] [TRT] Tactic: 4 Time: 1.41428
[05/21/2022-02:50:24] [V] [TRT] Tactic: 5 Time: 1.27997
[05/21/2022-02:50:24] [V] [TRT] Tactic: 6 Time: 2.08424
[05/21/2022-02:50:24] [V] [TRT] Tactic: 7 Time: 1.73114
[05/21/2022-02:50:24] [V] [TRT] Tactic: 8 Time: 1.6906
[05/21/2022-02:50:24] [V] [TRT] Tactic: 9 Time: 1.48239
[05/21/2022-02:50:24] [V] [TRT] Tactic: 28 Time: 1.80879
[05/21/2022-02:50:24] [V] [TRT] Fastest Tactic: 2 Time: 1.19942
[05/21/2022-02:50:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-02:50:24] [V] [TRT] Tactic: 128 Time: 6.00733
[05/21/2022-02:50:24] [V] [TRT] Tactic: 256 Time: 6.00919
[05/21/2022-02:50:24] [V] [TRT] Tactic: 512 Time: 6.03655
[05/21/2022-02:50:24] [V] [TRT] Tactic: -32 Time: 6.06706
[05/21/2022-02:50:25] [V] [TRT] Tactic: -64 Time: 6.64599
[05/21/2022-02:50:25] [V] [TRT] Tactic: -128 Time: 6.63381
[05/21/2022-02:50:25] [V] [TRT] Fastest Tactic: 128 Time: 6.00733
[05/21/2022-02:50:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:50:25] [V] [TRT] *************** Autotuning format combination: Float(82944,20736:32,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:50:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:25] [V] [TRT] Tactic: 24 Time: 0.996628
[05/21/2022-02:50:25] [V] [TRT] Tactic: 25 Time: 0.897637
[05/21/2022-02:50:25] [V] [TRT] Tactic: 26 Time: 0.892546
[05/21/2022-02:50:25] [V] [TRT] Tactic: 27 Time: 0.856146
[05/21/2022-02:50:25] [V] [TRT] Tactic: 31 Time: 0.996588
[05/21/2022-02:50:25] [V] [TRT] Fastest Tactic: 27 Time: 0.856146
[05/21/2022-02:50:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-02:50:25] [V] [TRT] Tactic: 128 Time: 6.03893
[05/21/2022-02:50:25] [V] [TRT] Tactic: 256 Time: 6.01043
[05/21/2022-02:50:25] [V] [TRT] Tactic: 512 Time: 6.03214
[05/21/2022-02:50:25] [V] [TRT] Tactic: -32 Time: 5.53952
[05/21/2022-02:50:26] [V] [TRT] Tactic: -64 Time: 5.56276
[05/21/2022-02:50:26] [V] [TRT] Tactic: -128 Time: 5.61697
[05/21/2022-02:50:26] [V] [TRT] Fastest Tactic: -32 Time: 5.53952
[05/21/2022-02:50:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:50:26] [V] [TRT] *************** Autotuning format combination: Half(2654208,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:50:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:26] [V] [TRT] Tactic: 0 Time: 1.88218
[05/21/2022-02:50:26] [V] [TRT] Tactic: 1 Time: 1.32656
[05/21/2022-02:50:26] [V] [TRT] Tactic: 2 Time: 1.23723
[05/21/2022-02:50:26] [V] [TRT] Tactic: 3 Time: 0.97916
[05/21/2022-02:50:26] [V] [TRT] Tactic: 4 Time: 0.926986
[05/21/2022-02:50:26] [V] [TRT] Tactic: 5 Time: 0.908203
[05/21/2022-02:50:26] [V] [TRT] Tactic: 6 Time: 0.821921
[05/21/2022-02:50:26] [V] [TRT] Tactic: 7 Time: 0.737246
[05/21/2022-02:50:26] [V] [TRT] Tactic: 8 Time: 0.749219
[05/21/2022-02:50:26] [V] [TRT] Tactic: 9 Time: 0.743105
[05/21/2022-02:50:26] [V] [TRT] Tactic: 28 Time: 1.87247
[05/21/2022-02:50:26] [V] [TRT] Fastest Tactic: 7 Time: 0.737246
[05/21/2022-02:50:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-02:50:26] [V] [TRT] Tactic: 128 Time: 5.78906
[05/21/2022-02:50:26] [V] [TRT] Tactic: 256 Time: 5.70689
[05/21/2022-02:50:26] [V] [TRT] Tactic: 512 Time: 5.31445
[05/21/2022-02:50:27] [V] [TRT] Tactic: -32 Time: 5.59109
[05/21/2022-02:50:27] [V] [TRT] Tactic: -64 Time: 5.61322
[05/21/2022-02:50:27] [V] [TRT] Tactic: -128 Time: 5.60684
[05/21/2022-02:50:27] [V] [TRT] Fastest Tactic: 512 Time: 5.31445
[05/21/2022-02:50:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:50:27] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736:2,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:50:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:27] [V] [TRT] Tactic: 0 Time: 1.27564
[05/21/2022-02:50:27] [V] [TRT] Tactic: 1 Time: 0.977415
[05/21/2022-02:50:27] [V] [TRT] Tactic: 2 Time: 0.980078
[05/21/2022-02:50:27] [V] [TRT] Tactic: 3 Time: 0.859089
[05/21/2022-02:50:27] [V] [TRT] Tactic: 4 Time: 0.834264
[05/21/2022-02:50:27] [V] [TRT] Tactic: 5 Time: 0.852936
[05/21/2022-02:50:27] [V] [TRT] Tactic: 6 Time: 0.807513
[05/21/2022-02:50:27] [V] [TRT] Tactic: 7 Time: 0.778932
[05/21/2022-02:50:27] [V] [TRT] Tactic: 8 Time: 0.766374
[05/21/2022-02:50:27] [V] [TRT] Tactic: 9 Time: 0.817565
[05/21/2022-02:50:27] [V] [TRT] Tactic: 10 Time: 1.93866
[05/21/2022-02:50:27] [V] [TRT] Tactic: 11 Time: 1.38663
[05/21/2022-02:50:27] [V] [TRT] Tactic: 12 Time: 1.29721
[05/21/2022-02:50:27] [V] [TRT] Tactic: 13 Time: 1.01617
[05/21/2022-02:50:27] [V] [TRT] Tactic: 14 Time: 0.964433
[05/21/2022-02:50:27] [V] [TRT] Tactic: 15 Time: 0.976387
[05/21/2022-02:50:27] [V] [TRT] Tactic: 16 Time: 0.846341
[05/21/2022-02:50:27] [V] [TRT] Tactic: 17 Time: 0.75737
[05/21/2022-02:50:27] [V] [TRT] Tactic: 18 Time: 0.772435
[05/21/2022-02:50:27] [V] [TRT] Tactic: 19 Time: 0.806817
[05/21/2022-02:50:27] [V] [TRT] Tactic: 28 Time: 1.25552
[05/21/2022-02:50:28] [V] [TRT] Tactic: 29 Time: 1.94926
[05/21/2022-02:50:28] [V] [TRT] Fastest Tactic: 17 Time: 0.75737
[05/21/2022-02:50:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-02:50:28] [V] [TRT] Tactic: 128 Time: 5.78453
[05/21/2022-02:50:28] [V] [TRT] Tactic: 256 Time: 5.70188
[05/21/2022-02:50:28] [V] [TRT] Tactic: 512 Time: 5.32691
[05/21/2022-02:50:28] [V] [TRT] Tactic: -32 Time: 5.55059
[05/21/2022-02:50:28] [V] [TRT] Tactic: -64 Time: 5.528
[05/21/2022-02:50:28] [V] [TRT] Tactic: -128 Time: 5.62191
[05/21/2022-02:50:28] [V] [TRT] Fastest Tactic: 512 Time: 5.32691
[05/21/2022-02:50:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:50:28] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:50:28] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:50:28] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:50:28] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:28] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:50:28] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:28] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:28] [V] [TRT] Tactic: 0 Time: 1.51637
[05/21/2022-02:50:28] [V] [TRT] Tactic: 1 Time: 1.25129
[05/21/2022-02:50:28] [V] [TRT] Tactic: 2 Time: 4.16416
[05/21/2022-02:50:28] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1115955200, available: 536870912
[05/21/2022-02:50:28] [V] [TRT] Tactic: 5 Time: 4.41868
[05/21/2022-02:50:28] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[05/21/2022-02:50:28] [V] [TRT] Fastest Tactic: 1 Time: 1.25129
[05/21/2022-02:50:28] [V] [TRT] Setting workspace to 1115955200enables more tactics for profiling
[05/21/2022-02:50:28] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-02:50:28] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:28] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:28] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:50:28] [V] [TRT] Tactic: 1062367460111450758 Time: 0.890332
[05/21/2022-02:50:28] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:50:28] [V] [TRT] Tactic: 1698681053543049347 Time: 0.805084
[05/21/2022-02:50:28] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:50:29] [V] [TRT] Tactic: 4501471010995462441 Time: 2.53324
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:50:29] [V] [TRT] Tactic: 5137655947464784826 Time: 1.26875
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:50:29] [V] [TRT] Tactic: 5288347012147084929 Time: 2.62848
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:50:29] [V] [TRT] Tactic: 5326823351883942011 Time: 2.51021
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:50:29] [V] [TRT] Tactic: 5500448035057547314 Time: 1.37939
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:50:29] [V] [TRT] Tactic: 6645123197870846056 Time: 1.27536
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:50:29] [V] [TRT] Tactic: 7144526460361122478 Time: 0.905872
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:50:29] [V] [TRT] Tactic: -8262349710178828730 Time: 2.63585
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:50:29] [V] [TRT] Tactic: -6576203419454146580 Time: 0.835873
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:50:29] [V] [TRT] Tactic: -4787320710726427159 Time: 0.938418
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:50:29] [V] [TRT] Tactic: -3456450830548107839 Time: 0.855918
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:50:29] [V] [TRT] Tactic: -1218658103698133241 Time: 1.46732
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:50:29] [V] [TRT] Tactic: -836875257600482091 Time: 1.43523
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:50:29] [V] [TRT] Tactic: -410470605513481746 Time: 2.58905
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:50:29] [V] [TRT] Tactic: -377491875521947884 Time: 2.58372
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:50:29] [V] [TRT] Tactic: -37215280111360163 Time: 1.23433
[05/21/2022-02:50:29] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 0.805084
[05/21/2022-02:50:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1698681053543049347
[05/21/2022-02:50:29] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:50:29] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:29] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:29] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-02:50:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:29] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:50:29] [V] [TRT] Tactic: 3886731678879822788 Time: 1.5453
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:50:29] [V] [TRT] Tactic: 6629944304117643200 Time: 1.98631
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:50:29] [V] [TRT] Tactic: -9153228964338181824 Time: 2.0041
[05/21/2022-02:50:29] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:50:29] [V] [TRT] Tactic: -7394439838318485025 Time: 1.50342
[05/21/2022-02:50:29] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.50342
[05/21/2022-02:50:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:50:29] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:50:29] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:29] [V] [TRT] Tactic: 0 Time: 1.49137
[05/21/2022-02:50:29] [V] [TRT] Tactic: 1 Time: 1.33434
[05/21/2022-02:50:30] [V] [TRT] Tactic: 2 Time: 4.13102
[05/21/2022-02:50:30] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1115955200, available: 536870912
[05/21/2022-02:50:30] [V] [TRT] Tactic: 5 Time: 4.46412
[05/21/2022-02:50:30] [V] [TRT] Fastest Tactic: 1 Time: 1.33434
[05/21/2022-02:50:30] [V] [TRT] Setting workspace to 1115955200enables more tactics for profiling
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-02:50:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:50:30] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:30] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:50:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-02:50:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:50:30] [V] [TRT] Tactic: 3066127711859985668 Time: 0.489993
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:50:30] [V] [TRT] Tactic: 3564772625446233998 Time: 0.526628
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:50:30] [V] [TRT] Tactic: 5319956359050645452 Time: 0.50403
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:50:30] [V] [TRT] Tactic: 7205456024582378848 Time: 0.750313
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:50:30] [V] [TRT] Tactic: 8163473458334948789 Time: 0.723828
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:50:30] [V] [TRT] Tactic: -4212163711445252890 Time: 1.43012
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:50:30] [V] [TRT] Tactic: -3898373634979201110 Time: 1.44931
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:50:30] [V] [TRT] Tactic: -2409163523992614473 Time: 0.723998
[05/21/2022-02:50:30] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:50:30] [V] [TRT] Tactic: -1716393687483585322 Time: 1.42834
[05/21/2022-02:50:30] [V] [TRT] Fastest Tactic: 3066127711859985668 Time: 0.489993
[05/21/2022-02:50:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668
[05/21/2022-02:50:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:50:30] [V] [TRT] *************** Autotuning format combination: Float(663552,20736,144,1) -> Float(663552,20736,144,1) ***************
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:30] [V] [TRT] Tactic: 0 Time: 0.723802
[05/21/2022-02:50:30] [V] [TRT] Tactic: 1 Time: 0.536647
[05/21/2022-02:50:30] [V] [TRT] Tactic: 2 Time: 0.508431
[05/21/2022-02:50:30] [V] [TRT] Tactic: 3 Time: 0.447103
[05/21/2022-02:50:30] [V] [TRT] Tactic: 4 Time: 0.383105
[05/21/2022-02:50:30] [V] [TRT] Tactic: 5 Time: 0.394356
[05/21/2022-02:50:30] [V] [TRT] Tactic: 6 Time: 0.406797
[05/21/2022-02:50:30] [V] [TRT] Tactic: 7 Time: 0.331354
[05/21/2022-02:50:30] [V] [TRT] Tactic: 8 Time: 0.314453
[05/21/2022-02:50:30] [V] [TRT] Tactic: 9 Time: 0.336901
[05/21/2022-02:50:30] [V] [TRT] Tactic: 28 Time: 0.712149
[05/21/2022-02:50:30] [V] [TRT] Fastest Tactic: 8 Time: 0.314453
[05/21/2022-02:50:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-02:50:30] [V] [TRT] Tactic: 128 Time: 2.66602
[05/21/2022-02:50:30] [V] [TRT] Tactic: 256 Time: 2.67234
[05/21/2022-02:50:30] [V] [TRT] Tactic: 512 Time: 2.6777
[05/21/2022-02:50:30] [V] [TRT] Tactic: -32 Time: 2.77917
[05/21/2022-02:50:30] [V] [TRT] Tactic: -64 Time: 2.76852
[05/21/2022-02:50:31] [V] [TRT] Tactic: -128 Time: 2.7758
[05/21/2022-02:50:31] [V] [TRT] Fastest Tactic: 128 Time: 2.66602
[05/21/2022-02:50:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:50:31] [V] [TRT] *************** Autotuning format combination: Float(663552,1,4608,32) -> Float(663552,1,4608,32) ***************
[05/21/2022-02:50:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:31] [V] [TRT] Tactic: 0 Time: 0.724154
[05/21/2022-02:50:31] [V] [TRT] Tactic: 1 Time: 0.536211
[05/21/2022-02:50:31] [V] [TRT] Tactic: 2 Time: 0.508509
[05/21/2022-02:50:31] [V] [TRT] Tactic: 3 Time: 0.445469
[05/21/2022-02:50:31] [V] [TRT] Tactic: 4 Time: 0.382292
[05/21/2022-02:50:31] [V] [TRT] Tactic: 5 Time: 0.394518
[05/21/2022-02:50:31] [V] [TRT] Tactic: 6 Time: 0.4089
[05/21/2022-02:50:31] [V] [TRT] Tactic: 7 Time: 0.331289
[05/21/2022-02:50:31] [V] [TRT] Tactic: 8 Time: 0.314505
[05/21/2022-02:50:31] [V] [TRT] Tactic: 9 Time: 0.337572
[05/21/2022-02:50:31] [V] [TRT] Tactic: 28 Time: 0.711875
[05/21/2022-02:50:31] [V] [TRT] Fastest Tactic: 8 Time: 0.314505
[05/21/2022-02:50:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-02:50:31] [V] [TRT] Tactic: 128 Time: 2.66686
[05/21/2022-02:50:31] [V] [TRT] Tactic: 256 Time: 2.67391
[05/21/2022-02:50:31] [V] [TRT] Tactic: 512 Time: 2.67689
[05/21/2022-02:50:31] [V] [TRT] Tactic: -32 Time: 2.77854
[05/21/2022-02:50:31] [V] [TRT] Tactic: -64 Time: 2.76505
[05/21/2022-02:50:31] [V] [TRT] Tactic: -128 Time: 2.77589
[05/21/2022-02:50:31] [V] [TRT] Fastest Tactic: 128 Time: 2.66686
[05/21/2022-02:50:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:50:31] [V] [TRT] *************** Autotuning format combination: Float(20736,20736:32,144,1) -> Float(20736,20736:32,144,1) ***************
[05/21/2022-02:50:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:31] [V] [TRT] Tactic: 24 Time: 0.494902
[05/21/2022-02:50:31] [V] [TRT] Tactic: 25 Time: 0.453015
[05/21/2022-02:50:31] [V] [TRT] Tactic: 26 Time: 0.444069
[05/21/2022-02:50:31] [V] [TRT] Tactic: 27 Time: 0.434981
[05/21/2022-02:50:31] [V] [TRT] Tactic: 31 Time: 0.495176
[05/21/2022-02:50:31] [V] [TRT] Fastest Tactic: 27 Time: 0.434981
[05/21/2022-02:50:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-02:50:31] [V] [TRT] Tactic: 128 Time: 2.66449
[05/21/2022-02:50:31] [V] [TRT] Tactic: 256 Time: 2.67139
[05/21/2022-02:50:31] [V] [TRT] Tactic: 512 Time: 2.67572
[05/21/2022-02:50:31] [V] [TRT] Tactic: -32 Time: 2.77695
[05/21/2022-02:50:32] [V] [TRT] Tactic: -64 Time: 2.76468
[05/21/2022-02:50:32] [V] [TRT] Tactic: -128 Time: 2.77605
[05/21/2022-02:50:32] [V] [TRT] Fastest Tactic: 128 Time: 2.66449
[05/21/2022-02:50:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:50:32] [V] [TRT] *************** Autotuning format combination: Half(663552,20736,144,1) -> Half(663552,20736,144,1) ***************
[05/21/2022-02:50:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:32] [V] [TRT] Tactic: 0 Time: 0.737468
[05/21/2022-02:50:32] [V] [TRT] Tactic: 1 Time: 0.559258
[05/21/2022-02:50:32] [V] [TRT] Tactic: 2 Time: 0.520384
[05/21/2022-02:50:32] [V] [TRT] Tactic: 3 Time: 0.445827
[05/21/2022-02:50:32] [V] [TRT] Tactic: 4 Time: 0.405651
[05/21/2022-02:50:32] [V] [TRT] Tactic: 5 Time: 0.414596
[05/21/2022-02:50:32] [V] [TRT] Tactic: 6 Time: 0.396322
[05/21/2022-02:50:32] [V] [TRT] Tactic: 7 Time: 0.346433
[05/21/2022-02:50:32] [V] [TRT] Tactic: 8 Time: 0.346914
[05/21/2022-02:50:32] [V] [TRT] Tactic: 9 Time: 0.358112
[05/21/2022-02:50:32] [V] [TRT] Tactic: 28 Time: 0.739792
[05/21/2022-02:50:32] [V] [TRT] Fastest Tactic: 7 Time: 0.346433
[05/21/2022-02:50:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-02:50:32] [V] [TRT] Tactic: 128 Time: 2.74355
[05/21/2022-02:50:32] [V] [TRT] Tactic: 256 Time: 2.71237
[05/21/2022-02:50:32] [V] [TRT] Tactic: 512 Time: 2.54671
[05/21/2022-02:50:32] [V] [TRT] Tactic: -32 Time: 2.77348
[05/21/2022-02:50:32] [V] [TRT] Tactic: -64 Time: 2.74798
[05/21/2022-02:50:32] [V] [TRT] Tactic: -128 Time: 2.75173
[05/21/2022-02:50:32] [V] [TRT] Fastest Tactic: 512 Time: 2.54671
[05/21/2022-02:50:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:50:32] [V] [TRT] *************** Autotuning format combination: Half(331776,20736:2,144,1) -> Half(331776,20736:2,144,1) ***************
[05/21/2022-02:50:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-02:50:32] [V] [TRT] Tactic: 0 Time: 0.56569
[05/21/2022-02:50:32] [V] [TRT] Tactic: 1 Time: 0.459154
[05/21/2022-02:50:32] [V] [TRT] Tactic: 2 Time: 0.460358
[05/21/2022-02:50:32] [V] [TRT] Tactic: 3 Time: 0.422031
[05/21/2022-02:50:32] [V] [TRT] Tactic: 4 Time: 0.409714
[05/21/2022-02:50:32] [V] [TRT] Tactic: 5 Time: 0.416348
[05/21/2022-02:50:32] [V] [TRT] Tactic: 6 Time: 0.402721
[05/21/2022-02:50:32] [V] [TRT] Tactic: 7 Time: 0.390573
[05/21/2022-02:50:32] [V] [TRT] Tactic: 8 Time: 0.383431
[05/21/2022-02:50:32] [V] [TRT] Tactic: 9 Time: 0.406387
[05/21/2022-02:50:32] [V] [TRT] Tactic: 10 Time: 0.777409
[05/21/2022-02:50:32] [V] [TRT] Tactic: 11 Time: 0.578763
[05/21/2022-02:50:32] [V] [TRT] Tactic: 12 Time: 0.549928
[05/21/2022-02:50:32] [V] [TRT] Tactic: 13 Time: 0.455547
[05/21/2022-02:50:32] [V] [TRT] Tactic: 14 Time: 0.421556
[05/21/2022-02:50:32] [V] [TRT] Tactic: 15 Time: 0.432012
[05/21/2022-02:50:33] [V] [TRT] Tactic: 16 Time: 0.402376
[05/21/2022-02:50:33] [V] [TRT] Tactic: 17 Time: 0.354173
[05/21/2022-02:50:33] [V] [TRT] Tactic: 18 Time: 0.351797
[05/21/2022-02:50:33] [V] [TRT] Tactic: 19 Time: 0.381178
[05/21/2022-02:50:33] [V] [TRT] Tactic: 28 Time: 0.555918
[05/21/2022-02:50:33] [V] [TRT] Tactic: 29 Time: 0.763613
[05/21/2022-02:50:33] [V] [TRT] Fastest Tactic: 18 Time: 0.351797
[05/21/2022-02:50:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-02:50:33] [V] [TRT] Tactic: 128 Time: 2.74045
[05/21/2022-02:50:33] [V] [TRT] Tactic: 256 Time: 2.72062
[05/21/2022-02:50:33] [V] [TRT] Tactic: 512 Time: 2.53833
[05/21/2022-02:50:33] [V] [TRT] Tactic: -32 Time: 2.77319
[05/21/2022-02:50:33] [V] [TRT] Tactic: -64 Time: 2.74788
[05/21/2022-02:50:33] [V] [TRT] Tactic: -128 Time: 2.7494
[05/21/2022-02:50:33] [V] [TRT] Fastest Tactic: 512 Time: 2.53833
[05/21/2022-02:50:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:50:33] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:50:33] [V] [TRT] *************** Autotuning format combination: Float(663552,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:50:33] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:50:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:33] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:50:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:33] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:33] [V] [TRT] Tactic: 0 Time: 14.0844
[05/21/2022-02:50:33] [V] [TRT] Tactic: 1 Time: 5.86808
[05/21/2022-02:50:34] [V] [TRT] Tactic: 2 Time: 14.2515
[05/21/2022-02:50:34] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1099112448, available: 536870912
[05/21/2022-02:50:34] [V] [TRT] Tactic: 5 Time: 47.0535
[05/21/2022-02:50:34] [V] [TRT] Tactic: 6 Time: 3.93681
[05/21/2022-02:50:34] [V] [TRT] Fastest Tactic: 6 Time: 3.93681
[05/21/2022-02:50:34] [V] [TRT] Setting workspace to 1099112448enables more tactics for profiling
[05/21/2022-02:50:34] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:34] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:50:35] [V] [TRT] Tactic: 1062367460111450758 Time: 5.27577
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:50:35] [V] [TRT] Tactic: 1754984623894446479 Time: 5.71044
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:50:35] [V] [TRT] Tactic: 3611739942397549984 Time: 8.47012
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:50:35] [V] [TRT] Tactic: 3827454225649558724 Time: 5.00643
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:50:35] [V] [TRT] Tactic: 4337000649858996379 Time: 4.2743
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:50:35] [V] [TRT] Tactic: 4501471010995462441 Time: 8.49176
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:50:35] [V] [TRT] Tactic: 5137655947464784826 Time: 4.1653
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:50:35] [V] [TRT] Tactic: 5288347012147084929 Time: 8.37331
[05/21/2022-02:50:35] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:50:36] [V] [TRT] Tactic: 5921334924264294896 Time: 3.29346
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:50:36] [V] [TRT] Tactic: 6645123197870846056 Time: 4.22344
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:50:36] [V] [TRT] Tactic: 7144526460361122478 Time: 5.31982
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:50:36] [V] [TRT] Tactic: 7852627285308570038 Time: 5.00446
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:50:36] [V] [TRT] Tactic: -9137461792520977713 Time: 8.49555
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:50:36] [V] [TRT] Tactic: -8776506421218919509 Time: 4.99822
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:50:36] [V] [TRT] Tactic: -8262349710178828730 Time: 8.56796
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:50:36] [V] [TRT] Tactic: -8133971918129952780 Time: 4.59969
[05/21/2022-02:50:36] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:50:37] [V] [TRT] Tactic: -6092040395344634144 Time: 5.47671
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:50:37] [V] [TRT] Tactic: -4787320710726427159 Time: 5.69198
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:50:37] [V] [TRT] Tactic: -3456450830548107839 Time: 4.88058
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:50:37] [V] [TRT] Tactic: -2318106587342035239 Time: 4.95741
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:50:37] [V] [TRT] Tactic: -1343271414618805657 Time: 3.20107
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:50:37] [V] [TRT] Tactic: -1218658103698133241 Time: 4.56556
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:50:37] [V] [TRT] Tactic: -836875257600482091 Time: 4.49945
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:50:37] [V] [TRT] Tactic: -410470605513481746 Time: 8.21295
[05/21/2022-02:50:37] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 3.20107
[05/21/2022-02:50:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-02:50:37] [V] [TRT] *************** Autotuning format combination: Float(663552,1,4608,32) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:50:37] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:37] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:37] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:50:37] [V] [TRT] Tactic: -9153228964338181824 Time: 6.93168
[05/21/2022-02:50:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:50:38] [V] [TRT] Tactic: -7394439838318485025 Time: 4.36687
[05/21/2022-02:50:38] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.36687
[05/21/2022-02:50:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:50:38] [V] [TRT] *************** Autotuning format combination: Half(663552,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:50:38] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:38] [V] [TRT] Tactic: 0 Time: 14.7567
[05/21/2022-02:50:38] [V] [TRT] Tactic: 1 Time: 5.34462
[05/21/2022-02:50:38] [V] [TRT] Tactic: 2 Time: 14.1666
[05/21/2022-02:50:38] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1099112448, available: 536870912
[05/21/2022-02:50:39] [V] [TRT] Tactic: 5 Time: 46.9735
[05/21/2022-02:50:39] [V] [TRT] Tactic: 6 Time: 5.48874
[05/21/2022-02:50:39] [V] [TRT] Fastest Tactic: 1 Time: 5.34462
[05/21/2022-02:50:39] [V] [TRT] Setting workspace to 1099112448enables more tactics for profiling
[05/21/2022-02:50:39] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:39] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:50:39] [V] [TRT] *************** Autotuning format combination: Half(331776,20736:2,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:50:39] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:50:39] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:39] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-02:50:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:50:39] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:50:39] [V] [TRT] Tactic: 3564772625446233998 Time: 2.77377
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:50:39] [V] [TRT] Tactic: 3650389455493082349 Time: 2.87632
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:50:39] [V] [TRT] Tactic: 4772821744921268633 Time: 1.92264
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:50:39] [V] [TRT] Tactic: 5319956359050645452 Time: 2.56895
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:50:39] [V] [TRT] Tactic: 7205456024582378848 Time: 2.20365
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:50:39] [V] [TRT] Tactic: -6490690591794140522 Time: 2.24907
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:50:39] [V] [TRT] Tactic: -4686027666808657977 Time: 4.46829
[05/21/2022-02:50:39] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:50:40] [V] [TRT] Tactic: -4212163711445252890 Time: 4.30009
[05/21/2022-02:50:40] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:50:40] [V] [TRT] Tactic: -3898373634979201110 Time: 4.38479
[05/21/2022-02:50:40] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:50:40] [V] [TRT] Tactic: -2409163523992614473 Time: 2.15031
[05/21/2022-02:50:40] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 1.92264
[05/21/2022-02:50:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-02:50:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:50:40] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1), Float(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:50:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-02:50:41] [V] [TRT] Tactic: 0 Time: 1.52193
[05/21/2022-02:50:42] [V] [TRT] Tactic: 1 Time: 1.1427
[05/21/2022-02:50:43] [V] [TRT] Tactic: 2 Time: 2.52279
[05/21/2022-02:50:43] [V] [TRT] Tactic: 3 Time: 1.66813
[05/21/2022-02:50:44] [V] [TRT] Tactic: 4 Time: 3.11134
[05/21/2022-02:50:45] [V] [TRT] Tactic: 5 Time: 2.15022
[05/21/2022-02:50:46] [V] [TRT] Tactic: 6 Time: 1.68833
[05/21/2022-02:50:47] [V] [TRT] Tactic: 7 Time: 1.7112
[05/21/2022-02:50:48] [V] [TRT] Tactic: 8 Time: 1.64218
[05/21/2022-02:50:49] [V] [TRT] Tactic: 9 Time: 2.32092
[05/21/2022-02:50:50] [V] [TRT] Tactic: 28 Time: 4.73322
[05/21/2022-02:50:50] [V] [TRT] Fastest Tactic: 1 Time: 1.1427
[05/21/2022-02:50:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-02:50:51] [V] [TRT] Tactic: 128 Time: 8.2635
[05/21/2022-02:50:51] [V] [TRT] Tactic: 256 Time: 6.17381
[05/21/2022-02:50:51] [V] [TRT] Tactic: 512 Time: 6.1849
[05/21/2022-02:50:51] [V] [TRT] Tactic: -32 Time: 6.45127
[05/21/2022-02:50:51] [V] [TRT] Tactic: -64 Time: 6.41756
[05/21/2022-02:50:51] [V] [TRT] Tactic: -128 Time: 6.44861
[05/21/2022-02:50:51] [V] [TRT] Fastest Tactic: 256 Time: 6.17381
[05/21/2022-02:50:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 1
[05/21/2022-02:50:51] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64), Float(1327104,1,9216,64) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:50:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-02:50:51] [V] [TRT] Tactic: 0 Time: 1.52259
[05/21/2022-02:50:51] [V] [TRT] Tactic: 1 Time: 1.14268
[05/21/2022-02:50:51] [V] [TRT] Tactic: 2 Time: 1.13719
[05/21/2022-02:50:51] [V] [TRT] Tactic: 3 Time: 0.994355
[05/21/2022-02:50:51] [V] [TRT] Tactic: 4 Time: 0.880417
[05/21/2022-02:50:51] [V] [TRT] Tactic: 5 Time: 0.846406
[05/21/2022-02:50:51] [V] [TRT] Tactic: 6 Time: 0.957168
[05/21/2022-02:50:51] [V] [TRT] Tactic: 7 Time: 0.810762
[05/21/2022-02:50:52] [V] [TRT] Tactic: 8 Time: 0.793503
[05/21/2022-02:50:52] [V] [TRT] Tactic: 9 Time: 0.831165
[05/21/2022-02:50:52] [V] [TRT] Tactic: 28 Time: 1.51031
[05/21/2022-02:50:52] [V] [TRT] Fastest Tactic: 8 Time: 0.793503
[05/21/2022-02:50:52] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-02:50:52] [V] [TRT] Tactic: 128 Time: 6.16193
[05/21/2022-02:50:52] [V] [TRT] Tactic: 256 Time: 6.17115
[05/21/2022-02:50:52] [V] [TRT] Tactic: 512 Time: 6.18469
[05/21/2022-02:50:52] [V] [TRT] Tactic: -32 Time: 6.47937
[05/21/2022-02:50:52] [V] [TRT] Tactic: -64 Time: 6.41394
[05/21/2022-02:50:52] [V] [TRT] Tactic: -128 Time: 6.44586
[05/21/2022-02:50:52] [V] [TRT] Fastest Tactic: 128 Time: 6.16193
[05/21/2022-02:50:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:50:52] [V] [TRT] *************** Autotuning format combination: Float(41472,20736:32,144,1), Float(41472,20736:32,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:50:52] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-02:50:53] [V] [TRT] Tactic: 24 Time: 2.62744
[05/21/2022-02:50:54] [V] [TRT] Tactic: 25 Time: 2.50702
[05/21/2022-02:50:55] [V] [TRT] Tactic: 26 Time: 2.2949
[05/21/2022-02:50:56] [V] [TRT] Tactic: 27 Time: 3.4165
[05/21/2022-02:50:57] [V] [TRT] Tactic: 31 Time: 3.55003
[05/21/2022-02:50:57] [V] [TRT] Fastest Tactic: 26 Time: 2.2949
[05/21/2022-02:50:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-02:50:58] [V] [TRT] Tactic: 128 Time: 7.18327
[05/21/2022-02:50:58] [V] [TRT] Tactic: 256 Time: 6.45967
[05/21/2022-02:50:58] [V] [TRT] Tactic: 512 Time: 6.18227
[05/21/2022-02:50:58] [V] [TRT] Tactic: -32 Time: 6.44818
[05/21/2022-02:50:58] [V] [TRT] Tactic: -64 Time: 6.41234
[05/21/2022-02:50:58] [V] [TRT] Tactic: -128 Time: 6.44409
[05/21/2022-02:50:58] [V] [TRT] Fastest Tactic: 512 Time: 6.18227
[05/21/2022-02:50:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:50:58] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1), Half(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:50:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-02:50:59] [V] [TRT] Tactic: 0 Time: 3.67892
[05/21/2022-02:51:00] [V] [TRT] Tactic: 1 Time: 2.89789
[05/21/2022-02:51:01] [V] [TRT] Tactic: 2 Time: 1.99339
[05/21/2022-02:51:02] [V] [TRT] Tactic: 3 Time: 2.32038
[05/21/2022-02:51:03] [V] [TRT] Tactic: 4 Time: 1.82462
[05/21/2022-02:51:04] [V] [TRT] Tactic: 5 Time: 2.12845
[05/21/2022-02:51:05] [V] [TRT] Tactic: 6 Time: 1.80147
[05/21/2022-02:51:06] [V] [TRT] Tactic: 7 Time: 2.3426
[05/21/2022-02:51:07] [V] [TRT] Tactic: 8 Time: 2.04432
[05/21/2022-02:51:08] [V] [TRT] Tactic: 9 Time: 1.82228
[05/21/2022-02:51:09] [V] [TRT] Tactic: 28 Time: 3.63071
[05/21/2022-02:51:09] [V] [TRT] Fastest Tactic: 6 Time: 1.80147
[05/21/2022-02:51:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-02:51:09] [V] [TRT] Tactic: 128 Time: 6.83168
[05/21/2022-02:51:09] [V] [TRT] Tactic: 256 Time: 6.30916
[05/21/2022-02:51:09] [V] [TRT] Tactic: 512 Time: 5.95594
[05/21/2022-02:51:09] [V] [TRT] Tactic: -32 Time: 6.58897
[05/21/2022-02:51:10] [V] [TRT] Tactic: -64 Time: 6.52182
[05/21/2022-02:51:10] [V] [TRT] Tactic: -128 Time: 6.51848
[05/21/2022-02:51:10] [V] [TRT] Fastest Tactic: 512 Time: 5.95594
[05/21/2022-02:51:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 6
[05/21/2022-02:51:10] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1), Half(663552,20736:2,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:51:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-02:51:11] [V] [TRT] Tactic: 0 Time: 1.30424
[05/21/2022-02:51:12] [V] [TRT] Tactic: 1 Time: 1.18423
[05/21/2022-02:51:13] [V] [TRT] Tactic: 2 Time: 1.12682
[05/21/2022-02:51:13] [V] [TRT] Tactic: 3 Time: 1.09397
[05/21/2022-02:51:14] [V] [TRT] Tactic: 4 Time: 1.19432
[05/21/2022-02:51:15] [V] [TRT] Tactic: 5 Time: 1.16003
[05/21/2022-02:51:16] [V] [TRT] Tactic: 6 Time: 1.16444
[05/21/2022-02:51:17] [V] [TRT] Tactic: 7 Time: 1.16413
[05/21/2022-02:51:18] [V] [TRT] Tactic: 8 Time: 1.30973
[05/21/2022-02:51:20] [V] [TRT] Tactic: 9 Time: 1.45512
[05/21/2022-02:51:21] [V] [TRT] Tactic: 10 Time: 1.99509
[05/21/2022-02:51:22] [V] [TRT] Tactic: 11 Time: 3.38124
[05/21/2022-02:51:23] [V] [TRT] Tactic: 12 Time: 2.44609
[05/21/2022-02:51:23] [V] [TRT] Tactic: 13 Time: 2.00788
[05/21/2022-02:51:25] [V] [TRT] Tactic: 14 Time: 1.59938
[05/21/2022-02:51:26] [V] [TRT] Tactic: 15 Time: 1.50999
[05/21/2022-02:51:27] [V] [TRT] Tactic: 16 Time: 1.3131
[05/21/2022-02:51:28] [V] [TRT] Tactic: 17 Time: 2.33417
[05/21/2022-02:51:29] [V] [TRT] Tactic: 18 Time: 1.53374
[05/21/2022-02:51:30] [V] [TRT] Tactic: 19 Time: 1.52631
[05/21/2022-02:51:31] [V] [TRT] Tactic: 28 Time: 1.83547
[05/21/2022-02:51:32] [V] [TRT] Tactic: 29 Time: 1.8554
[05/21/2022-02:51:32] [V] [TRT] Fastest Tactic: 3 Time: 1.09397
[05/21/2022-02:51:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-02:51:32] [V] [TRT] Tactic: 128 Time: 6.63732
[05/21/2022-02:51:32] [V] [TRT] Tactic: 256 Time: 6.48361
[05/21/2022-02:51:32] [V] [TRT] Tactic: 512 Time: 6.21614
[05/21/2022-02:51:32] [V] [TRT] Tactic: -32 Time: 6.88559
[05/21/2022-02:51:33] [V] [TRT] Tactic: -64 Time: 6.75915
[05/21/2022-02:51:33] [V] [TRT] Tactic: -128 Time: 6.7892
[05/21/2022-02:51:33] [V] [TRT] Fastest Tactic: 512 Time: 6.21614
[05/21/2022-02:51:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 3
[05/21/2022-02:51:33] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:33] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:51:33] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:33] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:51:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:33] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:33] [V] [TRT] Tactic: 0 Time: 4.49758
[05/21/2022-02:51:33] [V] [TRT] Tactic: 1 Time: 2.60706
[05/21/2022-02:51:33] [V] [TRT] Tactic: 2 Time: 4.79051
[05/21/2022-02:51:33] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198093824, available: 536870912
[05/21/2022-02:51:33] [V] [TRT] Tactic: 5 Time: 7.0219
[05/21/2022-02:51:33] [V] [TRT] Fastest Tactic: 1 Time: 2.60706
[05/21/2022-02:51:33] [V] [TRT] Setting workspace to 2198093824enables more tactics for profiling
[05/21/2022-02:51:33] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:33] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:33] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:33] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:51:33] [V] [TRT] Tactic: 1062367460111450758 Time: 1.89225
[05/21/2022-02:51:33] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:51:33] [V] [TRT] Tactic: 1698681053543049347 Time: 1.61313
[05/21/2022-02:51:33] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:51:33] [V] [TRT] Tactic: 4501471010995462441 Time: 2.63801
[05/21/2022-02:51:33] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:51:33] [V] [TRT] Tactic: 5137655947464784826 Time: 1.2817
[05/21/2022-02:51:33] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:51:33] [V] [TRT] Tactic: 5288347012147084929 Time: 2.64631
[05/21/2022-02:51:33] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:51:34] [V] [TRT] Tactic: 5326823351883942011 Time: 2.57719
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:51:34] [V] [TRT] Tactic: 5500448035057547314 Time: 1.42183
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:51:34] [V] [TRT] Tactic: 6645123197870846056 Time: 1.34296
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:51:34] [V] [TRT] Tactic: 7144526460361122478 Time: 1.93802
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:51:34] [V] [TRT] Tactic: -8262349710178828730 Time: 2.77301
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:51:34] [V] [TRT] Tactic: -6576203419454146580 Time: 1.72453
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:51:34] [V] [TRT] Tactic: -4787320710726427159 Time: 1.96826
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:51:34] [V] [TRT] Tactic: -3456450830548107839 Time: 1.81778
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:51:34] [V] [TRT] Tactic: -1218658103698133241 Time: 1.59126
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:51:34] [V] [TRT] Tactic: -836875257600482091 Time: 1.55675
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:51:34] [V] [TRT] Tactic: -410470605513481746 Time: 2.69783
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:51:34] [V] [TRT] Tactic: -377491875521947884 Time: 2.7429
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:51:34] [V] [TRT] Tactic: -37215280111360163 Time: 1.29732
[05/21/2022-02:51:34] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 1.2817
[05/21/2022-02:51:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-02:51:34] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:51:34] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:34] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:34] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:34] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:51:34] [V] [TRT] Tactic: 3886731678879822788 Time: 1.60345
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:51:34] [V] [TRT] Tactic: 6629944304117643200 Time: 4.14956
[05/21/2022-02:51:34] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:51:35] [V] [TRT] Tactic: -9153228964338181824 Time: 4.09066
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:51:35] [V] [TRT] Tactic: -7394439838318485025 Time: 1.57531
[05/21/2022-02:51:35] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.57531
[05/21/2022-02:51:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:51:35] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:35] [V] [TRT] Tactic: 0 Time: 2.9655
[05/21/2022-02:51:35] [V] [TRT] Tactic: 1 Time: 2.01307
[05/21/2022-02:51:35] [V] [TRT] Tactic: 2 Time: 4.47581
[05/21/2022-02:51:35] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198093824, available: 536870912
[05/21/2022-02:51:35] [V] [TRT] Tactic: 5 Time: 6.57788
[05/21/2022-02:51:35] [V] [TRT] Fastest Tactic: 1 Time: 2.01307
[05/21/2022-02:51:35] [V] [TRT] Setting workspace to 2198093824enables more tactics for profiling
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:35] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:51:35] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:35] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:35] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:35] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:51:35] [V] [TRT] Tactic: 3066127711859985668 Time: 0.950143
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:51:35] [V] [TRT] Tactic: 3564772625446233998 Time: 1.01967
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:51:35] [V] [TRT] Tactic: 5319956359050645452 Time: 0.974642
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:51:35] [V] [TRT] Tactic: 7205456024582378848 Time: 0.755743
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:51:35] [V] [TRT] Tactic: 8163473458334948789 Time: 0.724642
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:51:35] [V] [TRT] Tactic: -4212163711445252890 Time: 1.45628
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:51:35] [V] [TRT] Tactic: -3898373634979201110 Time: 1.47654
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:51:35] [V] [TRT] Tactic: -2409163523992614473 Time: 0.742708
[05/21/2022-02:51:35] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:51:35] [V] [TRT] Tactic: -1716393687483585322 Time: 1.45303
[05/21/2022-02:51:35] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 0.724642
[05/21/2022-02:51:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-02:51:35] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:35] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1) -> Float(2654208,20736,144,1) ***************
[05/21/2022-02:51:35] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:35] [V] [TRT] Tactic: 0 Time: 1.82842
[05/21/2022-02:51:35] [V] [TRT] Tactic: 1 Time: 1.26922
[05/21/2022-02:51:35] [V] [TRT] Tactic: 2 Time: 1.20145
[05/21/2022-02:51:35] [V] [TRT] Tactic: 3 Time: 0.959486
[05/21/2022-02:51:35] [V] [TRT] Tactic: 4 Time: 0.88612
[05/21/2022-02:51:35] [V] [TRT] Tactic: 5 Time: 0.875456
[05/21/2022-02:51:36] [V] [TRT] Tactic: 6 Time: 0.83539
[05/21/2022-02:51:36] [V] [TRT] Tactic: 7 Time: 0.711419
[05/21/2022-02:51:36] [V] [TRT] Tactic: 8 Time: 0.698574
[05/21/2022-02:51:36] [V] [TRT] Tactic: 9 Time: 0.721042
[05/21/2022-02:51:36] [V] [TRT] Tactic: 28 Time: 1.80803
[05/21/2022-02:51:36] [V] [TRT] Fastest Tactic: 8 Time: 0.698574
[05/21/2022-02:51:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-02:51:36] [V] [TRT] Tactic: 128 Time: 6.00702
[05/21/2022-02:51:36] [V] [TRT] Tactic: 256 Time: 6.00868
[05/21/2022-02:51:36] [V] [TRT] Tactic: 512 Time: 6.01585
[05/21/2022-02:51:36] [V] [TRT] Tactic: -32 Time: 5.53532
[05/21/2022-02:51:36] [V] [TRT] Tactic: -64 Time: 5.54687
[05/21/2022-02:51:36] [V] [TRT] Tactic: -128 Time: 5.61431
[05/21/2022-02:51:36] [V] [TRT] Fastest Tactic: -32 Time: 5.53532
[05/21/2022-02:51:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:51:36] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64) -> Float(2654208,1,18432,128) ***************
[05/21/2022-02:51:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:36] [V] [TRT] Tactic: 0 Time: 1.86294
[05/21/2022-02:51:36] [V] [TRT] Tactic: 1 Time: 1.27088
[05/21/2022-02:51:37] [V] [TRT] Tactic: 2 Time: 1.20016
[05/21/2022-02:51:37] [V] [TRT] Tactic: 3 Time: 1.52076
[05/21/2022-02:51:37] [V] [TRT] Tactic: 4 Time: 1.41415
[05/21/2022-02:51:37] [V] [TRT] Tactic: 5 Time: 1.27967
[05/21/2022-02:51:37] [V] [TRT] Tactic: 6 Time: 2.08453
[05/21/2022-02:51:37] [V] [TRT] Tactic: 7 Time: 1.73237
[05/21/2022-02:51:37] [V] [TRT] Tactic: 8 Time: 1.69073
[05/21/2022-02:51:37] [V] [TRT] Tactic: 9 Time: 1.48232
[05/21/2022-02:51:37] [V] [TRT] Tactic: 28 Time: 1.80943
[05/21/2022-02:51:37] [V] [TRT] Fastest Tactic: 2 Time: 1.20016
[05/21/2022-02:51:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-02:51:37] [V] [TRT] Tactic: 128 Time: 6.0073
[05/21/2022-02:51:37] [V] [TRT] Tactic: 256 Time: 6.00936
[05/21/2022-02:51:37] [V] [TRT] Tactic: 512 Time: 6.27142
[05/21/2022-02:51:37] [V] [TRT] Tactic: -32 Time: 6.06888
[05/21/2022-02:51:38] [V] [TRT] Tactic: -64 Time: 6.643
[05/21/2022-02:51:38] [V] [TRT] Tactic: -128 Time: 6.63083
[05/21/2022-02:51:38] [V] [TRT] Fastest Tactic: 128 Time: 6.0073
[05/21/2022-02:51:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:51:38] [V] [TRT] *************** Autotuning format combination: Float(41472,20736:32,144,1) -> Float(82944,20736:32,144,1) ***************
[05/21/2022-02:51:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:38] [V] [TRT] Tactic: 24 Time: 0.998222
[05/21/2022-02:51:38] [V] [TRT] Tactic: 25 Time: 0.897344
[05/21/2022-02:51:38] [V] [TRT] Tactic: 26 Time: 0.89584
[05/21/2022-02:51:38] [V] [TRT] Tactic: 27 Time: 0.867454
[05/21/2022-02:51:38] [V] [TRT] Tactic: 31 Time: 1.02327
[05/21/2022-02:51:38] [V] [TRT] Fastest Tactic: 27 Time: 0.867454
[05/21/2022-02:51:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-02:51:38] [V] [TRT] Tactic: 128 Time: 6.09624
[05/21/2022-02:51:38] [V] [TRT] Tactic: 256 Time: 6.24379
[05/21/2022-02:51:38] [V] [TRT] Tactic: 512 Time: 6.23487
[05/21/2022-02:51:38] [V] [TRT] Tactic: -32 Time: 5.85932
[05/21/2022-02:51:39] [V] [TRT] Tactic: -64 Time: 5.71641
[05/21/2022-02:51:39] [V] [TRT] Tactic: -128 Time: 5.81565
[05/21/2022-02:51:39] [V] [TRT] Fastest Tactic: -64 Time: 5.71641
[05/21/2022-02:51:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:51:39] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1) -> Half(2654208,20736,144,1) ***************
[05/21/2022-02:51:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:39] [V] [TRT] Tactic: 0 Time: 1.9472
[05/21/2022-02:51:39] [V] [TRT] Tactic: 1 Time: 1.32748
[05/21/2022-02:51:39] [V] [TRT] Tactic: 2 Time: 1.2368
[05/21/2022-02:51:39] [V] [TRT] Tactic: 3 Time: 0.981185
[05/21/2022-02:51:39] [V] [TRT] Tactic: 4 Time: 0.927285
[05/21/2022-02:51:39] [V] [TRT] Tactic: 5 Time: 0.908386
[05/21/2022-02:51:39] [V] [TRT] Tactic: 6 Time: 0.840338
[05/21/2022-02:51:39] [V] [TRT] Tactic: 7 Time: 0.748692
[05/21/2022-02:51:39] [V] [TRT] Tactic: 8 Time: 0.749245
[05/21/2022-02:51:39] [V] [TRT] Tactic: 9 Time: 0.7428
[05/21/2022-02:51:39] [V] [TRT] Tactic: 28 Time: 1.94961
[05/21/2022-02:51:39] [V] [TRT] Fastest Tactic: 9 Time: 0.7428
[05/21/2022-02:51:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-02:51:39] [V] [TRT] Tactic: 128 Time: 6.01561
[05/21/2022-02:51:39] [V] [TRT] Tactic: 256 Time: 5.89674
[05/21/2022-02:51:40] [V] [TRT] Tactic: 512 Time: 5.51995
[05/21/2022-02:51:40] [V] [TRT] Tactic: -32 Time: 5.77116
[05/21/2022-02:51:40] [V] [TRT] Tactic: -64 Time: 5.83476
[05/21/2022-02:51:40] [V] [TRT] Tactic: -128 Time: 5.69676
[05/21/2022-02:51:40] [V] [TRT] Fastest Tactic: 512 Time: 5.51995
[05/21/2022-02:51:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:51:40] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(1327104,20736:2,144,1) ***************
[05/21/2022-02:51:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:40] [V] [TRT] Tactic: 0 Time: 1.27674
[05/21/2022-02:51:40] [V] [TRT] Tactic: 1 Time: 0.979473
[05/21/2022-02:51:40] [V] [TRT] Tactic: 2 Time: 0.986582
[05/21/2022-02:51:40] [V] [TRT] Tactic: 3 Time: 0.873307
[05/21/2022-02:51:40] [V] [TRT] Tactic: 4 Time: 0.835247
[05/21/2022-02:51:40] [V] [TRT] Tactic: 5 Time: 0.868183
[05/21/2022-02:51:40] [V] [TRT] Tactic: 6 Time: 0.808581
[05/21/2022-02:51:40] [V] [TRT] Tactic: 7 Time: 0.778516
[05/21/2022-02:51:40] [V] [TRT] Tactic: 8 Time: 0.766771
[05/21/2022-02:51:40] [V] [TRT] Tactic: 9 Time: 0.822337
[05/21/2022-02:51:40] [V] [TRT] Tactic: 10 Time: 1.999
[05/21/2022-02:51:40] [V] [TRT] Tactic: 11 Time: 1.38614
[05/21/2022-02:51:40] [V] [TRT] Tactic: 12 Time: 1.29668
[05/21/2022-02:51:40] [V] [TRT] Tactic: 13 Time: 1.01677
[05/21/2022-02:51:40] [V] [TRT] Tactic: 14 Time: 0.964453
[05/21/2022-02:51:40] [V] [TRT] Tactic: 15 Time: 0.976048
[05/21/2022-02:51:40] [V] [TRT] Tactic: 16 Time: 0.847936
[05/21/2022-02:51:41] [V] [TRT] Tactic: 17 Time: 0.756432
[05/21/2022-02:51:41] [V] [TRT] Tactic: 18 Time: 0.772038
[05/21/2022-02:51:41] [V] [TRT] Tactic: 19 Time: 0.806569
[05/21/2022-02:51:41] [V] [TRT] Tactic: 28 Time: 1.25431
[05/21/2022-02:51:41] [V] [TRT] Tactic: 29 Time: 1.94852
[05/21/2022-02:51:41] [V] [TRT] Fastest Tactic: 17 Time: 0.756432
[05/21/2022-02:51:41] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-02:51:41] [V] [TRT] Tactic: 128 Time: 5.78564
[05/21/2022-02:51:41] [V] [TRT] Tactic: 256 Time: 5.69118
[05/21/2022-02:51:41] [V] [TRT] Tactic: 512 Time: 5.34291
[05/21/2022-02:51:41] [V] [TRT] Tactic: -32 Time: 5.55038
[05/21/2022-02:51:41] [V] [TRT] Tactic: -64 Time: 5.53141
[05/21/2022-02:51:41] [V] [TRT] Tactic: -128 Time: 5.62256
[05/21/2022-02:51:41] [V] [TRT] Fastest Tactic: 512 Time: 5.34291
[05/21/2022-02:51:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:51:41] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:41] [V] [TRT] *************** Autotuning format combination: Float(2654208,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:51:41] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:41] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:41] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:51:41] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:41] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:41] [V] [TRT] Tactic: 0 Time: 7.11805
[05/21/2022-02:51:42] [V] [TRT] Tactic: 1 Time: 3.46492
[05/21/2022-02:51:42] [V] [TRT] Tactic: 2 Time: 7.78437
[05/21/2022-02:51:42] [V] [TRT] Tactic: 5 Time: 11.1053
[05/21/2022-02:51:42] [V] [TRT] Fastest Tactic: 1 Time: 3.46492
[05/21/2022-02:51:42] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:42] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:42] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:51:42] [V] [TRT] Tactic: 1062367460111450758 Time: 2.97608
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:51:42] [V] [TRT] Tactic: 1698681053543049347 Time: 2.66281
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:51:42] [V] [TRT] Tactic: 4501471010995462441 Time: 4.28969
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:51:42] [V] [TRT] Tactic: 5137655947464784826 Time: 2.10329
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:51:42] [V] [TRT] Tactic: 5288347012147084929 Time: 4.34733
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:51:42] [V] [TRT] Tactic: 5326823351883942011 Time: 4.11815
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:51:42] [V] [TRT] Tactic: 5500448035057547314 Time: 2.35695
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:51:42] [V] [TRT] Tactic: 6645123197870846056 Time: 2.16548
[05/21/2022-02:51:42] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:51:43] [V] [TRT] Tactic: 7144526460361122478 Time: 3.03796
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:51:43] [V] [TRT] Tactic: -8262349710178828730 Time: 4.42686
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:51:43] [V] [TRT] Tactic: -6576203419454146580 Time: 2.7296
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:51:43] [V] [TRT] Tactic: -4787320710726427159 Time: 3.28342
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:51:43] [V] [TRT] Tactic: -3456450830548107839 Time: 2.7487
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:51:43] [V] [TRT] Tactic: -1218658103698133241 Time: 2.43726
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:51:43] [V] [TRT] Tactic: -836875257600482091 Time: 2.43486
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:51:43] [V] [TRT] Tactic: -410470605513481746 Time: 4.25317
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:51:43] [V] [TRT] Tactic: -377491875521947884 Time: 4.27815
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:51:43] [V] [TRT] Tactic: -37215280111360163 Time: 2.12632
[05/21/2022-02:51:43] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 2.10329
[05/21/2022-02:51:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-02:51:43] [V] [TRT] *************** Autotuning format combination: Float(2654208,1,18432,128) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:51:43] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:43] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:43] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:43] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:51:43] [V] [TRT] Tactic: 3886731678879822788 Time: 2.40957
[05/21/2022-02:51:43] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:51:44] [V] [TRT] Tactic: 6629944304117643200 Time: 5.24246
[05/21/2022-02:51:44] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:51:44] [V] [TRT] Tactic: -9153228964338181824 Time: 5.23141
[05/21/2022-02:51:44] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:51:44] [V] [TRT] Tactic: -7394439838318485025 Time: 2.41341
[05/21/2022-02:51:44] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 2.40957
[05/21/2022-02:51:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:51:44] [V] [TRT] *************** Autotuning format combination: Half(2654208,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:44] [V] [TRT] Tactic: 0 Time: 4.87219
[05/21/2022-02:51:44] [V] [TRT] Tactic: 1 Time: 3.39891
[05/21/2022-02:51:44] [V] [TRT] Tactic: 2 Time: 7.99729
[05/21/2022-02:51:44] [V] [TRT] Tactic: 5 Time: 11.8833
[05/21/2022-02:51:44] [V] [TRT] Fastest Tactic: 1 Time: 3.39891
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:51:44] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736:2,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:44] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736:2,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:44] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:44] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:44] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:51:44] [V] [TRT] Tactic: 3066127711859985668 Time: 1.55228
[05/21/2022-02:51:44] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:51:45] [V] [TRT] Tactic: 3564772625446233998 Time: 1.68219
[05/21/2022-02:51:45] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:51:45] [V] [TRT] Tactic: 5319956359050645452 Time: 1.58911
[05/21/2022-02:51:45] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:51:45] [V] [TRT] Tactic: 7205456024582378848 Time: 1.20495
[05/21/2022-02:51:45] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:51:45] [V] [TRT] Tactic: 8163473458334948789 Time: 1.15667
[05/21/2022-02:51:45] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:51:45] [V] [TRT] Tactic: -4212163711445252890 Time: 2.30116
[05/21/2022-02:51:45] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:51:45] [V] [TRT] Tactic: -3898373634979201110 Time: 2.39799
[05/21/2022-02:51:45] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:51:45] [V] [TRT] Tactic: -2409163523992614473 Time: 1.16199
[05/21/2022-02:51:45] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:51:45] [V] [TRT] Tactic: -1716393687483585322 Time: 2.30631
[05/21/2022-02:51:45] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 1.15667
[05/21/2022-02:51:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-02:51:45] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:45] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1) -> Float(1327104,20736,144,1) ***************
[05/21/2022-02:51:45] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64) -> Float(1327104,1,9216,64) ***************
[05/21/2022-02:51:45] [V] [TRT] *************** Autotuning format combination: Float(41472,20736:32,144,1) -> Float(41472,20736:32,144,1) ***************
[05/21/2022-02:51:45] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1) -> Half(1327104,20736,144,1) ***************
[05/21/2022-02:51:45] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(663552,20736:2,144,1) ***************
[05/21/2022-02:51:45] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:45] [V] [TRT] *************** Autotuning format combination: Float(1327104,20736,144,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:51:45] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:45] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:51:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:45] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:45] [V] [TRT] Tactic: 0 Time: 10.9081
[05/21/2022-02:51:45] [V] [TRT] Tactic: 1 Time: 5.68523
[05/21/2022-02:51:45] [V] [TRT] Tactic: 2 Time: 9.10846
[05/21/2022-02:51:48] [V] [TRT] Tactic: 5 Time: 133.57
[05/21/2022-02:51:48] [V] [TRT] Fastest Tactic: 1 Time: 5.68523
[05/21/2022-02:51:48] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:51:48] [V] [TRT] Tactic: 1062367460111450758 Time: 5.18185
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:51:48] [V] [TRT] Tactic: 1754984623894446479 Time: 6.42047
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:51:48] [V] [TRT] Tactic: 3611739942397549984 Time: 4.24714
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:51:48] [V] [TRT] Tactic: 4337000649858996379 Time: 4.18473
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:51:48] [V] [TRT] Tactic: 4501471010995462441 Time: 4.16134
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:51:48] [V] [TRT] Tactic: 5137655947464784826 Time: 4.04417
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:51:48] [V] [TRT] Tactic: 5288347012147084929 Time: 4.1743
[05/21/2022-02:51:48] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:51:49] [V] [TRT] Tactic: 6645123197870846056 Time: 4.21314
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:51:49] [V] [TRT] Tactic: 7144526460361122478 Time: 5.87926
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:51:49] [V] [TRT] Tactic: -9137461792520977713 Time: 4.35811
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:51:49] [V] [TRT] Tactic: -8262349710178828730 Time: 4.23958
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:51:49] [V] [TRT] Tactic: -8133971918129952780 Time: 4.63527
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:51:49] [V] [TRT] Tactic: -6092040395344634144 Time: 5.43074
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:51:49] [V] [TRT] Tactic: -4787320710726427159 Time: 6.04085
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:51:49] [V] [TRT] Tactic: -3456450830548107839 Time: 4.81724
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:51:49] [V] [TRT] Tactic: -1218658103698133241 Time: 4.76518
[05/21/2022-02:51:49] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:51:50] [V] [TRT] Tactic: -836875257600482091 Time: 4.78067
[05/21/2022-02:51:50] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:51:50] [V] [TRT] Tactic: -410470605513481746 Time: 4.10928
[05/21/2022-02:51:50] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 4.04417
[05/21/2022-02:51:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-02:51:50] [V] [TRT] *************** Autotuning format combination: Float(1327104,1,9216,64) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:51:50] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:50] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:50] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:51:50] [V] [TRT] Tactic: -9153228964338181824 Time: 6.77172
[05/21/2022-02:51:50] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:51:50] [V] [TRT] Tactic: -7394439838318485025 Time: 4.15598
[05/21/2022-02:51:50] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.15598
[05/21/2022-02:51:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:51:50] [V] [TRT] *************** Autotuning format combination: Half(1327104,20736,144,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:51:50] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:50] [V] [TRT] Tactic: 0 Time: 8.58242
[05/21/2022-02:51:50] [V] [TRT] Tactic: 1 Time: 5.84943
[05/21/2022-02:51:50] [V] [TRT] Tactic: 2 Time: 8.26954
[05/21/2022-02:51:52] [V] [TRT] Tactic: 5 Time: 133.033
[05/21/2022-02:51:52] [V] [TRT] Fastest Tactic: 1 Time: 5.84943
[05/21/2022-02:51:52] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:51:52] [V] [TRT] *************** Autotuning format combination: Half(663552,20736:2,144,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:51:52] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:52] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:52] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:52] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:52] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:51:53] [V] [TRT] Tactic: 3564772625446233998 Time: 2.6243
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:51:53] [V] [TRT] Tactic: 3650389455493082349 Time: 2.74166
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:51:53] [V] [TRT] Tactic: 5319956359050645452 Time: 2.41799
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:51:53] [V] [TRT] Tactic: 7205456024582378848 Time: 2.1867
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:51:53] [V] [TRT] Tactic: -6490690591794140522 Time: 2.20188
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:51:53] [V] [TRT] Tactic: -4686027666808657977 Time: 2.16806
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:51:53] [V] [TRT] Tactic: -4212163711445252890 Time: 2.03979
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:51:53] [V] [TRT] Tactic: -3898373634979201110 Time: 2.1782
[05/21/2022-02:51:53] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:51:53] [V] [TRT] Tactic: -2409163523992614473 Time: 2.08161
[05/21/2022-02:51:53] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 2.03979
[05/21/2022-02:51:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:51:53] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:53] [V] [TRT] *************** Autotuning format combination: Float(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:51:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:53] [V] [TRT] Tactic: 0 Time: 0.725039
[05/21/2022-02:51:53] [V] [TRT] Tactic: 1 Time: 0.544505
[05/21/2022-02:51:53] [V] [TRT] Tactic: 2 Time: 0.521524
[05/21/2022-02:51:53] [V] [TRT] Tactic: 3 Time: 0.449427
[05/21/2022-02:51:53] [V] [TRT] Tactic: 4 Time: 0.38388
[05/21/2022-02:51:53] [V] [TRT] Tactic: 5 Time: 0.394942
[05/21/2022-02:51:53] [V] [TRT] Tactic: 6 Time: 0.421614
[05/21/2022-02:51:53] [V] [TRT] Tactic: 7 Time: 0.34166
[05/21/2022-02:51:53] [V] [TRT] Tactic: 8 Time: 0.317442
[05/21/2022-02:51:53] [V] [TRT] Tactic: 9 Time: 0.338483
[05/21/2022-02:51:53] [V] [TRT] Tactic: 28 Time: 0.713054
[05/21/2022-02:51:53] [V] [TRT] Fastest Tactic: 8 Time: 0.317442
[05/21/2022-02:51:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-02:51:53] [V] [TRT] Tactic: 128 Time: 2.66674
[05/21/2022-02:51:54] [V] [TRT] Tactic: 256 Time: 2.67283
[05/21/2022-02:51:54] [V] [TRT] Tactic: 512 Time: 2.79464
[05/21/2022-02:51:54] [V] [TRT] Tactic: -32 Time: 2.78393
[05/21/2022-02:51:54] [V] [TRT] Tactic: -64 Time: 2.79335
[05/21/2022-02:51:54] [V] [TRT] Tactic: -128 Time: 2.79062
[05/21/2022-02:51:54] [V] [TRT] Fastest Tactic: 128 Time: 2.66674
[05/21/2022-02:51:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:51:54] [V] [TRT] *************** Autotuning format combination: Float(663552,1,9216,128) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:51:54] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:54] [V] [TRT] Tactic: 0 Time: 0.725365
[05/21/2022-02:51:54] [V] [TRT] Tactic: 1 Time: 0.544779
[05/21/2022-02:51:54] [V] [TRT] Tactic: 2 Time: 0.512955
[05/21/2022-02:51:54] [V] [TRT] Tactic: 3 Time: 0.448535
[05/21/2022-02:51:54] [V] [TRT] Tactic: 4 Time: 0.384382
[05/21/2022-02:51:54] [V] [TRT] Tactic: 5 Time: 0.395026
[05/21/2022-02:51:54] [V] [TRT] Tactic: 6 Time: 0.408327
[05/21/2022-02:51:54] [V] [TRT] Tactic: 7 Time: 0.331022
[05/21/2022-02:51:54] [V] [TRT] Tactic: 8 Time: 0.314681
[05/21/2022-02:51:54] [V] [TRT] Tactic: 9 Time: 0.337123
[05/21/2022-02:51:54] [V] [TRT] Tactic: 28 Time: 0.712474
[05/21/2022-02:51:54] [V] [TRT] Fastest Tactic: 8 Time: 0.314681
[05/21/2022-02:51:54] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-02:51:54] [V] [TRT] Tactic: 128 Time: 2.6671
[05/21/2022-02:51:54] [V] [TRT] Tactic: 256 Time: 2.67206
[05/21/2022-02:51:54] [V] [TRT] Tactic: 512 Time: 2.67775
[05/21/2022-02:51:54] [V] [TRT] Tactic: -32 Time: 2.79218
[05/21/2022-02:51:54] [V] [TRT] Tactic: -64 Time: 2.76607
[05/21/2022-02:51:54] [V] [TRT] Tactic: -128 Time: 2.81294
[05/21/2022-02:51:54] [V] [TRT] Fastest Tactic: 128 Time: 2.6671
[05/21/2022-02:51:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:51:54] [V] [TRT] *************** Autotuning format combination: Float(20736,5184:32,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:51:54] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:54] [V] [TRT] Tactic: 24 Time: 0.506934
[05/21/2022-02:51:55] [V] [TRT] Tactic: 25 Time: 0.475449
[05/21/2022-02:51:55] [V] [TRT] Tactic: 26 Time: 0.474792
[05/21/2022-02:51:55] [V] [TRT] Tactic: 27 Time: 0.443138
[05/21/2022-02:51:55] [V] [TRT] Tactic: 31 Time: 0.526816
[05/21/2022-02:51:55] [V] [TRT] Fastest Tactic: 27 Time: 0.443138
[05/21/2022-02:51:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-02:51:55] [V] [TRT] Tactic: 128 Time: 2.68569
[05/21/2022-02:51:55] [V] [TRT] Tactic: 256 Time: 2.67447
[05/21/2022-02:51:55] [V] [TRT] Tactic: 512 Time: 2.70838
[05/21/2022-02:51:55] [V] [TRT] Tactic: -32 Time: 2.78329
[05/21/2022-02:51:55] [V] [TRT] Tactic: -64 Time: 2.79423
[05/21/2022-02:51:55] [V] [TRT] Tactic: -128 Time: 2.80604
[05/21/2022-02:51:55] [V] [TRT] Fastest Tactic: 256 Time: 2.67447
[05/21/2022-02:51:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:51:55] [V] [TRT] *************** Autotuning format combination: Half(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:51:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:55] [V] [TRT] Tactic: 0 Time: 0.7389
[05/21/2022-02:51:55] [V] [TRT] Tactic: 1 Time: 0.564753
[05/21/2022-02:51:55] [V] [TRT] Tactic: 2 Time: 0.521152
[05/21/2022-02:51:55] [V] [TRT] Tactic: 3 Time: 0.447735
[05/21/2022-02:51:55] [V] [TRT] Tactic: 4 Time: 0.406178
[05/21/2022-02:51:55] [V] [TRT] Tactic: 5 Time: 0.415058
[05/21/2022-02:51:55] [V] [TRT] Tactic: 6 Time: 0.399785
[05/21/2022-02:51:55] [V] [TRT] Tactic: 7 Time: 0.347929
[05/21/2022-02:51:55] [V] [TRT] Tactic: 8 Time: 0.347676
[05/21/2022-02:51:55] [V] [TRT] Tactic: 9 Time: 0.358353
[05/21/2022-02:51:55] [V] [TRT] Tactic: 28 Time: 0.740625
[05/21/2022-02:51:55] [V] [TRT] Fastest Tactic: 8 Time: 0.347676
[05/21/2022-02:51:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-02:51:56] [V] [TRT] Tactic: 128 Time: 2.74428
[05/21/2022-02:51:56] [V] [TRT] Tactic: 256 Time: 2.71997
[05/21/2022-02:51:56] [V] [TRT] Tactic: 512 Time: 2.5403
[05/21/2022-02:51:56] [V] [TRT] Tactic: -32 Time: 2.77921
[05/21/2022-02:51:56] [V] [TRT] Tactic: -64 Time: 2.74875
[05/21/2022-02:51:56] [V] [TRT] Tactic: -128 Time: 2.75233
[05/21/2022-02:51:56] [V] [TRT] Fastest Tactic: 512 Time: 2.5403
[05/21/2022-02:51:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:51:56] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:51:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:56] [V] [TRT] Tactic: 0 Time: 0.570156
[05/21/2022-02:51:56] [V] [TRT] Tactic: 1 Time: 0.469531
[05/21/2022-02:51:56] [V] [TRT] Tactic: 2 Time: 0.469427
[05/21/2022-02:51:56] [V] [TRT] Tactic: 3 Time: 0.43485
[05/21/2022-02:51:56] [V] [TRT] Tactic: 4 Time: 0.420716
[05/21/2022-02:51:56] [V] [TRT] Tactic: 5 Time: 0.427044
[05/21/2022-02:51:56] [V] [TRT] Tactic: 6 Time: 0.423105
[05/21/2022-02:51:56] [V] [TRT] Tactic: 7 Time: 0.396029
[05/21/2022-02:51:56] [V] [TRT] Tactic: 8 Time: 0.397441
[05/21/2022-02:51:56] [V] [TRT] Tactic: 9 Time: 0.409043
[05/21/2022-02:51:56] [V] [TRT] Tactic: 10 Time: 0.777871
[05/21/2022-02:51:56] [V] [TRT] Tactic: 11 Time: 0.579941
[05/21/2022-02:51:56] [V] [TRT] Tactic: 12 Time: 0.55056
[05/21/2022-02:51:56] [V] [TRT] Tactic: 13 Time: 0.457207
[05/21/2022-02:51:56] [V] [TRT] Tactic: 14 Time: 0.422194
[05/21/2022-02:51:56] [V] [TRT] Tactic: 15 Time: 0.432995
[05/21/2022-02:51:56] [V] [TRT] Tactic: 16 Time: 0.403672
[05/21/2022-02:51:56] [V] [TRT] Tactic: 17 Time: 0.354362
[05/21/2022-02:51:56] [V] [TRT] Tactic: 18 Time: 0.353184
[05/21/2022-02:51:56] [V] [TRT] Tactic: 19 Time: 0.382174
[05/21/2022-02:51:56] [V] [TRT] Tactic: 28 Time: 0.560338
[05/21/2022-02:51:56] [V] [TRT] Tactic: 29 Time: 0.764727
[05/21/2022-02:51:56] [V] [TRT] Fastest Tactic: 18 Time: 0.353184
[05/21/2022-02:51:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-02:51:57] [V] [TRT] Tactic: 128 Time: 2.74622
[05/21/2022-02:51:57] [V] [TRT] Tactic: 256 Time: 2.71722
[05/21/2022-02:51:57] [V] [TRT] Tactic: 512 Time: 2.54606
[05/21/2022-02:51:57] [V] [TRT] Tactic: -32 Time: 2.78037
[05/21/2022-02:51:57] [V] [TRT] Tactic: -64 Time: 2.7458
[05/21/2022-02:51:57] [V] [TRT] Tactic: -128 Time: 2.75691
[05/21/2022-02:51:57] [V] [TRT] Fastest Tactic: 512 Time: 2.54606
[05/21/2022-02:51:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:51:57] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:57] [V] [TRT] *************** Autotuning format combination: Float(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:51:57] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:57] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:57] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:51:57] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:57] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:57] [V] [TRT] Tactic: 0 Time: 2.55845
[05/21/2022-02:51:57] [V] [TRT] Tactic: 1 Time: 1.67137
[05/21/2022-02:51:57] [V] [TRT] Tactic: 2 Time: 2.3343
[05/21/2022-02:51:57] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198142976, available: 536870912
[05/21/2022-02:51:57] [V] [TRT] Tactic: 5 Time: 6.87072
[05/21/2022-02:51:57] [V] [TRT] Fastest Tactic: 1 Time: 1.67137
[05/21/2022-02:51:57] [V] [TRT] Setting workspace to 2198142976enables more tactics for profiling
[05/21/2022-02:51:57] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:57] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:57] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:51:57] [V] [TRT] Tactic: 1062367460111450758 Time: 1.51448
[05/21/2022-02:51:57] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:51:57] [V] [TRT] Tactic: 1698681053543049347 Time: 1.41112
[05/21/2022-02:51:57] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:51:57] [V] [TRT] Tactic: 4501471010995462441 Time: 1.1315
[05/21/2022-02:51:57] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:51:57] [V] [TRT] Tactic: 5137655947464784826 Time: 1.08122
[05/21/2022-02:51:57] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:51:57] [V] [TRT] Tactic: 5288347012147084929 Time: 1.14483
[05/21/2022-02:51:57] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:51:58] [V] [TRT] Tactic: 5326823351883942011 Time: 1.12535
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:51:58] [V] [TRT] Tactic: 5500448035057547314 Time: 1.21775
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:51:58] [V] [TRT] Tactic: 6645123197870846056 Time: 1.11482
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:51:58] [V] [TRT] Tactic: 7144526460361122478 Time: 1.55558
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:51:58] [V] [TRT] Tactic: -8262349710178828730 Time: 1.14011
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:51:58] [V] [TRT] Tactic: -6576203419454146580 Time: 1.36365
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:51:58] [V] [TRT] Tactic: -4787320710726427159 Time: 1.62512
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:51:58] [V] [TRT] Tactic: -3456450830548107839 Time: 1.45369
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:51:58] [V] [TRT] Tactic: -1218658103698133241 Time: 1.29384
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:51:58] [V] [TRT] Tactic: -836875257600482091 Time: 1.23671
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:51:58] [V] [TRT] Tactic: -410470605513481746 Time: 1.11325
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:51:58] [V] [TRT] Tactic: -377491875521947884 Time: 1.1085
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:51:58] [V] [TRT] Tactic: -37215280111360163 Time: 1.07409
[05/21/2022-02:51:58] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 1.07409
[05/21/2022-02:51:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-02:51:58] [V] [TRT] *************** Autotuning format combination: Float(663552,1,9216,128) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:51:58] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:58] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:58] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:58] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:51:58] [V] [TRT] Tactic: 3886731678879822788 Time: 1.21544
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:51:58] [V] [TRT] Tactic: 6629944304117643200 Time: 2.63495
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:51:58] [V] [TRT] Tactic: -9153228964338181824 Time: 2.71259
[05/21/2022-02:51:58] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:51:58] [V] [TRT] Tactic: -7394439838318485025 Time: 1.20018
[05/21/2022-02:51:58] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.20018
[05/21/2022-02:51:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:51:58] [V] [TRT] *************** Autotuning format combination: Half(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:51:58] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:58] [V] [TRT] Tactic: 0 Time: 2.19787
[05/21/2022-02:51:58] [V] [TRT] Tactic: 1 Time: 1.61104
[05/21/2022-02:51:58] [V] [TRT] Tactic: 2 Time: 2.24311
[05/21/2022-02:51:58] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198142976, available: 536870912
[05/21/2022-02:51:59] [V] [TRT] Tactic: 5 Time: 6.71457
[05/21/2022-02:51:59] [V] [TRT] Fastest Tactic: 1 Time: 1.61104
[05/21/2022-02:51:59] [V] [TRT] Setting workspace to 2198142976enables more tactics for profiling
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:59] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:59] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:51:59] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:59] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:59] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:51:59] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-02:51:59] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-02:51:59] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:51:59] [V] [TRT] Tactic: 3066127711859985668 Time: 0.753203
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:51:59] [V] [TRT] Tactic: 3564772625446233998 Time: 0.805228
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:51:59] [V] [TRT] Tactic: 5319956359050645452 Time: 0.767851
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:51:59] [V] [TRT] Tactic: 7205456024582378848 Time: 0.602995
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:51:59] [V] [TRT] Tactic: 8163473458334948789 Time: 0.580801
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:51:59] [V] [TRT] Tactic: -4212163711445252890 Time: 0.588952
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:51:59] [V] [TRT] Tactic: -3898373634979201110 Time: 0.603216
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:51:59] [V] [TRT] Tactic: -2409163523992614473 Time: 0.584876
[05/21/2022-02:51:59] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:51:59] [V] [TRT] Tactic: -1716393687483585322 Time: 0.5861
[05/21/2022-02:51:59] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 0.580801
[05/21/2022-02:51:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-02:51:59] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:51:59] [V] [TRT] *************** Autotuning format combination: Float(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:59] [V] [TRT] Tactic: 0 Time: 0.464538
[05/21/2022-02:51:59] [V] [TRT] Tactic: 1 Time: 0.325117
[05/21/2022-02:51:59] [V] [TRT] Tactic: 2 Time: 0.307155
[05/21/2022-02:51:59] [V] [TRT] Tactic: 3 Time: 0.245951
[05/21/2022-02:51:59] [V] [TRT] Tactic: 4 Time: 0.229355
[05/21/2022-02:51:59] [V] [TRT] Tactic: 5 Time: 0.226393
[05/21/2022-02:51:59] [V] [TRT] Tactic: 6 Time: 0.216107
[05/21/2022-02:51:59] [V] [TRT] Tactic: 7 Time: 0.184577
[05/21/2022-02:51:59] [V] [TRT] Tactic: 8 Time: 0.182389
[05/21/2022-02:51:59] [V] [TRT] Tactic: 9 Time: 0.18834
[05/21/2022-02:51:59] [V] [TRT] Tactic: 28 Time: 0.459707
[05/21/2022-02:51:59] [V] [TRT] Fastest Tactic: 8 Time: 0.182389
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-02:51:59] [V] [TRT] Tactic: 128 Time: 1.50825
[05/21/2022-02:51:59] [V] [TRT] Tactic: 256 Time: 1.50822
[05/21/2022-02:51:59] [V] [TRT] Tactic: 512 Time: 1.51001
[05/21/2022-02:51:59] [V] [TRT] Tactic: -32 Time: 1.42668
[05/21/2022-02:51:59] [V] [TRT] Tactic: -64 Time: 1.40471
[05/21/2022-02:51:59] [V] [TRT] Tactic: -128 Time: 1.41615
[05/21/2022-02:51:59] [V] [TRT] Fastest Tactic: -64 Time: 1.40471
[05/21/2022-02:51:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:51:59] [V] [TRT] *************** Autotuning format combination: Float(663552,1,9216,128) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-02:51:59] [V] [TRT] Tactic: 0 Time: 0.464609
[05/21/2022-02:51:59] [V] [TRT] Tactic: 1 Time: 0.325514
[05/21/2022-02:51:59] [V] [TRT] Tactic: 2 Time: 0.307741
[05/21/2022-02:51:59] [V] [TRT] Tactic: 3 Time: 0.388685
[05/21/2022-02:51:59] [V] [TRT] Tactic: 4 Time: 0.360976
[05/21/2022-02:51:59] [V] [TRT] Tactic: 5 Time: 0.328203
[05/21/2022-02:51:59] [V] [TRT] Tactic: 6 Time: 0.528503
[05/21/2022-02:51:59] [V] [TRT] Tactic: 7 Time: 0.440397
[05/21/2022-02:51:59] [V] [TRT] Tactic: 8 Time: 0.430338
[05/21/2022-02:51:59] [V] [TRT] Tactic: 9 Time: 0.378014
[05/21/2022-02:51:59] [V] [TRT] Tactic: 28 Time: 0.459961
[05/21/2022-02:51:59] [V] [TRT] Fastest Tactic: 2 Time: 0.307741
[05/21/2022-02:51:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-02:51:59] [V] [TRT] Tactic: 128 Time: 1.50867
[05/21/2022-02:52:00] [V] [TRT] Tactic: 256 Time: 1.5087
[05/21/2022-02:52:00] [V] [TRT] Tactic: 512 Time: 1.51067
[05/21/2022-02:52:00] [V] [TRT] Tactic: -32 Time: 1.52579
[05/21/2022-02:52:00] [V] [TRT] Tactic: -64 Time: 1.66774
[05/21/2022-02:52:00] [V] [TRT] Tactic: -128 Time: 1.66525
[05/21/2022-02:52:00] [V] [TRT] Fastest Tactic: 128 Time: 1.50867
[05/21/2022-02:52:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:52:00] [V] [TRT] *************** Autotuning format combination: Float(20736,5184:32,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:52:00] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:00] [V] [TRT] Tactic: 24 Time: 0.26097
[05/21/2022-02:52:00] [V] [TRT] Tactic: 25 Time: 0.231816
[05/21/2022-02:52:00] [V] [TRT] Tactic: 26 Time: 0.227663
[05/21/2022-02:52:00] [V] [TRT] Tactic: 27 Time: 0.227409
[05/21/2022-02:52:00] [V] [TRT] Tactic: 31 Time: 0.258281
[05/21/2022-02:52:00] [V] [TRT] Fastest Tactic: 27 Time: 0.227409
[05/21/2022-02:52:00] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-02:52:00] [V] [TRT] Tactic: 128 Time: 1.509
[05/21/2022-02:52:00] [V] [TRT] Tactic: 256 Time: 1.50866
[05/21/2022-02:52:00] [V] [TRT] Tactic: 512 Time: 1.50969
[05/21/2022-02:52:00] [V] [TRT] Tactic: -32 Time: 1.4284
[05/21/2022-02:52:00] [V] [TRT] Tactic: -64 Time: 1.40583
[05/21/2022-02:52:00] [V] [TRT] Tactic: -128 Time: 1.41624
[05/21/2022-02:52:00] [V] [TRT] Fastest Tactic: -64 Time: 1.40583
[05/21/2022-02:52:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:00] [V] [TRT] *************** Autotuning format combination: Half(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:52:00] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:00] [V] [TRT] Tactic: 0 Time: 0.478105
[05/21/2022-02:52:00] [V] [TRT] Tactic: 1 Time: 0.339082
[05/21/2022-02:52:00] [V] [TRT] Tactic: 2 Time: 0.316712
[05/21/2022-02:52:00] [V] [TRT] Tactic: 3 Time: 0.253229
[05/21/2022-02:52:00] [V] [TRT] Tactic: 4 Time: 0.239382
[05/21/2022-02:52:00] [V] [TRT] Tactic: 5 Time: 0.234336
[05/21/2022-02:52:00] [V] [TRT] Tactic: 6 Time: 0.213958
[05/21/2022-02:52:00] [V] [TRT] Tactic: 7 Time: 0.193001
[05/21/2022-02:52:00] [V] [TRT] Tactic: 8 Time: 0.195111
[05/21/2022-02:52:00] [V] [TRT] Tactic: 9 Time: 0.193568
[05/21/2022-02:52:00] [V] [TRT] Tactic: 28 Time: 0.475566
[05/21/2022-02:52:00] [V] [TRT] Fastest Tactic: 7 Time: 0.193001
[05/21/2022-02:52:00] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-02:52:00] [V] [TRT] Tactic: 128 Time: 1.45175
[05/21/2022-02:52:00] [V] [TRT] Tactic: 256 Time: 1.43858
[05/21/2022-02:52:00] [V] [TRT] Tactic: 512 Time: 1.32643
[05/21/2022-02:52:00] [V] [TRT] Tactic: -32 Time: 1.4318
[05/21/2022-02:52:00] [V] [TRT] Tactic: -64 Time: 1.3979
[05/21/2022-02:52:00] [V] [TRT] Tactic: -128 Time: 1.40841
[05/21/2022-02:52:00] [V] [TRT] Fastest Tactic: 512 Time: 1.32643
[05/21/2022-02:52:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:52:00] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:52:00] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:00] [V] [TRT] Tactic: 0 Time: 0.326068
[05/21/2022-02:52:00] [V] [TRT] Tactic: 1 Time: 0.253014
[05/21/2022-02:52:00] [V] [TRT] Tactic: 2 Time: 0.252461
[05/21/2022-02:52:00] [V] [TRT] Tactic: 3 Time: 0.22526
[05/21/2022-02:52:00] [V] [TRT] Tactic: 4 Time: 0.216608
[05/21/2022-02:52:00] [V] [TRT] Tactic: 5 Time: 0.22123
[05/21/2022-02:52:00] [V] [TRT] Tactic: 6 Time: 0.212064
[05/21/2022-02:52:00] [V] [TRT] Tactic: 7 Time: 0.20668
[05/21/2022-02:52:01] [V] [TRT] Tactic: 8 Time: 0.205365
[05/21/2022-02:52:01] [V] [TRT] Tactic: 9 Time: 0.214388
[05/21/2022-02:52:01] [V] [TRT] Tactic: 10 Time: 0.492865
[05/21/2022-02:52:01] [V] [TRT] Tactic: 11 Time: 0.354642
[05/21/2022-02:52:01] [V] [TRT] Tactic: 12 Time: 0.331654
[05/21/2022-02:52:01] [V] [TRT] Tactic: 13 Time: 0.262741
[05/21/2022-02:52:01] [V] [TRT] Tactic: 14 Time: 0.249082
[05/21/2022-02:52:01] [V] [TRT] Tactic: 15 Time: 0.251087
[05/21/2022-02:52:01] [V] [TRT] Tactic: 16 Time: 0.220391
[05/21/2022-02:52:01] [V] [TRT] Tactic: 17 Time: 0.197747
[05/21/2022-02:52:01] [V] [TRT] Tactic: 18 Time: 0.201113
[05/21/2022-02:52:01] [V] [TRT] Tactic: 19 Time: 0.209531
[05/21/2022-02:52:01] [V] [TRT] Tactic: 28 Time: 0.320638
[05/21/2022-02:52:01] [V] [TRT] Tactic: 29 Time: 0.494909
[05/21/2022-02:52:01] [V] [TRT] Fastest Tactic: 17 Time: 0.197747
[05/21/2022-02:52:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-02:52:01] [V] [TRT] Tactic: 128 Time: 1.45192
[05/21/2022-02:52:01] [V] [TRT] Tactic: 256 Time: 1.4389
[05/21/2022-02:52:01] [V] [TRT] Tactic: 512 Time: 1.32721
[05/21/2022-02:52:01] [V] [TRT] Tactic: -32 Time: 1.4344
[05/21/2022-02:52:01] [V] [TRT] Tactic: -64 Time: 1.39594
[05/21/2022-02:52:01] [V] [TRT] Tactic: -128 Time: 1.4099
[05/21/2022-02:52:01] [V] [TRT] Fastest Tactic: 512 Time: 1.32721
[05/21/2022-02:52:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:01] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:01] [V] [TRT] *************** Autotuning format combination: Float(663552,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:01] [V] [TRT] Tactic: 0 Time: 0.465169
[05/21/2022-02:52:01] [V] [TRT] Tactic: 1 Time: 0.325234
[05/21/2022-02:52:01] [V] [TRT] Tactic: 2 Time: 0.307025
[05/21/2022-02:52:01] [V] [TRT] Tactic: 3 Time: 0.247103
[05/21/2022-02:52:01] [V] [TRT] Tactic: 4 Time: 0.229212
[05/21/2022-02:52:01] [V] [TRT] Tactic: 5 Time: 0.226217
[05/21/2022-02:52:01] [V] [TRT] Tactic: 6 Time: 0.217832
[05/21/2022-02:52:01] [V] [TRT] Tactic: 7 Time: 0.185534
[05/21/2022-02:52:01] [V] [TRT] Tactic: 8 Time: 0.182813
[05/21/2022-02:52:01] [V] [TRT] Tactic: 9 Time: 0.187871
[05/21/2022-02:52:01] [V] [TRT] Tactic: 28 Time: 0.459811
[05/21/2022-02:52:01] [V] [TRT] Fastest Tactic: 8 Time: 0.182813
[05/21/2022-02:52:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-02:52:01] [V] [TRT] Tactic: 128 Time: 1.50749
[05/21/2022-02:52:01] [V] [TRT] Tactic: 256 Time: 1.5074
[05/21/2022-02:52:01] [V] [TRT] Tactic: 512 Time: 1.50898
[05/21/2022-02:52:01] [V] [TRT] Tactic: -32 Time: 1.42694
[05/21/2022-02:52:01] [V] [TRT] Tactic: -64 Time: 1.40518
[05/21/2022-02:52:01] [V] [TRT] Tactic: -128 Time: 1.41643
[05/21/2022-02:52:01] [V] [TRT] Fastest Tactic: -64 Time: 1.40518
[05/21/2022-02:52:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:01] [V] [TRT] *************** Autotuning format combination: Float(663552,1,9216,128) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:01] [V] [TRT] Tactic: 0 Time: 0.464915
[05/21/2022-02:52:01] [V] [TRT] Tactic: 1 Time: 0.32511
[05/21/2022-02:52:01] [V] [TRT] Tactic: 2 Time: 0.307617
[05/21/2022-02:52:01] [V] [TRT] Tactic: 3 Time: 0.387565
[05/21/2022-02:52:01] [V] [TRT] Tactic: 4 Time: 0.361217
[05/21/2022-02:52:01] [V] [TRT] Tactic: 5 Time: 0.327611
[05/21/2022-02:52:01] [V] [TRT] Tactic: 6 Time: 0.527734
[05/21/2022-02:52:02] [V] [TRT] Tactic: 7 Time: 0.440052
[05/21/2022-02:52:02] [V] [TRT] Tactic: 8 Time: 0.430299
[05/21/2022-02:52:02] [V] [TRT] Tactic: 9 Time: 0.378444
[05/21/2022-02:52:02] [V] [TRT] Tactic: 28 Time: 0.459876
[05/21/2022-02:52:02] [V] [TRT] Fastest Tactic: 2 Time: 0.307617
[05/21/2022-02:52:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-02:52:02] [V] [TRT] Tactic: 128 Time: 1.50908
[05/21/2022-02:52:02] [V] [TRT] Tactic: 256 Time: 1.50898
[05/21/2022-02:52:02] [V] [TRT] Tactic: 512 Time: 1.50985
[05/21/2022-02:52:02] [V] [TRT] Tactic: -32 Time: 1.52641
[05/21/2022-02:52:02] [V] [TRT] Tactic: -64 Time: 1.66855
[05/21/2022-02:52:02] [V] [TRT] Tactic: -128 Time: 1.66564
[05/21/2022-02:52:02] [V] [TRT] Fastest Tactic: 256 Time: 1.50898
[05/21/2022-02:52:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:52:02] [V] [TRT] *************** Autotuning format combination: Float(20736,5184:32,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:52:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:02] [V] [TRT] Tactic: 24 Time: 0.25487
[05/21/2022-02:52:02] [V] [TRT] Tactic: 25 Time: 0.231159
[05/21/2022-02:52:02] [V] [TRT] Tactic: 26 Time: 0.227741
[05/21/2022-02:52:02] [V] [TRT] Tactic: 27 Time: 0.225182
[05/21/2022-02:52:02] [V] [TRT] Tactic: 31 Time: 0.256139
[05/21/2022-02:52:02] [V] [TRT] Fastest Tactic: 27 Time: 0.225182
[05/21/2022-02:52:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-02:52:02] [V] [TRT] Tactic: 128 Time: 1.50913
[05/21/2022-02:52:02] [V] [TRT] Tactic: 256 Time: 1.50857
[05/21/2022-02:52:02] [V] [TRT] Tactic: 512 Time: 1.51052
[05/21/2022-02:52:02] [V] [TRT] Tactic: -32 Time: 1.42871
[05/21/2022-02:52:02] [V] [TRT] Tactic: -64 Time: 1.40488
[05/21/2022-02:52:02] [V] [TRT] Tactic: -128 Time: 1.41628
[05/21/2022-02:52:02] [V] [TRT] Fastest Tactic: -64 Time: 1.40488
[05/21/2022-02:52:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:02] [V] [TRT] *************** Autotuning format combination: Half(663552,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:02] [V] [TRT] Tactic: 0 Time: 0.477995
[05/21/2022-02:52:02] [V] [TRT] Tactic: 1 Time: 0.339336
[05/21/2022-02:52:02] [V] [TRT] Tactic: 2 Time: 0.316602
[05/21/2022-02:52:02] [V] [TRT] Tactic: 3 Time: 0.25293
[05/21/2022-02:52:02] [V] [TRT] Tactic: 4 Time: 0.239082
[05/21/2022-02:52:02] [V] [TRT] Tactic: 5 Time: 0.234141
[05/21/2022-02:52:02] [V] [TRT] Tactic: 6 Time: 0.213626
[05/21/2022-02:52:02] [V] [TRT] Tactic: 7 Time: 0.19252
[05/21/2022-02:52:02] [V] [TRT] Tactic: 8 Time: 0.195489
[05/21/2022-02:52:02] [V] [TRT] Tactic: 9 Time: 0.193457
[05/21/2022-02:52:02] [V] [TRT] Tactic: 28 Time: 0.475163
[05/21/2022-02:52:02] [V] [TRT] Fastest Tactic: 7 Time: 0.19252
[05/21/2022-02:52:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-02:52:02] [V] [TRT] Tactic: 128 Time: 1.45421
[05/21/2022-02:52:02] [V] [TRT] Tactic: 256 Time: 1.43986
[05/21/2022-02:52:02] [V] [TRT] Tactic: 512 Time: 1.32681
[05/21/2022-02:52:02] [V] [TRT] Tactic: -32 Time: 1.4324
[05/21/2022-02:52:02] [V] [TRT] Tactic: -64 Time: 1.39643
[05/21/2022-02:52:02] [V] [TRT] Tactic: -128 Time: 1.40839
[05/21/2022-02:52:02] [V] [TRT] Fastest Tactic: 512 Time: 1.32681
[05/21/2022-02:52:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:52:02] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:02] [V] [TRT] Tactic: 0 Time: 0.325807
[05/21/2022-02:52:03] [V] [TRT] Tactic: 1 Time: 0.252532
[05/21/2022-02:52:03] [V] [TRT] Tactic: 2 Time: 0.253014
[05/21/2022-02:52:03] [V] [TRT] Tactic: 3 Time: 0.223477
[05/21/2022-02:52:03] [V] [TRT] Tactic: 4 Time: 0.216706
[05/21/2022-02:52:03] [V] [TRT] Tactic: 5 Time: 0.220833
[05/21/2022-02:52:03] [V] [TRT] Tactic: 6 Time: 0.211856
[05/21/2022-02:52:03] [V] [TRT] Tactic: 7 Time: 0.203197
[05/21/2022-02:52:03] [V] [TRT] Tactic: 8 Time: 0.201302
[05/21/2022-02:52:03] [V] [TRT] Tactic: 9 Time: 0.212318
[05/21/2022-02:52:03] [V] [TRT] Tactic: 10 Time: 0.491947
[05/21/2022-02:52:03] [V] [TRT] Tactic: 11 Time: 0.354199
[05/21/2022-02:52:03] [V] [TRT] Tactic: 12 Time: 0.331888
[05/21/2022-02:52:03] [V] [TRT] Tactic: 13 Time: 0.262643
[05/21/2022-02:52:03] [V] [TRT] Tactic: 14 Time: 0.248971
[05/21/2022-02:52:03] [V] [TRT] Tactic: 15 Time: 0.251523
[05/21/2022-02:52:03] [V] [TRT] Tactic: 16 Time: 0.220534
[05/21/2022-02:52:03] [V] [TRT] Tactic: 17 Time: 0.197318
[05/21/2022-02:52:03] [V] [TRT] Tactic: 18 Time: 0.200898
[05/21/2022-02:52:03] [V] [TRT] Tactic: 19 Time: 0.209056
[05/21/2022-02:52:03] [V] [TRT] Tactic: 28 Time: 0.320553
[05/21/2022-02:52:03] [V] [TRT] Tactic: 29 Time: 0.494466
[05/21/2022-02:52:03] [V] [TRT] Fastest Tactic: 17 Time: 0.197318
[05/21/2022-02:52:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-02:52:03] [V] [TRT] Tactic: 128 Time: 1.45325
[05/21/2022-02:52:03] [V] [TRT] Tactic: 256 Time: 1.43634
[05/21/2022-02:52:03] [V] [TRT] Tactic: 512 Time: 1.32857
[05/21/2022-02:52:03] [V] [TRT] Tactic: -32 Time: 1.4313
[05/21/2022-02:52:03] [V] [TRT] Tactic: -64 Time: 1.39868
[05/21/2022-02:52:03] [V] [TRT] Tactic: -128 Time: 1.40916
[05/21/2022-02:52:03] [V] [TRT] Fastest Tactic: 512 Time: 1.32857
[05/21/2022-02:52:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:03] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:03] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:03] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:03] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:03] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:03] [V] [TRT] Tactic: 0 Time: 0.758405
[05/21/2022-02:52:03] [V] [TRT] Tactic: 1 Time: 0.521387
[05/21/2022-02:52:03] [V] [TRT] Tactic: 2 Time: 1.1762
[05/21/2022-02:52:03] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553795584, available: 536870912
[05/21/2022-02:52:03] [V] [TRT] Tactic: 5 Time: 2.40701
[05/21/2022-02:52:03] [V] [TRT] Fastest Tactic: 1 Time: 0.521387
[05/21/2022-02:52:03] [V] [TRT] Setting workspace to 553795584enables more tactics for profiling
[05/21/2022-02:52:03] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:03] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:03] [V] [TRT] Tactic: 1062367460111450758 Time: 0.461368
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:52:03] [V] [TRT] Tactic: 1698681053543049347 Time: 0.414245
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:03] [V] [TRT] Tactic: 4501471010995462441 Time: 0.656992
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:03] [V] [TRT] Tactic: 5137655947464784826 Time: 0.334017
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:03] [V] [TRT] Tactic: 5288347012147084929 Time: 0.681556
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:52:03] [V] [TRT] Tactic: 5326823351883942011 Time: 0.637428
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:52:03] [V] [TRT] Tactic: 5500448035057547314 Time: 0.370032
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:03] [V] [TRT] Tactic: 6645123197870846056 Time: 0.346152
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:03] [V] [TRT] Tactic: 7144526460361122478 Time: 0.467696
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:03] [V] [TRT] Tactic: -8262349710178828730 Time: 0.692142
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:52:03] [V] [TRT] Tactic: -6576203419454146580 Time: 0.425026
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:03] [V] [TRT] Tactic: -4787320710726427159 Time: 0.480469
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:03] [V] [TRT] Tactic: -3456450830548107839 Time: 0.436321
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:03] [V] [TRT] Tactic: -1218658103698133241 Time: 0.39015
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:03] [V] [TRT] Tactic: -836875257600482091 Time: 0.372858
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:03] [V] [TRT] Tactic: -410470605513481746 Time: 0.657396
[05/21/2022-02:52:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:52:04] [V] [TRT] Tactic: -377491875521947884 Time: 0.665052
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:52:04] [V] [TRT] Tactic: -37215280111360163 Time: 0.331081
[05/21/2022-02:52:04] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.331081
[05/21/2022-02:52:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-02:52:04] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:04] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:52:04] [V] [TRT] Tactic: 3886731678879822788 Time: 0.395957
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:52:04] [V] [TRT] Tactic: 6629944304117643200 Time: 0.99472
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:04] [V] [TRT] Tactic: -9153228964338181824 Time: 1.00038
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:04] [V] [TRT] Tactic: -7394439838318485025 Time: 0.396654
[05/21/2022-02:52:04] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.395957
[05/21/2022-02:52:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:52:04] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:04] [V] [TRT] Tactic: 0 Time: 0.739238
[05/21/2022-02:52:04] [V] [TRT] Tactic: 1 Time: 0.639961
[05/21/2022-02:52:04] [V] [TRT] Tactic: 2 Time: 1.11262
[05/21/2022-02:52:04] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553795584, available: 536870912
[05/21/2022-02:52:04] [V] [TRT] Tactic: 5 Time: 2.34397
[05/21/2022-02:52:04] [V] [TRT] Fastest Tactic: 1 Time: 0.639961
[05/21/2022-02:52:04] [V] [TRT] Setting workspace to 553795584enables more tactics for profiling
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:52:04] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:04] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:04] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:04] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:52:04] [V] [TRT] Tactic: 3066127711859985668 Time: 0.246348
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:04] [V] [TRT] Tactic: 3564772625446233998 Time: 0.262435
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:04] [V] [TRT] Tactic: 5319956359050645452 Time: 0.252695
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:04] [V] [TRT] Tactic: 7205456024582378848 Time: 0.200742
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:52:04] [V] [TRT] Tactic: 8163473458334948789 Time: 0.19239
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:04] [V] [TRT] Tactic: -4212163711445252890 Time: 0.373463
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:04] [V] [TRT] Tactic: -3898373634979201110 Time: 0.382767
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:04] [V] [TRT] Tactic: -2409163523992614473 Time: 0.196908
[05/21/2022-02:52:04] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:52:04] [V] [TRT] Tactic: -1716393687483585322 Time: 0.374238
[05/21/2022-02:52:04] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 0.19239
[05/21/2022-02:52:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-02:52:04] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:04] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:04] [V] [TRT] Tactic: 0 Time: 0.366569
[05/21/2022-02:52:04] [V] [TRT] Tactic: 1 Time: 0.273314
[05/21/2022-02:52:04] [V] [TRT] Tactic: 2 Time: 0.258919
[05/21/2022-02:52:04] [V] [TRT] Tactic: 3 Time: 0.227995
[05/21/2022-02:52:04] [V] [TRT] Tactic: 4 Time: 0.195964
[05/21/2022-02:52:04] [V] [TRT] Tactic: 5 Time: 0.201901
[05/21/2022-02:52:04] [V] [TRT] Tactic: 6 Time: 0.208874
[05/21/2022-02:52:04] [V] [TRT] Tactic: 7 Time: 0.170085
[05/21/2022-02:52:04] [V] [TRT] Tactic: 8 Time: 0.162649
[05/21/2022-02:52:04] [V] [TRT] Tactic: 9 Time: 0.174785
[05/21/2022-02:52:04] [V] [TRT] Tactic: 28 Time: 0.361126
[05/21/2022-02:52:04] [V] [TRT] Fastest Tactic: 8 Time: 0.162649
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-02:52:04] [V] [TRT] Tactic: 128 Time: 1.33758
[05/21/2022-02:52:04] [V] [TRT] Tactic: 256 Time: 1.34064
[05/21/2022-02:52:04] [V] [TRT] Tactic: 512 Time: 1.3427
[05/21/2022-02:52:04] [V] [TRT] Tactic: -32 Time: 1.42217
[05/21/2022-02:52:04] [V] [TRT] Tactic: -64 Time: 1.39465
[05/21/2022-02:52:04] [V] [TRT] Tactic: -128 Time: 1.39615
[05/21/2022-02:52:04] [V] [TRT] Fastest Tactic: 128 Time: 1.33758
[05/21/2022-02:52:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:04] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:04] [V] [TRT] Tactic: 0 Time: 0.366986
[05/21/2022-02:52:04] [V] [TRT] Tactic: 1 Time: 0.273763
[05/21/2022-02:52:04] [V] [TRT] Tactic: 2 Time: 0.258841
[05/21/2022-02:52:04] [V] [TRT] Tactic: 3 Time: 0.227852
[05/21/2022-02:52:04] [V] [TRT] Tactic: 4 Time: 0.196231
[05/21/2022-02:52:04] [V] [TRT] Tactic: 5 Time: 0.201875
[05/21/2022-02:52:04] [V] [TRT] Tactic: 6 Time: 0.207344
[05/21/2022-02:52:04] [V] [TRT] Tactic: 7 Time: 0.170273
[05/21/2022-02:52:04] [V] [TRT] Tactic: 8 Time: 0.162415
[05/21/2022-02:52:04] [V] [TRT] Tactic: 9 Time: 0.17403
[05/21/2022-02:52:04] [V] [TRT] Tactic: 28 Time: 0.361087
[05/21/2022-02:52:04] [V] [TRT] Fastest Tactic: 8 Time: 0.162415
[05/21/2022-02:52:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-02:52:04] [V] [TRT] Tactic: 128 Time: 1.3378
[05/21/2022-02:52:04] [V] [TRT] Tactic: 256 Time: 1.34029
[05/21/2022-02:52:04] [V] [TRT] Tactic: 512 Time: 1.34272
[05/21/2022-02:52:05] [V] [TRT] Tactic: -32 Time: 1.42321
[05/21/2022-02:52:05] [V] [TRT] Tactic: -64 Time: 1.39448
[05/21/2022-02:52:05] [V] [TRT] Tactic: -128 Time: 1.39692
[05/21/2022-02:52:05] [V] [TRT] Fastest Tactic: 128 Time: 1.3378
[05/21/2022-02:52:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:05] [V] [TRT] *************** Autotuning format combination: Float(10368,5184:32,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:52:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:05] [V] [TRT] Tactic: 24 Time: 0.252435
[05/21/2022-02:52:05] [V] [TRT] Tactic: 25 Time: 0.230508
[05/21/2022-02:52:05] [V] [TRT] Tactic: 26 Time: 0.226055
[05/21/2022-02:52:05] [V] [TRT] Tactic: 27 Time: 0.223939
[05/21/2022-02:52:05] [V] [TRT] Tactic: 31 Time: 0.251484
[05/21/2022-02:52:05] [V] [TRT] Fastest Tactic: 27 Time: 0.223939
[05/21/2022-02:52:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-02:52:05] [V] [TRT] Tactic: 128 Time: 1.33775
[05/21/2022-02:52:05] [V] [TRT] Tactic: 256 Time: 1.33982
[05/21/2022-02:52:05] [V] [TRT] Tactic: 512 Time: 1.34225
[05/21/2022-02:52:05] [V] [TRT] Tactic: -32 Time: 1.42268
[05/21/2022-02:52:05] [V] [TRT] Tactic: -64 Time: 1.39396
[05/21/2022-02:52:05] [V] [TRT] Tactic: -128 Time: 1.39543
[05/21/2022-02:52:05] [V] [TRT] Fastest Tactic: 128 Time: 1.33775
[05/21/2022-02:52:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:05] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:05] [V] [TRT] Tactic: 0 Time: 0.373346
[05/21/2022-02:52:05] [V] [TRT] Tactic: 1 Time: 0.284811
[05/21/2022-02:52:05] [V] [TRT] Tactic: 2 Time: 0.264622
[05/21/2022-02:52:05] [V] [TRT] Tactic: 3 Time: 0.227721
[05/21/2022-02:52:05] [V] [TRT] Tactic: 4 Time: 0.208027
[05/21/2022-02:52:05] [V] [TRT] Tactic: 5 Time: 0.211673
[05/21/2022-02:52:05] [V] [TRT] Tactic: 6 Time: 0.204082
[05/21/2022-02:52:05] [V] [TRT] Tactic: 7 Time: 0.178385
[05/21/2022-02:52:05] [V] [TRT] Tactic: 8 Time: 0.178451
[05/21/2022-02:52:05] [V] [TRT] Tactic: 9 Time: 0.183255
[05/21/2022-02:52:05] [V] [TRT] Tactic: 28 Time: 0.374486
[05/21/2022-02:52:05] [V] [TRT] Fastest Tactic: 7 Time: 0.178385
[05/21/2022-02:52:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-02:52:05] [V] [TRT] Tactic: 128 Time: 1.37744
[05/21/2022-02:52:05] [V] [TRT] Tactic: 256 Time: 1.36574
[05/21/2022-02:52:05] [V] [TRT] Tactic: 512 Time: 1.27546
[05/21/2022-02:52:05] [V] [TRT] Tactic: -32 Time: 1.42512
[05/21/2022-02:52:05] [V] [TRT] Tactic: -64 Time: 1.3841
[05/21/2022-02:52:05] [V] [TRT] Tactic: -128 Time: 1.38405
[05/21/2022-02:52:05] [V] [TRT] Fastest Tactic: 512 Time: 1.27546
[05/21/2022-02:52:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:52:05] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:05] [V] [TRT] Tactic: 0 Time: 0.288041
[05/21/2022-02:52:05] [V] [TRT] Tactic: 1 Time: 0.235482
[05/21/2022-02:52:05] [V] [TRT] Tactic: 2 Time: 0.235807
[05/21/2022-02:52:05] [V] [TRT] Tactic: 3 Time: 0.215683
[05/21/2022-02:52:05] [V] [TRT] Tactic: 4 Time: 0.209623
[05/21/2022-02:52:05] [V] [TRT] Tactic: 5 Time: 0.21291
[05/21/2022-02:52:05] [V] [TRT] Tactic: 6 Time: 0.208086
[05/21/2022-02:52:05] [V] [TRT] Tactic: 7 Time: 0.200078
[05/21/2022-02:52:05] [V] [TRT] Tactic: 8 Time: 0.197409
[05/21/2022-02:52:05] [V] [TRT] Tactic: 9 Time: 0.207839
[05/21/2022-02:52:05] [V] [TRT] Tactic: 10 Time: 0.39321
[05/21/2022-02:52:05] [V] [TRT] Tactic: 11 Time: 0.294642
[05/21/2022-02:52:05] [V] [TRT] Tactic: 12 Time: 0.279889
[05/21/2022-02:52:05] [V] [TRT] Tactic: 13 Time: 0.233119
[05/21/2022-02:52:05] [V] [TRT] Tactic: 14 Time: 0.215397
[05/21/2022-02:52:05] [V] [TRT] Tactic: 15 Time: 0.221198
[05/21/2022-02:52:05] [V] [TRT] Tactic: 16 Time: 0.206569
[05/21/2022-02:52:05] [V] [TRT] Tactic: 17 Time: 0.182402
[05/21/2022-02:52:06] [V] [TRT] Tactic: 18 Time: 0.181673
[05/21/2022-02:52:06] [V] [TRT] Tactic: 19 Time: 0.195612
[05/21/2022-02:52:06] [V] [TRT] Tactic: 28 Time: 0.282422
[05/21/2022-02:52:06] [V] [TRT] Tactic: 29 Time: 0.386875
[05/21/2022-02:52:06] [V] [TRT] Fastest Tactic: 18 Time: 0.181673
[05/21/2022-02:52:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-02:52:06] [V] [TRT] Tactic: 128 Time: 1.37882
[05/21/2022-02:52:06] [V] [TRT] Tactic: 256 Time: 1.36449
[05/21/2022-02:52:06] [V] [TRT] Tactic: 512 Time: 1.27213
[05/21/2022-02:52:06] [V] [TRT] Tactic: -32 Time: 1.42562
[05/21/2022-02:52:06] [V] [TRT] Tactic: -64 Time: 1.38305
[05/21/2022-02:52:06] [V] [TRT] Tactic: -128 Time: 1.38433
[05/21/2022-02:52:06] [V] [TRT] Fastest Tactic: 512 Time: 1.27213
[05/21/2022-02:52:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:52:06] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:06] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:06] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:06] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:06] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:06] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:06] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:06] [V] [TRT] Tactic: 0 Time: 6.80755
[05/21/2022-02:52:06] [V] [TRT] Tactic: 1 Time: 2.65458
[05/21/2022-02:52:06] [V] [TRT] Tactic: 2 Time: 7.01724
[05/21/2022-02:52:06] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553926656, available: 536870912
[05/21/2022-02:52:07] [V] [TRT] Tactic: 5 Time: 24.6787
[05/21/2022-02:52:07] [V] [TRT] Tactic: 6 Time: 1.84701
[05/21/2022-02:52:07] [V] [TRT] Fastest Tactic: 6 Time: 1.84701
[05/21/2022-02:52:07] [V] [TRT] Setting workspace to 553926656enables more tactics for profiling
[05/21/2022-02:52:07] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:07] [V] [TRT] Tactic: 1062367460111450758 Time: 2.52654
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:52:07] [V] [TRT] Tactic: 1754984623894446479 Time: 2.81611
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:52:07] [V] [TRT] Tactic: 3611739942397549984 Time: 4.12585
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:52:07] [V] [TRT] Tactic: 3827454225649558724 Time: 2.38301
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:52:07] [V] [TRT] Tactic: 4337000649858996379 Time: 2.11976
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:07] [V] [TRT] Tactic: 4501471010995462441 Time: 4.12684
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:07] [V] [TRT] Tactic: 5137655947464784826 Time: 2.11141
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:07] [V] [TRT] Tactic: 5288347012147084929 Time: 3.99973
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:52:07] [V] [TRT] Tactic: 5921334924264294896 Time: 1.64632
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:07] [V] [TRT] Tactic: 6645123197870846056 Time: 2.08284
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:07] [V] [TRT] Tactic: 7144526460361122478 Time: 2.60872
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:52:07] [V] [TRT] Tactic: 7852627285308570038 Time: 2.33374
[05/21/2022-02:52:07] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:52:08] [V] [TRT] Tactic: -9137461792520977713 Time: 4.14319
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:52:08] [V] [TRT] Tactic: -8776506421218919509 Time: 2.33464
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:08] [V] [TRT] Tactic: -8262349710178828730 Time: 4.14915
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:52:08] [V] [TRT] Tactic: -8133971918129952780 Time: 2.30395
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:52:08] [V] [TRT] Tactic: -6092040395344634144 Time: 2.66746
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:08] [V] [TRT] Tactic: -4787320710726427159 Time: 2.86255
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:08] [V] [TRT] Tactic: -3456450830548107839 Time: 2.34917
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:52:08] [V] [TRT] Tactic: -2318106587342035239 Time: 2.41382
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:52:08] [V] [TRT] Tactic: -1343271414618805657 Time: 1.49816
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:08] [V] [TRT] Tactic: -1218658103698133241 Time: 2.26891
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:08] [V] [TRT] Tactic: -836875257600482091 Time: 2.18458
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:08] [V] [TRT] Tactic: -410470605513481746 Time: 4.04527
[05/21/2022-02:52:08] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 1.49816
[05/21/2022-02:52:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-02:52:08] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:08] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:08] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:08] [V] [TRT] Tactic: -9153228964338181824 Time: 2.83193
[05/21/2022-02:52:08] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:08] [V] [TRT] Tactic: -7394439838318485025 Time: 2.01143
[05/21/2022-02:52:08] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.01143
[05/21/2022-02:52:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:08] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:08] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:08] [V] [TRT] Tactic: 0 Time: 4.96646
[05/21/2022-02:52:09] [V] [TRT] Tactic: 1 Time: 4.92979
[05/21/2022-02:52:09] [V] [TRT] Tactic: 2 Time: 6.70708
[05/21/2022-02:52:09] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553926656, available: 536870912
[05/21/2022-02:52:09] [V] [TRT] Tactic: 5 Time: 24.6022
[05/21/2022-02:52:09] [V] [TRT] Tactic: 6 Time: 2.8769
[05/21/2022-02:52:09] [V] [TRT] Fastest Tactic: 6 Time: 2.8769
[05/21/2022-02:52:09] [V] [TRT] Setting workspace to 553926656enables more tactics for profiling
[05/21/2022-02:52:09] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:09] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-02:52:09] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:09] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:09] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:09] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:09] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:09] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:09] [V] [TRT] Tactic: 3564772625446233998 Time: 1.32085
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:52:09] [V] [TRT] Tactic: 3650389455493082349 Time: 1.3743
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:52:09] [V] [TRT] Tactic: 4772821744921268633 Time: 0.82349
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:09] [V] [TRT] Tactic: 5319956359050645452 Time: 1.21021
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:09] [V] [TRT] Tactic: 7205456024582378848 Time: 1.05781
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:52:09] [V] [TRT] Tactic: -6490690591794140522 Time: 1.07796
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:52:09] [V] [TRT] Tactic: -4686027666808657977 Time: 2.11149
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:09] [V] [TRT] Tactic: -4212163711445252890 Time: 2.03535
[05/21/2022-02:52:09] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:10] [V] [TRT] Tactic: -3898373634979201110 Time: 2.0829
[05/21/2022-02:52:10] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:10] [V] [TRT] Tactic: -2409163523992614473 Time: 1.03187
[05/21/2022-02:52:10] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.82349
[05/21/2022-02:52:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-02:52:10] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:10] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1), Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-02:52:10] [V] [TRT] Tactic: 0 Time: 0.388106
[05/21/2022-02:52:10] [V] [TRT] Tactic: 1 Time: 0.293255
[05/21/2022-02:52:10] [V] [TRT] Tactic: 2 Time: 0.289779
[05/21/2022-02:52:10] [V] [TRT] Tactic: 3 Time: 0.254564
[05/21/2022-02:52:10] [V] [TRT] Tactic: 4 Time: 0.228099
[05/21/2022-02:52:10] [V] [TRT] Tactic: 5 Time: 0.219291
[05/21/2022-02:52:10] [V] [TRT] Tactic: 6 Time: 0.248079
[05/21/2022-02:52:10] [V] [TRT] Tactic: 7 Time: 0.206934
[05/21/2022-02:52:10] [V] [TRT] Tactic: 8 Time: 0.205722
[05/21/2022-02:52:10] [V] [TRT] Tactic: 9 Time: 0.212318
[05/21/2022-02:52:10] [V] [TRT] Tactic: 28 Time: 0.384948
[05/21/2022-02:52:10] [V] [TRT] Fastest Tactic: 8 Time: 0.205722
[05/21/2022-02:52:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-02:52:10] [V] [TRT] Tactic: 128 Time: 1.54803
[05/21/2022-02:52:10] [V] [TRT] Tactic: 256 Time: 1.54943
[05/21/2022-02:52:10] [V] [TRT] Tactic: 512 Time: 1.55233
[05/21/2022-02:52:10] [V] [TRT] Tactic: -32 Time: 1.66351
[05/21/2022-02:52:10] [V] [TRT] Tactic: -64 Time: 1.62335
[05/21/2022-02:52:10] [V] [TRT] Tactic: -128 Time: 1.62557
[05/21/2022-02:52:10] [V] [TRT] Fastest Tactic: 128 Time: 1.54803
[05/21/2022-02:52:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:10] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64), Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-02:52:10] [V] [TRT] Tactic: 0 Time: 0.388359
[05/21/2022-02:52:10] [V] [TRT] Tactic: 1 Time: 0.292845
[05/21/2022-02:52:10] [V] [TRT] Tactic: 2 Time: 0.290638
[05/21/2022-02:52:10] [V] [TRT] Tactic: 3 Time: 0.254609
[05/21/2022-02:52:10] [V] [TRT] Tactic: 4 Time: 0.228685
[05/21/2022-02:52:10] [V] [TRT] Tactic: 5 Time: 0.219167
[05/21/2022-02:52:10] [V] [TRT] Tactic: 6 Time: 0.246419
[05/21/2022-02:52:10] [V] [TRT] Tactic: 7 Time: 0.208887
[05/21/2022-02:52:10] [V] [TRT] Tactic: 8 Time: 0.204837
[05/21/2022-02:52:10] [V] [TRT] Tactic: 9 Time: 0.211022
[05/21/2022-02:52:10] [V] [TRT] Tactic: 28 Time: 0.385058
[05/21/2022-02:52:10] [V] [TRT] Fastest Tactic: 8 Time: 0.204837
[05/21/2022-02:52:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-02:52:10] [V] [TRT] Tactic: 128 Time: 1.54691
[05/21/2022-02:52:10] [V] [TRT] Tactic: 256 Time: 1.54971
[05/21/2022-02:52:10] [V] [TRT] Tactic: 512 Time: 1.55272
[05/21/2022-02:52:10] [V] [TRT] Tactic: -32 Time: 1.66549
[05/21/2022-02:52:10] [V] [TRT] Tactic: -64 Time: 1.62419
[05/21/2022-02:52:10] [V] [TRT] Tactic: -128 Time: 1.62495
[05/21/2022-02:52:10] [V] [TRT] Fastest Tactic: 128 Time: 1.54691
[05/21/2022-02:52:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:10] [V] [TRT] *************** Autotuning format combination: Float(10368,5184:32,72,1), Float(10368,5184:32,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:52:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-02:52:10] [V] [TRT] Tactic: 24 Time: 0.359798
[05/21/2022-02:52:10] [V] [TRT] Tactic: 25 Time: 0.308242
[05/21/2022-02:52:10] [V] [TRT] Tactic: 26 Time: 0.310475
[05/21/2022-02:52:10] [V] [TRT] Tactic: 27 Time: 0.303118
[05/21/2022-02:52:10] [V] [TRT] Tactic: 31 Time: 0.359805
[05/21/2022-02:52:10] [V] [TRT] Fastest Tactic: 27 Time: 0.303118
[05/21/2022-02:52:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-02:52:11] [V] [TRT] Tactic: 128 Time: 1.54736
[05/21/2022-02:52:11] [V] [TRT] Tactic: 256 Time: 1.54938
[05/21/2022-02:52:11] [V] [TRT] Tactic: 512 Time: 1.55261
[05/21/2022-02:52:11] [V] [TRT] Tactic: -32 Time: 1.66325
[05/21/2022-02:52:11] [V] [TRT] Tactic: -64 Time: 1.62421
[05/21/2022-02:52:11] [V] [TRT] Tactic: -128 Time: 1.62546
[05/21/2022-02:52:11] [V] [TRT] Fastest Tactic: 128 Time: 1.54736
[05/21/2022-02:52:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:11] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1), Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-02:52:11] [V] [TRT] Tactic: 0 Time: 0.39554
[05/21/2022-02:52:11] [V] [TRT] Tactic: 1 Time: 0.298997
[05/21/2022-02:52:11] [V] [TRT] Tactic: 2 Time: 0.28334
[05/21/2022-02:52:11] [V] [TRT] Tactic: 3 Time: 0.24028
[05/21/2022-02:52:11] [V] [TRT] Tactic: 4 Time: 0.23974
[05/21/2022-02:52:11] [V] [TRT] Tactic: 5 Time: 0.225879
[05/21/2022-02:52:11] [V] [TRT] Tactic: 6 Time: 0.215521
[05/21/2022-02:52:11] [V] [TRT] Tactic: 7 Time: 0.208229
[05/21/2022-02:52:11] [V] [TRT] Tactic: 8 Time: 0.197865
[05/21/2022-02:52:11] [V] [TRT] Tactic: 9 Time: 0.202598
[05/21/2022-02:52:11] [V] [TRT] Tactic: 28 Time: 0.391074
[05/21/2022-02:52:11] [V] [TRT] Fastest Tactic: 8 Time: 0.197865
[05/21/2022-02:52:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-02:52:11] [V] [TRT] Tactic: 128 Time: 1.60434
[05/21/2022-02:52:11] [V] [TRT] Tactic: 256 Time: 1.58956
[05/21/2022-02:52:11] [V] [TRT] Tactic: 512 Time: 1.49738
[05/21/2022-02:52:11] [V] [TRT] Tactic: -32 Time: 1.70344
[05/21/2022-02:52:11] [V] [TRT] Tactic: -64 Time: 1.65544
[05/21/2022-02:52:11] [V] [TRT] Tactic: -128 Time: 1.64262
[05/21/2022-02:52:11] [V] [TRT] Fastest Tactic: 512 Time: 1.49738
[05/21/2022-02:52:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:11] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1), Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-02:52:11] [V] [TRT] Tactic: 0 Time: 0.335032
[05/21/2022-02:52:11] [V] [TRT] Tactic: 1 Time: 0.302396
[05/21/2022-02:52:11] [V] [TRT] Tactic: 2 Time: 0.287305
[05/21/2022-02:52:11] [V] [TRT] Tactic: 3 Time: 0.278971
[05/21/2022-02:52:11] [V] [TRT] Tactic: 4 Time: 0.272174
[05/21/2022-02:52:11] [V] [TRT] Tactic: 5 Time: 0.268366
[05/21/2022-02:52:11] [V] [TRT] Tactic: 6 Time: 0.267904
[05/21/2022-02:52:11] [V] [TRT] Tactic: 7 Time: 0.263008
[05/21/2022-02:52:11] [V] [TRT] Tactic: 8 Time: 0.302077
[05/21/2022-02:52:11] [V] [TRT] Tactic: 9 Time: 0.354466
[05/21/2022-02:52:11] [V] [TRT] Tactic: 10 Time: 0.423281
[05/21/2022-02:52:11] [V] [TRT] Tactic: 11 Time: 0.33179
[05/21/2022-02:52:11] [V] [TRT] Tactic: 12 Time: 0.317109
[05/21/2022-02:52:11] [V] [TRT] Tactic: 13 Time: 0.265241
[05/21/2022-02:52:11] [V] [TRT] Tactic: 14 Time: 0.277298
[05/21/2022-02:52:11] [V] [TRT] Tactic: 15 Time: 0.262083
[05/21/2022-02:52:11] [V] [TRT] Tactic: 16 Time: 0.236282
[05/21/2022-02:52:11] [V] [TRT] Tactic: 17 Time: 0.243405
[05/21/2022-02:52:11] [V] [TRT] Tactic: 18 Time: 0.234961
[05/21/2022-02:52:11] [V] [TRT] Tactic: 19 Time: 0.242012
[05/21/2022-02:52:11] [V] [TRT] Tactic: 28 Time: 0.330807
[05/21/2022-02:52:11] [V] [TRT] Tactic: 29 Time: 0.414785
[05/21/2022-02:52:11] [V] [TRT] Fastest Tactic: 18 Time: 0.234961
[05/21/2022-02:52:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-02:52:11] [V] [TRT] Tactic: 128 Time: 1.60359
[05/21/2022-02:52:12] [V] [TRT] Tactic: 256 Time: 1.58852
[05/21/2022-02:52:12] [V] [TRT] Tactic: 512 Time: 1.49683
[05/21/2022-02:52:12] [V] [TRT] Tactic: -32 Time: 1.70301
[05/21/2022-02:52:12] [V] [TRT] Tactic: -64 Time: 1.64613
[05/21/2022-02:52:12] [V] [TRT] Tactic: -128 Time: 1.64264
[05/21/2022-02:52:12] [V] [TRT] Fastest Tactic: 512 Time: 1.49683
[05/21/2022-02:52:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:52:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(10368,5184:32,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1), Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64), Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(10368,5184:32,72,1), Float(10368,5184:32,72,1) -> Float(10368,5184:32,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1), Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1), Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(331776,1,4608,64) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(331776,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(165888,5184:2,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:52:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:12] [V] [TRT] Tactic: 0 Time: 0.46446
[05/21/2022-02:52:12] [V] [TRT] Tactic: 1 Time: 0.325286
[05/21/2022-02:52:12] [V] [TRT] Tactic: 2 Time: 0.307578
[05/21/2022-02:52:12] [V] [TRT] Tactic: 3 Time: 0.246959
[05/21/2022-02:52:12] [V] [TRT] Tactic: 4 Time: 0.229557
[05/21/2022-02:52:12] [V] [TRT] Tactic: 5 Time: 0.226641
[05/21/2022-02:52:12] [V] [TRT] Tactic: 6 Time: 0.216367
[05/21/2022-02:52:12] [V] [TRT] Tactic: 7 Time: 0.185124
[05/21/2022-02:52:12] [V] [TRT] Tactic: 8 Time: 0.182162
[05/21/2022-02:52:12] [V] [TRT] Tactic: 9 Time: 0.187832
[05/21/2022-02:52:12] [V] [TRT] Tactic: 28 Time: 0.459212
[05/21/2022-02:52:12] [V] [TRT] Fastest Tactic: 8 Time: 0.182162
[05/21/2022-02:52:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-02:52:12] [V] [TRT] Tactic: 128 Time: 1.50776
[05/21/2022-02:52:12] [V] [TRT] Tactic: 256 Time: 1.50822
[05/21/2022-02:52:12] [V] [TRT] Tactic: 512 Time: 1.54031
[05/21/2022-02:52:12] [V] [TRT] Tactic: -32 Time: 1.42984
[05/21/2022-02:52:12] [V] [TRT] Tactic: -64 Time: 1.40463
[05/21/2022-02:52:12] [V] [TRT] Tactic: -128 Time: 1.42072
[05/21/2022-02:52:12] [V] [TRT] Fastest Tactic: -64 Time: 1.40463
[05/21/2022-02:52:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:12] [V] [TRT] *************** Autotuning format combination: Float(331776,1,4608,64) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:52:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:12] [V] [TRT] Tactic: 0 Time: 0.464454
[05/21/2022-02:52:12] [V] [TRT] Tactic: 1 Time: 0.325853
[05/21/2022-02:52:12] [V] [TRT] Tactic: 2 Time: 0.308249
[05/21/2022-02:52:12] [V] [TRT] Tactic: 3 Time: 0.389186
[05/21/2022-02:52:12] [V] [TRT] Tactic: 4 Time: 0.361797
[05/21/2022-02:52:12] [V] [TRT] Tactic: 5 Time: 0.32791
[05/21/2022-02:52:12] [V] [TRT] Tactic: 6 Time: 0.528047
[05/21/2022-02:52:12] [V] [TRT] Tactic: 7 Time: 0.440762
[05/21/2022-02:52:12] [V] [TRT] Tactic: 8 Time: 0.430599
[05/21/2022-02:52:12] [V] [TRT] Tactic: 9 Time: 0.378659
[05/21/2022-02:52:12] [V] [TRT] Tactic: 28 Time: 0.459889
[05/21/2022-02:52:12] [V] [TRT] Fastest Tactic: 2 Time: 0.308249
[05/21/2022-02:52:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-02:52:13] [V] [TRT] Tactic: 128 Time: 1.50762
[05/21/2022-02:52:13] [V] [TRT] Tactic: 256 Time: 1.50823
[05/21/2022-02:52:13] [V] [TRT] Tactic: 512 Time: 1.509
[05/21/2022-02:52:13] [V] [TRT] Tactic: -32 Time: 1.525
[05/21/2022-02:52:13] [V] [TRT] Tactic: -64 Time: 1.66787
[05/21/2022-02:52:13] [V] [TRT] Tactic: -128 Time: 1.66466
[05/21/2022-02:52:13] [V] [TRT] Fastest Tactic: 128 Time: 1.50762
[05/21/2022-02:52:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:52:13] [V] [TRT] *************** Autotuning format combination: Float(10368,5184:32,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:52:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:13] [V] [TRT] Tactic: 24 Time: 0.259655
[05/21/2022-02:52:13] [V] [TRT] Tactic: 25 Time: 0.236602
[05/21/2022-02:52:13] [V] [TRT] Tactic: 26 Time: 0.232617
[05/21/2022-02:52:13] [V] [TRT] Tactic: 27 Time: 0.231237
[05/21/2022-02:52:13] [V] [TRT] Tactic: 31 Time: 0.257643
[05/21/2022-02:52:13] [V] [TRT] Fastest Tactic: 27 Time: 0.231237
[05/21/2022-02:52:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-02:52:13] [V] [TRT] Tactic: 128 Time: 1.50822
[05/21/2022-02:52:13] [V] [TRT] Tactic: 256 Time: 1.50805
[05/21/2022-02:52:13] [V] [TRT] Tactic: 512 Time: 1.50937
[05/21/2022-02:52:13] [V] [TRT] Tactic: -32 Time: 1.42921
[05/21/2022-02:52:13] [V] [TRT] Tactic: -64 Time: 1.40461
[05/21/2022-02:52:13] [V] [TRT] Tactic: -128 Time: 1.41528
[05/21/2022-02:52:13] [V] [TRT] Fastest Tactic: -64 Time: 1.40461
[05/21/2022-02:52:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:13] [V] [TRT] *************** Autotuning format combination: Half(331776,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:52:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:13] [V] [TRT] Tactic: 0 Time: 0.47752
[05/21/2022-02:52:13] [V] [TRT] Tactic: 1 Time: 0.339258
[05/21/2022-02:52:13] [V] [TRT] Tactic: 2 Time: 0.316647
[05/21/2022-02:52:13] [V] [TRT] Tactic: 3 Time: 0.252969
[05/21/2022-02:52:13] [V] [TRT] Tactic: 4 Time: 0.239518
[05/21/2022-02:52:13] [V] [TRT] Tactic: 5 Time: 0.233691
[05/21/2022-02:52:13] [V] [TRT] Tactic: 6 Time: 0.214264
[05/21/2022-02:52:13] [V] [TRT] Tactic: 7 Time: 0.192233
[05/21/2022-02:52:13] [V] [TRT] Tactic: 8 Time: 0.194648
[05/21/2022-02:52:13] [V] [TRT] Tactic: 9 Time: 0.193294
[05/21/2022-02:52:13] [V] [TRT] Tactic: 28 Time: 0.475338
[05/21/2022-02:52:13] [V] [TRT] Fastest Tactic: 7 Time: 0.192233
[05/21/2022-02:52:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-02:52:13] [V] [TRT] Tactic: 128 Time: 1.45368
[05/21/2022-02:52:13] [V] [TRT] Tactic: 256 Time: 1.44107
[05/21/2022-02:52:13] [V] [TRT] Tactic: 512 Time: 1.32745
[05/21/2022-02:52:13] [V] [TRT] Tactic: -32 Time: 1.43123
[05/21/2022-02:52:13] [V] [TRT] Tactic: -64 Time: 1.39734
[05/21/2022-02:52:13] [V] [TRT] Tactic: -128 Time: 1.40854
[05/21/2022-02:52:13] [V] [TRT] Fastest Tactic: 512 Time: 1.32745
[05/21/2022-02:52:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:52:13] [V] [TRT] *************** Autotuning format combination: Half(165888,5184:2,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:52:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:13] [V] [TRT] Tactic: 0 Time: 0.326634
[05/21/2022-02:52:13] [V] [TRT] Tactic: 1 Time: 0.252109
[05/21/2022-02:52:13] [V] [TRT] Tactic: 2 Time: 0.251393
[05/21/2022-02:52:13] [V] [TRT] Tactic: 3 Time: 0.223815
[05/21/2022-02:52:13] [V] [TRT] Tactic: 4 Time: 0.215527
[05/21/2022-02:52:13] [V] [TRT] Tactic: 5 Time: 0.221315
[05/21/2022-02:52:14] [V] [TRT] Tactic: 6 Time: 0.211087
[05/21/2022-02:52:14] [V] [TRT] Tactic: 7 Time: 0.203548
[05/21/2022-02:52:14] [V] [TRT] Tactic: 8 Time: 0.201836
[05/21/2022-02:52:14] [V] [TRT] Tactic: 9 Time: 0.212083
[05/21/2022-02:52:14] [V] [TRT] Tactic: 10 Time: 0.492161
[05/21/2022-02:52:14] [V] [TRT] Tactic: 11 Time: 0.354414
[05/21/2022-02:52:14] [V] [TRT] Tactic: 12 Time: 0.331647
[05/21/2022-02:52:14] [V] [TRT] Tactic: 13 Time: 0.26222
[05/21/2022-02:52:14] [V] [TRT] Tactic: 14 Time: 0.249024
[05/21/2022-02:52:14] [V] [TRT] Tactic: 15 Time: 0.251224
[05/21/2022-02:52:14] [V] [TRT] Tactic: 16 Time: 0.220495
[05/21/2022-02:52:14] [V] [TRT] Tactic: 17 Time: 0.197519
[05/21/2022-02:52:14] [V] [TRT] Tactic: 18 Time: 0.200371
[05/21/2022-02:52:14] [V] [TRT] Tactic: 19 Time: 0.209564
[05/21/2022-02:52:14] [V] [TRT] Tactic: 28 Time: 0.320306
[05/21/2022-02:52:14] [V] [TRT] Tactic: 29 Time: 0.49429
[05/21/2022-02:52:14] [V] [TRT] Fastest Tactic: 17 Time: 0.197519
[05/21/2022-02:52:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-02:52:14] [V] [TRT] Tactic: 128 Time: 1.45241
[05/21/2022-02:52:14] [V] [TRT] Tactic: 256 Time: 1.43729
[05/21/2022-02:52:14] [V] [TRT] Tactic: 512 Time: 1.32597
[05/21/2022-02:52:14] [V] [TRT] Tactic: -32 Time: 1.43202
[05/21/2022-02:52:14] [V] [TRT] Tactic: -64 Time: 1.39575
[05/21/2022-02:52:14] [V] [TRT] Tactic: -128 Time: 1.4084
[05/21/2022-02:52:14] [V] [TRT] Fastest Tactic: 512 Time: 1.32597
[05/21/2022-02:52:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:14] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Float(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Float(663552,1,9216,128) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Half(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Float(663552,5184,72,1) -> Float(663552,5184,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Float(663552,1,9216,128) -> Float(663552,1,9216,128) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Float(20736,5184:32,72,1) -> Float(20736,5184:32,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Half(663552,5184,72,1) -> Half(663552,5184,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(331776,5184:2,72,1) ***************
[05/21/2022-02:52:14] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:14] [V] [TRT] *************** Autotuning format combination: Float(663552,5184,72,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:52:14] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:14] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:14] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:14] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:14] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:14] [V] [TRT] Tactic: 0 Time: 7.94677
[05/21/2022-02:52:14] [V] [TRT] Tactic: 1 Time: 7.82873
[05/21/2022-02:52:14] [V] [TRT] Tactic: 2 Time: 7.22912
[05/21/2022-02:52:17] [V] [TRT] Tactic: 5 Time: 149.044
[05/21/2022-02:52:17] [V] [TRT] Fastest Tactic: 2 Time: 7.22912
[05/21/2022-02:52:17] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:17] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:17] [V] [TRT] Tactic: 1062367460111450758 Time: 5.42053
[05/21/2022-02:52:17] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:52:17] [V] [TRT] Tactic: 1754984623894446479 Time: 6.25773
[05/21/2022-02:52:17] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:52:17] [V] [TRT] Tactic: 3611739942397549984 Time: 4.36658
[05/21/2022-02:52:17] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:52:17] [V] [TRT] Tactic: 4337000649858996379 Time: 4.40733
[05/21/2022-02:52:17] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:18] [V] [TRT] Tactic: 4501471010995462441 Time: 4.34353
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:18] [V] [TRT] Tactic: 5137655947464784826 Time: 4.25615
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:18] [V] [TRT] Tactic: 5288347012147084929 Time: 4.27326
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:18] [V] [TRT] Tactic: 6645123197870846056 Time: 4.42219
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:18] [V] [TRT] Tactic: 7144526460361122478 Time: 5.82283
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:52:18] [V] [TRT] Tactic: -9137461792520977713 Time: 4.35627
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:18] [V] [TRT] Tactic: -8262349710178828730 Time: 4.37344
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:52:18] [V] [TRT] Tactic: -8133971918129952780 Time: 5.1871
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:52:18] [V] [TRT] Tactic: -6092040395344634144 Time: 5.71124
[05/21/2022-02:52:18] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:19] [V] [TRT] Tactic: -4787320710726427159 Time: 6.30127
[05/21/2022-02:52:19] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:19] [V] [TRT] Tactic: -3456450830548107839 Time: 5.17094
[05/21/2022-02:52:19] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:19] [V] [TRT] Tactic: -1218658103698133241 Time: 5.00437
[05/21/2022-02:52:19] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:19] [V] [TRT] Tactic: -836875257600482091 Time: 4.88341
[05/21/2022-02:52:19] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:19] [V] [TRT] Tactic: -410470605513481746 Time: 4.26116
[05/21/2022-02:52:19] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 4.25615
[05/21/2022-02:52:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-02:52:19] [V] [TRT] *************** Autotuning format combination: Float(663552,1,9216,128) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:52:19] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:19] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:19] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:19] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:19] [V] [TRT] Tactic: -9153228964338181824 Time: 6.44271
[05/21/2022-02:52:19] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:19] [V] [TRT] Tactic: -7394439838318485025 Time: 4.34322
[05/21/2022-02:52:19] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.34322
[05/21/2022-02:52:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:19] [V] [TRT] *************** Autotuning format combination: Half(663552,5184,72,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:19] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:19] [V] [TRT] Tactic: 0 Time: 8.07425
[05/21/2022-02:52:19] [V] [TRT] Tactic: 1 Time: 8.12836
[05/21/2022-02:52:20] [V] [TRT] Tactic: 2 Time: 6.87762
[05/21/2022-02:52:22] [V] [TRT] Tactic: 5 Time: 147.779
[05/21/2022-02:52:22] [V] [TRT] Fastest Tactic: 2 Time: 6.87762
[05/21/2022-02:52:22] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:52:22] [V] [TRT] *************** Autotuning format combination: Half(331776,5184:2,72,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:52:22] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:22] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:22] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:22] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:22] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:22] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:22] [V] [TRT] Tactic: 3564772625446233998 Time: 2.70108
[05/21/2022-02:52:22] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:52:22] [V] [TRT] Tactic: 3650389455493082349 Time: 2.84921
[05/21/2022-02:52:22] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:22] [V] [TRT] Tactic: 5319956359050645452 Time: 2.51408
[05/21/2022-02:52:22] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:22] [V] [TRT] Tactic: 7205456024582378848 Time: 2.20467
[05/21/2022-02:52:22] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:52:22] [V] [TRT] Tactic: -6490690591794140522 Time: 2.27716
[05/21/2022-02:52:22] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:52:22] [V] [TRT] Tactic: -4686027666808657977 Time: 2.20859
[05/21/2022-02:52:22] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:23] [V] [TRT] Tactic: -4212163711445252890 Time: 2.13175
[05/21/2022-02:52:23] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:23] [V] [TRT] Tactic: -3898373634979201110 Time: 2.18132
[05/21/2022-02:52:23] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:23] [V] [TRT] Tactic: -2409163523992614473 Time: 2.17004
[05/21/2022-02:52:23] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 2.13175
[05/21/2022-02:52:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:52:23] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:23] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:52:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:23] [V] [TRT] Tactic: 0 Time: 0.368203
[05/21/2022-02:52:23] [V] [TRT] Tactic: 1 Time: 0.273587
[05/21/2022-02:52:23] [V] [TRT] Tactic: 2 Time: 0.266842
[05/21/2022-02:52:23] [V] [TRT] Tactic: 3 Time: 0.228301
[05/21/2022-02:52:23] [V] [TRT] Tactic: 4 Time: 0.196217
[05/21/2022-02:52:23] [V] [TRT] Tactic: 5 Time: 0.203197
[05/21/2022-02:52:23] [V] [TRT] Tactic: 6 Time: 0.21082
[05/21/2022-02:52:23] [V] [TRT] Tactic: 7 Time: 0.171745
[05/21/2022-02:52:23] [V] [TRT] Tactic: 8 Time: 0.162682
[05/21/2022-02:52:23] [V] [TRT] Tactic: 9 Time: 0.174479
[05/21/2022-02:52:23] [V] [TRT] Tactic: 28 Time: 0.361309
[05/21/2022-02:52:23] [V] [TRT] Fastest Tactic: 8 Time: 0.162682
[05/21/2022-02:52:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-02:52:23] [V] [TRT] Tactic: 128 Time: 1.33829
[05/21/2022-02:52:23] [V] [TRT] Tactic: 256 Time: 1.34119
[05/21/2022-02:52:23] [V] [TRT] Tactic: 512 Time: 1.34258
[05/21/2022-02:52:23] [V] [TRT] Tactic: -32 Time: 1.42374
[05/21/2022-02:52:23] [V] [TRT] Tactic: -64 Time: 1.39457
[05/21/2022-02:52:23] [V] [TRT] Tactic: -128 Time: 1.39637
[05/21/2022-02:52:23] [V] [TRT] Fastest Tactic: 128 Time: 1.33829
[05/21/2022-02:52:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:23] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:52:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:23] [V] [TRT] Tactic: 0 Time: 0.367096
[05/21/2022-02:52:23] [V] [TRT] Tactic: 1 Time: 0.273646
[05/21/2022-02:52:23] [V] [TRT] Tactic: 2 Time: 0.259518
[05/21/2022-02:52:23] [V] [TRT] Tactic: 3 Time: 0.227598
[05/21/2022-02:52:23] [V] [TRT] Tactic: 4 Time: 0.196569
[05/21/2022-02:52:23] [V] [TRT] Tactic: 5 Time: 0.20209
[05/21/2022-02:52:23] [V] [TRT] Tactic: 6 Time: 0.208405
[05/21/2022-02:52:23] [V] [TRT] Tactic: 7 Time: 0.170033
[05/21/2022-02:52:23] [V] [TRT] Tactic: 8 Time: 0.162291
[05/21/2022-02:52:23] [V] [TRT] Tactic: 9 Time: 0.174304
[05/21/2022-02:52:23] [V] [TRT] Tactic: 28 Time: 0.361484
[05/21/2022-02:52:23] [V] [TRT] Fastest Tactic: 8 Time: 0.162291
[05/21/2022-02:52:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-02:52:23] [V] [TRT] Tactic: 128 Time: 1.3382
[05/21/2022-02:52:23] [V] [TRT] Tactic: 256 Time: 1.34036
[05/21/2022-02:52:23] [V] [TRT] Tactic: 512 Time: 1.34211
[05/21/2022-02:52:23] [V] [TRT] Tactic: -32 Time: 1.42264
[05/21/2022-02:52:23] [V] [TRT] Tactic: -64 Time: 1.39439
[05/21/2022-02:52:23] [V] [TRT] Tactic: -128 Time: 1.39614
[05/21/2022-02:52:23] [V] [TRT] Fastest Tactic: 128 Time: 1.3382
[05/21/2022-02:52:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:23] [V] [TRT] *************** Autotuning format combination: Float(10368,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:52:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:23] [V] [TRT] Tactic: 24 Time: 0.252643
[05/21/2022-02:52:24] [V] [TRT] Tactic: 25 Time: 0.230567
[05/21/2022-02:52:24] [V] [TRT] Tactic: 26 Time: 0.225026
[05/21/2022-02:52:24] [V] [TRT] Tactic: 27 Time: 0.226524
[05/21/2022-02:52:24] [V] [TRT] Tactic: 31 Time: 0.252956
[05/21/2022-02:52:24] [V] [TRT] Fastest Tactic: 26 Time: 0.225026
[05/21/2022-02:52:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-02:52:24] [V] [TRT] Tactic: 128 Time: 1.33781
[05/21/2022-02:52:24] [V] [TRT] Tactic: 256 Time: 1.34073
[05/21/2022-02:52:24] [V] [TRT] Tactic: 512 Time: 1.34294
[05/21/2022-02:52:24] [V] [TRT] Tactic: -32 Time: 1.4229
[05/21/2022-02:52:24] [V] [TRT] Tactic: -64 Time: 1.39404
[05/21/2022-02:52:24] [V] [TRT] Tactic: -128 Time: 1.39642
[05/21/2022-02:52:24] [V] [TRT] Fastest Tactic: 128 Time: 1.33781
[05/21/2022-02:52:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:52:24] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:24] [V] [TRT] Tactic: 0 Time: 0.374212
[05/21/2022-02:52:24] [V] [TRT] Tactic: 1 Time: 0.284616
[05/21/2022-02:52:24] [V] [TRT] Tactic: 2 Time: 0.264961
[05/21/2022-02:52:24] [V] [TRT] Tactic: 3 Time: 0.230124
[05/21/2022-02:52:24] [V] [TRT] Tactic: 4 Time: 0.207715
[05/21/2022-02:52:24] [V] [TRT] Tactic: 5 Time: 0.212513
[05/21/2022-02:52:24] [V] [TRT] Tactic: 6 Time: 0.204818
[05/21/2022-02:52:24] [V] [TRT] Tactic: 7 Time: 0.178411
[05/21/2022-02:52:24] [V] [TRT] Tactic: 8 Time: 0.178158
[05/21/2022-02:52:24] [V] [TRT] Tactic: 9 Time: 0.183704
[05/21/2022-02:52:24] [V] [TRT] Tactic: 28 Time: 0.374238
[05/21/2022-02:52:24] [V] [TRT] Fastest Tactic: 8 Time: 0.178158
[05/21/2022-02:52:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-02:52:24] [V] [TRT] Tactic: 128 Time: 1.37773
[05/21/2022-02:52:24] [V] [TRT] Tactic: 256 Time: 1.36581
[05/21/2022-02:52:24] [V] [TRT] Tactic: 512 Time: 1.27607
[05/21/2022-02:52:24] [V] [TRT] Tactic: -32 Time: 1.42557
[05/21/2022-02:52:24] [V] [TRT] Tactic: -64 Time: 1.38598
[05/21/2022-02:52:24] [V] [TRT] Tactic: -128 Time: 1.38408
[05/21/2022-02:52:24] [V] [TRT] Fastest Tactic: 512 Time: 1.27607
[05/21/2022-02:52:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:24] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:52:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:24] [V] [TRT] Tactic: 0 Time: 0.288919
[05/21/2022-02:52:24] [V] [TRT] Tactic: 1 Time: 0.235593
[05/21/2022-02:52:24] [V] [TRT] Tactic: 2 Time: 0.234941
[05/21/2022-02:52:24] [V] [TRT] Tactic: 3 Time: 0.21651
[05/21/2022-02:52:24] [V] [TRT] Tactic: 4 Time: 0.210026
[05/21/2022-02:52:24] [V] [TRT] Tactic: 5 Time: 0.213477
[05/21/2022-02:52:24] [V] [TRT] Tactic: 6 Time: 0.207884
[05/21/2022-02:52:24] [V] [TRT] Tactic: 7 Time: 0.200475
[05/21/2022-02:52:24] [V] [TRT] Tactic: 8 Time: 0.197767
[05/21/2022-02:52:24] [V] [TRT] Tactic: 9 Time: 0.208314
[05/21/2022-02:52:24] [V] [TRT] Tactic: 10 Time: 0.393737
[05/21/2022-02:52:24] [V] [TRT] Tactic: 11 Time: 0.29433
[05/21/2022-02:52:24] [V] [TRT] Tactic: 12 Time: 0.279629
[05/21/2022-02:52:24] [V] [TRT] Tactic: 13 Time: 0.233594
[05/21/2022-02:52:24] [V] [TRT] Tactic: 14 Time: 0.215807
[05/21/2022-02:52:24] [V] [TRT] Tactic: 15 Time: 0.221093
[05/21/2022-02:52:24] [V] [TRT] Tactic: 16 Time: 0.206751
[05/21/2022-02:52:24] [V] [TRT] Tactic: 17 Time: 0.18207
[05/21/2022-02:52:24] [V] [TRT] Tactic: 18 Time: 0.181107
[05/21/2022-02:52:24] [V] [TRT] Tactic: 19 Time: 0.195384
[05/21/2022-02:52:24] [V] [TRT] Tactic: 28 Time: 0.282565
[05/21/2022-02:52:24] [V] [TRT] Tactic: 29 Time: 0.386641
[05/21/2022-02:52:24] [V] [TRT] Fastest Tactic: 18 Time: 0.181107
[05/21/2022-02:52:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-02:52:24] [V] [TRT] Tactic: 128 Time: 1.37751
[05/21/2022-02:52:25] [V] [TRT] Tactic: 256 Time: 1.36439
[05/21/2022-02:52:25] [V] [TRT] Tactic: 512 Time: 1.2742
[05/21/2022-02:52:25] [V] [TRT] Tactic: -32 Time: 1.42393
[05/21/2022-02:52:25] [V] [TRT] Tactic: -64 Time: 1.38326
[05/21/2022-02:52:25] [V] [TRT] Tactic: -128 Time: 1.38417
[05/21/2022-02:52:25] [V] [TRT] Fastest Tactic: 512 Time: 1.2742
[05/21/2022-02:52:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:52:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:25] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:52:25] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:25] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:25] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:25] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:25] [V] [TRT] Tactic: 0 Time: 2.15266
[05/21/2022-02:52:25] [V] [TRT] Tactic: 1 Time: 1.55973
[05/21/2022-02:52:25] [V] [TRT] Tactic: 2 Time: 1.82459
[05/21/2022-02:52:25] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2223505408, available: 536870912
[05/21/2022-02:52:25] [V] [TRT] Tactic: 5 Time: 8.50543
[05/21/2022-02:52:25] [V] [TRT] Fastest Tactic: 1 Time: 1.55973
[05/21/2022-02:52:25] [V] [TRT] Setting workspace to 2223505408enables more tactics for profiling
[05/21/2022-02:52:25] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:25] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:25] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:25] [V] [TRT] Tactic: 1062367460111450758 Time: 1.37992
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:52:25] [V] [TRT] Tactic: 1698681053543049347 Time: 1.28747
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:25] [V] [TRT] Tactic: 4501471010995462441 Time: 1.07519
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:25] [V] [TRT] Tactic: 5137655947464784826 Time: 1.05274
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:25] [V] [TRT] Tactic: 5288347012147084929 Time: 1.07462
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:52:25] [V] [TRT] Tactic: 5326823351883942011 Time: 1.03122
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:52:25] [V] [TRT] Tactic: 5500448035057547314 Time: 1.18883
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:25] [V] [TRT] Tactic: 6645123197870846056 Time: 1.07542
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:25] [V] [TRT] Tactic: 7144526460361122478 Time: 1.45535
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:25] [V] [TRT] Tactic: -8262349710178828730 Time: 1.08284
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:52:25] [V] [TRT] Tactic: -6576203419454146580 Time: 1.23486
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:25] [V] [TRT] Tactic: -4787320710726427159 Time: 1.5214
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:25] [V] [TRT] Tactic: -3456450830548107839 Time: 1.2907
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:25] [V] [TRT] Tactic: -1218658103698133241 Time: 1.20616
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:25] [V] [TRT] Tactic: -836875257600482091 Time: 1.17089
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:25] [V] [TRT] Tactic: -410470605513481746 Time: 1.05551
[05/21/2022-02:52:25] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:52:26] [V] [TRT] Tactic: -377491875521947884 Time: 1.06438
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:52:26] [V] [TRT] Tactic: -37215280111360163 Time: 1.02179
[05/21/2022-02:52:26] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 1.02179
[05/21/2022-02:52:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-02:52:26] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:52:26] [V] [TRT] Tactic: 3886731678879822788 Time: 1.09253
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:52:26] [V] [TRT] Tactic: 6629944304117643200 Time: 2.03159
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:26] [V] [TRT] Tactic: -9153228964338181824 Time: 2.05629
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:26] [V] [TRT] Tactic: -7394439838318485025 Time: 1.08881
[05/21/2022-02:52:26] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.08881
[05/21/2022-02:52:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:26] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:26] [V] [TRT] Tactic: 0 Time: 1.87036
[05/21/2022-02:52:26] [V] [TRT] Tactic: 1 Time: 1.88839
[05/21/2022-02:52:26] [V] [TRT] Tactic: 2 Time: 1.74483
[05/21/2022-02:52:26] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2223505408, available: 536870912
[05/21/2022-02:52:26] [V] [TRT] Tactic: 5 Time: 8.08687
[05/21/2022-02:52:26] [V] [TRT] Fastest Tactic: 2 Time: 1.74483
[05/21/2022-02:52:26] [V] [TRT] Setting workspace to 2223505408enables more tactics for profiling
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:52:26] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:52:26] [V] [TRT] Tactic: 3066127711859985668 Time: 0.672213
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:26] [V] [TRT] Tactic: 3564772625446233998 Time: 0.746602
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:26] [V] [TRT] Tactic: 5319956359050645452 Time: 0.696497
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:26] [V] [TRT] Tactic: 7205456024582378848 Time: 0.564095
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:52:26] [V] [TRT] Tactic: 8163473458334948789 Time: 0.537298
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:26] [V] [TRT] Tactic: -4212163711445252890 Time: 0.547493
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:26] [V] [TRT] Tactic: -3898373634979201110 Time: 0.561914
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:26] [V] [TRT] Tactic: -2409163523992614473 Time: 0.54819
[05/21/2022-02:52:26] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:52:26] [V] [TRT] Tactic: -1716393687483585322 Time: 0.537305
[05/21/2022-02:52:26] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 0.537298
[05/21/2022-02:52:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-02:52:26] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:26] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:26] [V] [TRT] Tactic: 0 Time: 0.237409
[05/21/2022-02:52:26] [V] [TRT] Tactic: 1 Time: 0.167311
[05/21/2022-02:52:26] [V] [TRT] Tactic: 2 Time: 0.158125
[05/21/2022-02:52:26] [V] [TRT] Tactic: 3 Time: 0.127747
[05/21/2022-02:52:26] [V] [TRT] Tactic: 4 Time: 0.118965
[05/21/2022-02:52:26] [V] [TRT] Tactic: 5 Time: 0.117773
[05/21/2022-02:52:26] [V] [TRT] Tactic: 6 Time: 0.113249
[05/21/2022-02:52:26] [V] [TRT] Tactic: 7 Time: 0.0966796
[05/21/2022-02:52:26] [V] [TRT] Tactic: 8 Time: 0.0954494
[05/21/2022-02:52:26] [V] [TRT] Tactic: 9 Time: 0.0979169
[05/21/2022-02:52:26] [V] [TRT] Tactic: 28 Time: 0.234466
[05/21/2022-02:52:26] [V] [TRT] Fastest Tactic: 8 Time: 0.0954494
[05/21/2022-02:52:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-02:52:26] [V] [TRT] Tactic: 128 Time: 0.758073
[05/21/2022-02:52:26] [V] [TRT] Tactic: 256 Time: 0.758262
[05/21/2022-02:52:26] [V] [TRT] Tactic: 512 Time: 0.758776
[05/21/2022-02:52:27] [V] [TRT] Tactic: -32 Time: 0.759362
[05/21/2022-02:52:27] [V] [TRT] Tactic: -64 Time: 0.71347
[05/21/2022-02:52:27] [V] [TRT] Tactic: -128 Time: 0.715801
[05/21/2022-02:52:27] [V] [TRT] Fastest Tactic: -64 Time: 0.71347
[05/21/2022-02:52:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:27] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:52:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:27] [V] [TRT] Tactic: 0 Time: 0.237018
[05/21/2022-02:52:27] [V] [TRT] Tactic: 1 Time: 0.167207
[05/21/2022-02:52:27] [V] [TRT] Tactic: 2 Time: 0.158014
[05/21/2022-02:52:27] [V] [TRT] Tactic: 3 Time: 0.128105
[05/21/2022-02:52:27] [V] [TRT] Tactic: 4 Time: 0.11877
[05/21/2022-02:52:27] [V] [TRT] Tactic: 5 Time: 0.11735
[05/21/2022-02:52:27] [V] [TRT] Tactic: 6 Time: 0.159368
[05/21/2022-02:52:27] [V] [TRT] Tactic: 7 Time: 0.138372
[05/21/2022-02:52:27] [V] [TRT] Tactic: 8 Time: 0.136172
[05/21/2022-02:52:27] [V] [TRT] Tactic: 9 Time: 0.129284
[05/21/2022-02:52:27] [V] [TRT] Tactic: 28 Time: 0.234889
[05/21/2022-02:52:27] [V] [TRT] Fastest Tactic: 5 Time: 0.11735
[05/21/2022-02:52:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-02:52:27] [V] [TRT] Tactic: 128 Time: 0.758184
[05/21/2022-02:52:27] [V] [TRT] Tactic: 256 Time: 0.758014
[05/21/2022-02:52:27] [V] [TRT] Tactic: 512 Time: 0.75877
[05/21/2022-02:52:27] [V] [TRT] Tactic: -32 Time: 0.733522
[05/21/2022-02:52:27] [V] [TRT] Tactic: -64 Time: 0.764343
[05/21/2022-02:52:27] [V] [TRT] Tactic: -128 Time: 0.837077
[05/21/2022-02:52:27] [V] [TRT] Fastest Tactic: -32 Time: 0.733522
[05/21/2022-02:52:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:52:27] [V] [TRT] *************** Autotuning format combination: Float(10368,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:52:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:27] [V] [TRT] Tactic: 24 Time: 0.132207
[05/21/2022-02:52:27] [V] [TRT] Tactic: 25 Time: 0.120534
[05/21/2022-02:52:27] [V] [TRT] Tactic: 26 Time: 0.119421
[05/21/2022-02:52:27] [V] [TRT] Tactic: 27 Time: 0.120638
[05/21/2022-02:52:27] [V] [TRT] Tactic: 31 Time: 0.132539
[05/21/2022-02:52:27] [V] [TRT] Fastest Tactic: 26 Time: 0.119421
[05/21/2022-02:52:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-02:52:27] [V] [TRT] Tactic: 128 Time: 0.758092
[05/21/2022-02:52:27] [V] [TRT] Tactic: 256 Time: 0.75821
[05/21/2022-02:52:27] [V] [TRT] Tactic: 512 Time: 0.758919
[05/21/2022-02:52:27] [V] [TRT] Tactic: -32 Time: 0.758893
[05/21/2022-02:52:27] [V] [TRT] Tactic: -64 Time: 0.71362
[05/21/2022-02:52:27] [V] [TRT] Tactic: -128 Time: 0.715592
[05/21/2022-02:52:27] [V] [TRT] Fastest Tactic: -64 Time: 0.71362
[05/21/2022-02:52:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:52:27] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:27] [V] [TRT] Tactic: 0 Time: 0.243197
[05/21/2022-02:52:27] [V] [TRT] Tactic: 1 Time: 0.174167
[05/21/2022-02:52:27] [V] [TRT] Tactic: 2 Time: 0.162871
[05/21/2022-02:52:27] [V] [TRT] Tactic: 3 Time: 0.131165
[05/21/2022-02:52:27] [V] [TRT] Tactic: 4 Time: 0.123457
[05/21/2022-02:52:27] [V] [TRT] Tactic: 5 Time: 0.121042
[05/21/2022-02:52:27] [V] [TRT] Tactic: 6 Time: 0.112389
[05/21/2022-02:52:27] [V] [TRT] Tactic: 7 Time: 0.100351
[05/21/2022-02:52:27] [V] [TRT] Tactic: 8 Time: 0.101204
[05/21/2022-02:52:27] [V] [TRT] Tactic: 9 Time: 0.100397
[05/21/2022-02:52:27] [V] [TRT] Tactic: 28 Time: 0.241895
[05/21/2022-02:52:27] [V] [TRT] Fastest Tactic: 7 Time: 0.100351
[05/21/2022-02:52:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-02:52:27] [V] [TRT] Tactic: 128 Time: 0.730742
[05/21/2022-02:52:27] [V] [TRT] Tactic: 256 Time: 0.724902
[05/21/2022-02:52:27] [V] [TRT] Tactic: 512 Time: 0.667389
[05/21/2022-02:52:27] [V] [TRT] Tactic: -32 Time: 0.762637
[05/21/2022-02:52:27] [V] [TRT] Tactic: -64 Time: 0.712663
[05/21/2022-02:52:27] [V] [TRT] Tactic: -128 Time: 0.712207
[05/21/2022-02:52:27] [V] [TRT] Fastest Tactic: 512 Time: 0.667389
[05/21/2022-02:52:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:52:27] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:52:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:27] [V] [TRT] Tactic: 0 Time: 0.166777
[05/21/2022-02:52:27] [V] [TRT] Tactic: 1 Time: 0.130638
[05/21/2022-02:52:27] [V] [TRT] Tactic: 2 Time: 0.130065
[05/21/2022-02:52:27] [V] [TRT] Tactic: 3 Time: 0.1161
[05/21/2022-02:52:27] [V] [TRT] Tactic: 4 Time: 0.112747
[05/21/2022-02:52:27] [V] [TRT] Tactic: 5 Time: 0.114577
[05/21/2022-02:52:27] [V] [TRT] Tactic: 6 Time: 0.112409
[05/21/2022-02:52:27] [V] [TRT] Tactic: 7 Time: 0.107728
[05/21/2022-02:52:27] [V] [TRT] Tactic: 8 Time: 0.107259
[05/21/2022-02:52:27] [V] [TRT] Tactic: 9 Time: 0.112044
[05/21/2022-02:52:27] [V] [TRT] Tactic: 10 Time: 0.250749
[05/21/2022-02:52:27] [V] [TRT] Tactic: 11 Time: 0.18192
[05/21/2022-02:52:27] [V] [TRT] Tactic: 12 Time: 0.170527
[05/21/2022-02:52:27] [V] [TRT] Tactic: 13 Time: 0.135807
[05/21/2022-02:52:27] [V] [TRT] Tactic: 14 Time: 0.129115
[05/21/2022-02:52:28] [V] [TRT] Tactic: 15 Time: 0.130124
[05/21/2022-02:52:28] [V] [TRT] Tactic: 16 Time: 0.114974
[05/21/2022-02:52:28] [V] [TRT] Tactic: 17 Time: 0.103386
[05/21/2022-02:52:28] [V] [TRT] Tactic: 18 Time: 0.10474
[05/21/2022-02:52:28] [V] [TRT] Tactic: 19 Time: 0.108893
[05/21/2022-02:52:28] [V] [TRT] Tactic: 28 Time: 0.164551
[05/21/2022-02:52:28] [V] [TRT] Tactic: 29 Time: 0.251764
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: 17 Time: 0.103386
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 128 Time: 0.730631
[05/21/2022-02:52:28] [V] [TRT] Tactic: 256 Time: 0.722611
[05/21/2022-02:52:28] [V] [TRT] Tactic: 512 Time: 0.667825
[05/21/2022-02:52:28] [V] [TRT] Tactic: -32 Time: 0.762422
[05/21/2022-02:52:28] [V] [TRT] Tactic: -64 Time: 0.71138
[05/21/2022-02:52:28] [V] [TRT] Tactic: -128 Time: 0.712038
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: 512 Time: 0.667825
[05/21/2022-02:52:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:28] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:28] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 0 Time: 0.236927
[05/21/2022-02:52:28] [V] [TRT] Tactic: 1 Time: 0.167253
[05/21/2022-02:52:28] [V] [TRT] Tactic: 2 Time: 0.158132
[05/21/2022-02:52:28] [V] [TRT] Tactic: 3 Time: 0.128574
[05/21/2022-02:52:28] [V] [TRT] Tactic: 4 Time: 0.118952
[05/21/2022-02:52:28] [V] [TRT] Tactic: 5 Time: 0.116784
[05/21/2022-02:52:28] [V] [TRT] Tactic: 6 Time: 0.113099
[05/21/2022-02:52:28] [V] [TRT] Tactic: 7 Time: 0.0965433
[05/21/2022-02:52:28] [V] [TRT] Tactic: 8 Time: 0.0952799
[05/21/2022-02:52:28] [V] [TRT] Tactic: 9 Time: 0.0978645
[05/21/2022-02:52:28] [V] [TRT] Tactic: 28 Time: 0.234167
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: 8 Time: 0.0952799
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 128 Time: 0.75817
[05/21/2022-02:52:28] [V] [TRT] Tactic: 256 Time: 0.757663
[05/21/2022-02:52:28] [V] [TRT] Tactic: 512 Time: 0.75901
[05/21/2022-02:52:28] [V] [TRT] Tactic: -32 Time: 0.758724
[05/21/2022-02:52:28] [V] [TRT] Tactic: -64 Time: 0.713796
[05/21/2022-02:52:28] [V] [TRT] Tactic: -128 Time: 0.715423
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: -64 Time: 0.713796
[05/21/2022-02:52:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:28] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 0 Time: 0.237175
[05/21/2022-02:52:28] [V] [TRT] Tactic: 1 Time: 0.167304
[05/21/2022-02:52:28] [V] [TRT] Tactic: 2 Time: 0.158464
[05/21/2022-02:52:28] [V] [TRT] Tactic: 3 Time: 0.128516
[05/21/2022-02:52:28] [V] [TRT] Tactic: 4 Time: 0.118958
[05/21/2022-02:52:28] [V] [TRT] Tactic: 5 Time: 0.117363
[05/21/2022-02:52:28] [V] [TRT] Tactic: 6 Time: 0.15944
[05/21/2022-02:52:28] [V] [TRT] Tactic: 7 Time: 0.13905
[05/21/2022-02:52:28] [V] [TRT] Tactic: 8 Time: 0.136068
[05/21/2022-02:52:28] [V] [TRT] Tactic: 9 Time: 0.129427
[05/21/2022-02:52:28] [V] [TRT] Tactic: 28 Time: 0.234752
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: 5 Time: 0.117363
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 128 Time: 0.758386
[05/21/2022-02:52:28] [V] [TRT] Tactic: 256 Time: 0.758099
[05/21/2022-02:52:28] [V] [TRT] Tactic: 512 Time: 0.758151
[05/21/2022-02:52:28] [V] [TRT] Tactic: -32 Time: 0.733099
[05/21/2022-02:52:28] [V] [TRT] Tactic: -64 Time: 0.764915
[05/21/2022-02:52:28] [V] [TRT] Tactic: -128 Time: 0.836289
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: -32 Time: 0.733099
[05/21/2022-02:52:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:52:28] [V] [TRT] *************** Autotuning format combination: Float(10368,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 24 Time: 0.13252
[05/21/2022-02:52:28] [V] [TRT] Tactic: 25 Time: 0.120104
[05/21/2022-02:52:28] [V] [TRT] Tactic: 26 Time: 0.119004
[05/21/2022-02:52:28] [V] [TRT] Tactic: 27 Time: 0.119095
[05/21/2022-02:52:28] [V] [TRT] Tactic: 31 Time: 0.131868
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: 26 Time: 0.119004
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 128 Time: 0.758047
[05/21/2022-02:52:28] [V] [TRT] Tactic: 256 Time: 0.757793
[05/21/2022-02:52:28] [V] [TRT] Tactic: 512 Time: 0.758763
[05/21/2022-02:52:28] [V] [TRT] Tactic: -32 Time: 0.759264
[05/21/2022-02:52:28] [V] [TRT] Tactic: -64 Time: 0.712865
[05/21/2022-02:52:28] [V] [TRT] Tactic: -128 Time: 0.715592
[05/21/2022-02:52:28] [V] [TRT] Fastest Tactic: -64 Time: 0.712865
[05/21/2022-02:52:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:52:28] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:28] [V] [TRT] Tactic: 0 Time: 0.243366
[05/21/2022-02:52:28] [V] [TRT] Tactic: 1 Time: 0.174199
[05/21/2022-02:52:28] [V] [TRT] Tactic: 2 Time: 0.162402
[05/21/2022-02:52:28] [V] [TRT] Tactic: 3 Time: 0.131049
[05/21/2022-02:52:29] [V] [TRT] Tactic: 4 Time: 0.123919
[05/21/2022-02:52:29] [V] [TRT] Tactic: 5 Time: 0.121048
[05/21/2022-02:52:29] [V] [TRT] Tactic: 6 Time: 0.11181
[05/21/2022-02:52:29] [V] [TRT] Tactic: 7 Time: 0.10043
[05/21/2022-02:52:29] [V] [TRT] Tactic: 8 Time: 0.101224
[05/21/2022-02:52:29] [V] [TRT] Tactic: 9 Time: 0.100234
[05/21/2022-02:52:29] [V] [TRT] Tactic: 28 Time: 0.24235
[05/21/2022-02:52:29] [V] [TRT] Fastest Tactic: 9 Time: 0.100234
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-02:52:29] [V] [TRT] Tactic: 128 Time: 0.73028
[05/21/2022-02:52:29] [V] [TRT] Tactic: 256 Time: 0.724173
[05/21/2022-02:52:29] [V] [TRT] Tactic: 512 Time: 0.666615
[05/21/2022-02:52:29] [V] [TRT] Tactic: -32 Time: 0.762357
[05/21/2022-02:52:29] [V] [TRT] Tactic: -64 Time: 0.709857
[05/21/2022-02:52:29] [V] [TRT] Tactic: -128 Time: 0.71138
[05/21/2022-02:52:29] [V] [TRT] Fastest Tactic: 512 Time: 0.666615
[05/21/2022-02:52:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:52:29] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:29] [V] [TRT] Tactic: 0 Time: 0.167799
[05/21/2022-02:52:29] [V] [TRT] Tactic: 1 Time: 0.131074
[05/21/2022-02:52:29] [V] [TRT] Tactic: 2 Time: 0.129642
[05/21/2022-02:52:29] [V] [TRT] Tactic: 3 Time: 0.11571
[05/21/2022-02:52:29] [V] [TRT] Tactic: 4 Time: 0.112702
[05/21/2022-02:52:29] [V] [TRT] Tactic: 5 Time: 0.114928
[05/21/2022-02:52:29] [V] [TRT] Tactic: 6 Time: 0.112676
[05/21/2022-02:52:29] [V] [TRT] Tactic: 7 Time: 0.1078
[05/21/2022-02:52:29] [V] [TRT] Tactic: 8 Time: 0.106992
[05/21/2022-02:52:29] [V] [TRT] Tactic: 9 Time: 0.111751
[05/21/2022-02:52:29] [V] [TRT] Tactic: 10 Time: 0.250455
[05/21/2022-02:52:29] [V] [TRT] Tactic: 11 Time: 0.181946
[05/21/2022-02:52:29] [V] [TRT] Tactic: 12 Time: 0.170391
[05/21/2022-02:52:29] [V] [TRT] Tactic: 13 Time: 0.135684
[05/21/2022-02:52:29] [V] [TRT] Tactic: 14 Time: 0.128698
[05/21/2022-02:52:29] [V] [TRT] Tactic: 15 Time: 0.130039
[05/21/2022-02:52:29] [V] [TRT] Tactic: 16 Time: 0.115156
[05/21/2022-02:52:29] [V] [TRT] Tactic: 17 Time: 0.102858
[05/21/2022-02:52:29] [V] [TRT] Tactic: 18 Time: 0.104616
[05/21/2022-02:52:29] [V] [TRT] Tactic: 19 Time: 0.108112
[05/21/2022-02:52:29] [V] [TRT] Tactic: 28 Time: 0.163913
[05/21/2022-02:52:29] [V] [TRT] Tactic: 29 Time: 0.252129
[05/21/2022-02:52:29] [V] [TRT] Fastest Tactic: 17 Time: 0.102858
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-02:52:29] [V] [TRT] Tactic: 128 Time: 0.730788
[05/21/2022-02:52:29] [V] [TRT] Tactic: 256 Time: 0.72349
[05/21/2022-02:52:29] [V] [TRT] Tactic: 512 Time: 0.667656
[05/21/2022-02:52:29] [V] [TRT] Tactic: -32 Time: 0.763118
[05/21/2022-02:52:29] [V] [TRT] Tactic: -64 Time: 0.711595
[05/21/2022-02:52:29] [V] [TRT] Tactic: -128 Time: 0.712722
[05/21/2022-02:52:29] [V] [TRT] Fastest Tactic: 512 Time: 0.667656
[05/21/2022-02:52:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:29] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:29] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:29] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:29] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:29] [V] [TRT] Tactic: 0 Time: 0.929421
[05/21/2022-02:52:29] [V] [TRT] Tactic: 1 Time: 0.527396
[05/21/2022-02:52:29] [V] [TRT] Tactic: 2 Time: 0.633268
[05/21/2022-02:52:29] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558039040, available: 536870912
[05/21/2022-02:52:29] [V] [TRT] Tactic: 5 Time: 2.49808
[05/21/2022-02:52:29] [V] [TRT] Fastest Tactic: 1 Time: 0.527396
[05/21/2022-02:52:29] [V] [TRT] Setting workspace to 558039040enables more tactics for profiling
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:29] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:29] [V] [TRT] Tactic: 1062367460111450758 Time: 0.402519
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:52:29] [V] [TRT] Tactic: 1698681053543049347 Time: 0.369694
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:29] [V] [TRT] Tactic: 4501471010995462441 Time: 0.30541
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:29] [V] [TRT] Tactic: 5137655947464784826 Time: 0.303698
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:29] [V] [TRT] Tactic: 5288347012147084929 Time: 0.309342
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:52:29] [V] [TRT] Tactic: 5326823351883942011 Time: 0.298568
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:52:29] [V] [TRT] Tactic: 5500448035057547314 Time: 0.33196
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:29] [V] [TRT] Tactic: 6645123197870846056 Time: 0.306341
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:29] [V] [TRT] Tactic: 7144526460361122478 Time: 0.417871
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:29] [V] [TRT] Tactic: -8262349710178828730 Time: 0.315794
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:52:29] [V] [TRT] Tactic: -6576203419454146580 Time: 0.365534
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:29] [V] [TRT] Tactic: -4787320710726427159 Time: 0.42987
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:29] [V] [TRT] Tactic: -3456450830548107839 Time: 0.379258
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:29] [V] [TRT] Tactic: -1218658103698133241 Time: 0.340618
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:29] [V] [TRT] Tactic: -836875257600482091 Time: 0.339642
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:29] [V] [TRT] Tactic: -410470605513481746 Time: 0.302708
[05/21/2022-02:52:29] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:52:29] [V] [TRT] Tactic: -377491875521947884 Time: 0.30778
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:52:30] [V] [TRT] Tactic: -37215280111360163 Time: 0.298646
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.298568
[05/21/2022-02:52:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:52:30] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:52:30] [V] [TRT] Tactic: 3886731678879822788 Time: 0.332441
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:52:30] [V] [TRT] Tactic: 6629944304117643200 Time: 0.686608
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:30] [V] [TRT] Tactic: -9153228964338181824 Time: 0.6978
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:30] [V] [TRT] Tactic: -7394439838318485025 Time: 0.324453
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.324453
[05/21/2022-02:52:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:30] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:30] [V] [TRT] Tactic: 0 Time: 0.615521
[05/21/2022-02:52:30] [V] [TRT] Tactic: 1 Time: 0.528919
[05/21/2022-02:52:30] [V] [TRT] Tactic: 2 Time: 0.557702
[05/21/2022-02:52:30] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558039040, available: 536870912
[05/21/2022-02:52:30] [V] [TRT] Tactic: 5 Time: 2.44551
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: 1 Time: 0.528919
[05/21/2022-02:52:30] [V] [TRT] Setting workspace to 558039040enables more tactics for profiling
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:52:30] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:52:30] [V] [TRT] Tactic: 3066127711859985668 Time: 0.210527
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:30] [V] [TRT] Tactic: 3564772625446233998 Time: 0.223093
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:30] [V] [TRT] Tactic: 5319956359050645452 Time: 0.212663
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:30] [V] [TRT] Tactic: 7205456024582378848 Time: 0.17319
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:52:30] [V] [TRT] Tactic: 8163473458334948789 Time: 0.165515
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:30] [V] [TRT] Tactic: -4212163711445252890 Time: 0.166497
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:30] [V] [TRT] Tactic: -3898373634979201110 Time: 0.170235
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:30] [V] [TRT] Tactic: -2409163523992614473 Time: 0.169681
[05/21/2022-02:52:30] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:52:30] [V] [TRT] Tactic: -1716393687483585322 Time: 0.165352
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.165352
[05/21/2022-02:52:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:52:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:30] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:30] [V] [TRT] Tactic: 0 Time: 0.187845
[05/21/2022-02:52:30] [V] [TRT] Tactic: 1 Time: 0.140996
[05/21/2022-02:52:30] [V] [TRT] Tactic: 2 Time: 0.133717
[05/21/2022-02:52:30] [V] [TRT] Tactic: 3 Time: 0.117363
[05/21/2022-02:52:30] [V] [TRT] Tactic: 4 Time: 0.101973
[05/21/2022-02:52:30] [V] [TRT] Tactic: 5 Time: 0.104896
[05/21/2022-02:52:30] [V] [TRT] Tactic: 6 Time: 0.109421
[05/21/2022-02:52:30] [V] [TRT] Tactic: 7 Time: 0.0895765
[05/21/2022-02:52:30] [V] [TRT] Tactic: 8 Time: 0.084824
[05/21/2022-02:52:30] [V] [TRT] Tactic: 9 Time: 0.0915561
[05/21/2022-02:52:30] [V] [TRT] Tactic: 28 Time: 0.184427
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: 8 Time: 0.084824
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-02:52:30] [V] [TRT] Tactic: 128 Time: 0.672878
[05/21/2022-02:52:30] [V] [TRT] Tactic: 256 Time: 0.674167
[05/21/2022-02:52:30] [V] [TRT] Tactic: 512 Time: 0.675176
[05/21/2022-02:52:30] [V] [TRT] Tactic: -32 Time: 0.756276
[05/21/2022-02:52:30] [V] [TRT] Tactic: -64 Time: 0.708854
[05/21/2022-02:52:30] [V] [TRT] Tactic: -128 Time: 0.705541
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: 128 Time: 0.672878
[05/21/2022-02:52:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:30] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:30] [V] [TRT] Tactic: 0 Time: 0.187259
[05/21/2022-02:52:30] [V] [TRT] Tactic: 1 Time: 0.140749
[05/21/2022-02:52:30] [V] [TRT] Tactic: 2 Time: 0.133906
[05/21/2022-02:52:30] [V] [TRT] Tactic: 3 Time: 0.118971
[05/21/2022-02:52:30] [V] [TRT] Tactic: 4 Time: 0.102624
[05/21/2022-02:52:30] [V] [TRT] Tactic: 5 Time: 0.104902
[05/21/2022-02:52:30] [V] [TRT] Tactic: 6 Time: 0.111771
[05/21/2022-02:52:30] [V] [TRT] Tactic: 7 Time: 0.0904036
[05/21/2022-02:52:30] [V] [TRT] Tactic: 8 Time: 0.0856383
[05/21/2022-02:52:30] [V] [TRT] Tactic: 9 Time: 0.091198
[05/21/2022-02:52:30] [V] [TRT] Tactic: 28 Time: 0.184609
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: 8 Time: 0.0856383
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-02:52:30] [V] [TRT] Tactic: 128 Time: 0.672936
[05/21/2022-02:52:30] [V] [TRT] Tactic: 256 Time: 0.673516
[05/21/2022-02:52:30] [V] [TRT] Tactic: 512 Time: 0.675313
[05/21/2022-02:52:30] [V] [TRT] Tactic: -32 Time: 0.757507
[05/21/2022-02:52:30] [V] [TRT] Tactic: -64 Time: 0.708047
[05/21/2022-02:52:30] [V] [TRT] Tactic: -128 Time: 0.705306
[05/21/2022-02:52:30] [V] [TRT] Fastest Tactic: 128 Time: 0.672936
[05/21/2022-02:52:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:30] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:30] [V] [TRT] Tactic: 24 Time: 0.139603
[05/21/2022-02:52:30] [V] [TRT] Tactic: 25 Time: 0.12433
[05/21/2022-02:52:31] [V] [TRT] Tactic: 26 Time: 0.123053
[05/21/2022-02:52:31] [V] [TRT] Tactic: 27 Time: 0.122604
[05/21/2022-02:52:31] [V] [TRT] Tactic: 31 Time: 0.131269
[05/21/2022-02:52:31] [V] [TRT] Fastest Tactic: 27 Time: 0.122604
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-02:52:31] [V] [TRT] Tactic: 128 Time: 0.673796
[05/21/2022-02:52:31] [V] [TRT] Tactic: 256 Time: 0.674206
[05/21/2022-02:52:31] [V] [TRT] Tactic: 512 Time: 0.67558
[05/21/2022-02:52:31] [V] [TRT] Tactic: -32 Time: 0.75627
[05/21/2022-02:52:31] [V] [TRT] Tactic: -64 Time: 0.709297
[05/21/2022-02:52:31] [V] [TRT] Tactic: -128 Time: 0.706081
[05/21/2022-02:52:31] [V] [TRT] Fastest Tactic: 128 Time: 0.673796
[05/21/2022-02:52:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:31] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:31] [V] [TRT] Tactic: 0 Time: 0.190944
[05/21/2022-02:52:31] [V] [TRT] Tactic: 1 Time: 0.146523
[05/21/2022-02:52:31] [V] [TRT] Tactic: 2 Time: 0.1364
[05/21/2022-02:52:31] [V] [TRT] Tactic: 3 Time: 0.118144
[05/21/2022-02:52:31] [V] [TRT] Tactic: 4 Time: 0.107741
[05/21/2022-02:52:31] [V] [TRT] Tactic: 5 Time: 0.109675
[05/21/2022-02:52:31] [V] [TRT] Tactic: 6 Time: 0.106478
[05/21/2022-02:52:31] [V] [TRT] Tactic: 7 Time: 0.0932489
[05/21/2022-02:52:31] [V] [TRT] Tactic: 8 Time: 0.0930795
[05/21/2022-02:52:31] [V] [TRT] Tactic: 9 Time: 0.0956185
[05/21/2022-02:52:31] [V] [TRT] Tactic: 28 Time: 0.191725
[05/21/2022-02:52:31] [V] [TRT] Fastest Tactic: 8 Time: 0.0930795
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-02:52:31] [V] [TRT] Tactic: 128 Time: 0.693945
[05/21/2022-02:52:31] [V] [TRT] Tactic: 256 Time: 0.686009
[05/21/2022-02:52:31] [V] [TRT] Tactic: 512 Time: 0.641094
[05/21/2022-02:52:31] [V] [TRT] Tactic: -32 Time: 0.758548
[05/21/2022-02:52:31] [V] [TRT] Tactic: -64 Time: 0.704219
[05/21/2022-02:52:31] [V] [TRT] Tactic: -128 Time: 0.699603
[05/21/2022-02:52:31] [V] [TRT] Fastest Tactic: 512 Time: 0.641094
[05/21/2022-02:52:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:31] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:31] [V] [TRT] Tactic: 0 Time: 0.147793
[05/21/2022-02:52:31] [V] [TRT] Tactic: 1 Time: 0.122018
[05/21/2022-02:52:31] [V] [TRT] Tactic: 2 Time: 0.120801
[05/21/2022-02:52:31] [V] [TRT] Tactic: 3 Time: 0.112298
[05/21/2022-02:52:31] [V] [TRT] Tactic: 4 Time: 0.109264
[05/21/2022-02:52:31] [V] [TRT] Tactic: 5 Time: 0.11084
[05/21/2022-02:52:31] [V] [TRT] Tactic: 6 Time: 0.110716
[05/21/2022-02:52:31] [V] [TRT] Tactic: 7 Time: 0.106498
[05/21/2022-02:52:31] [V] [TRT] Tactic: 8 Time: 0.105775
[05/21/2022-02:52:31] [V] [TRT] Tactic: 9 Time: 0.110013
[05/21/2022-02:52:31] [V] [TRT] Tactic: 10 Time: 0.200944
[05/21/2022-02:52:31] [V] [TRT] Tactic: 11 Time: 0.151452
[05/21/2022-02:52:31] [V] [TRT] Tactic: 12 Time: 0.143731
[05/21/2022-02:52:31] [V] [TRT] Tactic: 13 Time: 0.121244
[05/21/2022-02:52:31] [V] [TRT] Tactic: 14 Time: 0.11181
[05/21/2022-02:52:31] [V] [TRT] Tactic: 15 Time: 0.114297
[05/21/2022-02:52:31] [V] [TRT] Tactic: 16 Time: 0.107363
[05/21/2022-02:52:31] [V] [TRT] Tactic: 17 Time: 0.094772
[05/21/2022-02:52:31] [V] [TRT] Tactic: 18 Time: 0.0936524
[05/21/2022-02:52:31] [V] [TRT] Tactic: 19 Time: 0.101973
[05/21/2022-02:52:31] [V] [TRT] Tactic: 28 Time: 0.144941
[05/21/2022-02:52:31] [V] [TRT] Tactic: 29 Time: 0.197747
[05/21/2022-02:52:31] [V] [TRT] Fastest Tactic: 18 Time: 0.0936524
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-02:52:31] [V] [TRT] Tactic: 128 Time: 0.693431
[05/21/2022-02:52:31] [V] [TRT] Tactic: 256 Time: 0.686628
[05/21/2022-02:52:31] [V] [TRT] Tactic: 512 Time: 0.640912
[05/21/2022-02:52:31] [V] [TRT] Tactic: -32 Time: 0.758151
[05/21/2022-02:52:31] [V] [TRT] Tactic: -64 Time: 0.703418
[05/21/2022-02:52:31] [V] [TRT] Tactic: -128 Time: 0.699368
[05/21/2022-02:52:31] [V] [TRT] Fastest Tactic: 512 Time: 0.640912
[05/21/2022-02:52:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:52:31] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:31] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:31] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:31] [V] [TRT] Tactic: 0 Time: 3.64695
[05/21/2022-02:52:31] [V] [TRT] Tactic: 1 Time: 2.37937
[05/21/2022-02:52:32] [V] [TRT] Tactic: 2 Time: 3.65833
[05/21/2022-02:52:32] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558563328, available: 536870912
[05/21/2022-02:52:32] [V] [TRT] Tactic: 5 Time: 42.5865
[05/21/2022-02:52:32] [V] [TRT] Tactic: 6 Time: 1.9976
[05/21/2022-02:52:32] [V] [TRT] Fastest Tactic: 6 Time: 1.9976
[05/21/2022-02:52:32] [V] [TRT] Setting workspace to 558563328enables more tactics for profiling
[05/21/2022-02:52:32] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:32] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:32] [V] [TRT] Tactic: 1062367460111450758 Time: 2.7503
[05/21/2022-02:52:32] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:52:32] [V] [TRT] Tactic: 1754984623894446479 Time: 3.10393
[05/21/2022-02:52:32] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:52:33] [V] [TRT] Tactic: 3611739942397549984 Time: 2.24006
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:52:33] [V] [TRT] Tactic: 3827454225649558724 Time: 2.55546
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:52:33] [V] [TRT] Tactic: 4337000649858996379 Time: 2.2885
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:33] [V] [TRT] Tactic: 4501471010995462441 Time: 2.2137
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:33] [V] [TRT] Tactic: 5137655947464784826 Time: 2.15098
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:33] [V] [TRT] Tactic: 5288347012147084929 Time: 2.19655
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:52:33] [V] [TRT] Tactic: 5921334924264294896 Time: 1.89099
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:33] [V] [TRT] Tactic: 6645123197870846056 Time: 2.19372
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:33] [V] [TRT] Tactic: 7144526460361122478 Time: 2.77148
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:52:33] [V] [TRT] Tactic: 7852627285308570038 Time: 2.72566
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:52:33] [V] [TRT] Tactic: -9137461792520977713 Time: 2.25979
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:52:33] [V] [TRT] Tactic: -8776506421218919509 Time: 2.62771
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:33] [V] [TRT] Tactic: -8262349710178828730 Time: 2.2573
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:52:33] [V] [TRT] Tactic: -8133971918129952780 Time: 2.53321
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:52:33] [V] [TRT] Tactic: -6092040395344634144 Time: 2.93544
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:33] [V] [TRT] Tactic: -4787320710726427159 Time: 3.11497
[05/21/2022-02:52:33] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:34] [V] [TRT] Tactic: -3456450830548107839 Time: 2.54684
[05/21/2022-02:52:34] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:52:34] [V] [TRT] Tactic: -2318106587342035239 Time: 2.64579
[05/21/2022-02:52:34] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:52:34] [V] [TRT] Tactic: -1343271414618805657 Time: 1.73748
[05/21/2022-02:52:34] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:34] [V] [TRT] Tactic: -1218658103698133241 Time: 2.534
[05/21/2022-02:52:34] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:34] [V] [TRT] Tactic: -836875257600482091 Time: 2.35654
[05/21/2022-02:52:34] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:34] [V] [TRT] Tactic: -410470605513481746 Time: 2.19473
[05/21/2022-02:52:34] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 1.73748
[05/21/2022-02:52:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-02:52:34] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:34] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:34] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:34] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:34] [V] [TRT] Tactic: -9153228964338181824 Time: 2.7221
[05/21/2022-02:52:34] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:34] [V] [TRT] Tactic: -7394439838318485025 Time: 2.11356
[05/21/2022-02:52:34] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.11356
[05/21/2022-02:52:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:34] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:34] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:34] [V] [TRT] Tactic: 0 Time: 4.81142
[05/21/2022-02:52:34] [V] [TRT] Tactic: 1 Time: 4.43466
[05/21/2022-02:52:34] [V] [TRT] Tactic: 2 Time: 3.5523
[05/21/2022-02:52:34] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558563328, available: 536870912
[05/21/2022-02:52:35] [V] [TRT] Tactic: 5 Time: 41.9694
[05/21/2022-02:52:35] [V] [TRT] Tactic: 6 Time: 3.08749
[05/21/2022-02:52:35] [V] [TRT] Fastest Tactic: 6 Time: 3.08749
[05/21/2022-02:52:35] [V] [TRT] Setting workspace to 558563328enables more tactics for profiling
[05/21/2022-02:52:35] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-02:52:35] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:35] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:35] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:35] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:35] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:35] [V] [TRT] Tactic: 3564772625446233998 Time: 1.41233
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:52:35] [V] [TRT] Tactic: 3650389455493082349 Time: 1.45302
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:52:35] [V] [TRT] Tactic: 4772821744921268633 Time: 0.988216
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:35] [V] [TRT] Tactic: 5319956359050645452 Time: 1.25488
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:35] [V] [TRT] Tactic: 7205456024582378848 Time: 1.11479
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:52:35] [V] [TRT] Tactic: -6490690591794140522 Time: 1.12413
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:52:35] [V] [TRT] Tactic: -4686027666808657977 Time: 1.13559
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:35] [V] [TRT] Tactic: -4212163711445252890 Time: 1.07539
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:35] [V] [TRT] Tactic: -3898373634979201110 Time: 1.10909
[05/21/2022-02:52:35] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:35] [V] [TRT] Tactic: -2409163523992614473 Time: 1.08551
[05/21/2022-02:52:35] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 0.988216
[05/21/2022-02:52:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-02:52:35] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:35] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:35] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-02:52:35] [V] [TRT] Tactic: 0 Time: 0.199056
[05/21/2022-02:52:35] [V] [TRT] Tactic: 1 Time: 0.150801
[05/21/2022-02:52:35] [V] [TRT] Tactic: 2 Time: 0.149212
[05/21/2022-02:52:35] [V] [TRT] Tactic: 3 Time: 0.131504
[05/21/2022-02:52:35] [V] [TRT] Tactic: 4 Time: 0.118998
[05/21/2022-02:52:35] [V] [TRT] Tactic: 5 Time: 0.114798
[05/21/2022-02:52:35] [V] [TRT] Tactic: 6 Time: 0.128132
[05/21/2022-02:52:35] [V] [TRT] Tactic: 7 Time: 0.109427
[05/21/2022-02:52:36] [V] [TRT] Tactic: 8 Time: 0.106595
[05/21/2022-02:52:36] [V] [TRT] Tactic: 9 Time: 0.109902
[05/21/2022-02:52:36] [V] [TRT] Tactic: 28 Time: 0.197057
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 8 Time: 0.106595
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 128 Time: 0.778522
[05/21/2022-02:52:36] [V] [TRT] Tactic: 256 Time: 0.778366
[05/21/2022-02:52:36] [V] [TRT] Tactic: 512 Time: 0.779499
[05/21/2022-02:52:36] [V] [TRT] Tactic: -32 Time: 0.884519
[05/21/2022-02:52:36] [V] [TRT] Tactic: -64 Time: 0.82446
[05/21/2022-02:52:36] [V] [TRT] Tactic: -128 Time: 0.820404
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 256 Time: 0.778366
[05/21/2022-02:52:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:36] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 0 Time: 0.198366
[05/21/2022-02:52:36] [V] [TRT] Tactic: 1 Time: 0.150638
[05/21/2022-02:52:36] [V] [TRT] Tactic: 2 Time: 0.14832
[05/21/2022-02:52:36] [V] [TRT] Tactic: 3 Time: 0.132051
[05/21/2022-02:52:36] [V] [TRT] Tactic: 4 Time: 0.1189
[05/21/2022-02:52:36] [V] [TRT] Tactic: 5 Time: 0.114479
[05/21/2022-02:52:36] [V] [TRT] Tactic: 6 Time: 0.129232
[05/21/2022-02:52:36] [V] [TRT] Tactic: 7 Time: 0.109701
[05/21/2022-02:52:36] [V] [TRT] Tactic: 8 Time: 0.106634
[05/21/2022-02:52:36] [V] [TRT] Tactic: 9 Time: 0.108444
[05/21/2022-02:52:36] [V] [TRT] Tactic: 28 Time: 0.197018
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 8 Time: 0.106634
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 128 Time: 0.777435
[05/21/2022-02:52:36] [V] [TRT] Tactic: 256 Time: 0.778112
[05/21/2022-02:52:36] [V] [TRT] Tactic: 512 Time: 0.779388
[05/21/2022-02:52:36] [V] [TRT] Tactic: -32 Time: 0.884752
[05/21/2022-02:52:36] [V] [TRT] Tactic: -64 Time: 0.824206
[05/21/2022-02:52:36] [V] [TRT] Tactic: -128 Time: 0.820527
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 128 Time: 0.777435
[05/21/2022-02:52:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:36] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 24 Time: 0.183731
[05/21/2022-02:52:36] [V] [TRT] Tactic: 25 Time: 0.159147
[05/21/2022-02:52:36] [V] [TRT] Tactic: 26 Time: 0.163743
[05/21/2022-02:52:36] [V] [TRT] Tactic: 27 Time: 0.157298
[05/21/2022-02:52:36] [V] [TRT] Tactic: 31 Time: 0.186205
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 27 Time: 0.157298
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 128 Time: 0.777943
[05/21/2022-02:52:36] [V] [TRT] Tactic: 256 Time: 0.778392
[05/21/2022-02:52:36] [V] [TRT] Tactic: 512 Time: 0.780169
[05/21/2022-02:52:36] [V] [TRT] Tactic: -32 Time: 0.885593
[05/21/2022-02:52:36] [V] [TRT] Tactic: -64 Time: 0.824707
[05/21/2022-02:52:36] [V] [TRT] Tactic: -128 Time: 0.820247
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 128 Time: 0.777943
[05/21/2022-02:52:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:36] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 0 Time: 0.201973
[05/21/2022-02:52:36] [V] [TRT] Tactic: 1 Time: 0.154277
[05/21/2022-02:52:36] [V] [TRT] Tactic: 2 Time: 0.145905
[05/21/2022-02:52:36] [V] [TRT] Tactic: 3 Time: 0.124446
[05/21/2022-02:52:36] [V] [TRT] Tactic: 4 Time: 0.124088
[05/21/2022-02:52:36] [V] [TRT] Tactic: 5 Time: 0.117187
[05/21/2022-02:52:36] [V] [TRT] Tactic: 6 Time: 0.112428
[05/21/2022-02:52:36] [V] [TRT] Tactic: 7 Time: 0.108933
[05/21/2022-02:52:36] [V] [TRT] Tactic: 8 Time: 0.103522
[05/21/2022-02:52:36] [V] [TRT] Tactic: 9 Time: 0.105651
[05/21/2022-02:52:36] [V] [TRT] Tactic: 28 Time: 0.199759
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 8 Time: 0.103522
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 128 Time: 0.807917
[05/21/2022-02:52:36] [V] [TRT] Tactic: 256 Time: 0.798737
[05/21/2022-02:52:36] [V] [TRT] Tactic: 512 Time: 0.752461
[05/21/2022-02:52:36] [V] [TRT] Tactic: -32 Time: 0.909968
[05/21/2022-02:52:36] [V] [TRT] Tactic: -64 Time: 0.836367
[05/21/2022-02:52:36] [V] [TRT] Tactic: -128 Time: 0.830931
[05/21/2022-02:52:36] [V] [TRT] Fastest Tactic: 512 Time: 0.752461
[05/21/2022-02:52:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:36] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-02:52:36] [V] [TRT] Tactic: 0 Time: 0.171035
[05/21/2022-02:52:36] [V] [TRT] Tactic: 1 Time: 0.157051
[05/21/2022-02:52:36] [V] [TRT] Tactic: 2 Time: 0.147774
[05/21/2022-02:52:37] [V] [TRT] Tactic: 3 Time: 0.14293
[05/21/2022-02:52:37] [V] [TRT] Tactic: 4 Time: 0.140664
[05/21/2022-02:52:37] [V] [TRT] Tactic: 5 Time: 0.14069
[05/21/2022-02:52:37] [V] [TRT] Tactic: 6 Time: 0.141302
[05/21/2022-02:52:37] [V] [TRT] Tactic: 7 Time: 0.140371
[05/21/2022-02:52:37] [V] [TRT] Tactic: 8 Time: 0.154382
[05/21/2022-02:52:37] [V] [TRT] Tactic: 9 Time: 0.188438
[05/21/2022-02:52:37] [V] [TRT] Tactic: 10 Time: 0.216419
[05/21/2022-02:52:37] [V] [TRT] Tactic: 11 Time: 0.17123
[05/21/2022-02:52:37] [V] [TRT] Tactic: 12 Time: 0.16321
[05/21/2022-02:52:37] [V] [TRT] Tactic: 13 Time: 0.138027
[05/21/2022-02:52:37] [V] [TRT] Tactic: 14 Time: 0.143054
[05/21/2022-02:52:37] [V] [TRT] Tactic: 15 Time: 0.13556
[05/21/2022-02:52:37] [V] [TRT] Tactic: 16 Time: 0.123594
[05/21/2022-02:52:37] [V] [TRT] Tactic: 17 Time: 0.126257
[05/21/2022-02:52:37] [V] [TRT] Tactic: 18 Time: 0.122637
[05/21/2022-02:52:37] [V] [TRT] Tactic: 19 Time: 0.125234
[05/21/2022-02:52:37] [V] [TRT] Tactic: 28 Time: 0.170612
[05/21/2022-02:52:37] [V] [TRT] Tactic: 29 Time: 0.212246
[05/21/2022-02:52:37] [V] [TRT] Fastest Tactic: 18 Time: 0.122637
[05/21/2022-02:52:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-02:52:37] [V] [TRT] Tactic: 128 Time: 0.807897
[05/21/2022-02:52:37] [V] [TRT] Tactic: 256 Time: 0.79849
[05/21/2022-02:52:37] [V] [TRT] Tactic: 512 Time: 0.754629
[05/21/2022-02:52:37] [V] [TRT] Tactic: -32 Time: 0.909987
[05/21/2022-02:52:37] [V] [TRT] Tactic: -64 Time: 0.837285
[05/21/2022-02:52:37] [V] [TRT] Tactic: -128 Time: 0.829941
[05/21/2022-02:52:37] [V] [TRT] Fastest Tactic: 512 Time: 0.754629
[05/21/2022-02:52:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1), Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128), Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1), Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1), Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1), Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:52:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:37] [V] [TRT] Tactic: 0 Time: 0.236764
[05/21/2022-02:52:37] [V] [TRT] Tactic: 1 Time: 0.167252
[05/21/2022-02:52:37] [V] [TRT] Tactic: 2 Time: 0.158054
[05/21/2022-02:52:37] [V] [TRT] Tactic: 3 Time: 0.127956
[05/21/2022-02:52:37] [V] [TRT] Tactic: 4 Time: 0.118665
[05/21/2022-02:52:37] [V] [TRT] Tactic: 5 Time: 0.116732
[05/21/2022-02:52:37] [V] [TRT] Tactic: 6 Time: 0.112715
[05/21/2022-02:52:37] [V] [TRT] Tactic: 7 Time: 0.0981836
[05/21/2022-02:52:37] [V] [TRT] Tactic: 8 Time: 0.0954689
[05/21/2022-02:52:37] [V] [TRT] Tactic: 9 Time: 0.0980404
[05/21/2022-02:52:37] [V] [TRT] Tactic: 28 Time: 0.234538
[05/21/2022-02:52:37] [V] [TRT] Fastest Tactic: 8 Time: 0.0954689
[05/21/2022-02:52:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-02:52:37] [V] [TRT] Tactic: 128 Time: 0.758346
[05/21/2022-02:52:37] [V] [TRT] Tactic: 256 Time: 0.757936
[05/21/2022-02:52:37] [V] [TRT] Tactic: 512 Time: 0.758711
[05/21/2022-02:52:37] [V] [TRT] Tactic: -32 Time: 0.759505
[05/21/2022-02:52:37] [V] [TRT] Tactic: -64 Time: 0.712936
[05/21/2022-02:52:37] [V] [TRT] Tactic: -128 Time: 0.715026
[05/21/2022-02:52:37] [V] [TRT] Fastest Tactic: -64 Time: 0.712936
[05/21/2022-02:52:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:37] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:52:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:37] [V] [TRT] Tactic: 0 Time: 0.237051
[05/21/2022-02:52:37] [V] [TRT] Tactic: 1 Time: 0.167383
[05/21/2022-02:52:37] [V] [TRT] Tactic: 2 Time: 0.157819
[05/21/2022-02:52:37] [V] [TRT] Tactic: 3 Time: 0.128327
[05/21/2022-02:52:37] [V] [TRT] Tactic: 4 Time: 0.119414
[05/21/2022-02:52:37] [V] [TRT] Tactic: 5 Time: 0.116855
[05/21/2022-02:52:37] [V] [TRT] Tactic: 6 Time: 0.159316
[05/21/2022-02:52:37] [V] [TRT] Tactic: 7 Time: 0.138952
[05/21/2022-02:52:38] [V] [TRT] Tactic: 8 Time: 0.135573
[05/21/2022-02:52:38] [V] [TRT] Tactic: 9 Time: 0.129017
[05/21/2022-02:52:38] [V] [TRT] Tactic: 28 Time: 0.234225
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: 5 Time: 0.116855
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-02:52:38] [V] [TRT] Tactic: 128 Time: 0.758054
[05/21/2022-02:52:38] [V] [TRT] Tactic: 256 Time: 0.757272
[05/21/2022-02:52:38] [V] [TRT] Tactic: 512 Time: 0.758763
[05/21/2022-02:52:38] [V] [TRT] Tactic: -32 Time: 0.733112
[05/21/2022-02:52:38] [V] [TRT] Tactic: -64 Time: 0.764739
[05/21/2022-02:52:38] [V] [TRT] Tactic: -128 Time: 0.836087
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: -32 Time: 0.733112
[05/21/2022-02:52:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:38] [V] [TRT] Tactic: 24 Time: 0.131673
[05/21/2022-02:52:38] [V] [TRT] Tactic: 25 Time: 0.119818
[05/21/2022-02:52:38] [V] [TRT] Tactic: 26 Time: 0.119909
[05/21/2022-02:52:38] [V] [TRT] Tactic: 27 Time: 0.119225
[05/21/2022-02:52:38] [V] [TRT] Tactic: 31 Time: 0.131797
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: 27 Time: 0.119225
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-02:52:38] [V] [TRT] Tactic: 128 Time: 0.758581
[05/21/2022-02:52:38] [V] [TRT] Tactic: 256 Time: 0.758086
[05/21/2022-02:52:38] [V] [TRT] Tactic: 512 Time: 0.758372
[05/21/2022-02:52:38] [V] [TRT] Tactic: -32 Time: 0.759492
[05/21/2022-02:52:38] [V] [TRT] Tactic: -64 Time: 0.713795
[05/21/2022-02:52:38] [V] [TRT] Tactic: -128 Time: 0.715859
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: -64 Time: 0.713795
[05/21/2022-02:52:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:38] [V] [TRT] Tactic: 0 Time: 0.243574
[05/21/2022-02:52:38] [V] [TRT] Tactic: 1 Time: 0.174271
[05/21/2022-02:52:38] [V] [TRT] Tactic: 2 Time: 0.162702
[05/21/2022-02:52:38] [V] [TRT] Tactic: 3 Time: 0.130612
[05/21/2022-02:52:38] [V] [TRT] Tactic: 4 Time: 0.123561
[05/21/2022-02:52:38] [V] [TRT] Tactic: 5 Time: 0.120794
[05/21/2022-02:52:38] [V] [TRT] Tactic: 6 Time: 0.112272
[05/21/2022-02:52:38] [V] [TRT] Tactic: 7 Time: 0.10069
[05/21/2022-02:52:38] [V] [TRT] Tactic: 8 Time: 0.101536
[05/21/2022-02:52:38] [V] [TRT] Tactic: 9 Time: 0.100456
[05/21/2022-02:52:38] [V] [TRT] Tactic: 28 Time: 0.242936
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: 9 Time: 0.100456
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-02:52:38] [V] [TRT] Tactic: 128 Time: 0.730807
[05/21/2022-02:52:38] [V] [TRT] Tactic: 256 Time: 0.724303
[05/21/2022-02:52:38] [V] [TRT] Tactic: 512 Time: 0.667207
[05/21/2022-02:52:38] [V] [TRT] Tactic: -32 Time: 0.762051
[05/21/2022-02:52:38] [V] [TRT] Tactic: -64 Time: 0.710293
[05/21/2022-02:52:38] [V] [TRT] Tactic: -128 Time: 0.711556
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: 512 Time: 0.667207
[05/21/2022-02:52:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:38] [V] [TRT] Tactic: 0 Time: 0.166985
[05/21/2022-02:52:38] [V] [TRT] Tactic: 1 Time: 0.130729
[05/21/2022-02:52:38] [V] [TRT] Tactic: 2 Time: 0.129688
[05/21/2022-02:52:38] [V] [TRT] Tactic: 3 Time: 0.116152
[05/21/2022-02:52:38] [V] [TRT] Tactic: 4 Time: 0.113411
[05/21/2022-02:52:38] [V] [TRT] Tactic: 5 Time: 0.115118
[05/21/2022-02:52:38] [V] [TRT] Tactic: 6 Time: 0.111485
[05/21/2022-02:52:38] [V] [TRT] Tactic: 7 Time: 0.107396
[05/21/2022-02:52:38] [V] [TRT] Tactic: 8 Time: 0.10651
[05/21/2022-02:52:38] [V] [TRT] Tactic: 9 Time: 0.111803
[05/21/2022-02:52:38] [V] [TRT] Tactic: 10 Time: 0.251035
[05/21/2022-02:52:38] [V] [TRT] Tactic: 11 Time: 0.181556
[05/21/2022-02:52:38] [V] [TRT] Tactic: 12 Time: 0.170195
[05/21/2022-02:52:38] [V] [TRT] Tactic: 13 Time: 0.135345
[05/21/2022-02:52:38] [V] [TRT] Tactic: 14 Time: 0.128607
[05/21/2022-02:52:38] [V] [TRT] Tactic: 15 Time: 0.129843
[05/21/2022-02:52:38] [V] [TRT] Tactic: 16 Time: 0.115059
[05/21/2022-02:52:38] [V] [TRT] Tactic: 17 Time: 0.102656
[05/21/2022-02:52:38] [V] [TRT] Tactic: 18 Time: 0.10459
[05/21/2022-02:52:38] [V] [TRT] Tactic: 19 Time: 0.108756
[05/21/2022-02:52:38] [V] [TRT] Tactic: 28 Time: 0.163646
[05/21/2022-02:52:38] [V] [TRT] Tactic: 29 Time: 0.251654
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: 17 Time: 0.102656
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-02:52:38] [V] [TRT] Tactic: 128 Time: 0.730853
[05/21/2022-02:52:38] [V] [TRT] Tactic: 256 Time: 0.722923
[05/21/2022-02:52:38] [V] [TRT] Tactic: 512 Time: 0.668079
[05/21/2022-02:52:38] [V] [TRT] Tactic: -32 Time: 0.762506
[05/21/2022-02:52:38] [V] [TRT] Tactic: -64 Time: 0.710468
[05/21/2022-02:52:38] [V] [TRT] Tactic: -128 Time: 0.712064
[05/21/2022-02:52:38] [V] [TRT] Fastest Tactic: 512 Time: 0.668079
[05/21/2022-02:52:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:38] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Float(10368,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:52:38] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:38] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:38] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:38] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:38] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:39] [V] [TRT] Tactic: 0 Time: 10.4554
[05/21/2022-02:52:39] [V] [TRT] Tactic: 1 Time: 7.93007
[05/21/2022-02:52:39] [V] [TRT] Tactic: 2 Time: 7.17913
[05/21/2022-02:52:39] [V] [TRT] Tactic: 5 skipped. Scratch requested: 578511872, available: 536870912
[05/21/2022-02:52:39] [V] [TRT] Fastest Tactic: 2 Time: 7.17913
[05/21/2022-02:52:39] [V] [TRT] Setting workspace to 578511872enables more tactics for profiling
[05/21/2022-02:52:39] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:39] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:39] [V] [TRT] Tactic: 1062367460111450758 Time: 5.71493
[05/21/2022-02:52:39] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:52:39] [V] [TRT] Tactic: 1754984623894446479 Time: 6.78294
[05/21/2022-02:52:39] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:52:39] [V] [TRT] Tactic: 3611739942397549984 Time: 4.72037
[05/21/2022-02:52:39] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:52:39] [V] [TRT] Tactic: 4337000649858996379 Time: 4.81313
[05/21/2022-02:52:39] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:40] [V] [TRT] Tactic: 4501471010995462441 Time: 4.72391
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:40] [V] [TRT] Tactic: 5137655947464784826 Time: 4.6422
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:40] [V] [TRT] Tactic: 5288347012147084929 Time: 4.60889
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:40] [V] [TRT] Tactic: 6645123197870846056 Time: 4.70741
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:40] [V] [TRT] Tactic: 7144526460361122478 Time: 6.41333
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:52:40] [V] [TRT] Tactic: -9137461792520977713 Time: 4.7963
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:40] [V] [TRT] Tactic: -8262349710178828730 Time: 4.77396
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:52:40] [V] [TRT] Tactic: -8133971918129952780 Time: 5.44341
[05/21/2022-02:52:40] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:52:41] [V] [TRT] Tactic: -6092040395344634144 Time: 5.95475
[05/21/2022-02:52:41] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:41] [V] [TRT] Tactic: -4787320710726427159 Time: 6.90361
[05/21/2022-02:52:41] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:41] [V] [TRT] Tactic: -3456450830548107839 Time: 5.32512
[05/21/2022-02:52:41] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:41] [V] [TRT] Tactic: -1218658103698133241 Time: 5.19659
[05/21/2022-02:52:41] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:41] [V] [TRT] Tactic: -836875257600482091 Time: 5.30436
[05/21/2022-02:52:41] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:41] [V] [TRT] Tactic: -410470605513481746 Time: 4.57326
[05/21/2022-02:52:41] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 4.57326
[05/21/2022-02:52:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-02:52:41] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:52:41] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:41] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:41] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:41] [V] [TRT] Tactic: -9153228964338181824 Time: 6.40924
[05/21/2022-02:52:41] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:41] [V] [TRT] Tactic: -7394439838318485025 Time: 4.59857
[05/21/2022-02:52:41] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.59857
[05/21/2022-02:52:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:41] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:52:41] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:42] [V] [TRT] Tactic: 0 Time: 10.8366
[05/21/2022-02:52:42] [V] [TRT] Tactic: 1 Time: 8.22102
[05/21/2022-02:52:42] [V] [TRT] Tactic: 2 Time: 6.97445
[05/21/2022-02:52:42] [V] [TRT] Tactic: 5 skipped. Scratch requested: 577810944, available: 536870912
[05/21/2022-02:52:42] [V] [TRT] Fastest Tactic: 2 Time: 6.97445
[05/21/2022-02:52:42] [V] [TRT] Setting workspace to 577810944enables more tactics for profiling
[05/21/2022-02:52:42] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:42] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:52:42] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:52:42] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:42] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:42] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:42] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:42] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:42] [V] [TRT] Tactic: 3564772625446233998 Time: 2.85663
[05/21/2022-02:52:42] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:52:42] [V] [TRT] Tactic: 3650389455493082349 Time: 2.95361
[05/21/2022-02:52:42] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:42] [V] [TRT] Tactic: 5319956359050645452 Time: 2.6301
[05/21/2022-02:52:42] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:42] [V] [TRT] Tactic: 7205456024582378848 Time: 2.35189
[05/21/2022-02:52:42] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:52:42] [V] [TRT] Tactic: -6490690591794140522 Time: 2.37296
[05/21/2022-02:52:42] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:52:42] [V] [TRT] Tactic: -4686027666808657977 Time: 2.39124
[05/21/2022-02:52:43] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:43] [V] [TRT] Tactic: -4212163711445252890 Time: 2.27265
[05/21/2022-02:52:43] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:43] [V] [TRT] Tactic: -3898373634979201110 Time: 2.36432
[05/21/2022-02:52:43] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:43] [V] [TRT] Tactic: -2409163523992614473 Time: 2.31309
[05/21/2022-02:52:43] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 2.27265
[05/21/2022-02:52:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:52:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:43] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:52:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:43] [V] [TRT] Tactic: 0 Time: 0.187845
[05/21/2022-02:52:43] [V] [TRT] Tactic: 1 Time: 0.142253
[05/21/2022-02:52:43] [V] [TRT] Tactic: 2 Time: 0.142422
[05/21/2022-02:52:43] [V] [TRT] Tactic: 3 Time: 0.119037
[05/21/2022-02:52:43] [V] [TRT] Tactic: 4 Time: 0.102389
[05/21/2022-02:52:43] [V] [TRT] Tactic: 5 Time: 0.105091
[05/21/2022-02:52:43] [V] [TRT] Tactic: 6 Time: 0.111022
[05/21/2022-02:52:43] [V] [TRT] Tactic: 7 Time: 0.0910417
[05/21/2022-02:52:43] [V] [TRT] Tactic: 8 Time: 0.0864389
[05/21/2022-02:52:43] [V] [TRT] Tactic: 9 Time: 0.092526
[05/21/2022-02:52:43] [V] [TRT] Tactic: 28 Time: 0.185254
[05/21/2022-02:52:43] [V] [TRT] Fastest Tactic: 8 Time: 0.0864389
[05/21/2022-02:52:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-02:52:43] [V] [TRT] Tactic: 128 Time: 0.672969
[05/21/2022-02:52:43] [V] [TRT] Tactic: 256 Time: 0.674062
[05/21/2022-02:52:43] [V] [TRT] Tactic: 512 Time: 0.675156
[05/21/2022-02:52:43] [V] [TRT] Tactic: -32 Time: 0.757246
[05/21/2022-02:52:43] [V] [TRT] Tactic: -64 Time: 0.708464
[05/21/2022-02:52:43] [V] [TRT] Tactic: -128 Time: 0.70722
[05/21/2022-02:52:43] [V] [TRT] Fastest Tactic: 128 Time: 0.672969
[05/21/2022-02:52:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:43] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:52:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:43] [V] [TRT] Tactic: 0 Time: 0.187656
[05/21/2022-02:52:43] [V] [TRT] Tactic: 1 Time: 0.141589
[05/21/2022-02:52:43] [V] [TRT] Tactic: 2 Time: 0.13498
[05/21/2022-02:52:43] [V] [TRT] Tactic: 3 Time: 0.11791
[05/21/2022-02:52:43] [V] [TRT] Tactic: 4 Time: 0.102363
[05/21/2022-02:52:43] [V] [TRT] Tactic: 5 Time: 0.104909
[05/21/2022-02:52:43] [V] [TRT] Tactic: 6 Time: 0.109297
[05/21/2022-02:52:43] [V] [TRT] Tactic: 7 Time: 0.089694
[05/21/2022-02:52:43] [V] [TRT] Tactic: 8 Time: 0.0849546
[05/21/2022-02:52:43] [V] [TRT] Tactic: 9 Time: 0.0913217
[05/21/2022-02:52:43] [V] [TRT] Tactic: 28 Time: 0.184525
[05/21/2022-02:52:43] [V] [TRT] Fastest Tactic: 8 Time: 0.0849546
[05/21/2022-02:52:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-02:52:43] [V] [TRT] Tactic: 128 Time: 0.67308
[05/21/2022-02:52:43] [V] [TRT] Tactic: 256 Time: 0.673698
[05/21/2022-02:52:43] [V] [TRT] Tactic: 512 Time: 0.674707
[05/21/2022-02:52:43] [V] [TRT] Tactic: -32 Time: 0.757207
[05/21/2022-02:52:43] [V] [TRT] Tactic: -64 Time: 0.707643
[05/21/2022-02:52:43] [V] [TRT] Tactic: -128 Time: 0.705156
[05/21/2022-02:52:43] [V] [TRT] Fastest Tactic: 128 Time: 0.67308
[05/21/2022-02:52:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:43] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:52:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:43] [V] [TRT] Tactic: 24 Time: 0.1303
[05/21/2022-02:52:43] [V] [TRT] Tactic: 25 Time: 0.120065
[05/21/2022-02:52:43] [V] [TRT] Tactic: 26 Time: 0.118997
[05/21/2022-02:52:43] [V] [TRT] Tactic: 27 Time: 0.121029
[05/21/2022-02:52:44] [V] [TRT] Tactic: 31 Time: 0.129447
[05/21/2022-02:52:44] [V] [TRT] Fastest Tactic: 26 Time: 0.118997
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-02:52:44] [V] [TRT] Tactic: 128 Time: 0.672285
[05/21/2022-02:52:44] [V] [TRT] Tactic: 256 Time: 0.67399
[05/21/2022-02:52:44] [V] [TRT] Tactic: 512 Time: 0.675378
[05/21/2022-02:52:44] [V] [TRT] Tactic: -32 Time: 0.756484
[05/21/2022-02:52:44] [V] [TRT] Tactic: -64 Time: 0.708561
[05/21/2022-02:52:44] [V] [TRT] Tactic: -128 Time: 0.70541
[05/21/2022-02:52:44] [V] [TRT] Fastest Tactic: 128 Time: 0.672285
[05/21/2022-02:52:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:52:44] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:44] [V] [TRT] Tactic: 0 Time: 0.190775
[05/21/2022-02:52:44] [V] [TRT] Tactic: 1 Time: 0.146627
[05/21/2022-02:52:44] [V] [TRT] Tactic: 2 Time: 0.136224
[05/21/2022-02:52:44] [V] [TRT] Tactic: 3 Time: 0.118919
[05/21/2022-02:52:44] [V] [TRT] Tactic: 4 Time: 0.107689
[05/21/2022-02:52:44] [V] [TRT] Tactic: 5 Time: 0.109278
[05/21/2022-02:52:44] [V] [TRT] Tactic: 6 Time: 0.106686
[05/21/2022-02:52:44] [V] [TRT] Tactic: 7 Time: 0.0933592
[05/21/2022-02:52:44] [V] [TRT] Tactic: 8 Time: 0.0928193
[05/21/2022-02:52:44] [V] [TRT] Tactic: 9 Time: 0.0955207
[05/21/2022-02:52:44] [V] [TRT] Tactic: 28 Time: 0.191667
[05/21/2022-02:52:44] [V] [TRT] Fastest Tactic: 8 Time: 0.0928193
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-02:52:44] [V] [TRT] Tactic: 128 Time: 0.694297
[05/21/2022-02:52:44] [V] [TRT] Tactic: 256 Time: 0.685312
[05/21/2022-02:52:44] [V] [TRT] Tactic: 512 Time: 0.641849
[05/21/2022-02:52:44] [V] [TRT] Tactic: -32 Time: 0.77571
[05/21/2022-02:52:44] [V] [TRT] Tactic: -64 Time: 0.704368
[05/21/2022-02:52:44] [V] [TRT] Tactic: -128 Time: 0.699284
[05/21/2022-02:52:44] [V] [TRT] Fastest Tactic: 512 Time: 0.641849
[05/21/2022-02:52:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:44] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:44] [V] [TRT] Tactic: 0 Time: 0.147637
[05/21/2022-02:52:44] [V] [TRT] Tactic: 1 Time: 0.121484
[05/21/2022-02:52:44] [V] [TRT] Tactic: 2 Time: 0.120696
[05/21/2022-02:52:44] [V] [TRT] Tactic: 3 Time: 0.111758
[05/21/2022-02:52:44] [V] [TRT] Tactic: 4 Time: 0.109199
[05/21/2022-02:52:44] [V] [TRT] Tactic: 5 Time: 0.111511
[05/21/2022-02:52:44] [V] [TRT] Tactic: 6 Time: 0.109681
[05/21/2022-02:52:44] [V] [TRT] Tactic: 7 Time: 0.106328
[05/21/2022-02:52:44] [V] [TRT] Tactic: 8 Time: 0.106087
[05/21/2022-02:52:44] [V] [TRT] Tactic: 9 Time: 0.109479
[05/21/2022-02:52:44] [V] [TRT] Tactic: 10 Time: 0.201152
[05/21/2022-02:52:44] [V] [TRT] Tactic: 11 Time: 0.151471
[05/21/2022-02:52:44] [V] [TRT] Tactic: 12 Time: 0.143796
[05/21/2022-02:52:44] [V] [TRT] Tactic: 13 Time: 0.120684
[05/21/2022-02:52:44] [V] [TRT] Tactic: 14 Time: 0.111569
[05/21/2022-02:52:44] [V] [TRT] Tactic: 15 Time: 0.113802
[05/21/2022-02:52:44] [V] [TRT] Tactic: 16 Time: 0.108073
[05/21/2022-02:52:44] [V] [TRT] Tactic: 17 Time: 0.0956384
[05/21/2022-02:52:44] [V] [TRT] Tactic: 18 Time: 0.0942055
[05/21/2022-02:52:44] [V] [TRT] Tactic: 19 Time: 0.101563
[05/21/2022-02:52:44] [V] [TRT] Tactic: 28 Time: 0.144902
[05/21/2022-02:52:44] [V] [TRT] Tactic: 29 Time: 0.197357
[05/21/2022-02:52:44] [V] [TRT] Fastest Tactic: 18 Time: 0.0942055
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-02:52:44] [V] [TRT] Tactic: 128 Time: 0.693561
[05/21/2022-02:52:44] [V] [TRT] Tactic: 256 Time: 0.685925
[05/21/2022-02:52:44] [V] [TRT] Tactic: 512 Time: 0.642272
[05/21/2022-02:52:44] [V] [TRT] Tactic: -32 Time: 0.75806
[05/21/2022-02:52:44] [V] [TRT] Tactic: -64 Time: 0.704512
[05/21/2022-02:52:44] [V] [TRT] Tactic: -128 Time: 0.699805
[05/21/2022-02:52:44] [V] [TRT] Fastest Tactic: 512 Time: 0.642272
[05/21/2022-02:52:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:52:44] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:44] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:44] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:44] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:44] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:44] [V] [TRT] Tactic: 0 Time: 2.19247
[05/21/2022-02:52:44] [V] [TRT] Tactic: 1 Time: 1.86803
[05/21/2022-02:52:44] [V] [TRT] Tactic: 2 Time: 1.87531
[05/21/2022-02:52:44] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2287206400, available: 536870912
[05/21/2022-02:52:45] [V] [TRT] Tactic: 5 Time: 18.9203
[05/21/2022-02:52:45] [V] [TRT] Fastest Tactic: 1 Time: 1.86803
[05/21/2022-02:52:45] [V] [TRT] Setting workspace to 2287206400enables more tactics for profiling
[05/21/2022-02:52:45] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:45] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:45] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:45] [V] [TRT] Tactic: 1062367460111450758 Time: 1.42697
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:52:45] [V] [TRT] Tactic: 1698681053543049347 Time: 1.34445
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:45] [V] [TRT] Tactic: 4501471010995462441 Time: 1.09159
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:45] [V] [TRT] Tactic: 5137655947464784826 Time: 1.08084
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:45] [V] [TRT] Tactic: 5288347012147084929 Time: 1.08073
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:52:45] [V] [TRT] Tactic: 5326823351883942011 Time: 1.04346
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:52:45] [V] [TRT] Tactic: 5500448035057547314 Time: 1.15492
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:45] [V] [TRT] Tactic: 6645123197870846056 Time: 1.0984
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:45] [V] [TRT] Tactic: 7144526460361122478 Time: 1.49557
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:45] [V] [TRT] Tactic: -8262349710178828730 Time: 1.09761
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:52:45] [V] [TRT] Tactic: -6576203419454146580 Time: 1.26049
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:45] [V] [TRT] Tactic: -4787320710726427159 Time: 1.55262
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:45] [V] [TRT] Tactic: -3456450830548107839 Time: 1.32409
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:45] [V] [TRT] Tactic: -1218658103698133241 Time: 1.24421
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:45] [V] [TRT] Tactic: -836875257600482091 Time: 1.20435
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:45] [V] [TRT] Tactic: -410470605513481746 Time: 1.06251
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:52:45] [V] [TRT] Tactic: -377491875521947884 Time: 1.06949
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:52:45] [V] [TRT] Tactic: -37215280111360163 Time: 1.0564
[05/21/2022-02:52:45] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 1.04346
[05/21/2022-02:52:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:52:45] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:52:45] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:45] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:45] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:45] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:52:45] [V] [TRT] Tactic: 3886731678879822788 Time: 1.09149
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:52:45] [V] [TRT] Tactic: 6629944304117643200 Time: 1.8476
[05/21/2022-02:52:45] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:46] [V] [TRT] Tactic: -9153228964338181824 Time: 1.85563
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:46] [V] [TRT] Tactic: -7394439838318485025 Time: 1.08898
[05/21/2022-02:52:46] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.08898
[05/21/2022-02:52:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:46] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:46] [V] [TRT] Tactic: 0 Time: 2.24288
[05/21/2022-02:52:46] [V] [TRT] Tactic: 1 Time: 1.9384
[05/21/2022-02:52:46] [V] [TRT] Tactic: 2 Time: 1.80226
[05/21/2022-02:52:46] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2287206400, available: 536870912
[05/21/2022-02:52:46] [V] [TRT] Tactic: 5 Time: 19.3891
[05/21/2022-02:52:46] [V] [TRT] Fastest Tactic: 2 Time: 1.80226
[05/21/2022-02:52:46] [V] [TRT] Setting workspace to 2287206400enables more tactics for profiling
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:46] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:52:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:46] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:46] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:52:46] [V] [TRT] Tactic: 3066127711859985668 Time: 0.650938
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:46] [V] [TRT] Tactic: 3564772625446233998 Time: 0.715072
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:46] [V] [TRT] Tactic: 5319956359050645452 Time: 0.671445
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:46] [V] [TRT] Tactic: 7205456024582378848 Time: 0.571999
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:52:46] [V] [TRT] Tactic: 8163473458334948789 Time: 0.548874
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:46] [V] [TRT] Tactic: -4212163711445252890 Time: 0.555625
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:46] [V] [TRT] Tactic: -3898373634979201110 Time: 0.566113
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:46] [V] [TRT] Tactic: -2409163523992614473 Time: 0.562858
[05/21/2022-02:52:46] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:52:46] [V] [TRT] Tactic: -1716393687483585322 Time: 0.542793
[05/21/2022-02:52:46] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.542793
[05/21/2022-02:52:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:52:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:46] [V] [TRT] Tactic: 0 Time: 0.1225
[05/21/2022-02:52:46] [V] [TRT] Tactic: 1 Time: 0.0873827
[05/21/2022-02:52:46] [V] [TRT] Tactic: 2 Time: 0.0824024
[05/21/2022-02:52:46] [V] [TRT] Tactic: 3 Time: 0.0677539
[05/21/2022-02:52:46] [V] [TRT] Tactic: 4 Time: 0.0625586
[05/21/2022-02:52:46] [V] [TRT] Tactic: 5 Time: 0.0614519
[05/21/2022-02:52:46] [V] [TRT] Tactic: 6 Time: 0.0603974
[05/21/2022-02:52:46] [V] [TRT] Tactic: 7 Time: 0.0516861
[05/21/2022-02:52:46] [V] [TRT] Tactic: 8 Time: 0.050918
[05/21/2022-02:52:46] [V] [TRT] Tactic: 9 Time: 0.0516342
[05/21/2022-02:52:46] [V] [TRT] Tactic: 28 Time: 0.120696
[05/21/2022-02:52:46] [V] [TRT] Fastest Tactic: 8 Time: 0.050918
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-02:52:46] [V] [TRT] Tactic: 128 Time: 0.383183
[05/21/2022-02:52:46] [V] [TRT] Tactic: 256 Time: 0.383067
[05/21/2022-02:52:46] [V] [TRT] Tactic: 512 Time: 0.383021
[05/21/2022-02:52:46] [V] [TRT] Tactic: -32 Time: 0.389056
[05/21/2022-02:52:46] [V] [TRT] Tactic: -64 Time: 0.372148
[05/21/2022-02:52:46] [V] [TRT] Tactic: -128 Time: 0.364987
[05/21/2022-02:52:46] [V] [TRT] Fastest Tactic: -128 Time: 0.364987
[05/21/2022-02:52:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:46] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:52:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:46] [V] [TRT] Tactic: 0 Time: 0.122526
[05/21/2022-02:52:47] [V] [TRT] Tactic: 1 Time: 0.087591
[05/21/2022-02:52:47] [V] [TRT] Tactic: 2 Time: 0.0827085
[05/21/2022-02:52:47] [V] [TRT] Tactic: 3 Time: 0.067884
[05/21/2022-02:52:47] [V] [TRT] Tactic: 4 Time: 0.0632877
[05/21/2022-02:52:47] [V] [TRT] Tactic: 5 Time: 0.0612106
[05/21/2022-02:52:47] [V] [TRT] Tactic: 6 Time: 0.061569
[05/21/2022-02:52:47] [V] [TRT] Tactic: 7 Time: 0.0520055
[05/21/2022-02:52:47] [V] [TRT] Tactic: 8 Time: 0.0506054
[05/21/2022-02:52:47] [V] [TRT] Tactic: 9 Time: 0.0522463
[05/21/2022-02:52:47] [V] [TRT] Tactic: 28 Time: 0.121068
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: 8 Time: 0.0506054
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 128 Time: 0.38304
[05/21/2022-02:52:47] [V] [TRT] Tactic: 256 Time: 0.382995
[05/21/2022-02:52:47] [V] [TRT] Tactic: 512 Time: 0.383112
[05/21/2022-02:52:47] [V] [TRT] Tactic: -32 Time: 0.369329
[05/21/2022-02:52:47] [V] [TRT] Tactic: -64 Time: 0.370189
[05/21/2022-02:52:47] [V] [TRT] Tactic: -128 Time: 0.386016
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: -32 Time: 0.369329
[05/21/2022-02:52:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:47] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 24 Time: 0.0709439
[05/21/2022-02:52:47] [V] [TRT] Tactic: 25 Time: 0.0639582
[05/21/2022-02:52:47] [V] [TRT] Tactic: 26 Time: 0.0623439
[05/21/2022-02:52:47] [V] [TRT] Tactic: 27 Time: 0.0677473
[05/21/2022-02:52:47] [V] [TRT] Tactic: 31 Time: 0.0709114
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: 26 Time: 0.0623439
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 128 Time: 0.383112
[05/21/2022-02:52:47] [V] [TRT] Tactic: 256 Time: 0.382695
[05/21/2022-02:52:47] [V] [TRT] Tactic: 512 Time: 0.382448
[05/21/2022-02:52:47] [V] [TRT] Tactic: -32 Time: 0.390208
[05/21/2022-02:52:47] [V] [TRT] Tactic: -64 Time: 0.372494
[05/21/2022-02:52:47] [V] [TRT] Tactic: -128 Time: 0.364238
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: -128 Time: 0.364238
[05/21/2022-02:52:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:52:47] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 0 Time: 0.125365
[05/21/2022-02:52:47] [V] [TRT] Tactic: 1 Time: 0.0903841
[05/21/2022-02:52:47] [V] [TRT] Tactic: 2 Time: 0.0845964
[05/21/2022-02:52:47] [V] [TRT] Tactic: 3 Time: 0.0691536
[05/21/2022-02:52:47] [V] [TRT] Tactic: 4 Time: 0.0648697
[05/21/2022-02:52:47] [V] [TRT] Tactic: 5 Time: 0.0631381
[05/21/2022-02:52:47] [V] [TRT] Tactic: 6 Time: 0.0597721
[05/21/2022-02:52:47] [V] [TRT] Tactic: 7 Time: 0.0533267
[05/21/2022-02:52:47] [V] [TRT] Tactic: 8 Time: 0.0537761
[05/21/2022-02:52:47] [V] [TRT] Tactic: 9 Time: 0.0534766
[05/21/2022-02:52:47] [V] [TRT] Tactic: 28 Time: 0.124902
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: 7 Time: 0.0533267
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 128 Time: 0.368874
[05/21/2022-02:52:47] [V] [TRT] Tactic: 256 Time: 0.363854
[05/21/2022-02:52:47] [V] [TRT] Tactic: 512 Time: 0.339707
[05/21/2022-02:52:47] [V] [TRT] Tactic: -32 Time: 0.387324
[05/21/2022-02:52:47] [V] [TRT] Tactic: -64 Time: 0.367038
[05/21/2022-02:52:47] [V] [TRT] Tactic: -128 Time: 0.364128
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: 512 Time: 0.339707
[05/21/2022-02:52:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:52:47] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 0 Time: 0.0869856
[05/21/2022-02:52:47] [V] [TRT] Tactic: 1 Time: 0.0689255
[05/21/2022-02:52:47] [V] [TRT] Tactic: 2 Time: 0.0685221
[05/21/2022-02:52:47] [V] [TRT] Tactic: 3 Time: 0.0623894
[05/21/2022-02:52:47] [V] [TRT] Tactic: 4 Time: 0.060612
[05/21/2022-02:52:47] [V] [TRT] Tactic: 5 Time: 0.0610612
[05/21/2022-02:52:47] [V] [TRT] Tactic: 6 Time: 0.0602541
[05/21/2022-02:52:47] [V] [TRT] Tactic: 7 Time: 0.0577084
[05/21/2022-02:52:47] [V] [TRT] Tactic: 8 Time: 0.0567709
[05/21/2022-02:52:47] [V] [TRT] Tactic: 9 Time: 0.0593228
[05/21/2022-02:52:47] [V] [TRT] Tactic: 10 Time: 0.129505
[05/21/2022-02:52:47] [V] [TRT] Tactic: 11 Time: 0.094772
[05/21/2022-02:52:47] [V] [TRT] Tactic: 12 Time: 0.0888671
[05/21/2022-02:52:47] [V] [TRT] Tactic: 13 Time: 0.070879
[05/21/2022-02:52:47] [V] [TRT] Tactic: 14 Time: 0.0674938
[05/21/2022-02:52:47] [V] [TRT] Tactic: 15 Time: 0.0675846
[05/21/2022-02:52:47] [V] [TRT] Tactic: 16 Time: 0.0612108
[05/21/2022-02:52:47] [V] [TRT] Tactic: 17 Time: 0.0547916
[05/21/2022-02:52:47] [V] [TRT] Tactic: 18 Time: 0.0554751
[05/21/2022-02:52:47] [V] [TRT] Tactic: 19 Time: 0.0574088
[05/21/2022-02:52:47] [V] [TRT] Tactic: 28 Time: 0.0852735
[05/21/2022-02:52:47] [V] [TRT] Tactic: 29 Time: 0.129961
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: 17 Time: 0.0547916
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 128 Time: 0.369785
[05/21/2022-02:52:47] [V] [TRT] Tactic: 256 Time: 0.363561
[05/21/2022-02:52:47] [V] [TRT] Tactic: 512 Time: 0.340365
[05/21/2022-02:52:47] [V] [TRT] Tactic: -32 Time: 0.387507
[05/21/2022-02:52:47] [V] [TRT] Tactic: -64 Time: 0.367455
[05/21/2022-02:52:47] [V] [TRT] Tactic: -128 Time: 0.363737
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: 512 Time: 0.340365
[05/21/2022-02:52:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:47] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:47] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 0 Time: 0.122324
[05/21/2022-02:52:47] [V] [TRT] Tactic: 1 Time: 0.087604
[05/21/2022-02:52:47] [V] [TRT] Tactic: 2 Time: 0.0821937
[05/21/2022-02:52:47] [V] [TRT] Tactic: 3 Time: 0.0672266
[05/21/2022-02:52:47] [V] [TRT] Tactic: 4 Time: 0.0625519
[05/21/2022-02:52:47] [V] [TRT] Tactic: 5 Time: 0.0614714
[05/21/2022-02:52:47] [V] [TRT] Tactic: 6 Time: 0.0606186
[05/21/2022-02:52:47] [V] [TRT] Tactic: 7 Time: 0.0514976
[05/21/2022-02:52:47] [V] [TRT] Tactic: 8 Time: 0.0509115
[05/21/2022-02:52:47] [V] [TRT] Tactic: 9 Time: 0.0517251
[05/21/2022-02:52:47] [V] [TRT] Tactic: 28 Time: 0.121048
[05/21/2022-02:52:47] [V] [TRT] Fastest Tactic: 8 Time: 0.0509115
[05/21/2022-02:52:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-02:52:47] [V] [TRT] Tactic: 128 Time: 0.382897
[05/21/2022-02:52:48] [V] [TRT] Tactic: 256 Time: 0.382532
[05/21/2022-02:52:48] [V] [TRT] Tactic: 512 Time: 0.382839
[05/21/2022-02:52:48] [V] [TRT] Tactic: -32 Time: 0.389147
[05/21/2022-02:52:48] [V] [TRT] Tactic: -64 Time: 0.372207
[05/21/2022-02:52:48] [V] [TRT] Tactic: -128 Time: 0.364883
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: -128 Time: 0.364883
[05/21/2022-02:52:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:48] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 0 Time: 0.122487
[05/21/2022-02:52:48] [V] [TRT] Tactic: 1 Time: 0.0876238
[05/21/2022-02:52:48] [V] [TRT] Tactic: 2 Time: 0.0826171
[05/21/2022-02:52:48] [V] [TRT] Tactic: 3 Time: 0.0675652
[05/21/2022-02:52:48] [V] [TRT] Tactic: 4 Time: 0.0632745
[05/21/2022-02:52:48] [V] [TRT] Tactic: 5 Time: 0.0618424
[05/21/2022-02:52:48] [V] [TRT] Tactic: 6 Time: 0.0621356
[05/21/2022-02:52:48] [V] [TRT] Tactic: 7 Time: 0.0520184
[05/21/2022-02:52:48] [V] [TRT] Tactic: 8 Time: 0.0509961
[05/21/2022-02:52:48] [V] [TRT] Tactic: 9 Time: 0.0526171
[05/21/2022-02:52:48] [V] [TRT] Tactic: 28 Time: 0.121243
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: 8 Time: 0.0509961
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 128 Time: 0.382578
[05/21/2022-02:52:48] [V] [TRT] Tactic: 256 Time: 0.382845
[05/21/2022-02:52:48] [V] [TRT] Tactic: 512 Time: 0.382565
[05/21/2022-02:52:48] [V] [TRT] Tactic: -32 Time: 0.369056
[05/21/2022-02:52:48] [V] [TRT] Tactic: -64 Time: 0.369681
[05/21/2022-02:52:48] [V] [TRT] Tactic: -128 Time: 0.386608
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: -32 Time: 0.369056
[05/21/2022-02:52:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:48] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 24 Time: 0.0702605
[05/21/2022-02:52:48] [V] [TRT] Tactic: 25 Time: 0.0639061
[05/21/2022-02:52:48] [V] [TRT] Tactic: 26 Time: 0.0636524
[05/21/2022-02:52:48] [V] [TRT] Tactic: 27 Time: 0.0689777
[05/21/2022-02:52:48] [V] [TRT] Tactic: 31 Time: 0.0699347
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: 26 Time: 0.0636524
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 128 Time: 0.382747
[05/21/2022-02:52:48] [V] [TRT] Tactic: 256 Time: 0.382845
[05/21/2022-02:52:48] [V] [TRT] Tactic: 512 Time: 0.382611
[05/21/2022-02:52:48] [V] [TRT] Tactic: -32 Time: 0.387695
[05/21/2022-02:52:48] [V] [TRT] Tactic: -64 Time: 0.37252
[05/21/2022-02:52:48] [V] [TRT] Tactic: -128 Time: 0.364948
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: -128 Time: 0.364948
[05/21/2022-02:52:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:52:48] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 0 Time: 0.125501
[05/21/2022-02:52:48] [V] [TRT] Tactic: 1 Time: 0.0904948
[05/21/2022-02:52:48] [V] [TRT] Tactic: 2 Time: 0.0843425
[05/21/2022-02:52:48] [V] [TRT] Tactic: 3 Time: 0.0684766
[05/21/2022-02:52:48] [V] [TRT] Tactic: 4 Time: 0.064401
[05/21/2022-02:52:48] [V] [TRT] Tactic: 5 Time: 0.0630924
[05/21/2022-02:52:48] [V] [TRT] Tactic: 6 Time: 0.0601825
[05/21/2022-02:52:48] [V] [TRT] Tactic: 7 Time: 0.0534635
[05/21/2022-02:52:48] [V] [TRT] Tactic: 8 Time: 0.053522
[05/21/2022-02:52:48] [V] [TRT] Tactic: 9 Time: 0.053203
[05/21/2022-02:52:48] [V] [TRT] Tactic: 28 Time: 0.12513
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: 9 Time: 0.053203
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 128 Time: 0.368249
[05/21/2022-02:52:48] [V] [TRT] Tactic: 256 Time: 0.365241
[05/21/2022-02:52:48] [V] [TRT] Tactic: 512 Time: 0.33974
[05/21/2022-02:52:48] [V] [TRT] Tactic: -32 Time: 0.387851
[05/21/2022-02:52:48] [V] [TRT] Tactic: -64 Time: 0.367292
[05/21/2022-02:52:48] [V] [TRT] Tactic: -128 Time: 0.363815
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: 512 Time: 0.33974
[05/21/2022-02:52:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:52:48] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 0 Time: 0.0866664
[05/21/2022-02:52:48] [V] [TRT] Tactic: 1 Time: 0.0687239
[05/21/2022-02:52:48] [V] [TRT] Tactic: 2 Time: 0.0685936
[05/21/2022-02:52:48] [V] [TRT] Tactic: 3 Time: 0.0623179
[05/21/2022-02:52:48] [V] [TRT] Tactic: 4 Time: 0.060586
[05/21/2022-02:52:48] [V] [TRT] Tactic: 5 Time: 0.0614907
[05/21/2022-02:52:48] [V] [TRT] Tactic: 6 Time: 0.0606575
[05/21/2022-02:52:48] [V] [TRT] Tactic: 7 Time: 0.0582163
[05/21/2022-02:52:48] [V] [TRT] Tactic: 8 Time: 0.0566863
[05/21/2022-02:52:48] [V] [TRT] Tactic: 9 Time: 0.0599608
[05/21/2022-02:52:48] [V] [TRT] Tactic: 10 Time: 0.129069
[05/21/2022-02:52:48] [V] [TRT] Tactic: 11 Time: 0.0944335
[05/21/2022-02:52:48] [V] [TRT] Tactic: 12 Time: 0.0882943
[05/21/2022-02:52:48] [V] [TRT] Tactic: 13 Time: 0.0712435
[05/21/2022-02:52:48] [V] [TRT] Tactic: 14 Time: 0.0674806
[05/21/2022-02:52:48] [V] [TRT] Tactic: 15 Time: 0.0678777
[05/21/2022-02:52:48] [V] [TRT] Tactic: 16 Time: 0.0614256
[05/21/2022-02:52:48] [V] [TRT] Tactic: 17 Time: 0.0551172
[05/21/2022-02:52:48] [V] [TRT] Tactic: 18 Time: 0.0555856
[05/21/2022-02:52:48] [V] [TRT] Tactic: 19 Time: 0.0569533
[05/21/2022-02:52:48] [V] [TRT] Tactic: 28 Time: 0.08556
[05/21/2022-02:52:48] [V] [TRT] Tactic: 29 Time: 0.130267
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: 17 Time: 0.0551172
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-02:52:48] [V] [TRT] Tactic: 128 Time: 0.369069
[05/21/2022-02:52:48] [V] [TRT] Tactic: 256 Time: 0.364069
[05/21/2022-02:52:48] [V] [TRT] Tactic: 512 Time: 0.339981
[05/21/2022-02:52:48] [V] [TRT] Tactic: -32 Time: 0.38765
[05/21/2022-02:52:48] [V] [TRT] Tactic: -64 Time: 0.366933
[05/21/2022-02:52:48] [V] [TRT] Tactic: -128 Time: 0.364421
[05/21/2022-02:52:48] [V] [TRT] Fastest Tactic: 512 Time: 0.339981
[05/21/2022-02:52:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:52:48] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:48] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:52:48] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:49] [V] [TRT] Tactic: 589823 Time: 0.771081
[05/21/2022-02:52:49] [V] [TRT] Tactic: 655359 Time: 0.586484
[05/21/2022-02:52:49] [V] [TRT] Tactic: 786431 Time: 0.818301
[05/21/2022-02:52:49] [V] [TRT] Tactic: 851967 Time: 0.86737
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1179647 Time: 0.892298
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1310719 Time: 1.66098
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1376255 Time: 0.60067
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1441791 Time: 0.780032
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1507327 Time: 0.644245
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1638399 Time: 0.811419
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1835007 Time: 0.801634
[05/21/2022-02:52:49] [V] [TRT] Tactic: 1900543 Time: 0.633151
[05/21/2022-02:52:49] [V] [TRT] Tactic: 2097151 Time: 0.953802
[05/21/2022-02:52:49] [V] [TRT] Tactic: 2162687 Time: 0.620814
[05/21/2022-02:52:50] [V] [TRT] Tactic: 2293759 Time: 0.49209
[05/21/2022-02:52:50] [V] [TRT] Tactic: 2359295 Time: 0.573353
[05/21/2022-02:52:50] [V] [TRT] Tactic: 2686975 Time: 0.53164
[05/21/2022-02:52:50] [V] [TRT] Tactic: 3080191 Time: 0.689368
[05/21/2022-02:52:50] [V] [TRT] Tactic: 3342335 Time: 0.682507
[05/21/2022-02:52:50] [V] [TRT] Tactic: 3407871 Time: 0.532487
[05/21/2022-02:52:50] [V] [TRT] Tactic: 3538943 Time: 0.550137
[05/21/2022-02:52:50] [V] [TRT] Tactic: 3670015 Time: 0.497637
[05/21/2022-02:52:50] [V] [TRT] Tactic: 3932159 Time: 0.634349
[05/21/2022-02:52:50] [V] [TRT] Tactic: 3997695 Time: 0.822975
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4063231 Time: 0.802077
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4194303 Time: 0.801224
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4259839 Time: 1.01702
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4325375 Time: 0.695495
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4521983 Time: 0.682656
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4587519 Time: 0.654466
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4653055 Time: 0.636595
[05/21/2022-02:52:50] [V] [TRT] Tactic: 4915199 Time: 0.794225
[05/21/2022-02:52:51] [V] [TRT] Tactic: 4980735 Time: 0.712598
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5177343 Time: 0.932598
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5242879 Time: 0.663451
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5373951 Time: 1.05667
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5439487 Time: 0.929603
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5570559 Time: 0.644622
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5636095 Time: 0.827507
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5701631 Time: 0.689323
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5767167 Time: 1.38307
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5832703 Time: 0.718542
[05/21/2022-02:52:51] [V] [TRT] Tactic: 5898239 Time: 0.654577
[05/21/2022-02:52:51] [V] [TRT] Tactic: 6029311 Time: 0.631543
[05/21/2022-02:52:51] [V] [TRT] Tactic: 6225919 Time: 0.700912
[05/21/2022-02:52:51] [V] [TRT] Tactic: 6291455 Time: 0.891543
[05/21/2022-02:52:51] [V] [TRT] Tactic: 6422527 Time: 0.642793
[05/21/2022-02:52:52] [V] [TRT] Tactic: 6750207 Time: 0.845834
[05/21/2022-02:52:52] [V] [TRT] Tactic: 6815743 Time: 0.722663
[05/21/2022-02:52:52] [V] [TRT] Tactic: 6946815 Time: 1.143
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7012351 Time: 0.961856
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7077887 Time: 0.767298
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7143423 Time: 1.25526
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7208959 Time: 0.715449
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7340031 Time: 0.722337
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7405567 Time: 0.761497
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7536639 Time: 0.760866
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7602175 Time: 1.01492
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7733247 Time: 0.734714
[05/21/2022-02:52:52] [V] [TRT] Tactic: 7798783 Time: 0.809128
[05/21/2022-02:52:52] [V] [TRT] Tactic: 8191999 Time: 1.22079
[05/21/2022-02:52:52] [V] [TRT] Tactic: 8257535 Time: 0.85586
[05/21/2022-02:52:53] [V] [TRT] Tactic: 8323071 Time: 0.778366
[05/21/2022-02:52:53] [V] [TRT] Tactic: 8650751 Time: 1.01368
[05/21/2022-02:52:53] [V] [TRT] Tactic: 8716287 Time: 0.822435
[05/21/2022-02:52:53] [V] [TRT] Tactic: 9109503 Time: 1.01562
[05/21/2022-02:52:53] [V] [TRT] Tactic: 9568255 Time: 0.800527
[05/21/2022-02:52:53] [V] [TRT] Tactic: 9895935 Time: 0.797142
[05/21/2022-02:52:53] [V] [TRT] Tactic: 10223615 Time: 0.530768
[05/21/2022-02:52:53] [V] [TRT] Tactic: 10354687 Time: 0.979864
[05/21/2022-02:52:53] [V] [TRT] Tactic: 10551295 Time: 0.738242
[05/21/2022-02:52:53] [V] [TRT] Tactic: 10747903 Time: 0.690208
[05/21/2022-02:52:53] [V] [TRT] Tactic: 10944511 Time: 0.712201
[05/21/2022-02:52:53] [V] [TRT] Fastest Tactic: 2293759 Time: 0.49209
[05/21/2022-02:52:53] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:52:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:53] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:53] [V] [TRT] Tactic: 0 Time: 0.621608
[05/21/2022-02:52:53] [V] [TRT] Tactic: 1 Time: 0.535475
[05/21/2022-02:52:53] [V] [TRT] Tactic: 2 Time: 0.777181
[05/21/2022-02:52:53] [V] [TRT] Tactic: 4 skipped. Scratch requested: 572915712, available: 536870912
[05/21/2022-02:52:53] [V] [TRT] Tactic: 5 Time: 5.01578
[05/21/2022-02:52:53] [V] [TRT] Fastest Tactic: 1 Time: 0.535475
[05/21/2022-02:52:53] [V] [TRT] Setting workspace to 572915712enables more tactics for profiling
[05/21/2022-02:52:53] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:53] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:53] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:52:53] [V] [TRT] Tactic: 1062367460111450758 Time: 0.384199
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:52:53] [V] [TRT] Tactic: 1698681053543049347 Time: 0.363119
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:52:53] [V] [TRT] Tactic: 4501471010995462441 Time: 0.301667
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:52:53] [V] [TRT] Tactic: 5137655947464784826 Time: 0.302839
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:52:53] [V] [TRT] Tactic: 5288347012147084929 Time: 0.305951
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:52:53] [V] [TRT] Tactic: 5326823351883942011 Time: 0.289948
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:52:53] [V] [TRT] Tactic: 5500448035057547314 Time: 0.325801
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:52:53] [V] [TRT] Tactic: 6645123197870846056 Time: 0.307539
[05/21/2022-02:52:53] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:52:54] [V] [TRT] Tactic: 7144526460361122478 Time: 0.394766
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:52:54] [V] [TRT] Tactic: -8262349710178828730 Time: 0.308145
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:52:54] [V] [TRT] Tactic: -6576203419454146580 Time: 0.340996
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:52:54] [V] [TRT] Tactic: -4787320710726427159 Time: 0.422715
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:52:54] [V] [TRT] Tactic: -3456450830548107839 Time: 0.357259
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:52:54] [V] [TRT] Tactic: -1218658103698133241 Time: 0.342155
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:52:54] [V] [TRT] Tactic: -836875257600482091 Time: 0.335527
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:52:54] [V] [TRT] Tactic: -410470605513481746 Time: 0.29526
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:52:54] [V] [TRT] Tactic: -377491875521947884 Time: 0.302468
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:52:54] [V] [TRT] Tactic: -37215280111360163 Time: 0.29722
[05/21/2022-02:52:54] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.289948
[05/21/2022-02:52:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:52:54] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:54] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:52:54] [V] [TRT] Tactic: 3886731678879822788 Time: 0.305222
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:52:54] [V] [TRT] Tactic: 6629944304117643200 Time: 0.534564
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:52:54] [V] [TRT] Tactic: -9153228964338181824 Time: 0.539811
[05/21/2022-02:52:54] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:52:54] [V] [TRT] Tactic: -7394439838318485025 Time: 0.304935
[05/21/2022-02:52:54] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.304935
[05/21/2022-02:52:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:52:54] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:54] [V] [TRT] Tactic: 0 Time: 0.620208
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1 Time: 0.53401
[05/21/2022-02:52:54] [V] [TRT] Tactic: 2 Time: 0.655606
[05/21/2022-02:52:54] [V] [TRT] Tactic: 4 skipped. Scratch requested: 572915712, available: 536870912
[05/21/2022-02:52:54] [V] [TRT] Tactic: 5 Time: 4.5954
[05/21/2022-02:52:54] [V] [TRT] Fastest Tactic: 1 Time: 0.53401
[05/21/2022-02:52:54] [V] [TRT] Setting workspace to 572915712enables more tactics for profiling
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:54] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:52:54] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:54] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:52:54] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:54] [V] [TRT] Tactic: 589823 Time: 0.368639
[05/21/2022-02:52:54] [V] [TRT] Tactic: 655359 Time: 0.343867
[05/21/2022-02:52:54] [V] [TRT] Tactic: 786431 Time: 0.48138
[05/21/2022-02:52:54] [V] [TRT] Tactic: 851967 Time: 0.383789
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1179647 Time: 0.364355
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1310719 Time: 0.842051
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1376255 Time: 0.291881
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1441791 Time: 0.352038
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1507327 Time: 0.314883
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1638399 Time: 0.405814
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1835007 Time: 0.458164
[05/21/2022-02:52:54] [V] [TRT] Tactic: 1900543 Time: 0.32612
[05/21/2022-02:52:54] [V] [TRT] Tactic: 2097151 Time: 0.641022
[05/21/2022-02:52:54] [V] [TRT] Tactic: 2162687 Time: 0.313112
[05/21/2022-02:52:54] [V] [TRT] Tactic: 2293759 Time: 0.249577
[05/21/2022-02:52:54] [V] [TRT] Tactic: 2359295 Time: 0.279701
[05/21/2022-02:52:55] [V] [TRT] Tactic: 2686975 Time: 0.413874
[05/21/2022-02:52:55] [V] [TRT] Tactic: 3080191 Time: 0.327005
[05/21/2022-02:52:55] [V] [TRT] Tactic: 3342335 Time: 0.33694
[05/21/2022-02:52:55] [V] [TRT] Tactic: 3407871 Time: 0.247454
[05/21/2022-02:52:55] [V] [TRT] Tactic: 3538943 Time: 0.247891
[05/21/2022-02:52:55] [V] [TRT] Tactic: 3670015 Time: 0.3078
[05/21/2022-02:52:55] [V] [TRT] Tactic: 3932159 Time: 0.262663
[05/21/2022-02:52:55] [V] [TRT] Tactic: 3997695 Time: 0.501231
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4063231 Time: 0.354713
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4194303 Time: 0.45056
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4259839 Time: 0.649538
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4325375 Time: 0.341758
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4521983 Time: 0.332448
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4587519 Time: 0.377585
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4653055 Time: 0.313385
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4915199 Time: 0.464154
[05/21/2022-02:52:55] [V] [TRT] Tactic: 4980735 Time: 0.353223
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5177343 Time: 0.370117
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5242879 Time: 0.289655
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5373951 Time: 0.448412
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5439487 Time: 0.515599
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5570559 Time: 0.372558
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5636095 Time: 0.358274
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5701631 Time: 0.303216
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5767167 Time: 0.594447
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5832703 Time: 0.321504
[05/21/2022-02:52:55] [V] [TRT] Tactic: 5898239 Time: 0.398581
[05/21/2022-02:52:55] [V] [TRT] Tactic: 6029311 Time: 0.305651
[05/21/2022-02:52:56] [V] [TRT] Tactic: 6225919 Time: 0.294844
[05/21/2022-02:52:56] [V] [TRT] Tactic: 6291455 Time: 0.364922
[05/21/2022-02:52:56] [V] [TRT] Tactic: 6422527 Time: 0.312253
[05/21/2022-02:52:56] [V] [TRT] Tactic: 6750207 Time: 0.429238
[05/21/2022-02:52:56] [V] [TRT] Tactic: 6815743 Time: 0.347292
[05/21/2022-02:52:56] [V] [TRT] Tactic: 6946815 Time: 0.544531
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7012351 Time: 0.641048
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7077887 Time: 0.319479
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7143423 Time: 0.621842
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7208959 Time: 0.326497
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7340031 Time: 0.426204
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7405567 Time: 0.347194
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7536639 Time: 0.3772
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7602175 Time: 0.445267
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7733247 Time: 0.384329
[05/21/2022-02:52:56] [V] [TRT] Tactic: 7798783 Time: 0.481791
[05/21/2022-02:52:56] [V] [TRT] Tactic: 8191999 Time: 0.598171
[05/21/2022-02:52:56] [V] [TRT] Tactic: 8257535 Time: 0.474069
[05/21/2022-02:52:56] [V] [TRT] Tactic: 8323071 Time: 0.414251
[05/21/2022-02:52:56] [V] [TRT] Tactic: 8650751 Time: 0.460514
[05/21/2022-02:52:56] [V] [TRT] Tactic: 8716287 Time: 0.373398
[05/21/2022-02:52:56] [V] [TRT] Tactic: 9109503 Time: 0.662123
[05/21/2022-02:52:56] [V] [TRT] Tactic: 9568255 Time: 0.461211
[05/21/2022-02:52:56] [V] [TRT] Tactic: 9895935 Time: 0.451191
[05/21/2022-02:52:56] [V] [TRT] Tactic: 10223615 Time: 0.413672
[05/21/2022-02:52:56] [V] [TRT] Tactic: 10354687 Time: 0.636061
[05/21/2022-02:52:56] [V] [TRT] Tactic: 10551295 Time: 0.35752
[05/21/2022-02:52:56] [V] [TRT] Tactic: 10747903 Time: 0.335859
[05/21/2022-02:52:57] [V] [TRT] Tactic: 10944511 Time: 0.353171
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 3407871 Time: 0.247454
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-02:52:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-02:52:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:52:57] [V] [TRT] Tactic: 3066127711859985668 Time: 0.180456
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:52:57] [V] [TRT] Tactic: 3564772625446233998 Time: 0.204375
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:52:57] [V] [TRT] Tactic: 5319956359050645452 Time: 0.192513
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:52:57] [V] [TRT] Tactic: 7205456024582378848 Time: 0.166029
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:52:57] [V] [TRT] Tactic: 8163473458334948789 Time: 0.158366
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:52:57] [V] [TRT] Tactic: -4212163711445252890 Time: 0.157852
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:52:57] [V] [TRT] Tactic: -3898373634979201110 Time: 0.161907
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:52:57] [V] [TRT] Tactic: -2409163523992614473 Time: 0.160638
[05/21/2022-02:52:57] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:52:57] [V] [TRT] Tactic: -1716393687483585322 Time: 0.155521
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.155521
[05/21/2022-02:52:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:52:57] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:57] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 0 Time: 0.0973114
[05/21/2022-02:52:57] [V] [TRT] Tactic: 1 Time: 0.0736459
[05/21/2022-02:52:57] [V] [TRT] Tactic: 2 Time: 0.0696875
[05/21/2022-02:52:57] [V] [TRT] Tactic: 3 Time: 0.0612438
[05/21/2022-02:52:57] [V] [TRT] Tactic: 4 Time: 0.0537959
[05/21/2022-02:52:57] [V] [TRT] Tactic: 5 Time: 0.0546937
[05/21/2022-02:52:57] [V] [TRT] Tactic: 6 Time: 0.0585741
[05/21/2022-02:52:57] [V] [TRT] Tactic: 7 Time: 0.0476171
[05/21/2022-02:52:57] [V] [TRT] Tactic: 8 Time: 0.0448502
[05/21/2022-02:52:57] [V] [TRT] Tactic: 9 Time: 0.0484375
[05/21/2022-02:52:57] [V] [TRT] Tactic: 28 Time: 0.09528
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 8 Time: 0.0448502
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 128 Time: 0.340202
[05/21/2022-02:52:57] [V] [TRT] Tactic: 256 Time: 0.34082
[05/21/2022-02:52:57] [V] [TRT] Tactic: 512 Time: 0.341042
[05/21/2022-02:52:57] [V] [TRT] Tactic: -32 Time: 0.386784
[05/21/2022-02:52:57] [V] [TRT] Tactic: -64 Time: 0.370097
[05/21/2022-02:52:57] [V] [TRT] Tactic: -128 Time: 0.360026
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 128 Time: 0.340202
[05/21/2022-02:52:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:57] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 0 Time: 0.0972394
[05/21/2022-02:52:57] [V] [TRT] Tactic: 1 Time: 0.0733987
[05/21/2022-02:52:57] [V] [TRT] Tactic: 2 Time: 0.0695314
[05/21/2022-02:52:57] [V] [TRT] Tactic: 3 Time: 0.0615365
[05/21/2022-02:52:57] [V] [TRT] Tactic: 4 Time: 0.0533854
[05/21/2022-02:52:57] [V] [TRT] Tactic: 5 Time: 0.0549869
[05/21/2022-02:52:57] [V] [TRT] Tactic: 6 Time: 0.0588869
[05/21/2022-02:52:57] [V] [TRT] Tactic: 7 Time: 0.0482943
[05/21/2022-02:52:57] [V] [TRT] Tactic: 8 Time: 0.0453256
[05/21/2022-02:52:57] [V] [TRT] Tactic: 9 Time: 0.0480011
[05/21/2022-02:52:57] [V] [TRT] Tactic: 28 Time: 0.095599
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 8 Time: 0.0453256
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 128 Time: 0.340358
[05/21/2022-02:52:57] [V] [TRT] Tactic: 256 Time: 0.340911
[05/21/2022-02:52:57] [V] [TRT] Tactic: 512 Time: 0.341198
[05/21/2022-02:52:57] [V] [TRT] Tactic: -32 Time: 0.38806
[05/21/2022-02:52:57] [V] [TRT] Tactic: -64 Time: 0.368678
[05/21/2022-02:52:57] [V] [TRT] Tactic: -128 Time: 0.360547
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 128 Time: 0.340358
[05/21/2022-02:52:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:52:57] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 24 Time: 0.0682423
[05/21/2022-02:52:57] [V] [TRT] Tactic: 25 Time: 0.0639781
[05/21/2022-02:52:57] [V] [TRT] Tactic: 26 Time: 0.0637046
[05/21/2022-02:52:57] [V] [TRT] Tactic: 27 Time: 0.068594
[05/21/2022-02:52:57] [V] [TRT] Tactic: 31 Time: 0.0679949
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 26 Time: 0.0637046
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 128 Time: 0.340254
[05/21/2022-02:52:57] [V] [TRT] Tactic: 256 Time: 0.340645
[05/21/2022-02:52:57] [V] [TRT] Tactic: 512 Time: 0.34127
[05/21/2022-02:52:57] [V] [TRT] Tactic: -32 Time: 0.386842
[05/21/2022-02:52:57] [V] [TRT] Tactic: -64 Time: 0.369733
[05/21/2022-02:52:57] [V] [TRT] Tactic: -128 Time: 0.360013
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 128 Time: 0.340254
[05/21/2022-02:52:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:52:57] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 0 Time: 0.0986004
[05/21/2022-02:52:57] [V] [TRT] Tactic: 1 Time: 0.0765167
[05/21/2022-02:52:57] [V] [TRT] Tactic: 2 Time: 0.0712892
[05/21/2022-02:52:57] [V] [TRT] Tactic: 3 Time: 0.0628382
[05/21/2022-02:52:57] [V] [TRT] Tactic: 4 Time: 0.0566801
[05/21/2022-02:52:57] [V] [TRT] Tactic: 5 Time: 0.0572918
[05/21/2022-02:52:57] [V] [TRT] Tactic: 6 Time: 0.056452
[05/21/2022-02:52:57] [V] [TRT] Tactic: 7 Time: 0.0488802
[05/21/2022-02:52:57] [V] [TRT] Tactic: 8 Time: 0.0489905
[05/21/2022-02:52:57] [V] [TRT] Tactic: 9 Time: 0.0506903
[05/21/2022-02:52:57] [V] [TRT] Tactic: 28 Time: 0.0989585
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 7 Time: 0.0488802
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 128 Time: 0.350814
[05/21/2022-02:52:57] [V] [TRT] Tactic: 256 Time: 0.345781
[05/21/2022-02:52:57] [V] [TRT] Tactic: 512 Time: 0.327741
[05/21/2022-02:52:57] [V] [TRT] Tactic: -32 Time: 0.386341
[05/21/2022-02:52:57] [V] [TRT] Tactic: -64 Time: 0.363665
[05/21/2022-02:52:57] [V] [TRT] Tactic: -128 Time: 0.357624
[05/21/2022-02:52:57] [V] [TRT] Fastest Tactic: 512 Time: 0.327741
[05/21/2022-02:52:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:52:57] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:52:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-02:52:57] [V] [TRT] Tactic: 0 Time: 0.076719
[05/21/2022-02:52:57] [V] [TRT] Tactic: 1 Time: 0.0641536
[05/21/2022-02:52:57] [V] [TRT] Tactic: 2 Time: 0.0628252
[05/21/2022-02:52:57] [V] [TRT] Tactic: 3 Time: 0.0603126
[05/21/2022-02:52:57] [V] [TRT] Tactic: 4 Time: 0.0579885
[05/21/2022-02:52:57] [V] [TRT] Tactic: 5 Time: 0.059082
[05/21/2022-02:52:57] [V] [TRT] Tactic: 6 Time: 0.0589518
[05/21/2022-02:52:57] [V] [TRT] Tactic: 7 Time: 0.0563149
[05/21/2022-02:52:57] [V] [TRT] Tactic: 8 Time: 0.0554297
[05/21/2022-02:52:57] [V] [TRT] Tactic: 9 Time: 0.0581708
[05/21/2022-02:52:57] [V] [TRT] Tactic: 10 Time: 0.103601
[05/21/2022-02:52:57] [V] [TRT] Tactic: 11 Time: 0.0788801
[05/21/2022-02:52:57] [V] [TRT] Tactic: 12 Time: 0.0748696
[05/21/2022-02:52:57] [V] [TRT] Tactic: 13 Time: 0.063509
[05/21/2022-02:52:58] [V] [TRT] Tactic: 14 Time: 0.0583331
[05/21/2022-02:52:58] [V] [TRT] Tactic: 15 Time: 0.0600326
[05/21/2022-02:52:58] [V] [TRT] Tactic: 16 Time: 0.057422
[05/21/2022-02:52:58] [V] [TRT] Tactic: 17 Time: 0.050371
[05/21/2022-02:52:58] [V] [TRT] Tactic: 18 Time: 0.0497723
[05/21/2022-02:52:58] [V] [TRT] Tactic: 19 Time: 0.05319
[05/21/2022-02:52:58] [V] [TRT] Tactic: 28 Time: 0.074707
[05/21/2022-02:52:58] [V] [TRT] Tactic: 29 Time: 0.101953
[05/21/2022-02:52:58] [V] [TRT] Fastest Tactic: 18 Time: 0.0497723
[05/21/2022-02:52:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-02:52:58] [V] [TRT] Tactic: 128 Time: 0.351146
[05/21/2022-02:52:58] [V] [TRT] Tactic: 256 Time: 0.345397
[05/21/2022-02:52:58] [V] [TRT] Tactic: 512 Time: 0.326601
[05/21/2022-02:52:58] [V] [TRT] Tactic: -32 Time: 0.384792
[05/21/2022-02:52:58] [V] [TRT] Tactic: -64 Time: 0.363438
[05/21/2022-02:52:58] [V] [TRT] Tactic: -128 Time: 0.357735
[05/21/2022-02:52:58] [V] [TRT] Fastest Tactic: 512 Time: 0.326601
[05/21/2022-02:52:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:52:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:52:58] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:52:58] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:52:58] [V] [TRT] Tactic: 524287 Time: 2.94561
[05/21/2022-02:52:58] [V] [TRT] Tactic: 720895 Time: 2.28309
[05/21/2022-02:52:58] [V] [TRT] Tactic: 983039 Time: 2.77886
[05/21/2022-02:52:58] [V] [TRT] Tactic: 1048575 Time: 3.20787
[05/21/2022-02:52:58] [V] [TRT] Tactic: 1703935 Time: 3.19947
[05/21/2022-02:52:59] [V] [TRT] Tactic: 1769471 Time: 2.94032
[05/21/2022-02:52:59] [V] [TRT] Tactic: 1966079 Time: 2.94109
[05/21/2022-02:52:59] [V] [TRT] Tactic: 2031615 Time: 2.57824
[05/21/2022-02:52:59] [V] [TRT] Tactic: 2228223 Time: 3.06275
[05/21/2022-02:52:59] [V] [TRT] Tactic: 2424831 Time: 3.39811
[05/21/2022-02:53:00] [V] [TRT] Tactic: 2621439 Time: 3.80159
[05/21/2022-02:53:00] [V] [TRT] Tactic: 2752511 Time: 2.75827
[05/21/2022-02:53:00] [V] [TRT] Tactic: 2818047 Time: 3.78045
[05/21/2022-02:53:00] [V] [TRT] Tactic: 2883583 Time: 2.77063
[05/21/2022-02:53:00] [V] [TRT] Tactic: 3014655 Time: 3.32865
[05/21/2022-02:53:00] [V] [TRT] Tactic: 3145727 Time: 2.73984
[05/21/2022-02:53:01] [V] [TRT] Tactic: 3473407 Time: 2.72404
[05/21/2022-02:53:01] [V] [TRT] Tactic: 3604479 Time: 3.2825
[05/21/2022-02:53:01] [V] [TRT] Tactic: 3735551 Time: 3.29242
[05/21/2022-02:53:01] [V] [TRT] Tactic: 4390911 Time: 2.69231
[05/21/2022-02:53:01] [V] [TRT] Tactic: 5046271 Time: 2.9523
[05/21/2022-02:53:01] [V] [TRT] Tactic: 5963775 Time: 2.63417
[05/21/2022-02:53:02] [V] [TRT] Tactic: 6160383 Time: 2.90605
[05/21/2022-02:53:02] [V] [TRT] Tactic: 6488063 Time: 2.97732
[05/21/2022-02:53:02] [V] [TRT] Tactic: 6881279 Time: 2.53603
[05/21/2022-02:53:02] [V] [TRT] Tactic: 7274495 Time: 3.44342
[05/21/2022-02:53:02] [V] [TRT] Tactic: 7864319 Time: 2.99745
[05/21/2022-02:53:02] [V] [TRT] Tactic: 7995391 Time: 3.15802
[05/21/2022-02:53:02] [V] [TRT] Tactic: 8585215 Time: 2.80755
[05/21/2022-02:53:03] [V] [TRT] Tactic: 8847359 Time: 3.263
[05/21/2022-02:53:03] [V] [TRT] Tactic: 8978431 Time: 2.6632
[05/21/2022-02:53:03] [V] [TRT] Tactic: 9043967 Time: 3.02285
[05/21/2022-02:53:03] [V] [TRT] Tactic: 9175039 Time: 3.28012
[05/21/2022-02:53:03] [V] [TRT] Tactic: 9502719 Time: 2.77007
[05/21/2022-02:53:03] [V] [TRT] Tactic: 9830399 Time: 2.77468
[05/21/2022-02:53:04] [V] [TRT] Tactic: 9961471 Time: 3.60956
[05/21/2022-02:53:04] [V] [TRT] Tactic: 10027007 Time: 2.79482
[05/21/2022-02:53:04] [V] [TRT] Tactic: 10092543 Time: 2.68105
[05/21/2022-02:53:04] [V] [TRT] Tactic: 10289151 Time: 2.9504
[05/21/2022-02:53:04] [V] [TRT] Tactic: 10485759 Time: 2.8185
[05/21/2022-02:53:05] [V] [TRT] Tactic: 10682367 Time: 3.87803
[05/21/2022-02:53:05] [V] [TRT] Tactic: 10813439 Time: 3.14495
[05/21/2022-02:53:05] [V] [TRT] Fastest Tactic: 720895 Time: 2.28309
[05/21/2022-02:53:05] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:53:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:05] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:05] [V] [TRT] Tactic: 0 Time: 4.17458
[05/21/2022-02:53:05] [V] [TRT] Tactic: 1 Time: 2.56936
[05/21/2022-02:53:05] [V] [TRT] Tactic: 2 Time: 3.67189
[05/21/2022-02:53:05] [V] [TRT] Tactic: 4 skipped. Scratch requested: 575012864, available: 536870912
[05/21/2022-02:53:07] [V] [TRT] Tactic: 5 Time: 83.0714
[05/21/2022-02:53:07] [V] [TRT] Tactic: 6 Time: 3.16347
[05/21/2022-02:53:07] [V] [TRT] Fastest Tactic: 1 Time: 2.56936
[05/21/2022-02:53:07] [V] [TRT] Setting workspace to 575012864enables more tactics for profiling
[05/21/2022-02:53:07] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:53:07] [V] [TRT] Tactic: 1062367460111450758 Time: 2.91258
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:53:07] [V] [TRT] Tactic: 1754984623894446479 Time: 3.50941
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:53:07] [V] [TRT] Tactic: 3611739942397549984 Time: 2.39776
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:53:07] [V] [TRT] Tactic: 3827454225649558724 Time: 3.6201
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:53:07] [V] [TRT] Tactic: 4337000649858996379 Time: 2.41354
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:53:07] [V] [TRT] Tactic: 4501471010995462441 Time: 2.35062
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:53:07] [V] [TRT] Tactic: 5137655947464784826 Time: 2.31022
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:53:07] [V] [TRT] Tactic: 5288347012147084929 Time: 2.30101
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:53:07] [V] [TRT] Tactic: 5921334924264294896 Time: 2.61663
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:53:07] [V] [TRT] Tactic: 6645123197870846056 Time: 2.39797
[05/21/2022-02:53:07] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:53:07] [V] [TRT] Tactic: 7144526460361122478 Time: 3.09883
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:53:08] [V] [TRT] Tactic: 7852627285308570038 Time: 3.6766
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:53:08] [V] [TRT] Tactic: -9137461792520977713 Time: 2.39393
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:53:08] [V] [TRT] Tactic: -8776506421218919509 Time: 3.41828
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:53:08] [V] [TRT] Tactic: -8262349710178828730 Time: 2.39684
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:53:08] [V] [TRT] Tactic: -8133971918129952780 Time: 2.61691
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:53:08] [V] [TRT] Tactic: -6092040395344634144 Time: 2.99876
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:53:08] [V] [TRT] Tactic: -4787320710726427159 Time: 3.50647
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:53:08] [V] [TRT] Tactic: -3456450830548107839 Time: 2.61473
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:53:08] [V] [TRT] Tactic: -2318106587342035239 Time: 3.55786
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:53:08] [V] [TRT] Tactic: -1343271414618805657 Time: 2.49523
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:53:08] [V] [TRT] Tactic: -1218658103698133241 Time: 2.71785
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:53:08] [V] [TRT] Tactic: -836875257600482091 Time: 2.50169
[05/21/2022-02:53:08] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:53:08] [V] [TRT] Tactic: -410470605513481746 Time: 2.26336
[05/21/2022-02:53:08] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 2.26336
[05/21/2022-02:53:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-02:53:08] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:08] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:08] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:09] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:53:09] [V] [TRT] Tactic: -9153228964338181824 Time: 2.91475
[05/21/2022-02:53:09] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:53:09] [V] [TRT] Tactic: -7394439838318485025 Time: 2.22785
[05/21/2022-02:53:09] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.22785
[05/21/2022-02:53:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:53:09] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:09] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:09] [V] [TRT] Tactic: 0 Time: 4.15893
[05/21/2022-02:53:09] [V] [TRT] Tactic: 1 Time: 5.75302
[05/21/2022-02:53:09] [V] [TRT] Tactic: 2 Time: 3.54681
[05/21/2022-02:53:09] [V] [TRT] Tactic: 4 skipped. Scratch requested: 575012864, available: 536870912
[05/21/2022-02:53:10] [V] [TRT] Tactic: 5 Time: 81.9568
[05/21/2022-02:53:11] [V] [TRT] Tactic: 6 Time: 4.40999
[05/21/2022-02:53:11] [V] [TRT] Fastest Tactic: 2 Time: 3.54681
[05/21/2022-02:53:11] [V] [TRT] Setting workspace to 575012864enables more tactics for profiling
[05/21/2022-02:53:11] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:11] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:53:11] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:11] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:11] [V] [TRT] Tactic: 524287 Time: 1.54651
[05/21/2022-02:53:11] [V] [TRT] Tactic: 720895 Time: 1.35138
[05/21/2022-02:53:11] [V] [TRT] Tactic: 983039 Time: 1.51635
[05/21/2022-02:53:11] [V] [TRT] Tactic: 1048575 Time: 1.74658
[05/21/2022-02:53:11] [V] [TRT] Tactic: 1703935 Time: 1.7887
[05/21/2022-02:53:12] [V] [TRT] Tactic: 1769471 Time: 10.6786
[05/21/2022-02:53:12] [V] [TRT] Tactic: 1966079 Time: 1.73482
[05/21/2022-02:53:12] [V] [TRT] Tactic: 2031615 Time: 1.43133
[05/21/2022-02:53:12] [V] [TRT] Tactic: 2228223 Time: 1.65891
[05/21/2022-02:53:12] [V] [TRT] Tactic: 2424831 Time: 2.56672
[05/21/2022-02:53:12] [V] [TRT] Tactic: 2621439 Time: 2.02892
[05/21/2022-02:53:12] [V] [TRT] Tactic: 2752511 Time: 1.5426
[05/21/2022-02:53:12] [V] [TRT] Tactic: 2818047 Time: 2.08703
[05/21/2022-02:53:13] [V] [TRT] Tactic: 2883583 Time: 1.62227
[05/21/2022-02:53:13] [V] [TRT] Tactic: 3014655 Time: 1.84387
[05/21/2022-02:53:13] [V] [TRT] Tactic: 3145727 Time: 1.54844
[05/21/2022-02:53:13] [V] [TRT] Tactic: 3473407 Time: 1.68064
[05/21/2022-02:53:13] [V] [TRT] Tactic: 3604479 Time: 1.83023
[05/21/2022-02:53:13] [V] [TRT] Tactic: 3735551 Time: 1.85615
[05/21/2022-02:53:13] [V] [TRT] Tactic: 4390911 Time: 1.53627
[05/21/2022-02:53:13] [V] [TRT] Tactic: 5046271 Time: 1.55245
[05/21/2022-02:53:13] [V] [TRT] Tactic: 5963775 Time: 1.45699
[05/21/2022-02:53:14] [V] [TRT] Tactic: 6160383 Time: 1.6279
[05/21/2022-02:53:14] [V] [TRT] Tactic: 6488063 Time: 1.64686
[05/21/2022-02:53:14] [V] [TRT] Tactic: 6881279 Time: 1.36455
[05/21/2022-02:53:14] [V] [TRT] Tactic: 7274495 Time: 1.97056
[05/21/2022-02:53:14] [V] [TRT] Tactic: 7864319 Time: 1.63777
[05/21/2022-02:53:14] [V] [TRT] Tactic: 7995391 Time: 1.84045
[05/21/2022-02:53:14] [V] [TRT] Tactic: 8585215 Time: 1.54668
[05/21/2022-02:53:14] [V] [TRT] Tactic: 8847359 Time: 1.74833
[05/21/2022-02:53:14] [V] [TRT] Tactic: 8978431 Time: 1.52143
[05/21/2022-02:53:14] [V] [TRT] Tactic: 9043967 Time: 1.61747
[05/21/2022-02:53:15] [V] [TRT] Tactic: 9175039 Time: 1.82906
[05/21/2022-02:53:15] [V] [TRT] Tactic: 9502719 Time: 1.48349
[05/21/2022-02:53:15] [V] [TRT] Tactic: 9830399 Time: 1.61339
[05/21/2022-02:53:15] [V] [TRT] Tactic: 9961471 Time: 2.01251
[05/21/2022-02:53:15] [V] [TRT] Tactic: 10027007 Time: 1.49656
[05/21/2022-02:53:15] [V] [TRT] Tactic: 10092543 Time: 1.54363
[05/21/2022-02:53:15] [V] [TRT] Tactic: 10289151 Time: 1.74052
[05/21/2022-02:53:15] [V] [TRT] Tactic: 10485759 Time: 1.4916
[05/21/2022-02:53:15] [V] [TRT] Tactic: 10682367 Time: 1.98436
[05/21/2022-02:53:16] [V] [TRT] Tactic: 10813439 Time: 1.86863
[05/21/2022-02:53:16] [V] [TRT] Fastest Tactic: 720895 Time: 1.35138
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:16] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:53:16] [V] [TRT] Tactic: 3564772625446233998 Time: 1.47178
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:53:16] [V] [TRT] Tactic: 3650389455493082349 Time: 1.51617
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:53:16] [V] [TRT] Tactic: 4772821744921268633 Time: 1.39798
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:53:16] [V] [TRT] Tactic: 5319956359050645452 Time: 1.33094
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:53:16] [V] [TRT] Tactic: 7205456024582378848 Time: 1.19443
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:53:16] [V] [TRT] Tactic: -6490690591794140522 Time: 1.21359
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:53:16] [V] [TRT] Tactic: -4686027666808657977 Time: 1.19796
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:53:16] [V] [TRT] Tactic: -4212163711445252890 Time: 1.14426
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:53:16] [V] [TRT] Tactic: -3898373634979201110 Time: 1.19442
[05/21/2022-02:53:16] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:53:16] [V] [TRT] Tactic: -2409163523992614473 Time: 1.1465
[05/21/2022-02:53:16] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 1.14426
[05/21/2022-02:53:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:53:16] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:16] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-02:53:16] [V] [TRT] Tactic: 0 Time: 0.102552
[05/21/2022-02:53:16] [V] [TRT] Tactic: 1 Time: 0.0791733
[05/21/2022-02:53:16] [V] [TRT] Tactic: 2 Time: 0.077181
[05/21/2022-02:53:16] [V] [TRT] Tactic: 3 Time: 0.0687309
[05/21/2022-02:53:16] [V] [TRT] Tactic: 4 Time: 0.0628709
[05/21/2022-02:53:16] [V] [TRT] Tactic: 5 Time: 0.0605666
[05/21/2022-02:53:16] [V] [TRT] Tactic: 6 Time: 0.0689908
[05/21/2022-02:53:16] [V] [TRT] Tactic: 7 Time: 0.05778
[05/21/2022-02:53:16] [V] [TRT] Tactic: 8 Time: 0.0560677
[05/21/2022-02:53:16] [V] [TRT] Tactic: 9 Time: 0.0571939
[05/21/2022-02:53:16] [V] [TRT] Tactic: 28 Time: 0.101517
[05/21/2022-02:53:16] [V] [TRT] Fastest Tactic: 8 Time: 0.0560677
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-02:53:16] [V] [TRT] Tactic: 128 Time: 0.392812
[05/21/2022-02:53:16] [V] [TRT] Tactic: 256 Time: 0.393079
[05/21/2022-02:53:16] [V] [TRT] Tactic: 512 Time: 0.393613
[05/21/2022-02:53:16] [V] [TRT] Tactic: -32 Time: 0.450925
[05/21/2022-02:53:16] [V] [TRT] Tactic: -64 Time: 0.429336
[05/21/2022-02:53:16] [V] [TRT] Tactic: -128 Time: 0.41819
[05/21/2022-02:53:16] [V] [TRT] Fastest Tactic: 128 Time: 0.392812
[05/21/2022-02:53:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:16] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-02:53:16] [V] [TRT] Tactic: 0 Time: 0.102865
[05/21/2022-02:53:16] [V] [TRT] Tactic: 1 Time: 0.0788478
[05/21/2022-02:53:16] [V] [TRT] Tactic: 2 Time: 0.0780466
[05/21/2022-02:53:16] [V] [TRT] Tactic: 3 Time: 0.070026
[05/21/2022-02:53:16] [V] [TRT] Tactic: 4 Time: 0.0625457
[05/21/2022-02:53:16] [V] [TRT] Tactic: 5 Time: 0.0604233
[05/21/2022-02:53:16] [V] [TRT] Tactic: 6 Time: 0.0685155
[05/21/2022-02:53:16] [V] [TRT] Tactic: 7 Time: 0.057715
[05/21/2022-02:53:16] [V] [TRT] Tactic: 8 Time: 0.055859
[05/21/2022-02:53:16] [V] [TRT] Tactic: 9 Time: 0.057858
[05/21/2022-02:53:16] [V] [TRT] Tactic: 28 Time: 0.101478
[05/21/2022-02:53:16] [V] [TRT] Fastest Tactic: 8 Time: 0.055859
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-02:53:16] [V] [TRT] Tactic: 128 Time: 0.392233
[05/21/2022-02:53:16] [V] [TRT] Tactic: 256 Time: 0.393281
[05/21/2022-02:53:16] [V] [TRT] Tactic: 512 Time: 0.393639
[05/21/2022-02:53:16] [V] [TRT] Tactic: -32 Time: 0.451751
[05/21/2022-02:53:16] [V] [TRT] Tactic: -64 Time: 0.429831
[05/21/2022-02:53:16] [V] [TRT] Tactic: -128 Time: 0.41834
[05/21/2022-02:53:16] [V] [TRT] Fastest Tactic: 128 Time: 0.392233
[05/21/2022-02:53:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:16] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-02:53:16] [V] [TRT] Tactic: 24 Time: 0.0954426
[05/21/2022-02:53:16] [V] [TRT] Tactic: 25 Time: 0.0838411
[05/21/2022-02:53:16] [V] [TRT] Tactic: 26 Time: 0.0831706
[05/21/2022-02:53:16] [V] [TRT] Tactic: 27 Time: 0.0893293
[05/21/2022-02:53:16] [V] [TRT] Tactic: 31 Time: 0.0960872
[05/21/2022-02:53:16] [V] [TRT] Fastest Tactic: 26 Time: 0.0831706
[05/21/2022-02:53:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-02:53:16] [V] [TRT] Tactic: 128 Time: 0.393001
[05/21/2022-02:53:16] [V] [TRT] Tactic: 256 Time: 0.393184
[05/21/2022-02:53:17] [V] [TRT] Tactic: 512 Time: 0.394037
[05/21/2022-02:53:17] [V] [TRT] Tactic: -32 Time: 0.450983
[05/21/2022-02:53:17] [V] [TRT] Tactic: -64 Time: 0.429954
[05/21/2022-02:53:17] [V] [TRT] Tactic: -128 Time: 0.418242
[05/21/2022-02:53:17] [V] [TRT] Fastest Tactic: 128 Time: 0.393001
[05/21/2022-02:53:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-02:53:17] [V] [TRT] Tactic: 0 Time: 0.104264
[05/21/2022-02:53:17] [V] [TRT] Tactic: 1 Time: 0.0804102
[05/21/2022-02:53:17] [V] [TRT] Tactic: 2 Time: 0.0757487
[05/21/2022-02:53:17] [V] [TRT] Tactic: 3 Time: 0.0655144
[05/21/2022-02:53:17] [V] [TRT] Tactic: 4 Time: 0.0654688
[05/21/2022-02:53:17] [V] [TRT] Tactic: 5 Time: 0.0611394
[05/21/2022-02:53:17] [V] [TRT] Tactic: 6 Time: 0.0609314
[05/21/2022-02:53:17] [V] [TRT] Tactic: 7 Time: 0.0569856
[05/21/2022-02:53:17] [V] [TRT] Tactic: 8 Time: 0.054889
[05/21/2022-02:53:17] [V] [TRT] Tactic: 9 Time: 0.0561913
[05/21/2022-02:53:17] [V] [TRT] Tactic: 28 Time: 0.103086
[05/21/2022-02:53:17] [V] [TRT] Fastest Tactic: 8 Time: 0.054889
[05/21/2022-02:53:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-02:53:17] [V] [TRT] Tactic: 128 Time: 0.408073
[05/21/2022-02:53:17] [V] [TRT] Tactic: 256 Time: 0.402428
[05/21/2022-02:53:17] [V] [TRT] Tactic: 512 Time: 0.383665
[05/21/2022-02:53:17] [V] [TRT] Tactic: -32 Time: 0.461843
[05/21/2022-02:53:17] [V] [TRT] Tactic: -64 Time: 0.432806
[05/21/2022-02:53:17] [V] [TRT] Tactic: -128 Time: 0.424453
[05/21/2022-02:53:17] [V] [TRT] Fastest Tactic: 512 Time: 0.383665
[05/21/2022-02:53:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-02:53:17] [V] [TRT] Tactic: 0 Time: 0.0886199
[05/21/2022-02:53:17] [V] [TRT] Tactic: 1 Time: 0.0816017
[05/21/2022-02:53:17] [V] [TRT] Tactic: 2 Time: 0.077689
[05/21/2022-02:53:17] [V] [TRT] Tactic: 3 Time: 0.075189
[05/21/2022-02:53:17] [V] [TRT] Tactic: 4 Time: 0.0748633
[05/21/2022-02:53:17] [V] [TRT] Tactic: 5 Time: 0.0754492
[05/21/2022-02:53:17] [V] [TRT] Tactic: 6 Time: 0.0744661
[05/21/2022-02:53:17] [V] [TRT] Tactic: 7 Time: 0.0732748
[05/21/2022-02:53:17] [V] [TRT] Tactic: 8 Time: 0.0834374
[05/21/2022-02:53:17] [V] [TRT] Tactic: 9 Time: 0.0964062
[05/21/2022-02:53:17] [V] [TRT] Tactic: 10 Time: 0.111628
[05/21/2022-02:53:17] [V] [TRT] Tactic: 11 Time: 0.0887565
[05/21/2022-02:53:17] [V] [TRT] Tactic: 12 Time: 0.0847134
[05/21/2022-02:53:17] [V] [TRT] Tactic: 13 Time: 0.0723111
[05/21/2022-02:53:17] [V] [TRT] Tactic: 14 Time: 0.0747136
[05/21/2022-02:53:17] [V] [TRT] Tactic: 15 Time: 0.0708465
[05/21/2022-02:53:17] [V] [TRT] Tactic: 16 Time: 0.0659634
[05/21/2022-02:53:17] [V] [TRT] Tactic: 17 Time: 0.06666
[05/21/2022-02:53:17] [V] [TRT] Tactic: 18 Time: 0.0649024
[05/21/2022-02:53:17] [V] [TRT] Tactic: 19 Time: 0.0663152
[05/21/2022-02:53:17] [V] [TRT] Tactic: 28 Time: 0.0881969
[05/21/2022-02:53:17] [V] [TRT] Tactic: 29 Time: 0.110059
[05/21/2022-02:53:17] [V] [TRT] Fastest Tactic: 18 Time: 0.0649024
[05/21/2022-02:53:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-02:53:17] [V] [TRT] Tactic: 128 Time: 0.407904
[05/21/2022-02:53:17] [V] [TRT] Tactic: 256 Time: 0.402181
[05/21/2022-02:53:17] [V] [TRT] Tactic: 512 Time: 0.384766
[05/21/2022-02:53:17] [V] [TRT] Tactic: -32 Time: 0.461575
[05/21/2022-02:53:17] [V] [TRT] Tactic: -64 Time: 0.433144
[05/21/2022-02:53:17] [V] [TRT] Tactic: -128 Time: 0.424401
[05/21/2022-02:53:17] [V] [TRT] Fastest Tactic: 512 Time: 0.384766
[05/21/2022-02:53:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1), Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256), Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1), Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1), Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1), Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:17] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:53:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:17] [V] [TRT] Tactic: 0 Time: 0.121882
[05/21/2022-02:53:17] [V] [TRT] Tactic: 1 Time: 0.0870965
[05/21/2022-02:53:17] [V] [TRT] Tactic: 2 Time: 0.0821745
[05/21/2022-02:53:17] [V] [TRT] Tactic: 3 Time: 0.0671356
[05/21/2022-02:53:17] [V] [TRT] Tactic: 4 Time: 0.0625714
[05/21/2022-02:53:17] [V] [TRT] Tactic: 5 Time: 0.0614455
[05/21/2022-02:53:17] [V] [TRT] Tactic: 6 Time: 0.0602734
[05/21/2022-02:53:17] [V] [TRT] Tactic: 7 Time: 0.0516863
[05/21/2022-02:53:17] [V] [TRT] Tactic: 8 Time: 0.0501693
[05/21/2022-02:53:17] [V] [TRT] Tactic: 9 Time: 0.052168
[05/21/2022-02:53:18] [V] [TRT] Tactic: 28 Time: 0.120951
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: 8 Time: 0.0501693
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 128 Time: 0.383314
[05/21/2022-02:53:18] [V] [TRT] Tactic: 256 Time: 0.383099
[05/21/2022-02:53:18] [V] [TRT] Tactic: 512 Time: 0.382904
[05/21/2022-02:53:18] [V] [TRT] Tactic: -32 Time: 0.388294
[05/21/2022-02:53:18] [V] [TRT] Tactic: -64 Time: 0.372298
[05/21/2022-02:53:18] [V] [TRT] Tactic: -128 Time: 0.364831
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: -128 Time: 0.364831
[05/21/2022-02:53:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 0 Time: 0.12263
[05/21/2022-02:53:18] [V] [TRT] Tactic: 1 Time: 0.0869594
[05/21/2022-02:53:18] [V] [TRT] Tactic: 2 Time: 0.0828514
[05/21/2022-02:53:18] [V] [TRT] Tactic: 3 Time: 0.0676041
[05/21/2022-02:53:18] [V] [TRT] Tactic: 4 Time: 0.0628453
[05/21/2022-02:53:18] [V] [TRT] Tactic: 5 Time: 0.0614064
[05/21/2022-02:53:18] [V] [TRT] Tactic: 6 Time: 0.0605991
[05/21/2022-02:53:18] [V] [TRT] Tactic: 7 Time: 0.0521417
[05/21/2022-02:53:18] [V] [TRT] Tactic: 8 Time: 0.0502278
[05/21/2022-02:53:18] [V] [TRT] Tactic: 9 Time: 0.0516925
[05/21/2022-02:53:18] [V] [TRT] Tactic: 28 Time: 0.121309
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: 8 Time: 0.0502278
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 128 Time: 0.382813
[05/21/2022-02:53:18] [V] [TRT] Tactic: 256 Time: 0.382448
[05/21/2022-02:53:18] [V] [TRT] Tactic: 512 Time: 0.382975
[05/21/2022-02:53:18] [V] [TRT] Tactic: -32 Time: 0.368887
[05/21/2022-02:53:18] [V] [TRT] Tactic: -64 Time: 0.370221
[05/21/2022-02:53:18] [V] [TRT] Tactic: -128 Time: 0.386153
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: -32 Time: 0.368887
[05/21/2022-02:53:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 24 Time: 0.0695314
[05/21/2022-02:53:18] [V] [TRT] Tactic: 25 Time: 0.0639127
[05/21/2022-02:53:18] [V] [TRT] Tactic: 26 Time: 0.063255
[05/21/2022-02:53:18] [V] [TRT] Tactic: 27 Time: 0.0686003
[05/21/2022-02:53:18] [V] [TRT] Tactic: 31 Time: 0.0699741
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: 26 Time: 0.063255
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 128 Time: 0.382884
[05/21/2022-02:53:18] [V] [TRT] Tactic: 256 Time: 0.382904
[05/21/2022-02:53:18] [V] [TRT] Tactic: 512 Time: 0.382656
[05/21/2022-02:53:18] [V] [TRT] Tactic: -32 Time: 0.388438
[05/21/2022-02:53:18] [V] [TRT] Tactic: -64 Time: 0.371953
[05/21/2022-02:53:18] [V] [TRT] Tactic: -128 Time: 0.364902
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: -128 Time: 0.364902
[05/21/2022-02:53:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 0 Time: 0.125143
[05/21/2022-02:53:18] [V] [TRT] Tactic: 1 Time: 0.0907879
[05/21/2022-02:53:18] [V] [TRT] Tactic: 2 Time: 0.0842774
[05/21/2022-02:53:18] [V] [TRT] Tactic: 3 Time: 0.0692447
[05/21/2022-02:53:18] [V] [TRT] Tactic: 4 Time: 0.0652605
[05/21/2022-02:53:18] [V] [TRT] Tactic: 5 Time: 0.0633333
[05/21/2022-02:53:18] [V] [TRT] Tactic: 6 Time: 0.0598372
[05/21/2022-02:53:18] [V] [TRT] Tactic: 7 Time: 0.0532293
[05/21/2022-02:53:18] [V] [TRT] Tactic: 8 Time: 0.053366
[05/21/2022-02:53:18] [V] [TRT] Tactic: 9 Time: 0.0531182
[05/21/2022-02:53:18] [V] [TRT] Tactic: 28 Time: 0.124811
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: 9 Time: 0.0531182
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 128 Time: 0.369779
[05/21/2022-02:53:18] [V] [TRT] Tactic: 256 Time: 0.364981
[05/21/2022-02:53:18] [V] [TRT] Tactic: 512 Time: 0.339193
[05/21/2022-02:53:18] [V] [TRT] Tactic: -32 Time: 0.387442
[05/21/2022-02:53:18] [V] [TRT] Tactic: -64 Time: 0.367389
[05/21/2022-02:53:18] [V] [TRT] Tactic: -128 Time: 0.363757
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: 512 Time: 0.339193
[05/21/2022-02:53:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 0 Time: 0.0865039
[05/21/2022-02:53:18] [V] [TRT] Tactic: 1 Time: 0.0689583
[05/21/2022-02:53:18] [V] [TRT] Tactic: 2 Time: 0.0686651
[05/21/2022-02:53:18] [V] [TRT] Tactic: 3 Time: 0.0624934
[05/21/2022-02:53:18] [V] [TRT] Tactic: 4 Time: 0.0608724
[05/21/2022-02:53:18] [V] [TRT] Tactic: 5 Time: 0.0613409
[05/21/2022-02:53:18] [V] [TRT] Tactic: 6 Time: 0.0602539
[05/21/2022-02:53:18] [V] [TRT] Tactic: 7 Time: 0.0578776
[05/21/2022-02:53:18] [V] [TRT] Tactic: 8 Time: 0.0564516
[05/21/2022-02:53:18] [V] [TRT] Tactic: 9 Time: 0.0593034
[05/21/2022-02:53:18] [V] [TRT] Tactic: 10 Time: 0.12959
[05/21/2022-02:53:18] [V] [TRT] Tactic: 11 Time: 0.0948501
[05/21/2022-02:53:18] [V] [TRT] Tactic: 12 Time: 0.0881187
[05/21/2022-02:53:18] [V] [TRT] Tactic: 13 Time: 0.0714976
[05/21/2022-02:53:18] [V] [TRT] Tactic: 14 Time: 0.0676043
[05/21/2022-02:53:18] [V] [TRT] Tactic: 15 Time: 0.0674804
[05/21/2022-02:53:18] [V] [TRT] Tactic: 16 Time: 0.0606184
[05/21/2022-02:53:18] [V] [TRT] Tactic: 17 Time: 0.0543944
[05/21/2022-02:53:18] [V] [TRT] Tactic: 18 Time: 0.0550976
[05/21/2022-02:53:18] [V] [TRT] Tactic: 19 Time: 0.0573177
[05/21/2022-02:53:18] [V] [TRT] Tactic: 28 Time: 0.0852473
[05/21/2022-02:53:18] [V] [TRT] Tactic: 29 Time: 0.12998
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: 17 Time: 0.0543944
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-02:53:18] [V] [TRT] Tactic: 128 Time: 0.369095
[05/21/2022-02:53:18] [V] [TRT] Tactic: 256 Time: 0.365059
[05/21/2022-02:53:18] [V] [TRT] Tactic: 512 Time: 0.339739
[05/21/2022-02:53:18] [V] [TRT] Tactic: -32 Time: 0.387695
[05/21/2022-02:53:18] [V] [TRT] Tactic: -64 Time: 0.36653
[05/21/2022-02:53:18] [V] [TRT] Tactic: -128 Time: 0.363991
[05/21/2022-02:53:18] [V] [TRT] Fastest Tactic: 512 Time: 0.339739
[05/21/2022-02:53:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:53:18] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:53:18] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:18] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:53:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:18] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:19] [V] [TRT] Tactic: 0 Time: 11.0919
[05/21/2022-02:53:19] [V] [TRT] Tactic: 1 Time: 8.57927
[05/21/2022-02:53:19] [V] [TRT] Tactic: 2 Time: 9.52192
[05/21/2022-02:53:19] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2289125376, available: 536870912
[05/21/2022-02:53:19] [V] [TRT] Fastest Tactic: 1 Time: 8.57927
[05/21/2022-02:53:19] [V] [TRT] Setting workspace to 2289125376enables more tactics for profiling
[05/21/2022-02:53:19] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:19] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:53:19] [V] [TRT] Tactic: 1062367460111450758 Time: 8.35272
[05/21/2022-02:53:19] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:53:20] [V] [TRT] Tactic: 1754984623894446479 Time: 9.88003
[05/21/2022-02:53:20] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:53:20] [V] [TRT] Tactic: 3611739942397549984 Time: 6.34432
[05/21/2022-02:53:20] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:53:20] [V] [TRT] Tactic: 4337000649858996379 Time: 6.33109
[05/21/2022-02:53:20] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:53:20] [V] [TRT] Tactic: 4501471010995462441 Time: 6.2344
[05/21/2022-02:53:20] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:53:20] [V] [TRT] Tactic: 5137655947464784826 Time: 6.0544
[05/21/2022-02:53:20] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:53:20] [V] [TRT] Tactic: 5288347012147084929 Time: 6.14943
[05/21/2022-02:53:21] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:53:21] [V] [TRT] Tactic: 6645123197870846056 Time: 6.29182
[05/21/2022-02:53:21] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:53:21] [V] [TRT] Tactic: 7144526460361122478 Time: 8.85399
[05/21/2022-02:53:21] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:53:21] [V] [TRT] Tactic: -9137461792520977713 Time: 6.42276
[05/21/2022-02:53:21] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:53:21] [V] [TRT] Tactic: -8262349710178828730 Time: 6.32258
[05/21/2022-02:53:21] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:53:21] [V] [TRT] Tactic: -8133971918129952780 Time: 7.28064
[05/21/2022-02:53:22] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:53:22] [V] [TRT] Tactic: -6092040395344634144 Time: 8.71806
[05/21/2022-02:53:22] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:53:22] [V] [TRT] Tactic: -4787320710726427159 Time: 9.85224
[05/21/2022-02:53:22] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:53:22] [V] [TRT] Tactic: -3456450830548107839 Time: 7.31722
[05/21/2022-02:53:22] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:53:23] [V] [TRT] Tactic: -1218658103698133241 Time: 7.34374
[05/21/2022-02:53:23] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:53:23] [V] [TRT] Tactic: -836875257600482091 Time: 7.31172
[05/21/2022-02:53:23] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:53:23] [V] [TRT] Tactic: -410470605513481746 Time: 6.13921
[05/21/2022-02:53:23] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 6.0544
[05/21/2022-02:53:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-02:53:23] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:53:23] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:23] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:23] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:53:23] [V] [TRT] Tactic: -9153228964338181824 Time: 7.86051
[05/21/2022-02:53:23] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:53:23] [V] [TRT] Tactic: -7394439838318485025 Time: 5.88243
[05/21/2022-02:53:23] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 5.88243
[05/21/2022-02:53:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:53:23] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:53:23] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:24] [V] [TRT] Tactic: 0 Time: 12.5998
[05/21/2022-02:53:24] [V] [TRT] Tactic: 1 Time: 12.2234
[05/21/2022-02:53:24] [V] [TRT] Tactic: 2 Time: 9.2143
[05/21/2022-02:53:24] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2288755712, available: 536870912
[05/21/2022-02:53:24] [V] [TRT] Fastest Tactic: 2 Time: 9.2143
[05/21/2022-02:53:24] [V] [TRT] Setting workspace to 2288755712enables more tactics for profiling
[05/21/2022-02:53:24] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:53:24] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:53:24] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:24] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:24] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:24] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:24] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:53:24] [V] [TRT] Tactic: 3564772625446233998 Time: 4.21631
[05/21/2022-02:53:24] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:53:25] [V] [TRT] Tactic: 3650389455493082349 Time: 4.36128
[05/21/2022-02:53:25] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:53:25] [V] [TRT] Tactic: 5319956359050645452 Time: 3.77986
[05/21/2022-02:53:25] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:53:25] [V] [TRT] Tactic: 7205456024582378848 Time: 3.16299
[05/21/2022-02:53:25] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:53:25] [V] [TRT] Tactic: -6490690591794140522 Time: 3.21032
[05/21/2022-02:53:25] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:53:25] [V] [TRT] Tactic: -4686027666808657977 Time: 3.15783
[05/21/2022-02:53:25] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:53:25] [V] [TRT] Tactic: -4212163711445252890 Time: 2.98349
[05/21/2022-02:53:25] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:53:25] [V] [TRT] Tactic: -3898373634979201110 Time: 3.08044
[05/21/2022-02:53:25] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:53:25] [V] [TRT] Tactic: -2409163523992614473 Time: 3.0693
[05/21/2022-02:53:25] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 2.98349
[05/21/2022-02:53:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:53:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:25] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:53:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:25] [V] [TRT] Tactic: 0 Time: 0.0974416
[05/21/2022-02:53:26] [V] [TRT] Tactic: 1 Time: 0.0755077
[05/21/2022-02:53:26] [V] [TRT] Tactic: 2 Time: 0.0699738
[05/21/2022-02:53:26] [V] [TRT] Tactic: 3 Time: 0.0629103
[05/21/2022-02:53:26] [V] [TRT] Tactic: 4 Time: 0.053776
[05/21/2022-02:53:26] [V] [TRT] Tactic: 5 Time: 0.0549154
[05/21/2022-02:53:26] [V] [TRT] Tactic: 6 Time: 0.0601365
[05/21/2022-02:53:26] [V] [TRT] Tactic: 7 Time: 0.0489779
[05/21/2022-02:53:26] [V] [TRT] Tactic: 8 Time: 0.0467188
[05/21/2022-02:53:26] [V] [TRT] Tactic: 9 Time: 0.0486134
[05/21/2022-02:53:26] [V] [TRT] Tactic: 28 Time: 0.0954167
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 8 Time: 0.0467188
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 128 Time: 0.339765
[05/21/2022-02:53:26] [V] [TRT] Tactic: 256 Time: 0.341198
[05/21/2022-02:53:26] [V] [TRT] Tactic: 512 Time: 0.342051
[05/21/2022-02:53:26] [V] [TRT] Tactic: -32 Time: 0.388392
[05/21/2022-02:53:26] [V] [TRT] Tactic: -64 Time: 0.370098
[05/21/2022-02:53:26] [V] [TRT] Tactic: -128 Time: 0.360469
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 128 Time: 0.339765
[05/21/2022-02:53:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:26] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 0 Time: 0.0969856
[05/21/2022-02:53:26] [V] [TRT] Tactic: 1 Time: 0.073737
[05/21/2022-02:53:26] [V] [TRT] Tactic: 2 Time: 0.0696748
[05/21/2022-02:53:26] [V] [TRT] Tactic: 3 Time: 0.0624023
[05/21/2022-02:53:26] [V] [TRT] Tactic: 4 Time: 0.0538736
[05/21/2022-02:53:26] [V] [TRT] Tactic: 5 Time: 0.0549155
[05/21/2022-02:53:26] [V] [TRT] Tactic: 6 Time: 0.0585741
[05/21/2022-02:53:26] [V] [TRT] Tactic: 7 Time: 0.0481316
[05/21/2022-02:53:26] [V] [TRT] Tactic: 8 Time: 0.0452214
[05/21/2022-02:53:26] [V] [TRT] Tactic: 9 Time: 0.0488218
[05/21/2022-02:53:26] [V] [TRT] Tactic: 28 Time: 0.0953258
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 8 Time: 0.0452214
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 128 Time: 0.340117
[05/21/2022-02:53:26] [V] [TRT] Tactic: 256 Time: 0.341224
[05/21/2022-02:53:26] [V] [TRT] Tactic: 512 Time: 0.341517
[05/21/2022-02:53:26] [V] [TRT] Tactic: -32 Time: 0.388014
[05/21/2022-02:53:26] [V] [TRT] Tactic: -64 Time: 0.369811
[05/21/2022-02:53:26] [V] [TRT] Tactic: -128 Time: 0.360221
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 128 Time: 0.340117
[05/21/2022-02:53:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:26] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 24 Time: 0.0684636
[05/21/2022-02:53:26] [V] [TRT] Tactic: 25 Time: 0.0634439
[05/21/2022-02:53:26] [V] [TRT] Tactic: 26 Time: 0.0630012
[05/21/2022-02:53:26] [V] [TRT] Tactic: 27 Time: 0.0674414
[05/21/2022-02:53:26] [V] [TRT] Tactic: 31 Time: 0.0684181
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 26 Time: 0.0630012
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 128 Time: 0.339954
[05/21/2022-02:53:26] [V] [TRT] Tactic: 256 Time: 0.340508
[05/21/2022-02:53:26] [V] [TRT] Tactic: 512 Time: 0.341393
[05/21/2022-02:53:26] [V] [TRT] Tactic: -32 Time: 0.387357
[05/21/2022-02:53:26] [V] [TRT] Tactic: -64 Time: 0.369889
[05/21/2022-02:53:26] [V] [TRT] Tactic: -128 Time: 0.359987
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 128 Time: 0.339954
[05/21/2022-02:53:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:53:26] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 0 Time: 0.0987175
[05/21/2022-02:53:26] [V] [TRT] Tactic: 1 Time: 0.0766537
[05/21/2022-02:53:26] [V] [TRT] Tactic: 2 Time: 0.0712761
[05/21/2022-02:53:26] [V] [TRT] Tactic: 3 Time: 0.0623111
[05/21/2022-02:53:26] [V] [TRT] Tactic: 4 Time: 0.0568946
[05/21/2022-02:53:26] [V] [TRT] Tactic: 5 Time: 0.0575715
[05/21/2022-02:53:26] [V] [TRT] Tactic: 6 Time: 0.0567124
[05/21/2022-02:53:26] [V] [TRT] Tactic: 7 Time: 0.0485545
[05/21/2022-02:53:26] [V] [TRT] Tactic: 8 Time: 0.0489716
[05/21/2022-02:53:26] [V] [TRT] Tactic: 9 Time: 0.0499285
[05/21/2022-02:53:26] [V] [TRT] Tactic: 28 Time: 0.0987956
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 7 Time: 0.0485545
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 128 Time: 0.350651
[05/21/2022-02:53:26] [V] [TRT] Tactic: 256 Time: 0.345579
[05/21/2022-02:53:26] [V] [TRT] Tactic: 512 Time: 0.327376
[05/21/2022-02:53:26] [V] [TRT] Tactic: -32 Time: 0.386035
[05/21/2022-02:53:26] [V] [TRT] Tactic: -64 Time: 0.363724
[05/21/2022-02:53:26] [V] [TRT] Tactic: -128 Time: 0.357637
[05/21/2022-02:53:26] [V] [TRT] Fastest Tactic: 512 Time: 0.327376
[05/21/2022-02:53:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:53:26] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:53:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:26] [V] [TRT] Tactic: 0 Time: 0.0763866
[05/21/2022-02:53:26] [V] [TRT] Tactic: 1 Time: 0.0634894
[05/21/2022-02:53:26] [V] [TRT] Tactic: 2 Time: 0.0628385
[05/21/2022-02:53:26] [V] [TRT] Tactic: 3 Time: 0.0597594
[05/21/2022-02:53:26] [V] [TRT] Tactic: 4 Time: 0.0584637
[05/21/2022-02:53:26] [V] [TRT] Tactic: 5 Time: 0.0591471
[05/21/2022-02:53:26] [V] [TRT] Tactic: 6 Time: 0.0588084
[05/21/2022-02:53:26] [V] [TRT] Tactic: 7 Time: 0.0562891
[05/21/2022-02:53:26] [V] [TRT] Tactic: 8 Time: 0.0553059
[05/21/2022-02:53:26] [V] [TRT] Tactic: 9 Time: 0.0577606
[05/21/2022-02:53:26] [V] [TRT] Tactic: 10 Time: 0.103522
[05/21/2022-02:53:26] [V] [TRT] Tactic: 11 Time: 0.0789324
[05/21/2022-02:53:26] [V] [TRT] Tactic: 12 Time: 0.0749348
[05/21/2022-02:53:26] [V] [TRT] Tactic: 13 Time: 0.0636001
[05/21/2022-02:53:26] [V] [TRT] Tactic: 14 Time: 0.0583656
[05/21/2022-02:53:26] [V] [TRT] Tactic: 15 Time: 0.0599479
[05/21/2022-02:53:26] [V] [TRT] Tactic: 16 Time: 0.0572527
[05/21/2022-02:53:26] [V] [TRT] Tactic: 17 Time: 0.0500329
[05/21/2022-02:53:26] [V] [TRT] Tactic: 18 Time: 0.0497073
[05/21/2022-02:53:26] [V] [TRT] Tactic: 19 Time: 0.0535807
[05/21/2022-02:53:26] [V] [TRT] Tactic: 28 Time: 0.0751561
[05/21/2022-02:53:27] [V] [TRT] Tactic: 29 Time: 0.101816
[05/21/2022-02:53:27] [V] [TRT] Fastest Tactic: 18 Time: 0.0497073
[05/21/2022-02:53:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-02:53:27] [V] [TRT] Tactic: 128 Time: 0.35125
[05/21/2022-02:53:27] [V] [TRT] Tactic: 256 Time: 0.345417
[05/21/2022-02:53:27] [V] [TRT] Tactic: 512 Time: 0.326569
[05/21/2022-02:53:27] [V] [TRT] Tactic: -32 Time: 0.385
[05/21/2022-02:53:27] [V] [TRT] Tactic: -64 Time: 0.364076
[05/21/2022-02:53:27] [V] [TRT] Tactic: -128 Time: 0.358405
[05/21/2022-02:53:27] [V] [TRT] Fastest Tactic: 512 Time: 0.326569
[05/21/2022-02:53:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:53:27] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:27] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:53:27] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:27] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:53:27] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:27] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:27] [V] [TRT] Tactic: 0 Time: 2.52059
[05/21/2022-02:53:27] [V] [TRT] Tactic: 1 Time: 2.0812
[05/21/2022-02:53:27] [V] [TRT] Tactic: 2 Time: 2.51865
[05/21/2022-02:53:27] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2422472704, available: 536870912
[05/21/2022-02:53:28] [V] [TRT] Tactic: 5 Time: 83.391
[05/21/2022-02:53:28] [V] [TRT] Fastest Tactic: 1 Time: 2.0812
[05/21/2022-02:53:28] [V] [TRT] Setting workspace to 2422472704enables more tactics for profiling
[05/21/2022-02:53:28] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:28] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:28] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:28] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:53:28] [V] [TRT] Tactic: 1062367460111450758 Time: 1.82222
[05/21/2022-02:53:28] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:53:28] [V] [TRT] Tactic: 1698681053543049347 Time: 1.68395
[05/21/2022-02:53:28] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:53:28] [V] [TRT] Tactic: 4501471010995462441 Time: 1.39228
[05/21/2022-02:53:28] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:53:29] [V] [TRT] Tactic: 5137655947464784826 Time: 1.37341
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:53:29] [V] [TRT] Tactic: 5288347012147084929 Time: 1.38819
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:53:29] [V] [TRT] Tactic: 5326823351883942011 Time: 1.33686
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:53:29] [V] [TRT] Tactic: 5500448035057547314 Time: 1.48541
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:53:29] [V] [TRT] Tactic: 6645123197870846056 Time: 1.39921
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:53:29] [V] [TRT] Tactic: 7144526460361122478 Time: 1.89545
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:53:29] [V] [TRT] Tactic: -8262349710178828730 Time: 1.41069
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:53:29] [V] [TRT] Tactic: -6576203419454146580 Time: 1.5621
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:53:29] [V] [TRT] Tactic: -4787320710726427159 Time: 1.98899
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:53:29] [V] [TRT] Tactic: -3456450830548107839 Time: 1.64926
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:53:29] [V] [TRT] Tactic: -1218658103698133241 Time: 1.5548
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:53:29] [V] [TRT] Tactic: -836875257600482091 Time: 1.49978
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:53:29] [V] [TRT] Tactic: -410470605513481746 Time: 1.38127
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:53:29] [V] [TRT] Tactic: -377491875521947884 Time: 1.37168
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:53:29] [V] [TRT] Tactic: -37215280111360163 Time: 1.33542
[05/21/2022-02:53:29] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 1.33542
[05/21/2022-02:53:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-02:53:29] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:53:29] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:29] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:29] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:29] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:53:29] [V] [TRT] Tactic: 3886731678879822788 Time: 1.36065
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:53:29] [V] [TRT] Tactic: 6629944304117643200 Time: 2.08658
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:53:29] [V] [TRT] Tactic: -9153228964338181824 Time: 2.11128
[05/21/2022-02:53:29] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:53:29] [V] [TRT] Tactic: -7394439838318485025 Time: 1.36078
[05/21/2022-02:53:29] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 1.36065
[05/21/2022-02:53:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:53:29] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:53:29] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:30] [V] [TRT] Tactic: 0 Time: 2.48736
[05/21/2022-02:53:30] [V] [TRT] Tactic: 1 Time: 2.1538
[05/21/2022-02:53:30] [V] [TRT] Tactic: 2 Time: 2.4924
[05/21/2022-02:53:30] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2422472704, available: 536870912
[05/21/2022-02:53:31] [V] [TRT] Tactic: 5 Time: 83.548
[05/21/2022-02:53:31] [V] [TRT] Fastest Tactic: 1 Time: 2.1538
[05/21/2022-02:53:31] [V] [TRT] Setting workspace to 2422472704enables more tactics for profiling
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:31] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:53:31] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:31] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:31] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:31] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:31] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:53:31] [V] [TRT] Tactic: 3066127711859985668 Time: 0.796022
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:53:31] [V] [TRT] Tactic: 3564772625446233998 Time: 0.907539
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:53:31] [V] [TRT] Tactic: 5319956359050645452 Time: 0.840664
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:53:31] [V] [TRT] Tactic: 7205456024582378848 Time: 0.730169
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:53:31] [V] [TRT] Tactic: 8163473458334948789 Time: 0.693157
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:53:31] [V] [TRT] Tactic: -4212163711445252890 Time: 0.691725
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:53:31] [V] [TRT] Tactic: -3898373634979201110 Time: 0.707708
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:53:31] [V] [TRT] Tactic: -2409163523992614473 Time: 0.718958
[05/21/2022-02:53:31] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:53:31] [V] [TRT] Tactic: -1716393687483585322 Time: 0.680404
[05/21/2022-02:53:31] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.680404
[05/21/2022-02:53:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:53:31] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:31] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:53:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:31] [V] [TRT] Tactic: 0 Time: 0.0640234
[05/21/2022-02:53:31] [V] [TRT] Tactic: 1 Time: 0.0460025
[05/21/2022-02:53:32] [V] [TRT] Tactic: 2 Time: 0.0433527
[05/21/2022-02:53:32] [V] [TRT] Tactic: 3 Time: 0.03653
[05/21/2022-02:53:32] [V] [TRT] Tactic: 4 Time: 0.0335481
[05/21/2022-02:53:32] [V] [TRT] Tactic: 5 Time: 0.0326953
[05/21/2022-02:53:32] [V] [TRT] Tactic: 6 Time: 0.0336782
[05/21/2022-02:53:32] [V] [TRT] Tactic: 7 Time: 0.0289129
[05/21/2022-02:53:32] [V] [TRT] Tactic: 8 Time: 0.0278386
[05/21/2022-02:53:32] [V] [TRT] Tactic: 9 Time: 0.0283266
[05/21/2022-02:53:32] [V] [TRT] Tactic: 28 Time: 0.0631769
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: 8 Time: 0.0278386
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 128 Time: 0.195658
[05/21/2022-02:53:32] [V] [TRT] Tactic: 256 Time: 0.195469
[05/21/2022-02:53:32] [V] [TRT] Tactic: 512 Time: 0.195371
[05/21/2022-02:53:32] [V] [TRT] Tactic: -32 Time: 0.210619
[05/21/2022-02:53:32] [V] [TRT] Tactic: -64 Time: 0.202448
[05/21/2022-02:53:32] [V] [TRT] Tactic: -128 Time: 0.190423
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: -128 Time: 0.190423
[05/21/2022-02:53:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:32] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 0 Time: 0.0639713
[05/21/2022-02:53:32] [V] [TRT] Tactic: 1 Time: 0.0457291
[05/21/2022-02:53:32] [V] [TRT] Tactic: 2 Time: 0.0438281
[05/21/2022-02:53:32] [V] [TRT] Tactic: 3 Time: 0.036159
[05/21/2022-02:53:32] [V] [TRT] Tactic: 4 Time: 0.0338476
[05/21/2022-02:53:32] [V] [TRT] Tactic: 5 Time: 0.032962
[05/21/2022-02:53:32] [V] [TRT] Tactic: 6 Time: 0.0340951
[05/21/2022-02:53:32] [V] [TRT] Tactic: 7 Time: 0.0291471
[05/21/2022-02:53:32] [V] [TRT] Tactic: 8 Time: 0.02806
[05/21/2022-02:53:32] [V] [TRT] Tactic: 9 Time: 0.0286263
[05/21/2022-02:53:32] [V] [TRT] Tactic: 28 Time: 0.063496
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: 8 Time: 0.02806
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 128 Time: 0.195892
[05/21/2022-02:53:32] [V] [TRT] Tactic: 256 Time: 0.195124
[05/21/2022-02:53:32] [V] [TRT] Tactic: 512 Time: 0.195488
[05/21/2022-02:53:32] [V] [TRT] Tactic: -32 Time: 0.199473
[05/21/2022-02:53:32] [V] [TRT] Tactic: -64 Time: 0.192214
[05/21/2022-02:53:32] [V] [TRT] Tactic: -128 Time: 0.190658
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: -128 Time: 0.190658
[05/21/2022-02:53:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:32] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 24 Time: 0.0383659
[05/21/2022-02:53:32] [V] [TRT] Tactic: 25 Time: 0.0343232
[05/21/2022-02:53:32] [V] [TRT] Tactic: 26 Time: 0.037461
[05/21/2022-02:53:32] [V] [TRT] Tactic: 27 Time: 0.0376563
[05/21/2022-02:53:32] [V] [TRT] Tactic: 31 Time: 0.0392774
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: 25 Time: 0.0343232
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 128 Time: 0.195274
[05/21/2022-02:53:32] [V] [TRT] Tactic: 256 Time: 0.195391
[05/21/2022-02:53:32] [V] [TRT] Tactic: 512 Time: 0.195058
[05/21/2022-02:53:32] [V] [TRT] Tactic: -32 Time: 0.210775
[05/21/2022-02:53:32] [V] [TRT] Tactic: -64 Time: 0.202878
[05/21/2022-02:53:32] [V] [TRT] Tactic: -128 Time: 0.190345
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: -128 Time: 0.190345
[05/21/2022-02:53:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:53:32] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 0 Time: 0.0645051
[05/21/2022-02:53:32] [V] [TRT] Tactic: 1 Time: 0.0472005
[05/21/2022-02:53:32] [V] [TRT] Tactic: 2 Time: 0.044056
[05/21/2022-02:53:32] [V] [TRT] Tactic: 3 Time: 0.0362369
[05/21/2022-02:53:32] [V] [TRT] Tactic: 4 Time: 0.0337694
[05/21/2022-02:53:32] [V] [TRT] Tactic: 5 Time: 0.0332552
[05/21/2022-02:53:32] [V] [TRT] Tactic: 6 Time: 0.0311521
[05/21/2022-02:53:32] [V] [TRT] Tactic: 7 Time: 0.0287565
[05/21/2022-02:53:32] [V] [TRT] Tactic: 8 Time: 0.0287825
[05/21/2022-02:53:32] [V] [TRT] Tactic: 9 Time: 0.028776
[05/21/2022-02:53:32] [V] [TRT] Tactic: 28 Time: 0.0644727
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: 7 Time: 0.0287565
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 128 Time: 0.187077
[05/21/2022-02:53:32] [V] [TRT] Tactic: 256 Time: 0.184199
[05/21/2022-02:53:32] [V] [TRT] Tactic: 512 Time: 0.174251
[05/21/2022-02:53:32] [V] [TRT] Tactic: -32 Time: 0.21211
[05/21/2022-02:53:32] [V] [TRT] Tactic: -64 Time: 0.191478
[05/21/2022-02:53:32] [V] [TRT] Tactic: -128 Time: 0.198249
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: 512 Time: 0.174251
[05/21/2022-02:53:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:53:32] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 0 Time: 0.045215
[05/21/2022-02:53:32] [V] [TRT] Tactic: 1 Time: 0.0337566
[05/21/2022-02:53:32] [V] [TRT] Tactic: 2 Time: 0.0341079
[05/21/2022-02:53:32] [V] [TRT] Tactic: 3 Time: 0.0291861
[05/21/2022-02:53:32] [V] [TRT] Tactic: 4 Time: 0.0290949
[05/21/2022-02:53:32] [V] [TRT] Tactic: 5 Time: 0.0299609
[05/21/2022-02:53:32] [V] [TRT] Tactic: 6 Time: 0.0292512
[05/21/2022-02:53:32] [V] [TRT] Tactic: 7 Time: 0.0283203
[05/21/2022-02:53:32] [V] [TRT] Tactic: 8 Time: 0.0293099
[05/21/2022-02:53:32] [V] [TRT] Tactic: 9 Time: 0.0325391
[05/21/2022-02:53:32] [V] [TRT] Tactic: 10 Time: 0.0667905
[05/21/2022-02:53:32] [V] [TRT] Tactic: 11 Time: 0.0498048
[05/21/2022-02:53:32] [V] [TRT] Tactic: 12 Time: 0.0457556
[05/21/2022-02:53:32] [V] [TRT] Tactic: 13 Time: 0.0365429
[05/21/2022-02:53:32] [V] [TRT] Tactic: 14 Time: 0.0357357
[05/21/2022-02:53:32] [V] [TRT] Tactic: 15 Time: 0.0357879
[05/21/2022-02:53:32] [V] [TRT] Tactic: 16 Time: 0.031146
[05/21/2022-02:53:32] [V] [TRT] Tactic: 17 Time: 0.0290495
[05/21/2022-02:53:32] [V] [TRT] Tactic: 18 Time: 0.0289062
[05/21/2022-02:53:32] [V] [TRT] Tactic: 19 Time: 0.0307684
[05/21/2022-02:53:32] [V] [TRT] Tactic: 28 Time: 0.0436914
[05/21/2022-02:53:32] [V] [TRT] Tactic: 29 Time: 0.0674611
[05/21/2022-02:53:32] [V] [TRT] Fastest Tactic: 7 Time: 0.0283203
[05/21/2022-02:53:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-02:53:32] [V] [TRT] Tactic: 128 Time: 0.187201
[05/21/2022-02:53:32] [V] [TRT] Tactic: 256 Time: 0.18528
[05/21/2022-02:53:32] [V] [TRT] Tactic: 512 Time: 0.174609
[05/21/2022-02:53:33] [V] [TRT] Tactic: -32 Time: 0.211758
[05/21/2022-02:53:33] [V] [TRT] Tactic: -64 Time: 0.191693
[05/21/2022-02:53:33] [V] [TRT] Tactic: -128 Time: 0.198555
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: 512 Time: 0.174609
[05/21/2022-02:53:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:53:33] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:33] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 0 Time: 0.0638929
[05/21/2022-02:53:33] [V] [TRT] Tactic: 1 Time: 0.0462631
[05/21/2022-02:53:33] [V] [TRT] Tactic: 2 Time: 0.0438801
[05/21/2022-02:53:33] [V] [TRT] Tactic: 3 Time: 0.0364647
[05/21/2022-02:53:33] [V] [TRT] Tactic: 4 Time: 0.0335418
[05/21/2022-02:53:33] [V] [TRT] Tactic: 5 Time: 0.033008
[05/21/2022-02:53:33] [V] [TRT] Tactic: 6 Time: 0.0340691
[05/21/2022-02:53:33] [V] [TRT] Tactic: 7 Time: 0.0291278
[05/21/2022-02:53:33] [V] [TRT] Tactic: 8 Time: 0.0277407
[05/21/2022-02:53:33] [V] [TRT] Tactic: 9 Time: 0.0286197
[05/21/2022-02:53:33] [V] [TRT] Tactic: 28 Time: 0.0630141
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: 8 Time: 0.0277407
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 128 Time: 0.195567
[05/21/2022-02:53:33] [V] [TRT] Tactic: 256 Time: 0.195358
[05/21/2022-02:53:33] [V] [TRT] Tactic: 512 Time: 0.195065
[05/21/2022-02:53:33] [V] [TRT] Tactic: -32 Time: 0.210462
[05/21/2022-02:53:33] [V] [TRT] Tactic: -64 Time: 0.201758
[05/21/2022-02:53:33] [V] [TRT] Tactic: -128 Time: 0.19054
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: -128 Time: 0.19054
[05/21/2022-02:53:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:33] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 0 Time: 0.063828
[05/21/2022-02:53:33] [V] [TRT] Tactic: 1 Time: 0.0462438
[05/21/2022-02:53:33] [V] [TRT] Tactic: 2 Time: 0.0435222
[05/21/2022-02:53:33] [V] [TRT] Tactic: 3 Time: 0.0366536
[05/21/2022-02:53:33] [V] [TRT] Tactic: 4 Time: 0.0338216
[05/21/2022-02:53:33] [V] [TRT] Tactic: 5 Time: 0.0327081
[05/21/2022-02:53:33] [V] [TRT] Tactic: 6 Time: 0.0342316
[05/21/2022-02:53:33] [V] [TRT] Tactic: 7 Time: 0.0290103
[05/21/2022-02:53:33] [V] [TRT] Tactic: 8 Time: 0.0279428
[05/21/2022-02:53:33] [V] [TRT] Tactic: 9 Time: 0.0284898
[05/21/2022-02:53:33] [V] [TRT] Tactic: 28 Time: 0.0634246
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: 8 Time: 0.0279428
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 128 Time: 0.195814
[05/21/2022-02:53:33] [V] [TRT] Tactic: 256 Time: 0.195416
[05/21/2022-02:53:33] [V] [TRT] Tactic: 512 Time: 0.195091
[05/21/2022-02:53:33] [V] [TRT] Tactic: -32 Time: 0.199805
[05/21/2022-02:53:33] [V] [TRT] Tactic: -64 Time: 0.191745
[05/21/2022-02:53:33] [V] [TRT] Tactic: -128 Time: 0.19041
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: -128 Time: 0.19041
[05/21/2022-02:53:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:33] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 24 Time: 0.0384506
[05/21/2022-02:53:33] [V] [TRT] Tactic: 25 Time: 0.0342514
[05/21/2022-02:53:33] [V] [TRT] Tactic: 26 Time: 0.0377476
[05/21/2022-02:53:33] [V] [TRT] Tactic: 27 Time: 0.036992
[05/21/2022-02:53:33] [V] [TRT] Tactic: 31 Time: 0.0382876
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: 25 Time: 0.0342514
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 128 Time: 0.195443
[05/21/2022-02:53:33] [V] [TRT] Tactic: 256 Time: 0.195365
[05/21/2022-02:53:33] [V] [TRT] Tactic: 512 Time: 0.194635
[05/21/2022-02:53:33] [V] [TRT] Tactic: -32 Time: 0.210677
[05/21/2022-02:53:33] [V] [TRT] Tactic: -64 Time: 0.20127
[05/21/2022-02:53:33] [V] [TRT] Tactic: -128 Time: 0.190091
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: -128 Time: 0.190091
[05/21/2022-02:53:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:53:33] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 0 Time: 0.0652084
[05/21/2022-02:53:33] [V] [TRT] Tactic: 1 Time: 0.047487
[05/21/2022-02:53:33] [V] [TRT] Tactic: 2 Time: 0.0436001
[05/21/2022-02:53:33] [V] [TRT] Tactic: 3 Time: 0.0360289
[05/21/2022-02:53:33] [V] [TRT] Tactic: 4 Time: 0.0335938
[05/21/2022-02:53:33] [V] [TRT] Tactic: 5 Time: 0.0336265
[05/21/2022-02:53:33] [V] [TRT] Tactic: 6 Time: 0.031133
[05/21/2022-02:53:33] [V] [TRT] Tactic: 7 Time: 0.0287828
[05/21/2022-02:53:33] [V] [TRT] Tactic: 8 Time: 0.028854
[05/21/2022-02:53:33] [V] [TRT] Tactic: 9 Time: 0.0288085
[05/21/2022-02:53:33] [V] [TRT] Tactic: 28 Time: 0.0645377
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: 7 Time: 0.0287828
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 128 Time: 0.18668
[05/21/2022-02:53:33] [V] [TRT] Tactic: 256 Time: 0.184095
[05/21/2022-02:53:33] [V] [TRT] Tactic: 512 Time: 0.173672
[05/21/2022-02:53:33] [V] [TRT] Tactic: -32 Time: 0.211634
[05/21/2022-02:53:33] [V] [TRT] Tactic: -64 Time: 0.191452
[05/21/2022-02:53:33] [V] [TRT] Tactic: -128 Time: 0.198554
[05/21/2022-02:53:33] [V] [TRT] Fastest Tactic: 512 Time: 0.173672
[05/21/2022-02:53:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:53:33] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:53:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:33] [V] [TRT] Tactic: 0 Time: 0.045195
[05/21/2022-02:53:33] [V] [TRT] Tactic: 1 Time: 0.0342186
[05/21/2022-02:53:33] [V] [TRT] Tactic: 2 Time: 0.0337503
[05/21/2022-02:53:33] [V] [TRT] Tactic: 3 Time: 0.0299351
[05/21/2022-02:53:33] [V] [TRT] Tactic: 4 Time: 0.0294075
[05/21/2022-02:53:33] [V] [TRT] Tactic: 5 Time: 0.0308269
[05/21/2022-02:53:33] [V] [TRT] Tactic: 6 Time: 0.0291601
[05/21/2022-02:53:33] [V] [TRT] Tactic: 7 Time: 0.0281639
[05/21/2022-02:53:33] [V] [TRT] Tactic: 8 Time: 0.0294466
[05/21/2022-02:53:33] [V] [TRT] Tactic: 9 Time: 0.032435
[05/21/2022-02:53:33] [V] [TRT] Tactic: 10 Time: 0.0666994
[05/21/2022-02:53:33] [V] [TRT] Tactic: 11 Time: 0.0489973
[05/21/2022-02:53:33] [V] [TRT] Tactic: 12 Time: 0.0459309
[05/21/2022-02:53:33] [V] [TRT] Tactic: 13 Time: 0.0365691
[05/21/2022-02:53:34] [V] [TRT] Tactic: 14 Time: 0.0357616
[05/21/2022-02:53:34] [V] [TRT] Tactic: 15 Time: 0.0357226
[05/21/2022-02:53:34] [V] [TRT] Tactic: 16 Time: 0.0311525
[05/21/2022-02:53:34] [V] [TRT] Tactic: 17 Time: 0.0292579
[05/21/2022-02:53:34] [V] [TRT] Tactic: 18 Time: 0.0288674
[05/21/2022-02:53:34] [V] [TRT] Tactic: 19 Time: 0.0311718
[05/21/2022-02:53:34] [V] [TRT] Tactic: 28 Time: 0.0436914
[05/21/2022-02:53:34] [V] [TRT] Tactic: 29 Time: 0.0666797
[05/21/2022-02:53:34] [V] [TRT] Fastest Tactic: 7 Time: 0.0281639
[05/21/2022-02:53:34] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-02:53:34] [V] [TRT] Tactic: 128 Time: 0.187272
[05/21/2022-02:53:34] [V] [TRT] Tactic: 256 Time: 0.184649
[05/21/2022-02:53:34] [V] [TRT] Tactic: 512 Time: 0.174974
[05/21/2022-02:53:34] [V] [TRT] Tactic: -32 Time: 0.212057
[05/21/2022-02:53:34] [V] [TRT] Tactic: -64 Time: 0.192116
[05/21/2022-02:53:34] [V] [TRT] Tactic: -128 Time: 0.198203
[05/21/2022-02:53:34] [V] [TRT] Fastest Tactic: 512 Time: 0.174974
[05/21/2022-02:53:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:53:34] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:34] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:53:34] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:34] [V] [TRT] Tactic: 589823 Time: 1.06448
[05/21/2022-02:53:34] [V] [TRT] Tactic: 655359 Time: 0.62513
[05/21/2022-02:53:34] [V] [TRT] Tactic: 786431 Time: 0.718001
[05/21/2022-02:53:34] [V] [TRT] Tactic: 851967 Time: 0.841367
[05/21/2022-02:53:34] [V] [TRT] Tactic: 1179647 Time: 1.19753
[05/21/2022-02:53:34] [V] [TRT] Tactic: 1310719 Time: 2.38182
[05/21/2022-02:53:34] [V] [TRT] Tactic: 1376255 Time: 0.764981
[05/21/2022-02:53:34] [V] [TRT] Tactic: 1441791 Time: 0.643333
[05/21/2022-02:53:34] [V] [TRT] Tactic: 1507327 Time: 0.570084
[05/21/2022-02:53:34] [V] [TRT] Tactic: 1638399 Time: 0.724857
[05/21/2022-02:53:34] [V] [TRT] Tactic: 1835007 Time: 0.814102
[05/21/2022-02:53:35] [V] [TRT] Tactic: 1900543 Time: 0.750156
[05/21/2022-02:53:35] [V] [TRT] Tactic: 2097151 Time: 1.30156
[05/21/2022-02:53:35] [V] [TRT] Tactic: 2162687 Time: 0.559075
[05/21/2022-02:53:35] [V] [TRT] Tactic: 2293759 Time: 0.529388
[05/21/2022-02:53:35] [V] [TRT] Tactic: 2359295 Time: 0.508763
[05/21/2022-02:53:35] [V] [TRT] Tactic: 2686975 Time: 0.56586
[05/21/2022-02:53:35] [V] [TRT] Tactic: 3080191 Time: 0.765886
[05/21/2022-02:53:35] [V] [TRT] Tactic: 3342335 Time: 0.79987
[05/21/2022-02:53:35] [V] [TRT] Tactic: 3407871 Time: 0.535006
[05/21/2022-02:53:35] [V] [TRT] Tactic: 3538943 Time: 0.540065
[05/21/2022-02:53:35] [V] [TRT] Tactic: 3670015 Time: 0.492194
[05/21/2022-02:53:35] [V] [TRT] Tactic: 3932159 Time: 0.675293
[05/21/2022-02:53:35] [V] [TRT] Tactic: 3997695 Time: 0.70043
[05/21/2022-02:53:35] [V] [TRT] Tactic: 4063231 Time: 0.857682
[05/21/2022-02:53:35] [V] [TRT] Tactic: 4194303 Time: 1.08291
[05/21/2022-02:53:36] [V] [TRT] Tactic: 4259839 Time: 1.36283
[05/21/2022-02:53:36] [V] [TRT] Tactic: 4325375 Time: 0.615078
[05/21/2022-02:53:36] [V] [TRT] Tactic: 4521983 Time: 0.6239
[05/21/2022-02:53:36] [V] [TRT] Tactic: 4587519 Time: 0.55929
[05/21/2022-02:53:36] [V] [TRT] Tactic: 4653055 Time: 0.541042
[05/21/2022-02:53:36] [V] [TRT] Tactic: 4915199 Time: 1.08071
[05/21/2022-02:53:36] [V] [TRT] Tactic: 4980735 Time: 0.627012
[05/21/2022-02:53:36] [V] [TRT] Tactic: 5177343 Time: 1.08495
[05/21/2022-02:53:36] [V] [TRT] Tactic: 5242879 Time: 0.909303
[05/21/2022-02:53:36] [V] [TRT] Tactic: 5373951 Time: 1.21733
[05/21/2022-02:53:36] [V] [TRT] Tactic: 5439487 Time: 1.03689
[05/21/2022-02:53:36] [V] [TRT] Tactic: 5570559 Time: 0.812812
[05/21/2022-02:53:36] [V] [TRT] Tactic: 5636095 Time: 0.860586
[05/21/2022-02:53:36] [V] [TRT] Tactic: 5701631 Time: 0.900586
[05/21/2022-02:53:37] [V] [TRT] Tactic: 5767167 Time: 1.48514
[05/21/2022-02:53:37] [V] [TRT] Tactic: 5832703 Time: 1.01225
[05/21/2022-02:53:37] [V] [TRT] Tactic: 5898239 Time: 0.880059
[05/21/2022-02:53:37] [V] [TRT] Tactic: 6029311 Time: 0.903861
[05/21/2022-02:53:37] [V] [TRT] Tactic: 6225919 Time: 0.93405
[05/21/2022-02:53:37] [V] [TRT] Tactic: 6291455 Time: 1.1737
[05/21/2022-02:53:37] [V] [TRT] Tactic: 6422527 Time: 0.933177
[05/21/2022-02:53:37] [V] [TRT] Tactic: 6750207 Time: 1.04523
[05/21/2022-02:53:37] [V] [TRT] Tactic: 6815743 Time: 0.943119
[05/21/2022-02:53:37] [V] [TRT] Tactic: 6946815 Time: 1.43302
[05/21/2022-02:53:37] [V] [TRT] Tactic: 7012351 Time: 1.29023
[05/21/2022-02:53:37] [V] [TRT] Tactic: 7077887 Time: 1.04137
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7143423 Time: 1.47111
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7208959 Time: 0.944837
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7340031 Time: 0.921354
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7405567 Time: 0.886074
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7536639 Time: 1.1147
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7602175 Time: 1.39999
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7733247 Time: 0.930045
[05/21/2022-02:53:38] [V] [TRT] Tactic: 7798783 Time: 0.717702
[05/21/2022-02:53:38] [V] [TRT] Tactic: 8191999 Time: 1.58932
[05/21/2022-02:53:38] [V] [TRT] Tactic: 8257535 Time: 1.09384
[05/21/2022-02:53:38] [V] [TRT] Tactic: 8323071 Time: 1.00889
[05/21/2022-02:53:38] [V] [TRT] Tactic: 8650751 Time: 1.26538
[05/21/2022-02:53:38] [V] [TRT] Tactic: 8716287 Time: 0.987442
[05/21/2022-02:53:39] [V] [TRT] Tactic: 9109503 Time: 1.33228
[05/21/2022-02:53:39] [V] [TRT] Tactic: 9568255 Time: 1.08424
[05/21/2022-02:53:39] [V] [TRT] Tactic: 9895935 Time: 1.08214
[05/21/2022-02:53:39] [V] [TRT] Tactic: 10223615 Time: 0.561133
[05/21/2022-02:53:39] [V] [TRT] Tactic: 10354687 Time: 1.3815
[05/21/2022-02:53:39] [V] [TRT] Tactic: 10551295 Time: 1.0139
[05/21/2022-02:53:39] [V] [TRT] Tactic: 10747903 Time: 0.925
[05/21/2022-02:53:39] [V] [TRT] Tactic: 10944511 Time: 0.631048
[05/21/2022-02:53:39] [V] [TRT] Fastest Tactic: 3670015 Time: 0.492194
[05/21/2022-02:53:39] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:53:39] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:39] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:39] [V] [TRT] Tactic: 0 Time: 0.698424
[05/21/2022-02:53:39] [V] [TRT] Tactic: 1 Time: 0.601953
[05/21/2022-02:53:39] [V] [TRT] Tactic: 2 Time: 0.830944
[05/21/2022-02:53:39] [V] [TRT] Tactic: 4 skipped. Scratch requested: 606208000, available: 536870912
[05/21/2022-02:53:39] [V] [TRT] Tactic: 5 Time: 18.6329
[05/21/2022-02:53:39] [V] [TRT] Fastest Tactic: 1 Time: 0.601953
[05/21/2022-02:53:39] [V] [TRT] Setting workspace to 606208000enables more tactics for profiling
[05/21/2022-02:53:39] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:39] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:53:40] [V] [TRT] Tactic: 1062367460111450758 Time: 0.463333
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:53:40] [V] [TRT] Tactic: 1698681053543049347 Time: 0.439017
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:53:40] [V] [TRT] Tactic: 4501471010995462441 Time: 0.368854
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:53:40] [V] [TRT] Tactic: 5137655947464784826 Time: 0.37431
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:53:40] [V] [TRT] Tactic: 5288347012147084929 Time: 0.36709
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:53:40] [V] [TRT] Tactic: 5326823351883942011 Time: 0.354622
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:53:40] [V] [TRT] Tactic: 5500448035057547314 Time: 0.392376
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:53:40] [V] [TRT] Tactic: 6645123197870846056 Time: 0.383652
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:53:40] [V] [TRT] Tactic: 7144526460361122478 Time: 0.524674
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:53:40] [V] [TRT] Tactic: -8262349710178828730 Time: 0.370853
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:53:40] [V] [TRT] Tactic: -6576203419454146580 Time: 0.409844
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:53:40] [V] [TRT] Tactic: -4787320710726427159 Time: 0.556797
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:53:40] [V] [TRT] Tactic: -3456450830548107839 Time: 0.428144
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:53:40] [V] [TRT] Tactic: -1218658103698133241 Time: 0.409453
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:53:40] [V] [TRT] Tactic: -836875257600482091 Time: 0.400007
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:53:40] [V] [TRT] Tactic: -410470605513481746 Time: 0.36097
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:53:40] [V] [TRT] Tactic: -377491875521947884 Time: 0.363125
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:53:40] [V] [TRT] Tactic: -37215280111360163 Time: 0.358086
[05/21/2022-02:53:40] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.354622
[05/21/2022-02:53:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:53:40] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:40] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:53:40] [V] [TRT] Tactic: 3886731678879822788 Time: 0.367448
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:53:40] [V] [TRT] Tactic: 6629944304117643200 Time: 0.508346
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:53:40] [V] [TRT] Tactic: -9153228964338181824 Time: 0.510918
[05/21/2022-02:53:40] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:53:40] [V] [TRT] Tactic: -7394439838318485025 Time: 0.371003
[05/21/2022-02:53:40] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.367448
[05/21/2022-02:53:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:53:40] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:40] [V] [TRT] Tactic: 0 Time: 0.706784
[05/21/2022-02:53:40] [V] [TRT] Tactic: 1 Time: 0.621335
[05/21/2022-02:53:40] [V] [TRT] Tactic: 2 Time: 0.778229
[05/21/2022-02:53:40] [V] [TRT] Tactic: 4 skipped. Scratch requested: 606208000, available: 536870912
[05/21/2022-02:53:40] [V] [TRT] Tactic: 5 Time: 18.8713
[05/21/2022-02:53:40] [V] [TRT] Fastest Tactic: 1 Time: 0.621335
[05/21/2022-02:53:40] [V] [TRT] Setting workspace to 606208000enables more tactics for profiling
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:40] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:53:40] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:40] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:40] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:53:40] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:40] [V] [TRT] Tactic: 589823 Time: 0.535391
[05/21/2022-02:53:40] [V] [TRT] Tactic: 655359 Time: 0.394863
[05/21/2022-02:53:40] [V] [TRT] Tactic: 786431 Time: 0.437012
[05/21/2022-02:53:41] [V] [TRT] Tactic: 851967 Time: 0.440033
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1179647 Time: 0.517031
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1310719 Time: 1.24224
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1376255 Time: 0.38097
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1441791 Time: 0.310267
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1507327 Time: 0.29306
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1638399 Time: 0.378659
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1835007 Time: 0.51429
[05/21/2022-02:53:41] [V] [TRT] Tactic: 1900543 Time: 0.391934
[05/21/2022-02:53:41] [V] [TRT] Tactic: 2097151 Time: 0.904421
[05/21/2022-02:53:41] [V] [TRT] Tactic: 2162687 Time: 0.284785
[05/21/2022-02:53:41] [V] [TRT] Tactic: 2293759 Time: 0.265749
[05/21/2022-02:53:41] [V] [TRT] Tactic: 2359295 Time: 0.261035
[05/21/2022-02:53:41] [V] [TRT] Tactic: 2686975 Time: 0.47291
[05/21/2022-02:53:41] [V] [TRT] Tactic: 3080191 Time: 0.425827
[05/21/2022-02:53:41] [V] [TRT] Tactic: 3342335 Time: 0.407611
[05/21/2022-02:53:41] [V] [TRT] Tactic: 3407871 Time: 0.277611
[05/21/2022-02:53:41] [V] [TRT] Tactic: 3538943 Time: 0.274245
[05/21/2022-02:53:41] [V] [TRT] Tactic: 3670015 Time: 0.267383
[05/21/2022-02:53:41] [V] [TRT] Tactic: 3932159 Time: 0.297012
[05/21/2022-02:53:41] [V] [TRT] Tactic: 3997695 Time: 0.435527
[05/21/2022-02:53:41] [V] [TRT] Tactic: 4063231 Time: 0.449004
[05/21/2022-02:53:41] [V] [TRT] Tactic: 4194303 Time: 0.630117
[05/21/2022-02:53:41] [V] [TRT] Tactic: 4259839 Time: 0.90834
[05/21/2022-02:53:41] [V] [TRT] Tactic: 4325375 Time: 0.318763
[05/21/2022-02:53:42] [V] [TRT] Tactic: 4521983 Time: 0.308268
[05/21/2022-02:53:42] [V] [TRT] Tactic: 4587519 Time: 0.326224
[05/21/2022-02:53:42] [V] [TRT] Tactic: 4653055 Time: 0.275951
[05/21/2022-02:53:42] [V] [TRT] Tactic: 4915199 Time: 0.635
[05/21/2022-02:53:42] [V] [TRT] Tactic: 4980735 Time: 0.333932
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5177343 Time: 0.478118
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5242879 Time: 0.451627
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5373951 Time: 0.533151
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5439487 Time: 0.619186
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5570559 Time: 0.551087
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5636095 Time: 0.452995
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5701631 Time: 0.426146
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5767167 Time: 0.699479
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5832703 Time: 0.492409
[05/21/2022-02:53:42] [V] [TRT] Tactic: 5898239 Time: 0.546048
[05/21/2022-02:53:42] [V] [TRT] Tactic: 6029311 Time: 0.46985
[05/21/2022-02:53:42] [V] [TRT] Tactic: 6225919 Time: 0.443809
[05/21/2022-02:53:42] [V] [TRT] Tactic: 6291455 Time: 0.519479
[05/21/2022-02:53:42] [V] [TRT] Tactic: 6422527 Time: 0.480084
[05/21/2022-02:53:42] [V] [TRT] Tactic: 6750207 Time: 0.613906
[05/21/2022-02:53:42] [V] [TRT] Tactic: 6815743 Time: 0.462422
[05/21/2022-02:53:42] [V] [TRT] Tactic: 6946815 Time: 0.679303
[05/21/2022-02:53:42] [V] [TRT] Tactic: 7012351 Time: 0.909648
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7077887 Time: 0.491791
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7143423 Time: 0.734154
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7208959 Time: 0.461784
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7340031 Time: 0.567096
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7405567 Time: 0.455221
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7536639 Time: 0.542103
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7602175 Time: 0.661621
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7733247 Time: 0.545202
[05/21/2022-02:53:43] [V] [TRT] Tactic: 7798783 Time: 0.442728
[05/21/2022-02:53:43] [V] [TRT] Tactic: 8191999 Time: 0.781296
[05/21/2022-02:53:43] [V] [TRT] Tactic: 8257535 Time: 0.646901
[05/21/2022-02:53:43] [V] [TRT] Tactic: 8323071 Time: 0.593516
[05/21/2022-02:53:43] [V] [TRT] Tactic: 8650751 Time: 0.619681
[05/21/2022-02:53:43] [V] [TRT] Tactic: 8716287 Time: 0.468743
[05/21/2022-02:53:43] [V] [TRT] Tactic: 9109503 Time: 0.927461
[05/21/2022-02:53:43] [V] [TRT] Tactic: 9568255 Time: 0.638268
[05/21/2022-02:53:43] [V] [TRT] Tactic: 9895935 Time: 0.632175
[05/21/2022-02:53:43] [V] [TRT] Tactic: 10223615 Time: 0.475749
[05/21/2022-02:53:44] [V] [TRT] Tactic: 10354687 Time: 0.926706
[05/21/2022-02:53:44] [V] [TRT] Tactic: 10551295 Time: 0.513665
[05/21/2022-02:53:44] [V] [TRT] Tactic: 10747903 Time: 0.478236
[05/21/2022-02:53:44] [V] [TRT] Tactic: 10944511 Time: 0.332969
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: 2359295 Time: 0.261035
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-02:53:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:53:44] [V] [TRT] Tactic: 3066127711859985668 Time: 0.223333
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:53:44] [V] [TRT] Tactic: 3564772625446233998 Time: 0.258516
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:53:44] [V] [TRT] Tactic: 5319956359050645452 Time: 0.233131
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:53:44] [V] [TRT] Tactic: 7205456024582378848 Time: 0.203809
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:53:44] [V] [TRT] Tactic: 8163473458334948789 Time: 0.194779
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:53:44] [V] [TRT] Tactic: -4212163711445252890 Time: 0.193132
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:53:44] [V] [TRT] Tactic: -3898373634979201110 Time: 0.195925
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:53:44] [V] [TRT] Tactic: -2409163523992614473 Time: 0.200547
[05/21/2022-02:53:44] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:53:44] [V] [TRT] Tactic: -1716393687483585322 Time: 0.190456
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.190456
[05/21/2022-02:53:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:53:44] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:44] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:44] [V] [TRT] Tactic: 0 Time: 0.0506249
[05/21/2022-02:53:44] [V] [TRT] Tactic: 1 Time: 0.0389715
[05/21/2022-02:53:44] [V] [TRT] Tactic: 2 Time: 0.0371942
[05/21/2022-02:53:44] [V] [TRT] Tactic: 3 Time: 0.0333201
[05/21/2022-02:53:44] [V] [TRT] Tactic: 4 Time: 0.0291343
[05/21/2022-02:53:44] [V] [TRT] Tactic: 5 Time: 0.0291864
[05/21/2022-02:53:44] [V] [TRT] Tactic: 6 Time: 0.0320379
[05/21/2022-02:53:44] [V] [TRT] Tactic: 7 Time: 0.0269986
[05/21/2022-02:53:44] [V] [TRT] Tactic: 8 Time: 0.0251043
[05/21/2022-02:53:44] [V] [TRT] Tactic: 9 Time: 0.0268491
[05/21/2022-02:53:44] [V] [TRT] Tactic: 28 Time: 0.0500652
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: 8 Time: 0.0251043
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-02:53:44] [V] [TRT] Tactic: 128 Time: 0.173711
[05/21/2022-02:53:44] [V] [TRT] Tactic: 256 Time: 0.173926
[05/21/2022-02:53:44] [V] [TRT] Tactic: 512 Time: 0.174271
[05/21/2022-02:53:44] [V] [TRT] Tactic: -32 Time: 0.21002
[05/21/2022-02:53:44] [V] [TRT] Tactic: -64 Time: 0.200638
[05/21/2022-02:53:44] [V] [TRT] Tactic: -128 Time: 0.186732
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: 128 Time: 0.173711
[05/21/2022-02:53:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:44] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:44] [V] [TRT] Tactic: 0 Time: 0.050664
[05/21/2022-02:53:44] [V] [TRT] Tactic: 1 Time: 0.0389586
[05/21/2022-02:53:44] [V] [TRT] Tactic: 2 Time: 0.0374936
[05/21/2022-02:53:44] [V] [TRT] Tactic: 3 Time: 0.0336261
[05/21/2022-02:53:44] [V] [TRT] Tactic: 4 Time: 0.0296029
[05/21/2022-02:53:44] [V] [TRT] Tactic: 5 Time: 0.0297918
[05/21/2022-02:53:44] [V] [TRT] Tactic: 6 Time: 0.0329884
[05/21/2022-02:53:44] [V] [TRT] Tactic: 7 Time: 0.0269534
[05/21/2022-02:53:44] [V] [TRT] Tactic: 8 Time: 0.025156
[05/21/2022-02:53:44] [V] [TRT] Tactic: 9 Time: 0.027233
[05/21/2022-02:53:44] [V] [TRT] Tactic: 28 Time: 0.0499545
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: 8 Time: 0.025156
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-02:53:44] [V] [TRT] Tactic: 128 Time: 0.173867
[05/21/2022-02:53:44] [V] [TRT] Tactic: 256 Time: 0.173737
[05/21/2022-02:53:44] [V] [TRT] Tactic: 512 Time: 0.173965
[05/21/2022-02:53:44] [V] [TRT] Tactic: -32 Time: 0.209069
[05/21/2022-02:53:44] [V] [TRT] Tactic: -64 Time: 0.19957
[05/21/2022-02:53:44] [V] [TRT] Tactic: -128 Time: 0.187578
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: 256 Time: 0.173737
[05/21/2022-02:53:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:53:44] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:44] [V] [TRT] Tactic: 24 Time: 0.0374935
[05/21/2022-02:53:44] [V] [TRT] Tactic: 25 Time: 0.0337891
[05/21/2022-02:53:44] [V] [TRT] Tactic: 26 Time: 0.0367515
[05/21/2022-02:53:44] [V] [TRT] Tactic: 27 Time: 0.0365431
[05/21/2022-02:53:44] [V] [TRT] Tactic: 31 Time: 0.03737
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: 25 Time: 0.0337891
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-02:53:44] [V] [TRT] Tactic: 128 Time: 0.173593
[05/21/2022-02:53:44] [V] [TRT] Tactic: 256 Time: 0.173476
[05/21/2022-02:53:44] [V] [TRT] Tactic: 512 Time: 0.17446
[05/21/2022-02:53:44] [V] [TRT] Tactic: -32 Time: 0.209479
[05/21/2022-02:53:44] [V] [TRT] Tactic: -64 Time: 0.199818
[05/21/2022-02:53:44] [V] [TRT] Tactic: -128 Time: 0.186927
[05/21/2022-02:53:44] [V] [TRT] Fastest Tactic: 256 Time: 0.173476
[05/21/2022-02:53:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:53:44] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:53:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:44] [V] [TRT] Tactic: 0 Time: 0.050781
[05/21/2022-02:53:44] [V] [TRT] Tactic: 1 Time: 0.0400325
[05/21/2022-02:53:44] [V] [TRT] Tactic: 2 Time: 0.0358464
[05/21/2022-02:53:44] [V] [TRT] Tactic: 3 Time: 0.0318359
[05/21/2022-02:53:45] [V] [TRT] Tactic: 4 Time: 0.0290559
[05/21/2022-02:53:45] [V] [TRT] Tactic: 5 Time: 0.0299286
[05/21/2022-02:53:45] [V] [TRT] Tactic: 6 Time: 0.0288347
[05/21/2022-02:53:45] [V] [TRT] Tactic: 7 Time: 0.0264714
[05/21/2022-02:53:45] [V] [TRT] Tactic: 8 Time: 0.026667
[05/21/2022-02:53:45] [V] [TRT] Tactic: 9 Time: 0.0264646
[05/21/2022-02:53:45] [V] [TRT] Tactic: 28 Time: 0.0511199
[05/21/2022-02:53:45] [V] [TRT] Fastest Tactic: 9 Time: 0.0264646
[05/21/2022-02:53:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-02:53:45] [V] [TRT] Tactic: 128 Time: 0.177474
[05/21/2022-02:53:45] [V] [TRT] Tactic: 256 Time: 0.174381
[05/21/2022-02:53:45] [V] [TRT] Tactic: 512 Time: 0.168151
[05/21/2022-02:53:45] [V] [TRT] Tactic: -32 Time: 0.211139
[05/21/2022-02:53:45] [V] [TRT] Tactic: -64 Time: 0.19026
[05/21/2022-02:53:45] [V] [TRT] Tactic: -128 Time: 0.195241
[05/21/2022-02:53:45] [V] [TRT] Fastest Tactic: 512 Time: 0.168151
[05/21/2022-02:53:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:53:45] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:53:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-02:53:45] [V] [TRT] Tactic: 0 Time: 0.0383399
[05/21/2022-02:53:45] [V] [TRT] Tactic: 1 Time: 0.0313084
[05/21/2022-02:53:45] [V] [TRT] Tactic: 2 Time: 0.0313739
[05/21/2022-02:53:45] [V] [TRT] Tactic: 3 Time: 0.0280923
[05/21/2022-02:53:45] [V] [TRT] Tactic: 4 Time: 0.0268095
[05/21/2022-02:53:45] [V] [TRT] Tactic: 5 Time: 0.0291278
[05/21/2022-02:53:45] [V] [TRT] Tactic: 6 Time: 0.0275195
[05/21/2022-02:53:45] [V] [TRT] Tactic: 7 Time: 0.0266862
[05/21/2022-02:53:45] [V] [TRT] Tactic: 8 Time: 0.0284829
[05/21/2022-02:53:45] [V] [TRT] Tactic: 9 Time: 0.0312826
[05/21/2022-02:53:45] [V] [TRT] Tactic: 10 Time: 0.0533462
[05/21/2022-02:53:45] [V] [TRT] Tactic: 11 Time: 0.0409376
[05/21/2022-02:53:45] [V] [TRT] Tactic: 12 Time: 0.0387044
[05/21/2022-02:53:45] [V] [TRT] Tactic: 13 Time: 0.0326694
[05/21/2022-02:53:45] [V] [TRT] Tactic: 14 Time: 0.031341
[05/21/2022-02:53:45] [V] [TRT] Tactic: 15 Time: 0.0313736
[05/21/2022-02:53:45] [V] [TRT] Tactic: 16 Time: 0.0291276
[05/21/2022-02:53:45] [V] [TRT] Tactic: 17 Time: 0.026836
[05/21/2022-02:53:45] [V] [TRT] Tactic: 18 Time: 0.0267255
[05/21/2022-02:53:45] [V] [TRT] Tactic: 19 Time: 0.0289388
[05/21/2022-02:53:45] [V] [TRT] Tactic: 28 Time: 0.0377407
[05/21/2022-02:53:45] [V] [TRT] Tactic: 29 Time: 0.0523828
[05/21/2022-02:53:45] [V] [TRT] Fastest Tactic: 7 Time: 0.0266862
[05/21/2022-02:53:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-02:53:45] [V] [TRT] Tactic: 128 Time: 0.177864
[05/21/2022-02:53:45] [V] [TRT] Tactic: 256 Time: 0.175072
[05/21/2022-02:53:45] [V] [TRT] Tactic: 512 Time: 0.168151
[05/21/2022-02:53:45] [V] [TRT] Tactic: -32 Time: 0.210573
[05/21/2022-02:53:45] [V] [TRT] Tactic: -64 Time: 0.190052
[05/21/2022-02:53:45] [V] [TRT] Tactic: -128 Time: 0.195045
[05/21/2022-02:53:45] [V] [TRT] Fastest Tactic: 512 Time: 0.168151
[05/21/2022-02:53:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:53:45] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:53:45] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:53:45] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:53:45] [V] [TRT] Tactic: 524287 Time: 4.53902
[05/21/2022-02:53:46] [V] [TRT] Tactic: 720895 Time: 2.94953
[05/21/2022-02:53:46] [V] [TRT] Tactic: 983039 Time: 4.18188
[05/21/2022-02:53:46] [V] [TRT] Tactic: 1048575 Time: 4.18381
[05/21/2022-02:53:47] [V] [TRT] Tactic: 1703935 Time: 4.14742
[05/21/2022-02:53:47] [V] [TRT] Tactic: 1769471 Time: 3.73945
[05/21/2022-02:53:47] [V] [TRT] Tactic: 1966079 Time: 4.62445
[05/21/2022-02:53:47] [V] [TRT] Tactic: 2031615 Time: 2.57862
[05/21/2022-02:53:48] [V] [TRT] Tactic: 2228223 Time: 5.00137
[05/21/2022-02:53:48] [V] [TRT] Tactic: 2424831 Time: 5.4884
[05/21/2022-02:53:48] [V] [TRT] Tactic: 2621439 Time: 4.77995
[05/21/2022-02:53:49] [V] [TRT] Tactic: 2752511 Time: 3.56803
[05/21/2022-02:53:49] [V] [TRT] Tactic: 2818047 Time: 4.89384
[05/21/2022-02:53:49] [V] [TRT] Tactic: 2883583 Time: 3.14736
[05/21/2022-02:53:49] [V] [TRT] Tactic: 3014655 Time: 5.53397
[05/21/2022-02:53:50] [V] [TRT] Tactic: 3145727 Time: 3.57339
[05/21/2022-02:53:50] [V] [TRT] Tactic: 3473407 Time: 3.17038
[05/21/2022-02:53:50] [V] [TRT] Tactic: 3604479 Time: 5.49166
[05/21/2022-02:53:51] [V] [TRT] Tactic: 3735551 Time: 3.67746
[05/21/2022-02:53:51] [V] [TRT] Tactic: 4390911 Time: 3.478
[05/21/2022-02:53:51] [V] [TRT] Tactic: 5046271 Time: 4.51846
[05/21/2022-02:53:51] [V] [TRT] Tactic: 5963775 Time: 4.13062
[05/21/2022-02:53:52] [V] [TRT] Tactic: 6160383 Time: 4.33632
[05/21/2022-02:53:52] [V] [TRT] Tactic: 6488063 Time: 5.06019
[05/21/2022-02:53:52] [V] [TRT] Tactic: 6881279 Time: 3.44525
[05/21/2022-02:53:53] [V] [TRT] Tactic: 7274495 Time: 4.29368
[05/21/2022-02:53:53] [V] [TRT] Tactic: 7864319 Time: 4.98372
[05/21/2022-02:53:53] [V] [TRT] Tactic: 7995391 Time: 4.91913
[05/21/2022-02:53:54] [V] [TRT] Tactic: 8585215 Time: 3.63637
[05/21/2022-02:53:54] [V] [TRT] Tactic: 8847359 Time: 5.39907
[05/21/2022-02:53:54] [V] [TRT] Tactic: 8978431 Time: 4.16783
[05/21/2022-02:53:55] [V] [TRT] Tactic: 9043967 Time: 5.0739
[05/21/2022-02:53:55] [V] [TRT] Tactic: 9175039 Time: 5.50719
[05/21/2022-02:53:55] [V] [TRT] Tactic: 9502719 Time: 3.56881
[05/21/2022-02:53:56] [V] [TRT] Tactic: 9830399 Time: 4.46799
[05/21/2022-02:53:56] [V] [TRT] Tactic: 9961471 Time: 5.95689
[05/21/2022-02:53:56] [V] [TRT] Tactic: 10027007 Time: 3.61642
[05/21/2022-02:53:57] [V] [TRT] Tactic: 10092543 Time: 3.55456
[05/21/2022-02:53:57] [V] [TRT] Tactic: 10289151 Time: 4.65887
[05/21/2022-02:53:57] [V] [TRT] Tactic: 10485759 Time: 3.76431
[05/21/2022-02:53:58] [V] [TRT] Tactic: 10682367 Time: 4.91026
[05/21/2022-02:53:58] [V] [TRT] Tactic: 10813439 Time: 5.09092
[05/21/2022-02:53:58] [V] [TRT] Fastest Tactic: 2031615 Time: 2.57862
[05/21/2022-02:53:58] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:53:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:53:58] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-02:53:58] [V] [TRT] Tactic: 0 Time: 6.05484
[05/21/2022-02:53:58] [V] [TRT] Tactic: 1 Time: 3.447
[05/21/2022-02:53:58] [V] [TRT] Tactic: 2 Time: 4.8132
[05/21/2022-02:53:58] [V] [TRT] Tactic: 4 skipped. Scratch requested: 614596608, available: 536870912
[05/21/2022-02:53:58] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1145307136, available: 536870912
[05/21/2022-02:53:58] [V] [TRT] Tactic: 6 Time: 5.10686
[05/21/2022-02:53:58] [V] [TRT] Fastest Tactic: 1 Time: 3.447
[05/21/2022-02:53:58] [V] [TRT] Setting workspace to 614596608enables more tactics for profiling
[05/21/2022-02:53:58] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:53:59] [V] [TRT] Tactic: 1062367460111450758 Time: 4.38887
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:53:59] [V] [TRT] Tactic: 1754984623894446479 Time: 5.69723
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:53:59] [V] [TRT] Tactic: 3611739942397549984 Time: 3.19624
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:53:59] [V] [TRT] Tactic: 3827454225649558724 Time: 4.52097
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:53:59] [V] [TRT] Tactic: 4337000649858996379 Time: 3.32531
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:53:59] [V] [TRT] Tactic: 4501471010995462441 Time: 3.21387
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:53:59] [V] [TRT] Tactic: 5137655947464784826 Time: 3.14807
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:53:59] [V] [TRT] Tactic: 5288347012147084929 Time: 3.21795
[05/21/2022-02:53:59] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:54:00] [V] [TRT] Tactic: 5921334924264294896 Time: 3.33006
[05/21/2022-02:54:00] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:54:00] [V] [TRT] Tactic: 6645123197870846056 Time: 3.20141
[05/21/2022-02:54:00] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:54:00] [V] [TRT] Tactic: 7144526460361122478 Time: 5.14344
[05/21/2022-02:54:00] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:54:00] [V] [TRT] Tactic: 7852627285308570038 Time: 4.54953
[05/21/2022-02:54:00] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:54:00] [V] [TRT] Tactic: -9137461792520977713 Time: 3.24697
[05/21/2022-02:54:00] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:54:00] [V] [TRT] Tactic: -8776506421218919509 Time: 4.36941
[05/21/2022-02:54:00] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:54:00] [V] [TRT] Tactic: -8262349710178828730 Time: 3.20598
[05/21/2022-02:54:00] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:54:01] [V] [TRT] Tactic: -8133971918129952780 Time: 3.80548
[05/21/2022-02:54:01] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:54:01] [V] [TRT] Tactic: -6092040395344634144 Time: 4.54324
[05/21/2022-02:54:01] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:54:01] [V] [TRT] Tactic: -4787320710726427159 Time: 5.65012
[05/21/2022-02:54:01] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:54:01] [V] [TRT] Tactic: -3456450830548107839 Time: 3.85723
[05/21/2022-02:54:01] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:54:01] [V] [TRT] Tactic: -2318106587342035239 Time: 4.63581
[05/21/2022-02:54:01] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:54:01] [V] [TRT] Tactic: -1343271414618805657 Time: 3.17548
[05/21/2022-02:54:01] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:54:01] [V] [TRT] Tactic: -1218658103698133241 Time: 3.73029
[05/21/2022-02:54:01] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:54:02] [V] [TRT] Tactic: -836875257600482091 Time: 3.86431
[05/21/2022-02:54:02] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:54:02] [V] [TRT] Tactic: -410470605513481746 Time: 3.04822
[05/21/2022-02:54:02] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 3.04822
[05/21/2022-02:54:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: FusedConvActConvolution Tactic: 2031615
[05/21/2022-02:54:02] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:02] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-02:54:02] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:02] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:02] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:54:02] [V] [TRT] Tactic: -9153228964338181824 Time: 3.55968
[05/21/2022-02:54:02] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:54:02] [V] [TRT] Tactic: -7394439838318485025 Time: 2.94183
[05/21/2022-02:54:02] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.94183
[05/21/2022-02:54:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:54:02] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:02] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-02:54:02] [V] [TRT] Tactic: 0 Time: 5.93877
[05/21/2022-02:54:02] [V] [TRT] Tactic: 1 Time: 3.76667
[05/21/2022-02:54:02] [V] [TRT] Tactic: 2 Time: 4.79025
[05/21/2022-02:54:02] [V] [TRT] Tactic: 4 skipped. Scratch requested: 614596608, available: 536870912
[05/21/2022-02:54:02] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1145307136, available: 536870912
[05/21/2022-02:54:02] [V] [TRT] Tactic: 6 Time: 7.26348
[05/21/2022-02:54:02] [V] [TRT] Fastest Tactic: 1 Time: 3.76667
[05/21/2022-02:54:02] [V] [TRT] Setting workspace to 614596608enables more tactics for profiling
[05/21/2022-02:54:02] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:02] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:54:02] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:02] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:54:03] [V] [TRT] Tactic: 524287 Time: 2.43463
[05/21/2022-02:54:03] [V] [TRT] Tactic: 720895 Time: 1.73441
[05/21/2022-02:54:03] [V] [TRT] Tactic: 983039 Time: 2.3738
[05/21/2022-02:54:03] [V] [TRT] Tactic: 1048575 Time: 2.31027
[05/21/2022-02:54:03] [V] [TRT] Tactic: 1703935 Time: 2.31548
[05/21/2022-02:54:04] [V] [TRT] Tactic: 1769471 Time: 14.2165
[05/21/2022-02:54:04] [V] [TRT] Tactic: 1966079 Time: 2.7227
[05/21/2022-02:54:04] [V] [TRT] Tactic: 2031615 Time: 1.35259
[05/21/2022-02:54:05] [V] [TRT] Tactic: 2228223 Time: 2.84359
[05/21/2022-02:54:05] [V] [TRT] Tactic: 2424831 Time: 4.1329
[05/21/2022-02:54:05] [V] [TRT] Tactic: 2621439 Time: 2.48822
[05/21/2022-02:54:05] [V] [TRT] Tactic: 2752511 Time: 1.97757
[05/21/2022-02:54:05] [V] [TRT] Tactic: 2818047 Time: 2.69372
[05/21/2022-02:54:06] [V] [TRT] Tactic: 2883583 Time: 1.84456
[05/21/2022-02:54:06] [V] [TRT] Tactic: 3014655 Time: 3.127
[05/21/2022-02:54:06] [V] [TRT] Tactic: 3145727 Time: 1.92049
[05/21/2022-02:54:06] [V] [TRT] Tactic: 3473407 Time: 1.84511
[05/21/2022-02:54:06] [V] [TRT] Tactic: 3604479 Time: 3.12779
[05/21/2022-02:54:06] [V] [TRT] Tactic: 3735551 Time: 1.9816
[05/21/2022-02:54:07] [V] [TRT] Tactic: 4390911 Time: 1.97359
[05/21/2022-02:54:07] [V] [TRT] Tactic: 5046271 Time: 2.43439
[05/21/2022-02:54:07] [V] [TRT] Tactic: 5963775 Time: 2.18236
[05/21/2022-02:54:07] [V] [TRT] Tactic: 6160383 Time: 2.54349
[05/21/2022-02:54:07] [V] [TRT] Tactic: 6488063 Time: 2.81655
[05/21/2022-02:54:07] [V] [TRT] Tactic: 6881279 Time: 1.79119
[05/21/2022-02:54:08] [V] [TRT] Tactic: 7274495 Time: 2.43736
[05/21/2022-02:54:08] [V] [TRT] Tactic: 7864319 Time: 2.717
[05/21/2022-02:54:08] [V] [TRT] Tactic: 7995391 Time: 2.9151
[05/21/2022-02:54:08] [V] [TRT] Tactic: 8585215 Time: 1.98973
[05/21/2022-02:54:08] [V] [TRT] Tactic: 8847359 Time: 2.88772
[05/21/2022-02:54:09] [V] [TRT] Tactic: 8978431 Time: 2.37137
[05/21/2022-02:54:09] [V] [TRT] Tactic: 9043967 Time: 2.74969
[05/21/2022-02:54:09] [V] [TRT] Tactic: 9175039 Time: 3.10647
[05/21/2022-02:54:09] [V] [TRT] Tactic: 9502719 Time: 2.04324
[05/21/2022-02:54:09] [V] [TRT] Tactic: 9830399 Time: 2.32419
[05/21/2022-02:54:10] [V] [TRT] Tactic: 9961471 Time: 3.30889
[05/21/2022-02:54:10] [V] [TRT] Tactic: 10027007 Time: 1.96713
[05/21/2022-02:54:10] [V] [TRT] Tactic: 10092543 Time: 1.97454
[05/21/2022-02:54:10] [V] [TRT] Tactic: 10289151 Time: 2.71499
[05/21/2022-02:54:10] [V] [TRT] Tactic: 10485759 Time: 1.92271
[05/21/2022-02:54:10] [V] [TRT] Tactic: 10682367 Time: 2.47842
[05/21/2022-02:54:11] [V] [TRT] Tactic: 10813439 Time: 2.79543
[05/21/2022-02:54:11] [V] [TRT] Fastest Tactic: 2031615 Time: 1.35259
[05/21/2022-02:54:11] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-02:54:11] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:11] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:54:11] [V] [TRT] Tactic: 3564772625446233998 Time: 2.18651
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:54:11] [V] [TRT] Tactic: 3650389455493082349 Time: 2.25493
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:54:11] [V] [TRT] Tactic: 4772821744921268633 Time: 1.78022
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:54:11] [V] [TRT] Tactic: 5319956359050645452 Time: 1.79564
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:54:11] [V] [TRT] Tactic: 7205456024582378848 Time: 1.61603
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:54:11] [V] [TRT] Tactic: -6490690591794140522 Time: 1.73618
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:54:11] [V] [TRT] Tactic: -4686027666808657977 Time: 1.58965
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:54:11] [V] [TRT] Tactic: -4212163711445252890 Time: 1.49472
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:54:11] [V] [TRT] Tactic: -3898373634979201110 Time: 1.63687
[05/21/2022-02:54:11] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:54:11] [V] [TRT] Tactic: -2409163523992614473 Time: 1.54762
[05/21/2022-02:54:11] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 1.49472
[05/21/2022-02:54:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: FusedConvActConvolution Tactic: 2031615
[05/21/2022-02:54:11] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:11] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1), Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-02:54:11] [V] [TRT] Tactic: 0 Time: 0.0554295
[05/21/2022-02:54:12] [V] [TRT] Tactic: 1 Time: 0.0463805
[05/21/2022-02:54:12] [V] [TRT] Tactic: 2 Time: 0.0861328
[05/21/2022-02:54:12] [V] [TRT] Tactic: 3 Time: 0.0687829
[05/21/2022-02:54:12] [V] [TRT] Tactic: 4 Time: 0.0342709
[05/21/2022-02:54:12] [V] [TRT] Tactic: 5 Time: 0.0338346
[05/21/2022-02:54:12] [V] [TRT] Tactic: 6 Time: 0.0396939
[05/21/2022-02:54:12] [V] [TRT] Tactic: 7 Time: 0.032734
[05/21/2022-02:54:12] [V] [TRT] Tactic: 8 Time: 0.0336457
[05/21/2022-02:54:12] [V] [TRT] Tactic: 9 Time: 0.0335739
[05/21/2022-02:54:12] [V] [TRT] Tactic: 28 Time: 0.0532097
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 7 Time: 0.032734
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 128 Time: 0.20138
[05/21/2022-02:54:12] [V] [TRT] Tactic: 256 Time: 0.200827
[05/21/2022-02:54:12] [V] [TRT] Tactic: 512 Time: 0.201394
[05/21/2022-02:54:12] [V] [TRT] Tactic: -32 Time: 0.245801
[05/21/2022-02:54:12] [V] [TRT] Tactic: -64 Time: 0.232688
[05/21/2022-02:54:12] [V] [TRT] Tactic: -128 Time: 0.218197
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 256 Time: 0.200827
[05/21/2022-02:54:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:54:12] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512), Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 0 Time: 0.0539779
[05/21/2022-02:54:12] [V] [TRT] Tactic: 1 Time: 0.0427146
[05/21/2022-02:54:12] [V] [TRT] Tactic: 2 Time: 0.0409312
[05/21/2022-02:54:12] [V] [TRT] Tactic: 3 Time: 0.0380209
[05/21/2022-02:54:12] [V] [TRT] Tactic: 4 Time: 0.0342056
[05/21/2022-02:54:12] [V] [TRT] Tactic: 5 Time: 0.033659
[05/21/2022-02:54:12] [V] [TRT] Tactic: 6 Time: 0.0376628
[05/21/2022-02:54:12] [V] [TRT] Tactic: 7 Time: 0.032637
[05/21/2022-02:54:12] [V] [TRT] Tactic: 8 Time: 0.0314842
[05/21/2022-02:54:12] [V] [TRT] Tactic: 9 Time: 0.0332811
[05/21/2022-02:54:12] [V] [TRT] Tactic: 28 Time: 0.0534505
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 8 Time: 0.0314842
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 128 Time: 0.200911
[05/21/2022-02:54:12] [V] [TRT] Tactic: 256 Time: 0.20071
[05/21/2022-02:54:12] [V] [TRT] Tactic: 512 Time: 0.200703
[05/21/2022-02:54:12] [V] [TRT] Tactic: -32 Time: 0.243887
[05/21/2022-02:54:12] [V] [TRT] Tactic: -64 Time: 0.232376
[05/21/2022-02:54:12] [V] [TRT] Tactic: -128 Time: 0.217122
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 512 Time: 0.200703
[05/21/2022-02:54:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:54:12] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1), Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 24 Time: 0.0505664
[05/21/2022-02:54:12] [V] [TRT] Tactic: 25 Time: 0.0446745
[05/21/2022-02:54:12] [V] [TRT] Tactic: 26 Time: 0.0486331
[05/21/2022-02:54:12] [V] [TRT] Tactic: 27 Time: 0.0460545
[05/21/2022-02:54:12] [V] [TRT] Tactic: 31 Time: 0.050801
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 25 Time: 0.0446745
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 128 Time: 0.200651
[05/21/2022-02:54:12] [V] [TRT] Tactic: 256 Time: 0.200742
[05/21/2022-02:54:12] [V] [TRT] Tactic: 512 Time: 0.200807
[05/21/2022-02:54:12] [V] [TRT] Tactic: -32 Time: 0.244017
[05/21/2022-02:54:12] [V] [TRT] Tactic: -64 Time: 0.232728
[05/21/2022-02:54:12] [V] [TRT] Tactic: -128 Time: 0.217344
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 128 Time: 0.200651
[05/21/2022-02:54:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:54:12] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1), Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 0 Time: 0.0544856
[05/21/2022-02:54:12] [V] [TRT] Tactic: 1 Time: 0.0425194
[05/21/2022-02:54:12] [V] [TRT] Tactic: 2 Time: 0.0400651
[05/21/2022-02:54:12] [V] [TRT] Tactic: 3 Time: 0.0341862
[05/21/2022-02:54:12] [V] [TRT] Tactic: 4 Time: 0.0346616
[05/21/2022-02:54:12] [V] [TRT] Tactic: 5 Time: 0.0330729
[05/21/2022-02:54:12] [V] [TRT] Tactic: 6 Time: 0.0307485
[05/21/2022-02:54:12] [V] [TRT] Tactic: 7 Time: 0.0306769
[05/21/2022-02:54:12] [V] [TRT] Tactic: 8 Time: 0.0295641
[05/21/2022-02:54:12] [V] [TRT] Tactic: 9 Time: 0.0308267
[05/21/2022-02:54:12] [V] [TRT] Tactic: 28 Time: 0.0540037
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 8 Time: 0.0295641
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 128 Time: 0.207188
[05/21/2022-02:54:12] [V] [TRT] Tactic: 256 Time: 0.20442
[05/21/2022-02:54:12] [V] [TRT] Tactic: 512 Time: 0.198353
[05/21/2022-02:54:12] [V] [TRT] Tactic: -32 Time: 0.252292
[05/21/2022-02:54:12] [V] [TRT] Tactic: -64 Time: 0.226315
[05/21/2022-02:54:12] [V] [TRT] Tactic: -128 Time: 0.233613
[05/21/2022-02:54:12] [V] [TRT] Fastest Tactic: 512 Time: 0.198353
[05/21/2022-02:54:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:54:12] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1), Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-02:54:12] [V] [TRT] Tactic: 0 Time: 0.0452214
[05/21/2022-02:54:13] [V] [TRT] Tactic: 1 Time: 0.0409376
[05/21/2022-02:54:13] [V] [TRT] Tactic: 2 Time: 0.0400651
[05/21/2022-02:54:13] [V] [TRT] Tactic: 3 Time: 0.0388149
[05/21/2022-02:54:13] [V] [TRT] Tactic: 4 Time: 0.0387436
[05/21/2022-02:54:13] [V] [TRT] Tactic: 5 Time: 0.039772
[05/21/2022-02:54:13] [V] [TRT] Tactic: 6 Time: 0.0420249
[05/21/2022-02:54:13] [V] [TRT] Tactic: 7 Time: 0.0425582
[05/21/2022-02:54:13] [V] [TRT] Tactic: 8 Time: 0.0445834
[05/21/2022-02:54:13] [V] [TRT] Tactic: 9 Time: 0.0563281
[05/21/2022-02:54:13] [V] [TRT] Tactic: 10 Time: 0.0582616
[05/21/2022-02:54:13] [V] [TRT] Tactic: 11 Time: 0.046914
[05/21/2022-02:54:13] [V] [TRT] Tactic: 12 Time: 0.0446289
[05/21/2022-02:54:13] [V] [TRT] Tactic: 13 Time: 0.0379751
[05/21/2022-02:54:13] [V] [TRT] Tactic: 14 Time: 0.0404492
[05/21/2022-02:54:13] [V] [TRT] Tactic: 15 Time: 0.03819
[05/21/2022-02:54:13] [V] [TRT] Tactic: 16 Time: 0.0352474
[05/21/2022-02:54:13] [V] [TRT] Tactic: 17 Time: 0.0359439
[05/21/2022-02:54:13] [V] [TRT] Tactic: 18 Time: 0.0353775
[05/21/2022-02:54:13] [V] [TRT] Tactic: 19 Time: 0.0361588
[05/21/2022-02:54:13] [V] [TRT] Tactic: 28 Time: 0.0451105
[05/21/2022-02:54:13] [V] [TRT] Tactic: 29 Time: 0.0570051
[05/21/2022-02:54:13] [V] [TRT] Fastest Tactic: 16 Time: 0.0352474
[05/21/2022-02:54:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-02:54:13] [V] [TRT] Tactic: 128 Time: 0.209141
[05/21/2022-02:54:13] [V] [TRT] Tactic: 256 Time: 0.205534
[05/21/2022-02:54:13] [V] [TRT] Tactic: 512 Time: 0.196953
[05/21/2022-02:54:13] [V] [TRT] Tactic: -32 Time: 0.252513
[05/21/2022-02:54:13] [V] [TRT] Tactic: -64 Time: 0.226907
[05/21/2022-02:54:13] [V] [TRT] Tactic: -128 Time: 0.233939
[05/21/2022-02:54:13] [V] [TRT] Fastest Tactic: 512 Time: 0.196953
[05/21/2022-02:54:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 16
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1), Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512), Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1), Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1), Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1), Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1), Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512), Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1), Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1), Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1), Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1), Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512), Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1), Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1), Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1), Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:13] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:54:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-02:54:13] [V] [TRT] Tactic: 0 Time: 0.0645119
[05/21/2022-02:54:13] [V] [TRT] Tactic: 1 Time: 0.0464322
[05/21/2022-02:54:13] [V] [TRT] Tactic: 2 Time: 0.0438543
[05/21/2022-02:54:13] [V] [TRT] Tactic: 3 Time: 0.0364713
[05/21/2022-02:54:13] [V] [TRT] Tactic: 4 Time: 0.0338541
[05/21/2022-02:54:13] [V] [TRT] Tactic: 5 Time: 0.0327601
[05/21/2022-02:54:13] [V] [TRT] Tactic: 6 Time: 0.0341929
[05/21/2022-02:54:13] [V] [TRT] Tactic: 7 Time: 0.0290622
[05/21/2022-02:54:13] [V] [TRT] Tactic: 8 Time: 0.0276497
[05/21/2022-02:54:13] [V] [TRT] Tactic: 9 Time: 0.0286069
[05/21/2022-02:54:13] [V] [TRT] Tactic: 28 Time: 0.0631118
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: 8 Time: 0.0276497
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 128 Time: 0.19513
[05/21/2022-02:54:14] [V] [TRT] Tactic: 256 Time: 0.19541
[05/21/2022-02:54:14] [V] [TRT] Tactic: 512 Time: 0.195306
[05/21/2022-02:54:14] [V] [TRT] Tactic: -32 Time: 0.211165
[05/21/2022-02:54:14] [V] [TRT] Tactic: -64 Time: 0.201491
[05/21/2022-02:54:14] [V] [TRT] Tactic: -128 Time: 0.190417
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: -128 Time: 0.190417
[05/21/2022-02:54:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:54:14] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 0 Time: 0.0642903
[05/21/2022-02:54:14] [V] [TRT] Tactic: 1 Time: 0.0467576
[05/21/2022-02:54:14] [V] [TRT] Tactic: 2 Time: 0.043379
[05/21/2022-02:54:14] [V] [TRT] Tactic: 3 Time: 0.0365431
[05/21/2022-02:54:14] [V] [TRT] Tactic: 4 Time: 0.0337044
[05/21/2022-02:54:14] [V] [TRT] Tactic: 5 Time: 0.0327538
[05/21/2022-02:54:14] [V] [TRT] Tactic: 6 Time: 0.0351039
[05/21/2022-02:54:14] [V] [TRT] Tactic: 7 Time: 0.0286586
[05/21/2022-02:54:14] [V] [TRT] Tactic: 8 Time: 0.0278254
[05/21/2022-02:54:14] [V] [TRT] Tactic: 9 Time: 0.0283336
[05/21/2022-02:54:14] [V] [TRT] Tactic: 28 Time: 0.0631576
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: 8 Time: 0.0278254
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 128 Time: 0.195534
[05/21/2022-02:54:14] [V] [TRT] Tactic: 256 Time: 0.194811
[05/21/2022-02:54:14] [V] [TRT] Tactic: 512 Time: 0.195417
[05/21/2022-02:54:14] [V] [TRT] Tactic: -32 Time: 0.199655
[05/21/2022-02:54:14] [V] [TRT] Tactic: -64 Time: 0.191849
[05/21/2022-02:54:14] [V] [TRT] Tactic: -128 Time: 0.19069
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: -128 Time: 0.19069
[05/21/2022-02:54:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:54:14] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 24 Time: 0.0385935
[05/21/2022-02:54:14] [V] [TRT] Tactic: 25 Time: 0.0342123
[05/21/2022-02:54:14] [V] [TRT] Tactic: 26 Time: 0.0375326
[05/21/2022-02:54:14] [V] [TRT] Tactic: 27 Time: 0.0363606
[05/21/2022-02:54:14] [V] [TRT] Tactic: 31 Time: 0.038763
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: 25 Time: 0.0342123
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 128 Time: 0.19569
[05/21/2022-02:54:14] [V] [TRT] Tactic: 256 Time: 0.195469
[05/21/2022-02:54:14] [V] [TRT] Tactic: 512 Time: 0.195202
[05/21/2022-02:54:14] [V] [TRT] Tactic: -32 Time: 0.210846
[05/21/2022-02:54:14] [V] [TRT] Tactic: -64 Time: 0.20095
[05/21/2022-02:54:14] [V] [TRT] Tactic: -128 Time: 0.190716
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: -128 Time: 0.190716
[05/21/2022-02:54:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:54:14] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 0 Time: 0.0653061
[05/21/2022-02:54:14] [V] [TRT] Tactic: 1 Time: 0.0472654
[05/21/2022-02:54:14] [V] [TRT] Tactic: 2 Time: 0.04347
[05/21/2022-02:54:14] [V] [TRT] Tactic: 3 Time: 0.0358724
[05/21/2022-02:54:14] [V] [TRT] Tactic: 4 Time: 0.033548
[05/21/2022-02:54:14] [V] [TRT] Tactic: 5 Time: 0.0334307
[05/21/2022-02:54:14] [V] [TRT] Tactic: 6 Time: 0.0310938
[05/21/2022-02:54:14] [V] [TRT] Tactic: 7 Time: 0.0288606
[05/21/2022-02:54:14] [V] [TRT] Tactic: 8 Time: 0.028711
[05/21/2022-02:54:14] [V] [TRT] Tactic: 9 Time: 0.0288151
[05/21/2022-02:54:14] [V] [TRT] Tactic: 28 Time: 0.0645183
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: 8 Time: 0.028711
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 128 Time: 0.18722
[05/21/2022-02:54:14] [V] [TRT] Tactic: 256 Time: 0.184655
[05/21/2022-02:54:14] [V] [TRT] Tactic: 512 Time: 0.172819
[05/21/2022-02:54:14] [V] [TRT] Tactic: -32 Time: 0.212135
[05/21/2022-02:54:14] [V] [TRT] Tactic: -64 Time: 0.191973
[05/21/2022-02:54:14] [V] [TRT] Tactic: -128 Time: 0.198294
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: 512 Time: 0.172819
[05/21/2022-02:54:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:54:14] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 0 Time: 0.0449801
[05/21/2022-02:54:14] [V] [TRT] Tactic: 1 Time: 0.0339647
[05/21/2022-02:54:14] [V] [TRT] Tactic: 2 Time: 0.0337369
[05/21/2022-02:54:14] [V] [TRT] Tactic: 3 Time: 0.0294205
[05/21/2022-02:54:14] [V] [TRT] Tactic: 4 Time: 0.0292186
[05/21/2022-02:54:14] [V] [TRT] Tactic: 5 Time: 0.0302473
[05/21/2022-02:54:14] [V] [TRT] Tactic: 6 Time: 0.028789
[05/21/2022-02:54:14] [V] [TRT] Tactic: 7 Time: 0.0284309
[05/21/2022-02:54:14] [V] [TRT] Tactic: 8 Time: 0.0292835
[05/21/2022-02:54:14] [V] [TRT] Tactic: 9 Time: 0.0325062
[05/21/2022-02:54:14] [V] [TRT] Tactic: 10 Time: 0.067005
[05/21/2022-02:54:14] [V] [TRT] Tactic: 11 Time: 0.0495185
[05/21/2022-02:54:14] [V] [TRT] Tactic: 12 Time: 0.0453255
[05/21/2022-02:54:14] [V] [TRT] Tactic: 13 Time: 0.036914
[05/21/2022-02:54:14] [V] [TRT] Tactic: 14 Time: 0.0356312
[05/21/2022-02:54:14] [V] [TRT] Tactic: 15 Time: 0.0356119
[05/21/2022-02:54:14] [V] [TRT] Tactic: 16 Time: 0.0312499
[05/21/2022-02:54:14] [V] [TRT] Tactic: 17 Time: 0.0291146
[05/21/2022-02:54:14] [V] [TRT] Tactic: 18 Time: 0.0289259
[05/21/2022-02:54:14] [V] [TRT] Tactic: 19 Time: 0.0311521
[05/21/2022-02:54:14] [V] [TRT] Tactic: 28 Time: 0.0436524
[05/21/2022-02:54:14] [V] [TRT] Tactic: 29 Time: 0.0669401
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: 7 Time: 0.0284309
[05/21/2022-02:54:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-02:54:14] [V] [TRT] Tactic: 128 Time: 0.187546
[05/21/2022-02:54:14] [V] [TRT] Tactic: 256 Time: 0.185332
[05/21/2022-02:54:14] [V] [TRT] Tactic: 512 Time: 0.175248
[05/21/2022-02:54:14] [V] [TRT] Tactic: -32 Time: 0.21181
[05/21/2022-02:54:14] [V] [TRT] Tactic: -64 Time: 0.191641
[05/21/2022-02:54:14] [V] [TRT] Tactic: -128 Time: 0.198294
[05/21/2022-02:54:14] [V] [TRT] Fastest Tactic: 512 Time: 0.175248
[05/21/2022-02:54:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:54:14] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:14] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:54:14] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:54:14] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:15] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:15] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:54:15] [V] [TRT] Tactic: 589823 Time: 2.04915
[05/21/2022-02:54:15] [V] [TRT] Tactic: 655359 Time: 1.15119
[05/21/2022-02:54:15] [V] [TRT] Tactic: 786431 Time: 1.35516
[05/21/2022-02:54:15] [V] [TRT] Tactic: 851967 Time: 1.50351
[05/21/2022-02:54:15] [V] [TRT] Tactic: 1179647 Time: 2.30877
[05/21/2022-02:54:15] [V] [TRT] Tactic: 1310719 Time: 4.61677
[05/21/2022-02:54:15] [V] [TRT] Tactic: 1376255 Time: 1.47105
[05/21/2022-02:54:16] [V] [TRT] Tactic: 1441791 Time: 1.15406
[05/21/2022-02:54:16] [V] [TRT] Tactic: 1507327 Time: 1.01771
[05/21/2022-02:54:16] [V] [TRT] Tactic: 1638399 Time: 1.35522
[05/21/2022-02:54:16] [V] [TRT] Tactic: 1835007 Time: 1.53387
[05/21/2022-02:54:16] [V] [TRT] Tactic: 1900543 Time: 1.38906
[05/21/2022-02:54:16] [V] [TRT] Tactic: 2097151 Time: 2.40315
[05/21/2022-02:54:16] [V] [TRT] Tactic: 2162687 Time: 1.03903
[05/21/2022-02:54:16] [V] [TRT] Tactic: 2293759 Time: 1.03967
[05/21/2022-02:54:16] [V] [TRT] Tactic: 2359295 Time: 0.912506
[05/21/2022-02:54:16] [V] [TRT] Tactic: 2686975 Time: 1.06026
[05/21/2022-02:54:17] [V] [TRT] Tactic: 3080191 Time: 1.41852
[05/21/2022-02:54:17] [V] [TRT] Tactic: 3342335 Time: 1.44525
[05/21/2022-02:54:17] [V] [TRT] Tactic: 3407871 Time: 0.98345
[05/21/2022-02:54:17] [V] [TRT] Tactic: 3538943 Time: 1.02331
[05/21/2022-02:54:17] [V] [TRT] Tactic: 3670015 Time: 0.91457
[05/21/2022-02:54:17] [V] [TRT] Tactic: 3932159 Time: 1.24747
[05/21/2022-02:54:17] [V] [TRT] Tactic: 3997695 Time: 1.31326
[05/21/2022-02:54:17] [V] [TRT] Tactic: 4063231 Time: 1.57455
[05/21/2022-02:54:17] [V] [TRT] Tactic: 4194303 Time: 2.04665
[05/21/2022-02:54:18] [V] [TRT] Tactic: 4259839 Time: 2.52988
[05/21/2022-02:54:18] [V] [TRT] Tactic: 4325375 Time: 1.14166
[05/21/2022-02:54:18] [V] [TRT] Tactic: 4521983 Time: 1.16121
[05/21/2022-02:54:18] [V] [TRT] Tactic: 4587519 Time: 1.03275
[05/21/2022-02:54:18] [V] [TRT] Tactic: 4653055 Time: 0.973197
[05/21/2022-02:54:18] [V] [TRT] Tactic: 4915199 Time: 2.0613
[05/21/2022-02:54:18] [V] [TRT] Tactic: 4980735 Time: 1.15248
[05/21/2022-02:54:18] [V] [TRT] Tactic: 5177343 Time: 2.12607
[05/21/2022-02:54:18] [V] [TRT] Tactic: 5242879 Time: 1.71386
[05/21/2022-02:54:18] [V] [TRT] Tactic: 5373951 Time: 2.349
[05/21/2022-02:54:19] [V] [TRT] Tactic: 5439487 Time: 1.97106
[05/21/2022-02:54:19] [V] [TRT] Tactic: 5570559 Time: 1.46149
[05/21/2022-02:54:19] [V] [TRT] Tactic: 5636095 Time: 1.52913
[05/21/2022-02:54:19] [V] [TRT] Tactic: 5701631 Time: 1.64833
[05/21/2022-02:54:19] [V] [TRT] Tactic: 5767167 Time: 2.92602
[05/21/2022-02:54:19] [V] [TRT] Tactic: 5832703 Time: 1.85756
[05/21/2022-02:54:19] [V] [TRT] Tactic: 5898239 Time: 1.67006
[05/21/2022-02:54:19] [V] [TRT] Tactic: 6029311 Time: 1.71129
[05/21/2022-02:54:20] [V] [TRT] Tactic: 6225919 Time: 1.87296
[05/21/2022-02:54:20] [V] [TRT] Tactic: 6291455 Time: 2.31392
[05/21/2022-02:54:20] [V] [TRT] Tactic: 6422527 Time: 1.74293
[05/21/2022-02:54:20] [V] [TRT] Tactic: 6750207 Time: 2.00159
[05/21/2022-02:54:20] [V] [TRT] Tactic: 6815743 Time: 1.73067
[05/21/2022-02:54:20] [V] [TRT] Tactic: 6946815 Time: 2.75962
[05/21/2022-02:54:20] [V] [TRT] Tactic: 7012351 Time: 2.41775
[05/21/2022-02:54:20] [V] [TRT] Tactic: 7077887 Time: 2.05224
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7143423 Time: 2.86741
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7208959 Time: 1.78115
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7340031 Time: 1.74641
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7405567 Time: 1.71949
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7536639 Time: 2.20263
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7602175 Time: 2.71973
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7733247 Time: 1.73423
[05/21/2022-02:54:21] [V] [TRT] Tactic: 7798783 Time: 1.33084
[05/21/2022-02:54:22] [V] [TRT] Tactic: 8191999 Time: 3.13083
[05/21/2022-02:54:22] [V] [TRT] Tactic: 8257535 Time: 2.06623
[05/21/2022-02:54:22] [V] [TRT] Tactic: 8323071 Time: 1.93522
[05/21/2022-02:54:22] [V] [TRT] Tactic: 8650751 Time: 2.40423
[05/21/2022-02:54:22] [V] [TRT] Tactic: 8716287 Time: 1.93694
[05/21/2022-02:54:22] [V] [TRT] Tactic: 9109503 Time: 2.4367
[05/21/2022-02:54:22] [V] [TRT] Tactic: 9568255 Time: 2.0564
[05/21/2022-02:54:23] [V] [TRT] Tactic: 9895935 Time: 2.03921
[05/21/2022-02:54:23] [V] [TRT] Tactic: 10223615 Time: 1.0542
[05/21/2022-02:54:23] [V] [TRT] Tactic: 10354687 Time: 2.72049
[05/21/2022-02:54:23] [V] [TRT] Tactic: 10551295 Time: 1.95271
[05/21/2022-02:54:23] [V] [TRT] Tactic: 10747903 Time: 1.72351
[05/21/2022-02:54:23] [V] [TRT] Tactic: 10944511 Time: 1.15546
[05/21/2022-02:54:23] [V] [TRT] Fastest Tactic: 2359295 Time: 0.912506
[05/21/2022-02:54:23] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:54:23] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:23] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-02:54:23] [V] [TRT] Tactic: 0 Time: 1.28993
[05/21/2022-02:54:23] [V] [TRT] Tactic: 1 Time: 1.06544
[05/21/2022-02:54:23] [V] [TRT] Tactic: 2 Time: 1.49997
[05/21/2022-02:54:23] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1212416000, available: 536870912
[05/21/2022-02:54:24] [V] [TRT] Tactic: 5 Time: 36.2684
[05/21/2022-02:54:24] [V] [TRT] Fastest Tactic: 1 Time: 1.06544
[05/21/2022-02:54:24] [V] [TRT] Setting workspace to 1212416000enables more tactics for profiling
[05/21/2022-02:54:24] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-02:54:24] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:24] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:54:24] [V] [TRT] Tactic: 1062367460111450758 Time: 0.925716
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:54:24] [V] [TRT] Tactic: 1698681053543049347 Time: 0.841751
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:54:24] [V] [TRT] Tactic: 4501471010995462441 Time: 0.704889
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:54:24] [V] [TRT] Tactic: 5137655947464784826 Time: 0.705052
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:54:24] [V] [TRT] Tactic: 5288347012147084929 Time: 0.703444
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:54:24] [V] [TRT] Tactic: 5326823351883942011 Time: 0.677962
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:54:24] [V] [TRT] Tactic: 5500448035057547314 Time: 0.772494
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:54:24] [V] [TRT] Tactic: 6645123197870846056 Time: 0.711536
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:54:24] [V] [TRT] Tactic: 7144526460361122478 Time: 1.06146
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:54:24] [V] [TRT] Tactic: -8262349710178828730 Time: 0.721972
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:54:24] [V] [TRT] Tactic: -6576203419454146580 Time: 0.803457
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:54:24] [V] [TRT] Tactic: -4787320710726427159 Time: 1.13367
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:54:24] [V] [TRT] Tactic: -3456450830548107839 Time: 0.852552
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:54:24] [V] [TRT] Tactic: -1218658103698133241 Time: 0.818737
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:54:24] [V] [TRT] Tactic: -836875257600482091 Time: 0.823385
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:54:24] [V] [TRT] Tactic: -410470605513481746 Time: 0.693834
[05/21/2022-02:54:24] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:54:25] [V] [TRT] Tactic: -377491875521947884 Time: 0.691751
[05/21/2022-02:54:25] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:54:25] [V] [TRT] Tactic: -37215280111360163 Time: 0.683919
[05/21/2022-02:54:25] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.677962
[05/21/2022-02:54:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:54:25] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:25] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-02:54:25] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:25] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-02:54:25] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:25] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:25] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:54:25] [V] [TRT] Tactic: 3886731678879822788 Time: 0.688971
[05/21/2022-02:54:25] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:54:25] [V] [TRT] Tactic: 6629944304117643200 Time: 1.03695
[05/21/2022-02:54:25] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:54:25] [V] [TRT] Tactic: -9153228964338181824 Time: 1.09693
[05/21/2022-02:54:25] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:54:25] [V] [TRT] Tactic: -7394439838318485025 Time: 0.697559
[05/21/2022-02:54:25] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.688971
[05/21/2022-02:54:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:54:25] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:25] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-02:54:25] [V] [TRT] Tactic: 0 Time: 1.31273
[05/21/2022-02:54:25] [V] [TRT] Tactic: 1 Time: 1.08847
[05/21/2022-02:54:25] [V] [TRT] Tactic: 2 Time: 1.41915
[05/21/2022-02:54:25] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1212416000, available: 536870912
[05/21/2022-02:54:25] [V] [TRT] Tactic: 5 Time: 36.0396
[05/21/2022-02:54:25] [V] [TRT] Fastest Tactic: 1 Time: 1.08847
[05/21/2022-02:54:25] [V] [TRT] Setting workspace to 1212416000enables more tactics for profiling
[05/21/2022-02:54:26] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-02:54:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:26] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:54:26] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:26] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:26] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:26] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:54:26] [V] [TRT] Tactic: 589823 Time: 1.02649
[05/21/2022-02:54:26] [V] [TRT] Tactic: 655359 Time: 0.736022
[05/21/2022-02:54:26] [V] [TRT] Tactic: 786431 Time: 0.825443
[05/21/2022-02:54:26] [V] [TRT] Tactic: 851967 Time: 0.846152
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1179647 Time: 1.04342
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1310719 Time: 2.41878
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1376255 Time: 0.737018
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1441791 Time: 0.55916
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1507327 Time: 0.521959
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1638399 Time: 0.706276
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1835007 Time: 0.970788
[05/21/2022-02:54:26] [V] [TRT] Tactic: 1900543 Time: 0.728106
[05/21/2022-02:54:27] [V] [TRT] Tactic: 2097151 Time: 1.67092
[05/21/2022-02:54:27] [V] [TRT] Tactic: 2162687 Time: 0.525416
[05/21/2022-02:54:27] [V] [TRT] Tactic: 2293759 Time: 0.512077
[05/21/2022-02:54:27] [V] [TRT] Tactic: 2359295 Time: 0.467474
[05/21/2022-02:54:27] [V] [TRT] Tactic: 2686975 Time: 0.911387
[05/21/2022-02:54:27] [V] [TRT] Tactic: 3080191 Time: 0.785345
[05/21/2022-02:54:27] [V] [TRT] Tactic: 3342335 Time: 0.753887
[05/21/2022-02:54:27] [V] [TRT] Tactic: 3407871 Time: 0.531862
[05/21/2022-02:54:27] [V] [TRT] Tactic: 3538943 Time: 0.520052
[05/21/2022-02:54:27] [V] [TRT] Tactic: 3670015 Time: 0.485299
[05/21/2022-02:54:27] [V] [TRT] Tactic: 3932159 Time: 0.599277
[05/21/2022-02:54:27] [V] [TRT] Tactic: 3997695 Time: 0.838385
[05/21/2022-02:54:27] [V] [TRT] Tactic: 4063231 Time: 0.851856
[05/21/2022-02:54:27] [V] [TRT] Tactic: 4194303 Time: 1.16174
[05/21/2022-02:54:27] [V] [TRT] Tactic: 4259839 Time: 1.65009
[05/21/2022-02:54:28] [V] [TRT] Tactic: 4325375 Time: 0.581511
[05/21/2022-02:54:28] [V] [TRT] Tactic: 4521983 Time: 0.563567
[05/21/2022-02:54:28] [V] [TRT] Tactic: 4587519 Time: 0.589518
[05/21/2022-02:54:28] [V] [TRT] Tactic: 4653055 Time: 0.496315
[05/21/2022-02:54:28] [V] [TRT] Tactic: 4915199 Time: 1.18483
[05/21/2022-02:54:28] [V] [TRT] Tactic: 4980735 Time: 0.607305
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5177343 Time: 0.986387
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5242879 Time: 0.898926
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5373951 Time: 1.08852
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5439487 Time: 1.1509
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5570559 Time: 1.01182
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5636095 Time: 0.853489
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5701631 Time: 0.861881
[05/21/2022-02:54:28] [V] [TRT] Tactic: 5767167 Time: 1.37685
[05/21/2022-02:54:29] [V] [TRT] Tactic: 5832703 Time: 0.998281
[05/21/2022-02:54:29] [V] [TRT] Tactic: 5898239 Time: 1.0196
[05/21/2022-02:54:29] [V] [TRT] Tactic: 6029311 Time: 0.972526
[05/21/2022-02:54:29] [V] [TRT] Tactic: 6225919 Time: 0.915554
[05/21/2022-02:54:29] [V] [TRT] Tactic: 6291455 Time: 1.04455
[05/21/2022-02:54:29] [V] [TRT] Tactic: 6422527 Time: 0.929115
[05/21/2022-02:54:29] [V] [TRT] Tactic: 6750207 Time: 1.17098
[05/21/2022-02:54:29] [V] [TRT] Tactic: 6815743 Time: 0.920085
[05/21/2022-02:54:29] [V] [TRT] Tactic: 6946815 Time: 1.28773
[05/21/2022-02:54:29] [V] [TRT] Tactic: 7012351 Time: 1.64259
[05/21/2022-02:54:29] [V] [TRT] Tactic: 7077887 Time: 0.978008
[05/21/2022-02:54:29] [V] [TRT] Tactic: 7143423 Time: 1.42124
[05/21/2022-02:54:30] [V] [TRT] Tactic: 7208959 Time: 0.913535
[05/21/2022-02:54:30] [V] [TRT] Tactic: 7340031 Time: 1.05703
[05/21/2022-02:54:30] [V] [TRT] Tactic: 7405567 Time: 0.867559
[05/21/2022-02:54:30] [V] [TRT] Tactic: 7536639 Time: 1.18161
[05/21/2022-02:54:30] [V] [TRT] Tactic: 7602175 Time: 1.26042
[05/21/2022-02:54:30] [V] [TRT] Tactic: 7733247 Time: 1.00294
[05/21/2022-02:54:30] [V] [TRT] Tactic: 7798783 Time: 0.81011
[05/21/2022-02:54:30] [V] [TRT] Tactic: 8191999 Time: 1.53477
[05/21/2022-02:54:30] [V] [TRT] Tactic: 8257535 Time: 1.1893
[05/21/2022-02:54:30] [V] [TRT] Tactic: 8323071 Time: 1.1234
[05/21/2022-02:54:30] [V] [TRT] Tactic: 8650751 Time: 1.15527
[05/21/2022-02:54:30] [V] [TRT] Tactic: 8716287 Time: 0.932194
[05/21/2022-02:54:30] [V] [TRT] Tactic: 9109503 Time: 1.7205
[05/21/2022-02:54:31] [V] [TRT] Tactic: 9568255 Time: 1.1899
[05/21/2022-02:54:31] [V] [TRT] Tactic: 9895935 Time: 1.1644
[05/21/2022-02:54:31] [V] [TRT] Tactic: 10223615 Time: 0.899648
[05/21/2022-02:54:31] [V] [TRT] Tactic: 10354687 Time: 1.67904
[05/21/2022-02:54:31] [V] [TRT] Tactic: 10551295 Time: 0.997728
[05/21/2022-02:54:31] [V] [TRT] Tactic: 10747903 Time: 0.899518
[05/21/2022-02:54:31] [V] [TRT] Tactic: 10944511 Time: 0.606198
[05/21/2022-02:54:31] [V] [TRT] Fastest Tactic: 2359295 Time: 0.467474
[05/21/2022-02:54:31] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-02:54:31] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:31] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-02:54:31] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:54:31] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:54:31] [V] [TRT] Tactic: 3066127711859985668 Time: 0.41373
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:54:31] [V] [TRT] Tactic: 3564772625446233998 Time: 0.480859
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:54:31] [V] [TRT] Tactic: 5319956359050645452 Time: 0.425853
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:54:31] [V] [TRT] Tactic: 7205456024582378848 Time: 0.376628
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:54:31] [V] [TRT] Tactic: 8163473458334948789 Time: 0.364069
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:54:31] [V] [TRT] Tactic: -4212163711445252890 Time: 0.352689
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:54:31] [V] [TRT] Tactic: -3898373634979201110 Time: 0.36181
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:54:31] [V] [TRT] Tactic: -2409163523992614473 Time: 0.368425
[05/21/2022-02:54:31] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:54:31] [V] [TRT] Tactic: -1716393687483585322 Time: 0.347337
[05/21/2022-02:54:31] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.347337
[05/21/2022-02:54:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:54:31] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:54:31] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:54:31] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:54:32] [V] [TRT] Tactic: 0 Time: 0.0404101
[05/21/2022-02:54:33] [V] [TRT] Tactic: 1 Time: 0.0302212
[05/21/2022-02:54:34] [V] [TRT] Tactic: 2 Time: 0.027142
[05/21/2022-02:54:35] [V] [TRT] Tactic: 3 Time: 0.0474607
[05/21/2022-02:54:36] [V] [TRT] Tactic: 4 Time: 0.053034
[05/21/2022-02:54:37] [V] [TRT] Tactic: 5 Time: 0.0541538
[05/21/2022-02:54:38] [V] [TRT] Tactic: 6 Time: 0.0644208
[05/21/2022-02:54:39] [V] [TRT] Tactic: 7 Time: 0.080306
[05/21/2022-02:54:39] [V] [TRT] Tactic: 8 Time: 0.0795769
[05/21/2022-02:54:40] [V] [TRT] Tactic: 9 Time: 0.0884704
[05/21/2022-02:54:41] [V] [TRT] Tactic: 28 Time: 0.215892
[05/21/2022-02:54:41] [V] [TRT] Fastest Tactic: 2 Time: 0.027142
[05/21/2022-02:54:41] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-02:54:41] [V] [TRT] Tactic: 128 Time: 0.503118
[05/21/2022-02:54:41] [V] [TRT] Tactic: 256 Time: 0.501393
[05/21/2022-02:54:41] [V] [TRT] Tactic: 512 Time: 0.509499
[05/21/2022-02:54:41] [V] [TRT] Tactic: -32 Time: 0.584219
[05/21/2022-02:54:41] [V] [TRT] Tactic: -64 Time: 0.569538
[05/21/2022-02:54:41] [V] [TRT] Tactic: -128 Time: 0.363431
[05/21/2022-02:54:41] [V] [TRT] Fastest Tactic: -128 Time: 0.363431
[05/21/2022-02:54:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:54:41] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:54:41] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:54:41] [V] [TRT] Tactic: 0 Time: 0.148646
[05/21/2022-02:54:41] [V] [TRT] Tactic: 1 Time: 0.10265
[05/21/2022-02:54:41] [V] [TRT] Tactic: 2 Time: 0.0973895
[05/21/2022-02:54:41] [V] [TRT] Tactic: 3 Time: 0.0748893
[05/21/2022-02:54:41] [V] [TRT] Tactic: 4 Time: 0.0698632
[05/21/2022-02:54:41] [V] [TRT] Tactic: 5 Time: 0.0709505
[05/21/2022-02:54:42] [V] [TRT] Tactic: 6 Time: 0.0642315
[05/21/2022-02:54:42] [V] [TRT] Tactic: 7 Time: 0.0548371
[05/21/2022-02:54:42] [V] [TRT] Tactic: 8 Time: 0.0538477
[05/21/2022-02:54:42] [V] [TRT] Tactic: 9 Time: 0.0593032
[05/21/2022-02:54:42] [V] [TRT] Tactic: 28 Time: 0.144831
[05/21/2022-02:54:42] [V] [TRT] Fastest Tactic: 8 Time: 0.0538477
[05/21/2022-02:54:42] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-02:54:42] [V] [TRT] Tactic: 128 Time: 0.33543
[05/21/2022-02:54:42] [V] [TRT] Tactic: 256 Time: 0.335859
[05/21/2022-02:54:42] [V] [TRT] Tactic: 512 Time: 0.339681
[05/21/2022-02:54:42] [V] [TRT] Tactic: -32 Time: 0.393581
[05/21/2022-02:54:42] [V] [TRT] Tactic: -64 Time: 0.381224
[05/21/2022-02:54:42] [V] [TRT] Tactic: -128 Time: 0.363574
[05/21/2022-02:54:42] [V] [TRT] Fastest Tactic: 128 Time: 0.33543
[05/21/2022-02:54:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:54:42] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:54:42] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:54:43] [V] [TRT] Tactic: 24 Time: 0.0850458
[05/21/2022-02:54:44] [V] [TRT] Tactic: 25 Time: 0.0813347
[05/21/2022-02:54:45] [V] [TRT] Tactic: 26 Time: 0.0789581
[05/21/2022-02:54:45] [V] [TRT] Tactic: 27 Time: 0.115573
[05/21/2022-02:54:46] [V] [TRT] Tactic: 31 Time: 0.125775
[05/21/2022-02:54:46] [V] [TRT] Fastest Tactic: 26 Time: 0.0789581
[05/21/2022-02:54:46] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-02:54:46] [V] [TRT] Tactic: 128 Time: 0.500267
[05/21/2022-02:54:46] [V] [TRT] Tactic: 256 Time: 0.504472
[05/21/2022-02:54:46] [V] [TRT] Tactic: 512 Time: 0.50888
[05/21/2022-02:54:46] [V] [TRT] Tactic: -32 Time: 0.587031
[05/21/2022-02:54:47] [V] [TRT] Tactic: -64 Time: 0.499186
[05/21/2022-02:54:47] [V] [TRT] Tactic: -128 Time: 0.360514
[05/21/2022-02:54:47] [V] [TRT] Fastest Tactic: -128 Time: 0.360514
[05/21/2022-02:54:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:54:47] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:54:47] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:54:47] [V] [TRT] Tactic: 0 Time: 0.146934
[05/21/2022-02:54:48] [V] [TRT] Tactic: 1 Time: 0.105775
[05/21/2022-02:54:49] [V] [TRT] Tactic: 2 Time: 0.102012
[05/21/2022-02:54:50] [V] [TRT] Tactic: 3 Time: 0.113164
[05/21/2022-02:54:51] [V] [TRT] Tactic: 4 Time: 0.104226
[05/21/2022-02:54:52] [V] [TRT] Tactic: 5 Time: 0.110807
[05/21/2022-02:54:53] [V] [TRT] Tactic: 6 Time: 0.0964194
[05/21/2022-02:54:54] [V] [TRT] Tactic: 7 Time: 0.0827929
[05/21/2022-02:54:55] [V] [TRT] Tactic: 8 Time: 0.0831901
[05/21/2022-02:54:56] [V] [TRT] Tactic: 9 Time: 0.0916994
[05/21/2022-02:54:57] [V] [TRT] Tactic: 28 Time: 0.215274
[05/21/2022-02:54:57] [V] [TRT] Fastest Tactic: 7 Time: 0.0827929
[05/21/2022-02:54:57] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-02:54:57] [V] [TRT] Tactic: 128 Time: 0.457226
[05/21/2022-02:54:57] [V] [TRT] Tactic: 256 Time: 0.453437
[05/21/2022-02:54:57] [V] [TRT] Tactic: 512 Time: 0.442331
[05/21/2022-02:54:57] [V] [TRT] Tactic: -32 Time: 0.591771
[05/21/2022-02:54:57] [V] [TRT] Tactic: -64 Time: 0.526204
[05/21/2022-02:54:57] [V] [TRT] Tactic: -128 Time: 0.543099
[05/21/2022-02:54:57] [V] [TRT] Fastest Tactic: 512 Time: 0.442331
[05/21/2022-02:54:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:54:57] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:54:57] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:54:58] [V] [TRT] Tactic: 0 Time: 0.096048
[05/21/2022-02:54:59] [V] [TRT] Tactic: 1 Time: 0.0730079
[05/21/2022-02:55:00] [V] [TRT] Tactic: 2 Time: 0.0744336
[05/21/2022-02:55:01] [V] [TRT] Tactic: 3 Time: 0.0867189
[05/21/2022-02:55:02] [V] [TRT] Tactic: 4 Time: 0.0882421
[05/21/2022-02:55:03] [V] [TRT] Tactic: 5 Time: 0.105306
[05/21/2022-02:55:04] [V] [TRT] Tactic: 6 Time: 0.0877473
[05/21/2022-02:55:05] [V] [TRT] Tactic: 7 Time: 0.0880795
[05/21/2022-02:55:05] [V] [TRT] Tactic: 8 Time: 0.0940427
[05/21/2022-02:55:06] [V] [TRT] Tactic: 9 Time: 0.108646
[05/21/2022-02:55:07] [V] [TRT] Tactic: 10 Time: 0.239902
[05/21/2022-02:55:08] [V] [TRT] Tactic: 11 Time: 0.168711
[05/21/2022-02:55:09] [V] [TRT] Tactic: 12 Time: 0.164577
[05/21/2022-02:55:10] [V] [TRT] Tactic: 13 Time: 0.120671
[05/21/2022-02:55:11] [V] [TRT] Tactic: 14 Time: 0.111608
[05/21/2022-02:55:12] [V] [TRT] Tactic: 15 Time: 0.118835
[05/21/2022-02:55:13] [V] [TRT] Tactic: 16 Time: 0.0995182
[05/21/2022-02:55:14] [V] [TRT] Tactic: 17 Time: 0.0866145
[05/21/2022-02:55:15] [V] [TRT] Tactic: 18 Time: 0.0899608
[05/21/2022-02:55:16] [V] [TRT] Tactic: 19 Time: 0.102682
[05/21/2022-02:55:17] [V] [TRT] Tactic: 28 Time: 0.141784
[05/21/2022-02:55:18] [V] [TRT] Tactic: 29 Time: 0.231589
[05/21/2022-02:55:18] [V] [TRT] Fastest Tactic: 1 Time: 0.0730079
[05/21/2022-02:55:18] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-02:55:18] [V] [TRT] Tactic: 128 Time: 0.456426
[05/21/2022-02:55:18] [V] [TRT] Tactic: 256 Time: 0.453503
[05/21/2022-02:55:18] [V] [TRT] Tactic: 512 Time: 0.443574
[05/21/2022-02:55:18] [V] [TRT] Tactic: -32 Time: 0.586869
[05/21/2022-02:55:18] [V] [TRT] Tactic: -64 Time: 0.522754
[05/21/2022-02:55:18] [V] [TRT] Tactic: -128 Time: 0.542747
[05/21/2022-02:55:18] [V] [TRT] Fastest Tactic: 512 Time: 0.443574
[05/21/2022-02:55:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 1
[05/21/2022-02:55:18] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:18] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:55:18] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:55:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:18] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:55:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:18] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-02:55:18] [V] [TRT] Tactic: 0 Time: 10.715
[05/21/2022-02:55:18] [V] [TRT] Tactic: 1 Time: 10.1245
[05/21/2022-02:55:19] [V] [TRT] Tactic: 2 Time: 9.25979
[05/21/2022-02:55:19] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1228013568, available: 536870912
[05/21/2022-02:55:19] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2288386048, available: 536870912
[05/21/2022-02:55:19] [V] [TRT] Tactic: 6 Time: 10.8665
[05/21/2022-02:55:19] [V] [TRT] Fastest Tactic: 2 Time: 9.25979
[05/21/2022-02:55:19] [V] [TRT] Setting workspace to 1228013568enables more tactics for profiling
[05/21/2022-02:55:19] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:19] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:55:19] [V] [TRT] Tactic: 1062367460111450758 Time: 8.79349
[05/21/2022-02:55:19] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:55:19] [V] [TRT] Tactic: 1754984623894446479 Time: 10.2985
[05/21/2022-02:55:19] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:55:20] [V] [TRT] Tactic: 3611739942397549984 Time: 6.33632
[05/21/2022-02:55:20] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:55:20] [V] [TRT] Tactic: 3827454225649558724 Time: 9.6862
[05/21/2022-02:55:20] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:55:20] [V] [TRT] Tactic: 4337000649858996379 Time: 6.52484
[05/21/2022-02:55:20] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:55:20] [V] [TRT] Tactic: 4501471010995462441 Time: 6.3512
[05/21/2022-02:55:20] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:55:20] [V] [TRT] Tactic: 5137655947464784826 Time: 6.0354
[05/21/2022-02:55:20] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:55:21] [V] [TRT] Tactic: 5288347012147084929 Time: 6.21842
[05/21/2022-02:55:21] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:55:21] [V] [TRT] Tactic: 5921334924264294896 Time: 6.87154
[05/21/2022-02:55:21] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:55:21] [V] [TRT] Tactic: 6645123197870846056 Time: 6.37772
[05/21/2022-02:55:21] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:55:21] [V] [TRT] Tactic: 7144526460361122478 Time: 8.78551
[05/21/2022-02:55:21] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:55:22] [V] [TRT] Tactic: 7852627285308570038 Time: 9.69619
[05/21/2022-02:55:22] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:55:22] [V] [TRT] Tactic: -9137461792520977713 Time: 6.52414
[05/21/2022-02:55:22] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:55:22] [V] [TRT] Tactic: -8776506421218919509 Time: 9.21689
[05/21/2022-02:55:22] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:55:22] [V] [TRT] Tactic: -8262349710178828730 Time: 6.41732
[05/21/2022-02:55:22] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:55:22] [V] [TRT] Tactic: -8133971918129952780 Time: 7.38873
[05/21/2022-02:55:22] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:55:23] [V] [TRT] Tactic: -6092040395344634144 Time: 9.13052
[05/21/2022-02:55:23] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:55:23] [V] [TRT] Tactic: -4787320710726427159 Time: 10.3373
[05/21/2022-02:55:23] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:55:23] [V] [TRT] Tactic: -3456450830548107839 Time: 7.31827
[05/21/2022-02:55:23] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:55:23] [V] [TRT] Tactic: -2318106587342035239 Time: 9.4518
[05/21/2022-02:55:24] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:55:24] [V] [TRT] Tactic: -1343271414618805657 Time: 6.50151
[05/21/2022-02:55:24] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:55:24] [V] [TRT] Tactic: -1218658103698133241 Time: 7.37191
[05/21/2022-02:55:24] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:55:24] [V] [TRT] Tactic: -836875257600482091 Time: 7.14384
[05/21/2022-02:55:24] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:55:24] [V] [TRT] Tactic: -410470605513481746 Time: 6.05855
[05/21/2022-02:55:24] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 6.0354
[05/21/2022-02:55:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-02:55:24] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:55:24] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-02:55:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:24] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:24] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:55:24] [V] [TRT] Tactic: -9153228964338181824 Time: 7.08687
[05/21/2022-02:55:25] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:55:25] [V] [TRT] Tactic: -7394439838318485025 Time: 5.94056
[05/21/2022-02:55:25] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 5.94056
[05/21/2022-02:55:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:55:25] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:55:25] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-02:55:25] [V] [TRT] Tactic: 0 Time: 11.0975
[05/21/2022-02:55:25] [V] [TRT] Tactic: 1 Time: 11.0373
[05/21/2022-02:55:25] [V] [TRT] Tactic: 2 Time: 8.29083
[05/21/2022-02:55:25] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1228013568, available: 536870912
[05/21/2022-02:55:25] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2288386048, available: 536870912
[05/21/2022-02:55:26] [V] [TRT] Tactic: 6 Time: 13.6059
[05/21/2022-02:55:26] [V] [TRT] Fastest Tactic: 2 Time: 8.29083
[05/21/2022-02:55:26] [V] [TRT] Setting workspace to 1228013568enables more tactics for profiling
[05/21/2022-02:55:26] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:26] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:55:26] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:55:26] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:55:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:26] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-02:55:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:26] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:26] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:55:26] [V] [TRT] Tactic: 3564772625446233998 Time: 4.40513
[05/21/2022-02:55:26] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:55:26] [V] [TRT] Tactic: 3650389455493082349 Time: 4.54913
[05/21/2022-02:55:26] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:55:26] [V] [TRT] Tactic: 4772821744921268633 Time: 3.46347
[05/21/2022-02:55:26] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:55:26] [V] [TRT] Tactic: 5319956359050645452 Time: 3.64025
[05/21/2022-02:55:27] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:55:27] [V] [TRT] Tactic: 7205456024582378848 Time: 3.22691
[05/21/2022-02:55:27] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:55:27] [V] [TRT] Tactic: -6490690591794140522 Time: 3.35518
[05/21/2022-02:55:27] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:55:27] [V] [TRT] Tactic: -4686027666808657977 Time: 3.25601
[05/21/2022-02:55:27] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:55:27] [V] [TRT] Tactic: -4212163711445252890 Time: 3.04201
[05/21/2022-02:55:27] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:55:27] [V] [TRT] Tactic: -3898373634979201110 Time: 3.19411
[05/21/2022-02:55:27] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:55:27] [V] [TRT] Tactic: -2409163523992614473 Time: 3.11352
[05/21/2022-02:55:27] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 3.04201
[05/21/2022-02:55:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:55:27] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:27] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:55:27] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:55:27] [V] [TRT] Tactic: 0 Time: 0.0776236
[05/21/2022-02:55:27] [V] [TRT] Tactic: 1 Time: 0.0570701
[05/21/2022-02:55:27] [V] [TRT] Tactic: 2 Time: 0.0495313
[05/21/2022-02:55:27] [V] [TRT] Tactic: 3 Time: 0.0487435
[05/21/2022-02:55:27] [V] [TRT] Tactic: 4 Time: 0.0403064
[05/21/2022-02:55:27] [V] [TRT] Tactic: 5 Time: 0.0382159
[05/21/2022-02:55:27] [V] [TRT] Tactic: 6 Time: 0.049479
[05/21/2022-02:55:27] [V] [TRT] Tactic: 7 Time: 0.0418101
[05/21/2022-02:55:27] [V] [TRT] Tactic: 8 Time: 0.0388999
[05/21/2022-02:55:27] [V] [TRT] Tactic: 9 Time: 0.0377021
[05/21/2022-02:55:27] [V] [TRT] Tactic: 28 Time: 0.0750975
[05/21/2022-02:55:27] [V] [TRT] Fastest Tactic: 9 Time: 0.0377021
[05/21/2022-02:55:27] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-02:55:27] [V] [TRT] Tactic: 128 Time: 0.169362
[05/21/2022-02:55:27] [V] [TRT] Tactic: 256 Time: 0.170306
[05/21/2022-02:55:27] [V] [TRT] Tactic: 512 Time: 0.171204
[05/21/2022-02:55:27] [V] [TRT] Tactic: -32 Time: 0.196543
[05/21/2022-02:55:27] [V] [TRT] Tactic: -64 Time: 0.183516
[05/21/2022-02:55:27] [V] [TRT] Tactic: -128 Time: 0.180117
[05/21/2022-02:55:27] [V] [TRT] Fastest Tactic: 128 Time: 0.169362
[05/21/2022-02:55:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:55:27] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:55:27] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:55:27] [V] [TRT] Tactic: 0 Time: 0.0765104
[05/21/2022-02:55:27] [V] [TRT] Tactic: 1 Time: 0.056491
[05/21/2022-02:55:27] [V] [TRT] Tactic: 2 Time: 0.0492706
[05/21/2022-02:55:28] [V] [TRT] Tactic: 3 Time: 0.0488802
[05/21/2022-02:55:28] [V] [TRT] Tactic: 4 Time: 0.0396485
[05/21/2022-02:55:28] [V] [TRT] Tactic: 5 Time: 0.03694
[05/21/2022-02:55:28] [V] [TRT] Tactic: 6 Time: 0.0492514
[05/21/2022-02:55:28] [V] [TRT] Tactic: 7 Time: 0.0387302
[05/21/2022-02:55:28] [V] [TRT] Tactic: 8 Time: 0.0382292
[05/21/2022-02:55:28] [V] [TRT] Tactic: 9 Time: 0.0375975
[05/21/2022-02:55:28] [V] [TRT] Tactic: 28 Time: 0.074577
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 5 Time: 0.03694
[05/21/2022-02:55:28] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-02:55:28] [V] [TRT] Tactic: 128 Time: 0.169512
[05/21/2022-02:55:28] [V] [TRT] Tactic: 256 Time: 0.169564
[05/21/2022-02:55:28] [V] [TRT] Tactic: 512 Time: 0.170866
[05/21/2022-02:55:28] [V] [TRT] Tactic: -32 Time: 0.196791
[05/21/2022-02:55:28] [V] [TRT] Tactic: -64 Time: 0.18321
[05/21/2022-02:55:28] [V] [TRT] Tactic: -128 Time: 0.180235
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 128 Time: 0.169512
[05/21/2022-02:55:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:55:28] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:55:28] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:55:28] [V] [TRT] Tactic: 24 Time: 0.049284
[05/21/2022-02:55:28] [V] [TRT] Tactic: 25 Time: 0.0474806
[05/21/2022-02:55:28] [V] [TRT] Tactic: 26 Time: 0.0466275
[05/21/2022-02:55:28] [V] [TRT] Tactic: 27 Time: 0.0476044
[05/21/2022-02:55:28] [V] [TRT] Tactic: 31 Time: 0.0481315
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 26 Time: 0.0466275
[05/21/2022-02:55:28] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-02:55:28] [V] [TRT] Tactic: 128 Time: 0.169609
[05/21/2022-02:55:28] [V] [TRT] Tactic: 256 Time: 0.170117
[05/21/2022-02:55:28] [V] [TRT] Tactic: 512 Time: 0.170983
[05/21/2022-02:55:28] [V] [TRT] Tactic: -32 Time: 0.195625
[05/21/2022-02:55:28] [V] [TRT] Tactic: -64 Time: 0.183067
[05/21/2022-02:55:28] [V] [TRT] Tactic: -128 Time: 0.18002
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 128 Time: 0.169609
[05/21/2022-02:55:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:55:28] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:55:28] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:55:28] [V] [TRT] Tactic: 0 Time: 0.0761067
[05/21/2022-02:55:28] [V] [TRT] Tactic: 1 Time: 0.054974
[05/21/2022-02:55:28] [V] [TRT] Tactic: 2 Time: 0.0522722
[05/21/2022-02:55:28] [V] [TRT] Tactic: 3 Time: 0.0441536
[05/21/2022-02:55:28] [V] [TRT] Tactic: 4 Time: 0.035371
[05/21/2022-02:55:28] [V] [TRT] Tactic: 5 Time: 0.037168
[05/21/2022-02:55:28] [V] [TRT] Tactic: 6 Time: 0.0414648
[05/21/2022-02:55:28] [V] [TRT] Tactic: 7 Time: 0.0307551
[05/21/2022-02:55:28] [V] [TRT] Tactic: 8 Time: 0.0271222
[05/21/2022-02:55:28] [V] [TRT] Tactic: 9 Time: 0.03
[05/21/2022-02:55:28] [V] [TRT] Tactic: 28 Time: 0.07431
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 8 Time: 0.0271222
[05/21/2022-02:55:28] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-02:55:28] [V] [TRT] Tactic: 128 Time: 0.153464
[05/21/2022-02:55:28] [V] [TRT] Tactic: 256 Time: 0.152214
[05/21/2022-02:55:28] [V] [TRT] Tactic: 512 Time: 0.150221
[05/21/2022-02:55:28] [V] [TRT] Tactic: -32 Time: 0.184987
[05/21/2022-02:55:28] [V] [TRT] Tactic: -64 Time: 0.171803
[05/21/2022-02:55:28] [V] [TRT] Tactic: -128 Time: 0.171843
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 512 Time: 0.150221
[05/21/2022-02:55:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:55:28] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:55:28] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:55:28] [V] [TRT] Tactic: 0 Time: 0.0504755
[05/21/2022-02:55:28] [V] [TRT] Tactic: 1 Time: 0.0418295
[05/21/2022-02:55:28] [V] [TRT] Tactic: 2 Time: 0.0449025
[05/21/2022-02:55:28] [V] [TRT] Tactic: 3 Time: 0.0380339
[05/21/2022-02:55:28] [V] [TRT] Tactic: 4 Time: 0.0394532
[05/21/2022-02:55:28] [V] [TRT] Tactic: 5 Time: 0.043034
[05/21/2022-02:55:28] [V] [TRT] Tactic: 6 Time: 0.0377475
[05/21/2022-02:55:28] [V] [TRT] Tactic: 7 Time: 0.038548
[05/21/2022-02:55:28] [V] [TRT] Tactic: 8 Time: 0.0394139
[05/21/2022-02:55:28] [V] [TRT] Tactic: 9 Time: 0.0439454
[05/21/2022-02:55:28] [V] [TRT] Tactic: 10 Time: 0.0819075
[05/21/2022-02:55:28] [V] [TRT] Tactic: 11 Time: 0.0586264
[05/21/2022-02:55:28] [V] [TRT] Tactic: 12 Time: 0.056113
[05/21/2022-02:55:28] [V] [TRT] Tactic: 13 Time: 0.0454102
[05/21/2022-02:55:28] [V] [TRT] Tactic: 14 Time: 0.0378194
[05/21/2022-02:55:28] [V] [TRT] Tactic: 15 Time: 0.0399087
[05/21/2022-02:55:28] [V] [TRT] Tactic: 16 Time: 0.0429426
[05/21/2022-02:55:28] [V] [TRT] Tactic: 17 Time: 0.0312239
[05/21/2022-02:55:28] [V] [TRT] Tactic: 18 Time: 0.0290365
[05/21/2022-02:55:28] [V] [TRT] Tactic: 19 Time: 0.033711
[05/21/2022-02:55:28] [V] [TRT] Tactic: 28 Time: 0.0494272
[05/21/2022-02:55:28] [V] [TRT] Tactic: 29 Time: 0.0799939
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 18 Time: 0.0290365
[05/21/2022-02:55:28] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-02:55:28] [V] [TRT] Tactic: 128 Time: 0.154017
[05/21/2022-02:55:28] [V] [TRT] Tactic: 256 Time: 0.153053
[05/21/2022-02:55:28] [V] [TRT] Tactic: 512 Time: 0.150085
[05/21/2022-02:55:28] [V] [TRT] Tactic: -32 Time: 0.185117
[05/21/2022-02:55:28] [V] [TRT] Tactic: -64 Time: 0.172995
[05/21/2022-02:55:28] [V] [TRT] Tactic: -128 Time: 0.171042
[05/21/2022-02:55:28] [V] [TRT] Fastest Tactic: 512 Time: 0.150085
[05/21/2022-02:55:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:55:28] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:28] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:55:28] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:55:28] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:29] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:55:29] [V] [TRT] --------------- Timing Runner: 109_maxpool (TiledPooling)
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733505 Time: 2.87209
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733506 Time: 1.55331
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733508 Time: 2.02852
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733511 Time: 1.32184
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733512 Time: 1.35902
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733513 Time: 0.635755
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733761 Time: 1.58409
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733762 Time: 1.75381
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733764 Time: 1.04014
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733767 Time: 0.703971
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733768 Time: 0.775775
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7733769 Time: 0.35808
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734017 Time: 1.86424
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734018 Time: 1.04084
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734020 Time: 0.628581
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734023 Time: 0.428014
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734024 Time: 0.428131
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734025 Time: 0.219414
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734273 Time: 1.86227
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734274 Time: 1.03976
[05/21/2022-02:55:29] [V] [TRT] Tactic: 7734276 Time: 0.628079
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734279 Time: 0.427748
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734280 Time: 0.428184
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734281 Time: 0.319974
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734529 Time: 1.24501
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734530 Time: 0.696725
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734532 Time: 0.428171
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734535 Time: 0.420104
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734536 Time: 0.422272
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734537 Time: 0.217845
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734785 Time: 1.24567
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734786 Time: 0.696452
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734788 Time: 0.428066
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734791 Time: 0.422344
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734792 Time: 0.421712
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7734793 Time: 0.251758
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735041 Time: 1.24574
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735042 Time: 0.70515
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735044 Time: 0.428444
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735047 Time: 0.422617
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735048 Time: 0.49457
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735049 Time: 0.253392
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735297 Time: 1.36198
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735298 Time: 0.811335
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735300 Time: 0.428294
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735303 Time: 0.495488
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735304 Time: 0.494974
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735305 Time: 0.284896
[05/21/2022-02:55:30] [V] [TRT] Tactic: 7735553 Time: 0.636315
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7735554 Time: 0.358561
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7735556 Time: 0.322122
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7735559 Time: 0.254798
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7735560 Time: 0.288203
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7735561 Time: 0.18278
[05/21/2022-02:55:31] [V] [TRT] Fastest Tactic: 7735561 Time: 0.18278
[05/21/2022-02:55:31] [V] [TRT] --------------- Timing Runner: 109_maxpool (CudnnPooling)
[05/21/2022-02:55:31] [V] [TRT] Tactic: -1 Time: 0.323183
[05/21/2022-02:55:31] [V] [TRT] Fastest Tactic: -1 Time: 0.323183
[05/21/2022-02:55:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: TiledPooling Tactic: 7735561
[05/21/2022-02:55:31] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:31] [V] [TRT] --------------- Timing Runner: 109_maxpool (TiledPooling)
[05/21/2022-02:55:31] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-02:55:31] [V] [TRT] --------------- Timing Runner: 109_maxpool (CudnnPooling)
[05/21/2022-02:55:31] [V] [TRT] Tactic: -1 Time: 0.311107
[05/21/2022-02:55:31] [V] [TRT] Fastest Tactic: -1 Time: 0.311107
[05/21/2022-02:55:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-02:55:31] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:55:31] [V] [TRT] --------------- Timing Runner: 109_maxpool (TiledPooling)
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733505 Time: 1.75683
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733506 Time: 0.979271
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733508 Time: 1.17687
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733511 Time: 0.78914
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733512 Time: 0.788952
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733513 Time: 0.362187
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733761 Time: 1.07249
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733762 Time: 1.12238
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733764 Time: 0.701907
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733767 Time: 0.401035
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733768 Time: 0.400716
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7733769 Time: 0.204922
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734017 Time: 1.17712
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734018 Time: 0.657083
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734020 Time: 0.397806
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734023 Time: 0.244466
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734024 Time: 0.244499
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734025 Time: 0.126589
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734273 Time: 1.17635
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734274 Time: 0.656842
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734276 Time: 0.399642
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734279 Time: 0.244883
[05/21/2022-02:55:31] [V] [TRT] Tactic: 7734280 Time: 0.244726
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734281 Time: 0.189401
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734529 Time: 0.787871
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734530 Time: 0.504746
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734532 Time: 0.245267
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734535 Time: 0.247331
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734536 Time: 0.249368
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734537 Time: 0.131211
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734785 Time: 0.868275
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734786 Time: 0.442988
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734788 Time: 0.246029
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734791 Time: 0.249427
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734792 Time: 0.249447
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7734793 Time: 0.146992
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735041 Time: 0.857845
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735042 Time: 0.401882
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735044 Time: 0.244499
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735047 Time: 0.249746
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735048 Time: 0.286289
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735049 Time: 0.147129
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735297 Time: 0.839967
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735298 Time: 0.401276
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735300 Time: 0.245892
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735303 Time: 0.284902
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735304 Time: 0.285469
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735305 Time: 0.171595
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735553 Time: 0.362467
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735554 Time: 0.206634
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735556 Time: 0.191367
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735559 Time: 0.149486
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735560 Time: 0.174342
[05/21/2022-02:55:32] [V] [TRT] Tactic: 7735561 Time: 0.112468
[05/21/2022-02:55:32] [V] [TRT] Fastest Tactic: 7735561 Time: 0.112468
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 109_maxpool (CudaPooling)
[05/21/2022-02:55:32] [V] [TRT] Tactic: -3 Time: 0.121634
[05/21/2022-02:55:32] [V] [TRT] Fastest Tactic: -3 Time: 0.121634
[05/21/2022-02:55:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: TiledPooling Tactic: 7735561
[05/21/2022-02:55:32] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:32] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 111_maxpool (TiledPooling)
[05/21/2022-02:55:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 111_maxpool (CudnnPooling)
[05/21/2022-02:55:32] [V] [TRT] Tactic: -1 Time: 0.601074
[05/21/2022-02:55:32] [V] [TRT] Fastest Tactic: -1 Time: 0.601074
[05/21/2022-02:55:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-02:55:32] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 111_maxpool (TiledPooling)
[05/21/2022-02:55:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 111_maxpool (CudnnPooling)
[05/21/2022-02:55:32] [V] [TRT] Tactic: -1 Time: 0.600488
[05/21/2022-02:55:32] [V] [TRT] Fastest Tactic: -1 Time: 0.600488
[05/21/2022-02:55:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-02:55:32] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 111_maxpool (TiledPooling)
[05/21/2022-02:55:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 111_maxpool (CudaPooling)
[05/21/2022-02:55:32] [V] [TRT] Tactic: -3 Time: 0.258275
[05/21/2022-02:55:32] [V] [TRT] Fastest Tactic: -3 Time: 0.258275
[05/21/2022-02:55:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaPooling Tactic: -3
[05/21/2022-02:55:32] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:32] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 113_maxpool (TiledPooling)
[05/21/2022-02:55:32] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-02:55:32] [V] [TRT] --------------- Timing Runner: 113_maxpool (CudnnPooling)
[05/21/2022-02:55:33] [V] [TRT] Tactic: -1 Time: 1.02048
[05/21/2022-02:55:33] [V] [TRT] Fastest Tactic: -1 Time: 1.02048
[05/21/2022-02:55:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-02:55:33] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:33] [V] [TRT] --------------- Timing Runner: 113_maxpool (TiledPooling)
[05/21/2022-02:55:33] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-02:55:33] [V] [TRT] --------------- Timing Runner: 113_maxpool (CudnnPooling)
[05/21/2022-02:55:33] [V] [TRT] Tactic: -1 Time: 0.974968
[05/21/2022-02:55:33] [V] [TRT] Fastest Tactic: -1 Time: 0.974968
[05/21/2022-02:55:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-02:55:33] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:55:33] [V] [TRT] --------------- Timing Runner: 113_maxpool (TiledPooling)
[05/21/2022-02:55:33] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-02:55:33] [V] [TRT] --------------- Timing Runner: 113_maxpool (CudaPooling)
[05/21/2022-02:55:33] [V] [TRT] Tactic: -3 Time: 0.423034
[05/21/2022-02:55:33] [V] [TRT] Fastest Tactic: -3 Time: 0.423034
[05/21/2022-02:55:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaPooling Tactic: -3
[05/21/2022-02:55:33] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:55:33] [V] [TRT] *************** Autotuning format combination: Float(165888,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:55:33] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:55:33] [V] [TRT] Tactic: 589823 Time: 4.05641
[05/21/2022-02:55:33] [V] [TRT] Tactic: 655359 Time: 2.28884
[05/21/2022-02:55:33] [V] [TRT] Tactic: 786431 Time: 2.57755
[05/21/2022-02:55:33] [V] [TRT] Tactic: 851967 Time: 2.88283
[05/21/2022-02:55:34] [V] [TRT] Tactic: 1179647 Time: 4.21652
[05/21/2022-02:55:34] [V] [TRT] Tactic: 1310719 Time: 9.10359
[05/21/2022-02:55:34] [V] [TRT] Tactic: 1376255 Time: 2.88997
[05/21/2022-02:55:34] [V] [TRT] Tactic: 1441791 Time: 2.18403
[05/21/2022-02:55:35] [V] [TRT] Tactic: 1507327 Time: 1.92357
[05/21/2022-02:55:35] [V] [TRT] Tactic: 1638399 Time: 2.57098
[05/21/2022-02:55:35] [V] [TRT] Tactic: 1835007 Time: 2.93359
[05/21/2022-02:55:35] [V] [TRT] Tactic: 1900543 Time: 2.64766
[05/21/2022-02:55:35] [V] [TRT] Tactic: 2097151 Time: 4.59327
[05/21/2022-02:55:36] [V] [TRT] Tactic: 2162687 Time: 2.00257
[05/21/2022-02:55:36] [V] [TRT] Tactic: 2293759 Time: 2.00189
[05/21/2022-02:55:36] [V] [TRT] Tactic: 2359295 Time: 1.706
[05/21/2022-02:55:36] [V] [TRT] Tactic: 2686975 Time: 2.01385
[05/21/2022-02:55:36] [V] [TRT] Tactic: 3080191 Time: 2.61568
[05/21/2022-02:55:36] [V] [TRT] Tactic: 3342335 Time: 2.78901
[05/21/2022-02:55:37] [V] [TRT] Tactic: 3407871 Time: 1.91475
[05/21/2022-02:55:37] [V] [TRT] Tactic: 3538943 Time: 1.96114
[05/21/2022-02:55:37] [V] [TRT] Tactic: 3670015 Time: 1.77074
[05/21/2022-02:55:37] [V] [TRT] Tactic: 3932159 Time: 2.41531
[05/21/2022-02:55:37] [V] [TRT] Tactic: 3997695 Time: 2.5499
[05/21/2022-02:55:37] [V] [TRT] Tactic: 4063231 Time: 2.94772
[05/21/2022-02:55:38] [V] [TRT] Tactic: 4194303 Time: 3.94651
[05/21/2022-02:55:38] [V] [TRT] Tactic: 4259839 Time: 4.82066
[05/21/2022-02:55:38] [V] [TRT] Tactic: 4325375 Time: 2.20904
[05/21/2022-02:55:38] [V] [TRT] Tactic: 4521983 Time: 2.24822
[05/21/2022-02:55:38] [V] [TRT] Tactic: 4587519 Time: 1.98039
[05/21/2022-02:55:39] [V] [TRT] Tactic: 4653055 Time: 1.83347
[05/21/2022-02:55:39] [V] [TRT] Tactic: 4915199 Time: 4.02621
[05/21/2022-02:55:39] [V] [TRT] Tactic: 4980735 Time: 2.20382
[05/21/2022-02:55:39] [V] [TRT] Tactic: 5177343 Time: 3.83645
[05/21/2022-02:55:39] [V] [TRT] Tactic: 5242879 Time: 3.00512
[05/21/2022-02:55:40] [V] [TRT] Tactic: 5373951 Time: 4.25467
[05/21/2022-02:55:40] [V] [TRT] Tactic: 5439487 Time: 3.69801
[05/21/2022-02:55:40] [V] [TRT] Tactic: 5570559 Time: 2.75525
[05/21/2022-02:55:40] [V] [TRT] Tactic: 5636095 Time: 2.93978
[05/21/2022-02:55:40] [V] [TRT] Tactic: 5701631 Time: 3.08184
[05/21/2022-02:55:41] [V] [TRT] Tactic: 5767167 Time: 5.46949
[05/21/2022-02:55:41] [V] [TRT] Tactic: 5832703 Time: 3.8071
[05/21/2022-02:55:41] [V] [TRT] Tactic: 5898239 Time: 3.10387
[05/21/2022-02:55:41] [V] [TRT] Tactic: 6029311 Time: 3.07938
[05/21/2022-02:55:41] [V] [TRT] Tactic: 6225919 Time: 3.57438
[05/21/2022-02:55:42] [V] [TRT] Tactic: 6291455 Time: 4.18639
[05/21/2022-02:55:42] [V] [TRT] Tactic: 6422527 Time: 3.16729
[05/21/2022-02:55:42] [V] [TRT] Tactic: 6750207 Time: 4.00348
[05/21/2022-02:55:42] [V] [TRT] Tactic: 6815743 Time: 3.03428
[05/21/2022-02:55:43] [V] [TRT] Tactic: 6946815 Time: 5.42543
[05/21/2022-02:55:43] [V] [TRT] Tactic: 7012351 Time: 4.63364
[05/21/2022-02:55:43] [V] [TRT] Tactic: 7077887 Time: 3.946
[05/21/2022-02:55:43] [V] [TRT] Tactic: 7143423 Time: 5.58281
[05/21/2022-02:55:44] [V] [TRT] Tactic: 7208959 Time: 3.68658
[05/21/2022-02:55:44] [V] [TRT] Tactic: 7340031 Time: 3.22055
[05/21/2022-02:55:44] [V] [TRT] Tactic: 7405567 Time: 3.09236
[05/21/2022-02:55:44] [V] [TRT] Tactic: 7536639 Time: 4.04486
[05/21/2022-02:55:45] [V] [TRT] Tactic: 7602175 Time: 5.29098
[05/21/2022-02:55:45] [V] [TRT] Tactic: 7733247 Time: 3.34784
[05/21/2022-02:55:45] [V] [TRT] Tactic: 7798783 Time: 2.5432
[05/21/2022-02:55:45] [V] [TRT] Tactic: 8191999 Time: 5.91007
[05/21/2022-02:55:45] [V] [TRT] Tactic: 8257535 Time: 4.01273
[05/21/2022-02:55:46] [V] [TRT] Tactic: 8323071 Time: 3.69845
[05/21/2022-02:55:46] [V] [TRT] Tactic: 8650751 Time: 4.71514
[05/21/2022-02:55:46] [V] [TRT] Tactic: 8716287 Time: 3.57226
[05/21/2022-02:55:46] [V] [TRT] Tactic: 9109503 Time: 4.64385
[05/21/2022-02:55:47] [V] [TRT] Tactic: 9568255 Time: 3.99559
[05/21/2022-02:55:47] [V] [TRT] Tactic: 9895935 Time: 3.94266
[05/21/2022-02:55:47] [V] [TRT] Tactic: 10223615 Time: 2.00824
[05/21/2022-02:55:47] [V] [TRT] Tactic: 10354687 Time: 5.00231
[05/21/2022-02:55:48] [V] [TRT] Tactic: 10551295 Time: 3.80708
[05/21/2022-02:55:48] [V] [TRT] Tactic: 10747903 Time: 3.2903
[05/21/2022-02:55:48] [V] [TRT] Tactic: 10944511 Time: 2.20519
[05/21/2022-02:55:48] [V] [TRT] Fastest Tactic: 2359295 Time: 1.706
[05/21/2022-02:55:48] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:55:48] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:48] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-02:55:48] [V] [TRT] Tactic: 0 Time: 2.56042
[05/21/2022-02:55:48] [V] [TRT] Tactic: 1 Time: 2.02339
[05/21/2022-02:55:48] [V] [TRT] Tactic: 2 Time: 2.47845
[05/21/2022-02:55:48] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2424832000, available: 536870912
[05/21/2022-02:55:49] [V] [TRT] Tactic: 5 Time: 72.5264
[05/21/2022-02:55:49] [V] [TRT] Fastest Tactic: 1 Time: 2.02339
[05/21/2022-02:55:49] [V] [TRT] Setting workspace to 2424832000enables more tactics for profiling
[05/21/2022-02:55:49] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-02:55:49] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:49] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:49] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:55:49] [V] [TRT] Tactic: 1062367460111450758 Time: 1.95288
[05/21/2022-02:55:49] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:55:50] [V] [TRT] Tactic: 1698681053543049347 Time: 1.77795
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:55:50] [V] [TRT] Tactic: 4501471010995462441 Time: 1.42253
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:55:50] [V] [TRT] Tactic: 5137655947464784826 Time: 1.36682
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:55:50] [V] [TRT] Tactic: 5288347012147084929 Time: 1.39136
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:55:50] [V] [TRT] Tactic: 5326823351883942011 Time: 1.33738
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:55:50] [V] [TRT] Tactic: 5500448035057547314 Time: 1.50714
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:55:50] [V] [TRT] Tactic: 6645123197870846056 Time: 1.3881
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:55:50] [V] [TRT] Tactic: 7144526460361122478 Time: 2.11202
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:55:50] [V] [TRT] Tactic: -8262349710178828730 Time: 1.41213
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:55:50] [V] [TRT] Tactic: -6576203419454146580 Time: 1.54124
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:55:50] [V] [TRT] Tactic: -4787320710726427159 Time: 2.23038
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:55:50] [V] [TRT] Tactic: -3456450830548107839 Time: 1.63636
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:55:50] [V] [TRT] Tactic: -1218658103698133241 Time: 1.55327
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:55:50] [V] [TRT] Tactic: -836875257600482091 Time: 1.52391
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:55:50] [V] [TRT] Tactic: -410470605513481746 Time: 1.35769
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:55:50] [V] [TRT] Tactic: -377491875521947884 Time: 1.36355
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:55:50] [V] [TRT] Tactic: -37215280111360163 Time: 1.32264
[05/21/2022-02:55:50] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 1.32264
[05/21/2022-02:55:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-02:55:50] [V] [TRT] *************** Autotuning format combination: Float(165888,1,18432,2048) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:55:50] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-02:55:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:50] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-02:55:50] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:50] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:55:50] [V] [TRT] Tactic: 3886731678879822788 Time: 1.3527
[05/21/2022-02:55:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:55:50] [V] [TRT] Tactic: 6629944304117643200 Time: 2.03241
[05/21/2022-02:55:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:55:51] [V] [TRT] Tactic: -9153228964338181824 Time: 1.96128
[05/21/2022-02:55:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:55:51] [V] [TRT] Tactic: -7394439838318485025 Time: 1.34521
[05/21/2022-02:55:51] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.34521
[05/21/2022-02:55:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:55:51] [V] [TRT] *************** Autotuning format combination: Half(165888,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:51] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-02:55:51] [V] [TRT] Tactic: 0 Time: 2.44695
[05/21/2022-02:55:51] [V] [TRT] Tactic: 1 Time: 2.05494
[05/21/2022-02:55:51] [V] [TRT] Tactic: 2 Time: 2.45749
[05/21/2022-02:55:51] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2424832000, available: 536870912
[05/21/2022-02:55:52] [V] [TRT] Tactic: 5 Time: 73.7981
[05/21/2022-02:55:52] [V] [TRT] Fastest Tactic: 1 Time: 2.05494
[05/21/2022-02:55:52] [V] [TRT] Setting workspace to 2424832000enables more tactics for profiling
[05/21/2022-02:55:52] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-02:55:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:52] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:55:52] [V] [TRT] *************** Autotuning format combination: Half(82944,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:55:52] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-02:55:52] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:55:52] [V] [TRT] *************** Autotuning format combination: Half(82944,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:55:52] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:55:52] [V] [TRT] Tactic: 589823 Time: 2.06339
[05/21/2022-02:55:52] [V] [TRT] Tactic: 655359 Time: 1.41171
[05/21/2022-02:55:52] [V] [TRT] Tactic: 786431 Time: 1.53974
[05/21/2022-02:55:53] [V] [TRT] Tactic: 851967 Time: 1.5618
[05/21/2022-02:55:53] [V] [TRT] Tactic: 1179647 Time: 2.03936
[05/21/2022-02:55:53] [V] [TRT] Tactic: 1310719 Time: 4.75963
[05/21/2022-02:55:53] [V] [TRT] Tactic: 1376255 Time: 1.43695
[05/21/2022-02:55:53] [V] [TRT] Tactic: 1441791 Time: 1.03675
[05/21/2022-02:55:53] [V] [TRT] Tactic: 1507327 Time: 0.986283
[05/21/2022-02:55:53] [V] [TRT] Tactic: 1638399 Time: 1.3462
[05/21/2022-02:55:53] [V] [TRT] Tactic: 1835007 Time: 1.88938
[05/21/2022-02:55:54] [V] [TRT] Tactic: 1900543 Time: 1.40217
[05/21/2022-02:55:54] [V] [TRT] Tactic: 2097151 Time: 3.1979
[05/21/2022-02:55:54] [V] [TRT] Tactic: 2162687 Time: 0.975397
[05/21/2022-02:55:54] [V] [TRT] Tactic: 2293759 Time: 1.00872
[05/21/2022-02:55:54] [V] [TRT] Tactic: 2359295 Time: 0.868724
[05/21/2022-02:55:54] [V] [TRT] Tactic: 2686975 Time: 1.74853
[05/21/2022-02:55:54] [V] [TRT] Tactic: 3080191 Time: 1.51505
[05/21/2022-02:55:54] [V] [TRT] Tactic: 3342335 Time: 1.4346
[05/21/2022-02:55:54] [V] [TRT] Tactic: 3407871 Time: 1.01828
[05/21/2022-02:55:55] [V] [TRT] Tactic: 3538943 Time: 1.0615
[05/21/2022-02:55:55] [V] [TRT] Tactic: 3670015 Time: 0.919401
[05/21/2022-02:55:55] [V] [TRT] Tactic: 3932159 Time: 1.06701
[05/21/2022-02:55:55] [V] [TRT] Tactic: 3997695 Time: 1.64358
[05/21/2022-02:55:55] [V] [TRT] Tactic: 4063231 Time: 1.56479
[05/21/2022-02:55:55] [V] [TRT] Tactic: 4194303 Time: 2.20878
[05/21/2022-02:55:55] [V] [TRT] Tactic: 4259839 Time: 3.28081
[05/21/2022-02:55:55] [V] [TRT] Tactic: 4325375 Time: 1.1098
[05/21/2022-02:55:55] [V] [TRT] Tactic: 4521983 Time: 1.08044
[05/21/2022-02:55:56] [V] [TRT] Tactic: 4587519 Time: 1.10303
[05/21/2022-02:55:56] [V] [TRT] Tactic: 4653055 Time: 0.937644
[05/21/2022-02:55:56] [V] [TRT] Tactic: 4915199 Time: 2.31258
[05/21/2022-02:55:56] [V] [TRT] Tactic: 4980735 Time: 1.18335
[05/21/2022-02:55:56] [V] [TRT] Tactic: 5177343 Time: 1.95839
[05/21/2022-02:55:56] [V] [TRT] Tactic: 5242879 Time: 1.77564
[05/21/2022-02:55:56] [V] [TRT] Tactic: 5373951 Time: 2.15159
[05/21/2022-02:55:56] [V] [TRT] Tactic: 5439487 Time: 2.23881
[05/21/2022-02:55:57] [V] [TRT] Tactic: 5570559 Time: 1.94779
[05/21/2022-02:55:57] [V] [TRT] Tactic: 5636095 Time: 1.56111
[05/21/2022-02:55:57] [V] [TRT] Tactic: 5701631 Time: 1.61861
[05/21/2022-02:55:57] [V] [TRT] Tactic: 5767167 Time: 2.77628
[05/21/2022-02:55:57] [V] [TRT] Tactic: 5832703 Time: 1.86148
[05/21/2022-02:55:57] [V] [TRT] Tactic: 5898239 Time: 1.91235
[05/21/2022-02:55:57] [V] [TRT] Tactic: 6029311 Time: 1.8816
[05/21/2022-02:55:57] [V] [TRT] Tactic: 6225919 Time: 1.92038
[05/21/2022-02:55:58] [V] [TRT] Tactic: 6291455 Time: 2.0952
[05/21/2022-02:55:58] [V] [TRT] Tactic: 6422527 Time: 1.79206
[05/21/2022-02:55:58] [V] [TRT] Tactic: 6750207 Time: 2.38374
[05/21/2022-02:55:58] [V] [TRT] Tactic: 6815743 Time: 1.704
[05/21/2022-02:55:58] [V] [TRT] Tactic: 6946815 Time: 2.52053
[05/21/2022-02:55:58] [V] [TRT] Tactic: 7012351 Time: 3.25014
[05/21/2022-02:55:58] [V] [TRT] Tactic: 7077887 Time: 2.0577
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7143423 Time: 2.81674
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7208959 Time: 1.6831
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7340031 Time: 2.01486
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7405567 Time: 1.7127
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7536639 Time: 2.44408
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7602175 Time: 2.48048
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7733247 Time: 1.89639
[05/21/2022-02:55:59] [V] [TRT] Tactic: 7798783 Time: 1.52693
[05/21/2022-02:56:00] [V] [TRT] Tactic: 8191999 Time: 3.01572
[05/21/2022-02:56:00] [V] [TRT] Tactic: 8257535 Time: 2.31264
[05/21/2022-02:56:00] [V] [TRT] Tactic: 8323071 Time: 2.18304
[05/21/2022-02:56:00] [V] [TRT] Tactic: 8650751 Time: 2.2387
[05/21/2022-02:56:00] [V] [TRT] Tactic: 8716287 Time: 1.93705
[05/21/2022-02:56:00] [V] [TRT] Tactic: 9109503 Time: 3.31005
[05/21/2022-02:56:00] [V] [TRT] Tactic: 9568255 Time: 2.28304
[05/21/2022-02:56:01] [V] [TRT] Tactic: 9895935 Time: 2.24633
[05/21/2022-02:56:01] [V] [TRT] Tactic: 10223615 Time: 1.75544
[05/21/2022-02:56:01] [V] [TRT] Tactic: 10354687 Time: 3.31183
[05/21/2022-02:56:01] [V] [TRT] Tactic: 10551295 Time: 1.97154
[05/21/2022-02:56:01] [V] [TRT] Tactic: 10747903 Time: 1.73005
[05/21/2022-02:56:01] [V] [TRT] Tactic: 10944511 Time: 1.16738
[05/21/2022-02:56:01] [V] [TRT] Fastest Tactic: 2359295 Time: 0.868724
[05/21/2022-02:56:01] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-02:56:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:01] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-02:56:01] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:01] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-02:56:01] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:56:01] [V] [TRT] Tactic: 3066127711859985668 Time: 0.800625
[05/21/2022-02:56:01] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:56:01] [V] [TRT] Tactic: 3564772625446233998 Time: 0.896713
[05/21/2022-02:56:01] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:56:01] [V] [TRT] Tactic: 5319956359050645452 Time: 0.842904
[05/21/2022-02:56:01] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:56:01] [V] [TRT] Tactic: 7205456024582378848 Time: 0.705879
[05/21/2022-02:56:01] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:56:01] [V] [TRT] Tactic: 8163473458334948789 Time: 0.669642
[05/21/2022-02:56:01] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:56:01] [V] [TRT] Tactic: -4212163711445252890 Time: 0.681484
[05/21/2022-02:56:01] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:56:02] [V] [TRT] Tactic: -3898373634979201110 Time: 0.698053
[05/21/2022-02:56:02] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:56:02] [V] [TRT] Tactic: -2409163523992614473 Time: 0.689876
[05/21/2022-02:56:02] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:56:02] [V] [TRT] Tactic: -1716393687483585322 Time: 0.668138
[05/21/2022-02:56:02] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.668138
[05/21/2022-02:56:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:56:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:02] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:56:02] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:03] [V] [TRT] Tactic: 0 Time: 0.0534115
[05/21/2022-02:56:04] [V] [TRT] Tactic: 1 Time: 0.0365951
[05/21/2022-02:56:04] [V] [TRT] Tactic: 2 Time: 0.0338869
[05/21/2022-02:56:05] [V] [TRT] Tactic: 3 Time: 0.054961
[05/21/2022-02:56:06] [V] [TRT] Tactic: 4 Time: 0.0653709
[05/21/2022-02:56:07] [V] [TRT] Tactic: 5 Time: 0.0619856
[05/21/2022-02:56:08] [V] [TRT] Tactic: 6 Time: 0.0701757
[05/21/2022-02:56:09] [V] [TRT] Tactic: 7 Time: 0.0947656
[05/21/2022-02:56:10] [V] [TRT] Tactic: 8 Time: 0.0948765
[05/21/2022-02:56:11] [V] [TRT] Tactic: 9 Time: 0.095625
[05/21/2022-02:56:12] [V] [TRT] Tactic: 28 Time: 0.289544
[05/21/2022-02:56:12] [V] [TRT] Fastest Tactic: 2 Time: 0.0338869
[05/21/2022-02:56:12] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:12] [V] [TRT] Tactic: 128 Time: 0.62433
[05/21/2022-02:56:12] [V] [TRT] Tactic: 256 Time: 0.629713
[05/21/2022-02:56:12] [V] [TRT] Tactic: 512 Time: 0.526771
[05/21/2022-02:56:12] [V] [TRT] Tactic: -32 Time: 0.396881
[05/21/2022-02:56:12] [V] [TRT] Tactic: -64 Time: 0.391491
[05/21/2022-02:56:12] [V] [TRT] Tactic: -128 Time: 0.37457
[05/21/2022-02:56:12] [V] [TRT] Fastest Tactic: -128 Time: 0.37457
[05/21/2022-02:56:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:56:12] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:56:12] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:12] [V] [TRT] Tactic: 0 Time: 0.197637
[05/21/2022-02:56:12] [V] [TRT] Tactic: 1 Time: 0.13194
[05/21/2022-02:56:12] [V] [TRT] Tactic: 2 Time: 0.124596
[05/21/2022-02:56:12] [V] [TRT] Tactic: 3 Time: 0.090944
[05/21/2022-02:56:12] [V] [TRT] Tactic: 4 Time: 0.0857747
[05/21/2022-02:56:12] [V] [TRT] Tactic: 5 Time: 0.081953
[05/21/2022-02:56:12] [V] [TRT] Tactic: 6 Time: 0.0709506
[05/21/2022-02:56:12] [V] [TRT] Tactic: 7 Time: 0.065065
[05/21/2022-02:56:12] [V] [TRT] Tactic: 8 Time: 0.0645445
[05/21/2022-02:56:12] [V] [TRT] Tactic: 9 Time: 0.0645703
[05/21/2022-02:56:12] [V] [TRT] Tactic: 28 Time: 0.193861
[05/21/2022-02:56:12] [V] [TRT] Fastest Tactic: 8 Time: 0.0645445
[05/21/2022-02:56:12] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:12] [V] [TRT] Tactic: 128 Time: 0.418835
[05/21/2022-02:56:12] [V] [TRT] Tactic: 256 Time: 0.418053
[05/21/2022-02:56:12] [V] [TRT] Tactic: 512 Time: 0.420788
[05/21/2022-02:56:12] [V] [TRT] Tactic: -32 Time: 0.379466
[05/21/2022-02:56:12] [V] [TRT] Tactic: -64 Time: 0.376882
[05/21/2022-02:56:12] [V] [TRT] Tactic: -128 Time: 0.381582
[05/21/2022-02:56:12] [V] [TRT] Fastest Tactic: -64 Time: 0.376882
[05/21/2022-02:56:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:56:12] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:56:12] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:13] [V] [TRT] Tactic: 24 Time: 0.0863996
[05/21/2022-02:56:14] [V] [TRT] Tactic: 25 Time: 0.0839194
[05/21/2022-02:56:15] [V] [TRT] Tactic: 26 Time: 0.0818558
[05/21/2022-02:56:16] [V] [TRT] Tactic: 27 Time: 0.117174
[05/21/2022-02:56:17] [V] [TRT] Tactic: 31 Time: 0.131602
[05/21/2022-02:56:17] [V] [TRT] Fastest Tactic: 26 Time: 0.0818558
[05/21/2022-02:56:17] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:17] [V] [TRT] Tactic: 128 Time: 0.622852
[05/21/2022-02:56:17] [V] [TRT] Tactic: 256 Time: 0.626446
[05/21/2022-02:56:17] [V] [TRT] Tactic: 512 Time: 0.422969
[05/21/2022-02:56:17] [V] [TRT] Tactic: -32 Time: 0.395794
[05/21/2022-02:56:17] [V] [TRT] Tactic: -64 Time: 0.389974
[05/21/2022-02:56:17] [V] [TRT] Tactic: -128 Time: 0.372442
[05/21/2022-02:56:17] [V] [TRT] Fastest Tactic: -128 Time: 0.372442
[05/21/2022-02:56:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-02:56:17] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:56:17] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:18] [V] [TRT] Tactic: 0 Time: 0.199212
[05/21/2022-02:56:19] [V] [TRT] Tactic: 1 Time: 0.136908
[05/21/2022-02:56:20] [V] [TRT] Tactic: 2 Time: 0.126641
[05/21/2022-02:56:21] [V] [TRT] Tactic: 3 Time: 0.139368
[05/21/2022-02:56:22] [V] [TRT] Tactic: 4 Time: 0.132721
[05/21/2022-02:56:23] [V] [TRT] Tactic: 5 Time: 0.127422
[05/21/2022-02:56:23] [V] [TRT] Tactic: 6 Time: 0.10888
[05/21/2022-02:56:24] [V] [TRT] Tactic: 7 Time: 0.0976304
[05/21/2022-02:56:25] [V] [TRT] Tactic: 8 Time: 0.102845
[05/21/2022-02:56:26] [V] [TRT] Tactic: 9 Time: 0.103275
[05/21/2022-02:56:27] [V] [TRT] Tactic: 28 Time: 0.292598
[05/21/2022-02:56:27] [V] [TRT] Fastest Tactic: 7 Time: 0.0976304
[05/21/2022-02:56:27] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:27] [V] [TRT] Tactic: 128 Time: 0.500651
[05/21/2022-02:56:27] [V] [TRT] Tactic: 256 Time: 0.497598
[05/21/2022-02:56:27] [V] [TRT] Tactic: 512 Time: 0.479121
[05/21/2022-02:56:27] [V] [TRT] Tactic: -32 Time: 0.596556
[05/21/2022-02:56:27] [V] [TRT] Tactic: -64 Time: 0.53444
[05/21/2022-02:56:27] [V] [TRT] Tactic: -128 Time: 0.404101
[05/21/2022-02:56:27] [V] [TRT] Fastest Tactic: -128 Time: 0.404101
[05/21/2022-02:56:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:56:27] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:56:27] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:29] [V] [TRT] Tactic: 0 Time: 0.119232
[05/21/2022-02:56:29] [V] [TRT] Tactic: 1 Time: 0.0876758
[05/21/2022-02:56:30] [V] [TRT] Tactic: 2 Time: 0.0857356
[05/21/2022-02:56:31] [V] [TRT] Tactic: 3 Time: 0.0975911
[05/21/2022-02:56:32] [V] [TRT] Tactic: 4 Time: 0.100156
[05/21/2022-02:56:33] [V] [TRT] Tactic: 5 Time: 0.106621
[05/21/2022-02:56:34] [V] [TRT] Tactic: 6 Time: 0.0895052
[05/21/2022-02:56:35] [V] [TRT] Tactic: 7 Time: 0.0912176
[05/21/2022-02:56:36] [V] [TRT] Tactic: 8 Time: 0.0984244
[05/21/2022-02:56:37] [V] [TRT] Tactic: 9 Time: 0.112519
[05/21/2022-02:56:38] [V] [TRT] Tactic: 10 Time: 0.625364
[05/21/2022-02:56:39] [V] [TRT] Tactic: 11 Time: 0.425794
[05/21/2022-02:56:40] [V] [TRT] Tactic: 12 Time: 0.406445
[05/21/2022-02:56:41] [V] [TRT] Tactic: 13 Time: 0.290938
[05/21/2022-02:56:42] [V] [TRT] Tactic: 14 Time: 0.264876
[05/21/2022-02:56:43] [V] [TRT] Tactic: 15 Time: 0.277956
[05/21/2022-02:56:44] [V] [TRT] Tactic: 16 Time: 0.226855
[05/21/2022-02:56:44] [V] [TRT] Tactic: 17 Time: 0.188171
[05/21/2022-02:56:45] [V] [TRT] Tactic: 18 Time: 0.212936
[05/21/2022-02:56:46] [V] [TRT] Tactic: 19 Time: 0.226439
[05/21/2022-02:56:47] [V] [TRT] Tactic: 28 Time: 0.345762
[05/21/2022-02:56:48] [V] [TRT] Tactic: 29 Time: 0.612285
[05/21/2022-02:56:48] [V] [TRT] Fastest Tactic: 2 Time: 0.0857356
[05/21/2022-02:56:48] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:48] [V] [TRT] Tactic: 128 Time: 0.997728
[05/21/2022-02:56:48] [V] [TRT] Tactic: 256 Time: 0.983145
[05/21/2022-02:56:48] [V] [TRT] Tactic: 512 Time: 0.951517
[05/21/2022-02:56:48] [V] [TRT] Tactic: -32 Time: 1.17953
[05/21/2022-02:56:48] [V] [TRT] Tactic: -64 Time: 1.06388
[05/21/2022-02:56:48] [V] [TRT] Tactic: -128 Time: 1.11975
[05/21/2022-02:56:48] [V] [TRT] Fastest Tactic: 512 Time: 0.951517
[05/21/2022-02:56:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-02:56:48] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:48] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:56:48] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:56:48] [V] [TRT] Tactic: 589823 Time: 1.20027
[05/21/2022-02:56:48] [V] [TRT] Tactic: 655359 Time: 0.796367
[05/21/2022-02:56:48] [V] [TRT] Tactic: 786431 Time: 1.03954
[05/21/2022-02:56:48] [V] [TRT] Tactic: 851967 Time: 0.754388
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1179647 Time: 1.03516
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1310719 Time: 2.314
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1376255 Time: 0.670886
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1441791 Time: 0.459785
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1507327 Time: 0.395794
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1638399 Time: 0.541315
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1835007 Time: 0.689817
[05/21/2022-02:56:49] [V] [TRT] Tactic: 1900543 Time: 0.660273
[05/21/2022-02:56:49] [V] [TRT] Tactic: 2097151 Time: 1.01608
[05/21/2022-02:56:49] [V] [TRT] Tactic: 2162687 Time: 0.426875
[05/21/2022-02:56:49] [V] [TRT] Tactic: 2293759 Time: 0.412116
[05/21/2022-02:56:49] [V] [TRT] Tactic: 2359295 Time: 0.427149
[05/21/2022-02:56:49] [V] [TRT] Tactic: 2686975 Time: 0.446614
[05/21/2022-02:56:49] [V] [TRT] Tactic: 3080191 Time: 0.47694
[05/21/2022-02:56:49] [V] [TRT] Tactic: 3342335 Time: 0.551986
[05/21/2022-02:56:49] [V] [TRT] Tactic: 3407871 Time: 0.406686
[05/21/2022-02:56:49] [V] [TRT] Tactic: 3538943 Time: 0.354883
[05/21/2022-02:56:50] [V] [TRT] Tactic: 3670015 Time: 0.318171
[05/21/2022-02:56:50] [V] [TRT] Tactic: 3932159 Time: 0.51612
[05/21/2022-02:56:50] [V] [TRT] Tactic: 3997695 Time: 0.501374
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4063231 Time: 0.536601
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4194303 Time: 0.777227
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4259839 Time: 0.97778
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4325375 Time: 0.447923
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4521983 Time: 0.44431
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4587519 Time: 0.409466
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4653055 Time: 0.363711
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4915199 Time: 0.784277
[05/21/2022-02:56:50] [V] [TRT] Tactic: 4980735 Time: 0.478216
[05/21/2022-02:56:50] [V] [TRT] Tactic: 5177343 Time: 0.669603
[05/21/2022-02:56:50] [V] [TRT] Tactic: 5242879 Time: 0.553652
[05/21/2022-02:56:50] [V] [TRT] Tactic: 5373951 Time: 0.736692
[05/21/2022-02:56:50] [V] [TRT] Tactic: 5439487 Time: 0.701563
[05/21/2022-02:56:50] [V] [TRT] Tactic: 5570559 Time: 0.516946
[05/21/2022-02:56:51] [V] [TRT] Tactic: 5636095 Time: 0.538822
[05/21/2022-02:56:51] [V] [TRT] Tactic: 5701631 Time: 0.596582
[05/21/2022-02:56:51] [V] [TRT] Tactic: 5767167 Time: 0.885085
[05/21/2022-02:56:51] [V] [TRT] Tactic: 5832703 Time: 0.59127
[05/21/2022-02:56:51] [V] [TRT] Tactic: 5898239 Time: 0.54112
[05/21/2022-02:56:51] [V] [TRT] Tactic: 6029311 Time: 0.540554
[05/21/2022-02:56:51] [V] [TRT] Tactic: 6225919 Time: 0.521992
[05/21/2022-02:56:51] [V] [TRT] Tactic: 6291455 Time: 0.680098
[05/21/2022-02:56:51] [V] [TRT] Tactic: 6422527 Time: 0.524245
[05/21/2022-02:56:51] [V] [TRT] Tactic: 6750207 Time: 0.637793
[05/21/2022-02:56:51] [V] [TRT] Tactic: 6815743 Time: 0.519662
[05/21/2022-02:56:51] [V] [TRT] Tactic: 6946815 Time: 0.859251
[05/21/2022-02:56:51] [V] [TRT] Tactic: 7012351 Time: 0.815332
[05/21/2022-02:56:51] [V] [TRT] Tactic: 7077887 Time: 0.583783
[05/21/2022-02:56:51] [V] [TRT] Tactic: 7143423 Time: 0.965059
[05/21/2022-02:56:51] [V] [TRT] Tactic: 7208959 Time: 0.534121
[05/21/2022-02:56:51] [V] [TRT] Tactic: 7340031 Time: 0.54737
[05/21/2022-02:56:51] [V] [TRT] Tactic: 7405567 Time: 0.530534
[05/21/2022-02:56:52] [V] [TRT] Tactic: 7536639 Time: 0.578307
[05/21/2022-02:56:52] [V] [TRT] Tactic: 7602175 Time: 0.840325
[05/21/2022-02:56:52] [V] [TRT] Tactic: 7733247 Time: 0.580846
[05/21/2022-02:56:52] [V] [TRT] Tactic: 7798783 Time: 0.490566
[05/21/2022-02:56:52] [V] [TRT] Tactic: 8191999 Time: 0.947422
[05/21/2022-02:56:52] [V] [TRT] Tactic: 8257535 Time: 0.708216
[05/21/2022-02:56:52] [V] [TRT] Tactic: 8323071 Time: 0.63457
[05/21/2022-02:56:52] [V] [TRT] Tactic: 8650751 Time: 0.75944
[05/21/2022-02:56:52] [V] [TRT] Tactic: 8716287 Time: 0.550176
[05/21/2022-02:56:52] [V] [TRT] Tactic: 9109503 Time: 0.821354
[05/21/2022-02:56:52] [V] [TRT] Tactic: 9568255 Time: 0.714557
[05/21/2022-02:56:52] [V] [TRT] Tactic: 9895935 Time: 0.702975
[05/21/2022-02:56:52] [V] [TRT] Tactic: 10223615 Time: 0.362272
[05/21/2022-02:56:52] [V] [TRT] Tactic: 10354687 Time: 0.818457
[05/21/2022-02:56:52] [V] [TRT] Tactic: 10551295 Time: 0.564518
[05/21/2022-02:56:52] [V] [TRT] Tactic: 10747903 Time: 0.527415
[05/21/2022-02:56:52] [V] [TRT] Tactic: 10944511 Time: 0.408151
[05/21/2022-02:56:52] [V] [TRT] Fastest Tactic: 3670015 Time: 0.318171
[05/21/2022-02:56:52] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:56:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:52] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-02:56:52] [V] [TRT] Tactic: 0 Time: 0.441556
[05/21/2022-02:56:52] [V] [TRT] Tactic: 1 Time: 0.386478
[05/21/2022-02:56:53] [V] [TRT] Tactic: 2 Time: 0.610371
[05/21/2022-02:56:53] [V] [TRT] Tactic: 4 Time: 30.2047
[05/21/2022-02:56:53] [V] [TRT] Tactic: 5 Time: 9.13076
[05/21/2022-02:56:53] [V] [TRT] Fastest Tactic: 1 Time: 0.386478
[05/21/2022-02:56:53] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-02:56:53] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:53] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-02:56:53] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:56:53] [V] [TRT] Tactic: 1062367460111450758 Time: 0.278288
[05/21/2022-02:56:53] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:56:53] [V] [TRT] Tactic: 1698681053543049347 Time: 0.25668
[05/21/2022-02:56:53] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:56:53] [V] [TRT] Tactic: 4501471010995462441 Time: 0.189994
[05/21/2022-02:56:53] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:56:53] [V] [TRT] Tactic: 5137655947464784826 Time: 0.198477
[05/21/2022-02:56:53] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:56:53] [V] [TRT] Tactic: 5288347012147084929 Time: 0.190026
[05/21/2022-02:56:53] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:56:54] [V] [TRT] Tactic: 5326823351883942011 Time: 0.182155
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:56:54] [V] [TRT] Tactic: 5500448035057547314 Time: 0.206621
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:56:54] [V] [TRT] Tactic: 6645123197870846056 Time: 0.202533
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:56:54] [V] [TRT] Tactic: 7144526460361122478 Time: 0.2664
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:56:54] [V] [TRT] Tactic: -8262349710178828730 Time: 0.193353
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:56:54] [V] [TRT] Tactic: -6576203419454146580 Time: 0.233262
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:56:54] [V] [TRT] Tactic: -4787320710726427159 Time: 0.283144
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:56:54] [V] [TRT] Tactic: -3456450830548107839 Time: 0.247917
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:56:54] [V] [TRT] Tactic: -1218658103698133241 Time: 0.214824
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:56:54] [V] [TRT] Tactic: -836875257600482091 Time: 0.211276
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:56:54] [V] [TRT] Tactic: -410470605513481746 Time: 0.186699
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:56:54] [V] [TRT] Tactic: -377491875521947884 Time: 0.18748
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:56:54] [V] [TRT] Tactic: -37215280111360163 Time: 0.193054
[05/21/2022-02:56:54] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.182155
[05/21/2022-02:56:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:56:54] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(20736,1,2304,256) ***************
[05/21/2022-02:56:54] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-02:56:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:54] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-02:56:54] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:54] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:56:54] [V] [TRT] Tactic: 3886731678879822788 Time: 0.192454
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:56:54] [V] [TRT] Tactic: 6629944304117643200 Time: 0.252773
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:56:54] [V] [TRT] Tactic: -9153228964338181824 Time: 0.262891
[05/21/2022-02:56:54] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:56:54] [V] [TRT] Tactic: -7394439838318485025 Time: 0.193437
[05/21/2022-02:56:54] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.192454
[05/21/2022-02:56:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:56:54] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:56:54] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-02:56:54] [V] [TRT] Tactic: 0 Time: 0.37347
[05/21/2022-02:56:54] [V] [TRT] Tactic: 1 Time: 0.321296
[05/21/2022-02:56:54] [V] [TRT] Tactic: 2 Time: 0.5178
[05/21/2022-02:56:54] [V] [TRT] Tactic: 4 Time: 29.5672
[05/21/2022-02:56:55] [V] [TRT] Tactic: 5 Time: 9.27997
[05/21/2022-02:56:55] [V] [TRT] Fastest Tactic: 1 Time: 0.321296
[05/21/2022-02:56:55] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-02:56:55] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:55] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-02:56:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:56:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:56:55] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-02:56:55] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(10368,81:2,9,1) ***************
[05/21/2022-02:56:55] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:56:55] [V] [TRT] Tactic: 589823 Time: 0.268587
[05/21/2022-02:56:55] [V] [TRT] Tactic: 655359 Time: 0.239343
[05/21/2022-02:56:55] [V] [TRT] Tactic: 786431 Time: 0.224473
[05/21/2022-02:56:55] [V] [TRT] Tactic: 851967 Time: 0.226614
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1179647 Time: 0.269453
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1310719 Time: 0.601719
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1376255 Time: 0.227416
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1441791 Time: 0.158841
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1507327 Time: 0.14571
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1638399 Time: 0.19765
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1835007 Time: 0.262936
[05/21/2022-02:56:55] [V] [TRT] Tactic: 1900543 Time: 0.243444
[05/21/2022-02:56:55] [V] [TRT] Tactic: 2097151 Time: 0.460651
[05/21/2022-02:56:55] [V] [TRT] Tactic: 2162687 Time: 0.144407
[05/21/2022-02:56:55] [V] [TRT] Tactic: 2293759 Time: 0.13972
[05/21/2022-02:56:55] [V] [TRT] Tactic: 2359295 Time: 0.145371
[05/21/2022-02:56:55] [V] [TRT] Tactic: 2686975 Time: 0.229095
[05/21/2022-02:56:55] [V] [TRT] Tactic: 3080191 Time: 0.199023
[05/21/2022-02:56:55] [V] [TRT] Tactic: 3342335 Time: 0.205748
[05/21/2022-02:56:55] [V] [TRT] Tactic: 3407871 Time: 0.13541
[05/21/2022-02:56:55] [V] [TRT] Tactic: 3538943 Time: 0.138542
[05/21/2022-02:56:55] [V] [TRT] Tactic: 3670015 Time: 0.248438
[05/21/2022-02:56:55] [V] [TRT] Tactic: 3932159 Time: 0.138763
[05/21/2022-02:56:55] [V] [TRT] Tactic: 3997695 Time: 0.22403
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4063231 Time: 0.232741
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4194303 Time: 0.320091
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4259839 Time: 0.467467
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4325375 Time: 0.171022
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4521983 Time: 0.159577
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4587519 Time: 0.166361
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4653055 Time: 0.140729
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4915199 Time: 0.324277
[05/21/2022-02:56:56] [V] [TRT] Tactic: 4980735 Time: 0.169303
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5177343 Time: 0.240677
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5242879 Time: 0.204811
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5373951 Time: 0.267096
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5439487 Time: 0.290286
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5570559 Time: 0.269433
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5636095 Time: 0.237057
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5701631 Time: 0.209857
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5767167 Time: 0.347591
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5832703 Time: 0.228034
[05/21/2022-02:56:56] [V] [TRT] Tactic: 5898239 Time: 0.277383
[05/21/2022-02:56:56] [V] [TRT] Tactic: 6029311 Time: 0.219375
[05/21/2022-02:56:56] [V] [TRT] Tactic: 6225919 Time: 0.218099
[05/21/2022-02:56:56] [V] [TRT] Tactic: 6291455 Time: 0.269648
[05/21/2022-02:56:56] [V] [TRT] Tactic: 6422527 Time: 0.234069
[05/21/2022-02:56:56] [V] [TRT] Tactic: 6750207 Time: 0.314375
[05/21/2022-02:56:56] [V] [TRT] Tactic: 6815743 Time: 0.210658
[05/21/2022-02:56:56] [V] [TRT] Tactic: 6946815 Time: 0.342903
[05/21/2022-02:56:56] [V] [TRT] Tactic: 7012351 Time: 0.462383
[05/21/2022-02:56:56] [V] [TRT] Tactic: 7077887 Time: 0.24015
[05/21/2022-02:56:56] [V] [TRT] Tactic: 7143423 Time: 0.373945
[05/21/2022-02:56:56] [V] [TRT] Tactic: 7208959 Time: 0.206992
[05/21/2022-02:56:56] [V] [TRT] Tactic: 7340031 Time: 0.287546
[05/21/2022-02:56:56] [V] [TRT] Tactic: 7405567 Time: 0.234063
[05/21/2022-02:56:56] [V] [TRT] Tactic: 7536639 Time: 0.274876
[05/21/2022-02:56:57] [V] [TRT] Tactic: 7602175 Time: 0.324427
[05/21/2022-02:56:57] [V] [TRT] Tactic: 7733247 Time: 0.274043
[05/21/2022-02:56:57] [V] [TRT] Tactic: 7798783 Time: 0.223548
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8191999 Time: 0.374544
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8257535 Time: 0.329297
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8323071 Time: 0.290794
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8650751 Time: 0.302878
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8716287 Time: 0.219844
[05/21/2022-02:56:57] [V] [TRT] Tactic: 9109503 Time: 0.468607
[05/21/2022-02:56:57] [V] [TRT] Tactic: 9568255 Time: 0.32336
[05/21/2022-02:56:57] [V] [TRT] Tactic: 9895935 Time: 0.320325
[05/21/2022-02:56:57] [V] [TRT] Tactic: 10223615 Time: 0.228444
[05/21/2022-02:56:57] [V] [TRT] Tactic: 10354687 Time: 0.462233
[05/21/2022-02:56:57] [V] [TRT] Tactic: 10551295 Time: 0.250996
[05/21/2022-02:56:57] [V] [TRT] Tactic: 10747903 Time: 0.244844
[05/21/2022-02:56:57] [V] [TRT] Tactic: 10944511 Time: 0.168854
[05/21/2022-02:56:57] [V] [TRT] Fastest Tactic: 3407871 Time: 0.13541
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-02:56:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-02:56:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:56:57] [V] [TRT] Tactic: 3066127711859985668 Time: 0.125358
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:56:57] [V] [TRT] Tactic: 3564772625446233998 Time: 0.145489
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:56:57] [V] [TRT] Tactic: 5319956359050645452 Time: 0.130977
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:56:57] [V] [TRT] Tactic: 7205456024582378848 Time: 0.111172
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8163473458334948789 Time: 0.103985
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:56:57] [V] [TRT] Tactic: -4212163711445252890 Time: 0.101647
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:56:57] [V] [TRT] Tactic: -3898373634979201110 Time: 0.1025
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:56:57] [V] [TRT] Tactic: -2409163523992614473 Time: 0.107467
[05/21/2022-02:56:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:56:57] [V] [TRT] Tactic: -1716393687483585322 Time: 0.0996354
[05/21/2022-02:56:57] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.0996354
[05/21/2022-02:56:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:56:57] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:57] [V] [TRT] *************** Autotuning format combination: Float(20736,81,9,1) -> Float(20736,81,9,1) ***************
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:57] [V] [TRT] Tactic: 0 Time: 0.0217904
[05/21/2022-02:56:57] [V] [TRT] Tactic: 1 Time: 0.0148504
[05/21/2022-02:56:57] [V] [TRT] Tactic: 2 Time: 0.0148761
[05/21/2022-02:56:57] [V] [TRT] Tactic: 3 Time: 0.0126301
[05/21/2022-02:56:57] [V] [TRT] Tactic: 4 Time: 0.0103321
[05/21/2022-02:56:57] [V] [TRT] Tactic: 5 Time: 0.0117513
[05/21/2022-02:56:57] [V] [TRT] Tactic: 6 Time: 0.0103322
[05/21/2022-02:56:57] [V] [TRT] Tactic: 7 Time: 0.0100912
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8 Time: 0.008379
[05/21/2022-02:56:57] [V] [TRT] Tactic: 9 Time: 0.010345
[05/21/2022-02:56:57] [V] [TRT] Tactic: 28 Time: 0.0211461
[05/21/2022-02:56:57] [V] [TRT] Fastest Tactic: 8 Time: 0.008379
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:57] [V] [TRT] Tactic: 128 Time: 0.0451302
[05/21/2022-02:56:57] [V] [TRT] Tactic: 256 Time: 0.045228
[05/21/2022-02:56:57] [V] [TRT] Tactic: 512 Time: 0.045814
[05/21/2022-02:56:57] [V] [TRT] Tactic: -32 Time: 0.0501365
[05/21/2022-02:56:57] [V] [TRT] Tactic: -64 Time: 0.0567187
[05/21/2022-02:56:57] [V] [TRT] Tactic: -128 Time: 0.0498048
[05/21/2022-02:56:57] [V] [TRT] Fastest Tactic: 128 Time: 0.0451302
[05/21/2022-02:56:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:56:57] [V] [TRT] *************** Autotuning format combination: Float(20736,1,2304,256) -> Float(20736,1,2304,256) ***************
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:57] [V] [TRT] Tactic: 0 Time: 0.0218035
[05/21/2022-02:56:57] [V] [TRT] Tactic: 1 Time: 0.0149025
[05/21/2022-02:56:57] [V] [TRT] Tactic: 2 Time: 0.0148634
[05/21/2022-02:56:57] [V] [TRT] Tactic: 3 Time: 0.012513
[05/21/2022-02:56:57] [V] [TRT] Tactic: 4 Time: 0.0103059
[05/21/2022-02:56:57] [V] [TRT] Tactic: 5 Time: 0.0112699
[05/21/2022-02:56:57] [V] [TRT] Tactic: 6 Time: 0.0103191
[05/21/2022-02:56:57] [V] [TRT] Tactic: 7 Time: 0.0101238
[05/21/2022-02:56:57] [V] [TRT] Tactic: 8 Time: 0.0084505
[05/21/2022-02:56:57] [V] [TRT] Tactic: 9 Time: 0.0103451
[05/21/2022-02:56:57] [V] [TRT] Tactic: 28 Time: 0.0215952
[05/21/2022-02:56:57] [V] [TRT] Fastest Tactic: 8 Time: 0.0084505
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:57] [V] [TRT] Tactic: 128 Time: 0.0450714
[05/21/2022-02:56:57] [V] [TRT] Tactic: 256 Time: 0.0450977
[05/21/2022-02:56:57] [V] [TRT] Tactic: 512 Time: 0.0457877
[05/21/2022-02:56:57] [V] [TRT] Tactic: -32 Time: 0.0502539
[05/21/2022-02:56:57] [V] [TRT] Tactic: -64 Time: 0.0566926
[05/21/2022-02:56:57] [V] [TRT] Tactic: -128 Time: 0.0497659
[05/21/2022-02:56:57] [V] [TRT] Fastest Tactic: 128 Time: 0.0450714
[05/21/2022-02:56:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:56:57] [V] [TRT] *************** Autotuning format combination: Float(648,81:32,9,1) -> Float(648,81:32,9,1) ***************
[05/21/2022-02:56:57] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:57] [V] [TRT] Tactic: 24 Time: 0.0131641
[05/21/2022-02:56:58] [V] [TRT] Tactic: 25 Time: 0.0131381
[05/21/2022-02:56:58] [V] [TRT] Tactic: 26 Time: 0.0127343
[05/21/2022-02:56:58] [V] [TRT] Tactic: 27 Time: 0.0125261
[05/21/2022-02:56:58] [V] [TRT] Tactic: 31 Time: 0.0130271
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 27 Time: 0.0125261
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 128 Time: 0.0451174
[05/21/2022-02:56:58] [V] [TRT] Tactic: 256 Time: 0.0451756
[05/21/2022-02:56:58] [V] [TRT] Tactic: 512 Time: 0.0461589
[05/21/2022-02:56:58] [V] [TRT] Tactic: -32 Time: 0.0501564
[05/21/2022-02:56:58] [V] [TRT] Tactic: -64 Time: 0.0568489
[05/21/2022-02:56:58] [V] [TRT] Tactic: -128 Time: 0.04972
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 128 Time: 0.0451174
[05/21/2022-02:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-02:56:58] [V] [TRT] *************** Autotuning format combination: Half(20736,81,9,1) -> Half(20736,81,9,1) ***************
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 0 Time: 0.0218293
[05/21/2022-02:56:58] [V] [TRT] Tactic: 1 Time: 0.0149674
[05/21/2022-02:56:58] [V] [TRT] Tactic: 2 Time: 0.0148569
[05/21/2022-02:56:58] [V] [TRT] Tactic: 3 Time: 0.0125521
[05/21/2022-02:56:58] [V] [TRT] Tactic: 4 Time: 0.0112565
[05/21/2022-02:56:58] [V] [TRT] Tactic: 5 Time: 0.0125459
[05/21/2022-02:56:58] [V] [TRT] Tactic: 6 Time: 0.0103124
[05/21/2022-02:56:58] [V] [TRT] Tactic: 7 Time: 0.0102344
[05/21/2022-02:56:58] [V] [TRT] Tactic: 8 Time: 0.0101954
[05/21/2022-02:56:58] [V] [TRT] Tactic: 9 Time: 0.0102146
[05/21/2022-02:56:58] [V] [TRT] Tactic: 28 Time: 0.0212759
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 8 Time: 0.0101954
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 128 Time: 0.0419015
[05/21/2022-02:56:58] [V] [TRT] Tactic: 256 Time: 0.0421287
[05/21/2022-02:56:58] [V] [TRT] Tactic: 512 Time: 0.042168
[05/21/2022-02:56:58] [V] [TRT] Tactic: -32 Time: 0.0520311
[05/21/2022-02:56:58] [V] [TRT] Tactic: -64 Time: 0.0543816
[05/21/2022-02:56:58] [V] [TRT] Tactic: -128 Time: 0.0497788
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 128 Time: 0.0419015
[05/21/2022-02:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:56:58] [V] [TRT] *************** Autotuning format combination: Half(10368,81:2,9,1) -> Half(10368,81:2,9,1) ***************
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 0 Time: 0.01487
[05/21/2022-02:56:58] [V] [TRT] Tactic: 1 Time: 0.0123504
[05/21/2022-02:56:58] [V] [TRT] Tactic: 2 Time: 0.0123894
[05/21/2022-02:56:58] [V] [TRT] Tactic: 3 Time: 0.0102994
[05/21/2022-02:56:58] [V] [TRT] Tactic: 4 Time: 0.0102214
[05/21/2022-02:56:58] [V] [TRT] Tactic: 5 Time: 0.0108594
[05/21/2022-02:56:58] [V] [TRT] Tactic: 6 Time: 0.0101823
[05/21/2022-02:56:58] [V] [TRT] Tactic: 7 Time: 0.0101889
[05/21/2022-02:56:58] [V] [TRT] Tactic: 8 Time: 0.0103191
[05/21/2022-02:56:58] [V] [TRT] Tactic: 9 Time: 0.0125
[05/21/2022-02:56:58] [V] [TRT] Tactic: 10 Time: 0.0227864
[05/21/2022-02:56:58] [V] [TRT] Tactic: 11 Time: 0.0170376
[05/21/2022-02:56:58] [V] [TRT] Tactic: 12 Time: 0.0168164
[05/21/2022-02:56:58] [V] [TRT] Tactic: 13 Time: 0.0125913
[05/21/2022-02:56:58] [V] [TRT] Tactic: 14 Time: 0.0125391
[05/21/2022-02:56:58] [V] [TRT] Tactic: 15 Time: 0.0125456
[05/21/2022-02:56:58] [V] [TRT] Tactic: 16 Time: 0.0116994
[05/21/2022-02:56:58] [V] [TRT] Tactic: 17 Time: 0.0102019
[05/21/2022-02:56:58] [V] [TRT] Tactic: 18 Time: 0.0102214
[05/21/2022-02:56:58] [V] [TRT] Tactic: 19 Time: 0.0114777
[05/21/2022-02:56:58] [V] [TRT] Tactic: 28 Time: 0.0148374
[05/21/2022-02:56:58] [V] [TRT] Tactic: 29 Time: 0.0218487
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 6 Time: 0.0101823
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 128 Time: 0.0425259
[05/21/2022-02:56:58] [V] [TRT] Tactic: 256 Time: 0.0422526
[05/21/2022-02:56:58] [V] [TRT] Tactic: 512 Time: 0.0425914
[05/21/2022-02:56:58] [V] [TRT] Tactic: -32 Time: 0.0517838
[05/21/2022-02:56:58] [V] [TRT] Tactic: -64 Time: 0.0542904
[05/21/2022-02:56:58] [V] [TRT] Tactic: -128 Time: 0.0497658
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 256 Time: 0.0422526
[05/21/2022-02:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 6
[05/21/2022-02:56:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:58] [V] [TRT] *************** Autotuning format combination: Float(20736,81,9,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: 119_upsample (Resize)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 0 Time: 0.0775913
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0775913
[05/21/2022-02:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-02:56:58] [V] [TRT] *************** Autotuning format combination: Half(20736,81,9,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: 119_upsample (Resize)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 0 Time: 0.0793491
[05/21/2022-02:56:58] [V] [TRT] Fastest Tactic: 0 Time: 0.0793491
[05/21/2022-02:56:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-02:56:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:56:58] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:56:58] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:56:58] [V] [TRT] Tactic: 589823 Time: 1.38465
[05/21/2022-02:56:58] [V] [TRT] Tactic: 655359 Time: 0.931374
[05/21/2022-02:56:58] [V] [TRT] Tactic: 786431 Time: 1.40634
[05/21/2022-02:56:58] [V] [TRT] Tactic: 851967 Time: 1.47732
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1179647 Time: 1.75715
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1310719 Time: 3.08827
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1376255 Time: 1.07906
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1441791 Time: 1.30778
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1507327 Time: 1.10058
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1638399 Time: 1.49128
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1835007 Time: 1.37723
[05/21/2022-02:56:59] [V] [TRT] Tactic: 1900543 Time: 1.06549
[05/21/2022-02:56:59] [V] [TRT] Tactic: 2097151 Time: 1.71771
[05/21/2022-02:56:59] [V] [TRT] Tactic: 2162687 Time: 1.09763
[05/21/2022-02:56:59] [V] [TRT] Tactic: 2293759 Time: 0.876445
[05/21/2022-02:57:00] [V] [TRT] Tactic: 2359295 Time: 0.943262
[05/21/2022-02:57:00] [V] [TRT] Tactic: 2686975 Time: 0.979368
[05/21/2022-02:57:00] [V] [TRT] Tactic: 3080191 Time: 1.10816
[05/21/2022-02:57:00] [V] [TRT] Tactic: 3342335 Time: 1.13027
[05/21/2022-02:57:00] [V] [TRT] Tactic: 3407871 Time: 0.978151
[05/21/2022-02:57:00] [V] [TRT] Tactic: 3538943 Time: 1.03486
[05/21/2022-02:57:00] [V] [TRT] Tactic: 3670015 Time: 0.808626
[05/21/2022-02:57:00] [V] [TRT] Tactic: 3932159 Time: 1.17209
[05/21/2022-02:57:00] [V] [TRT] Tactic: 3997695 Time: 1.46929
[05/21/2022-02:57:00] [V] [TRT] Tactic: 4063231 Time: 1.37025
[05/21/2022-02:57:00] [V] [TRT] Tactic: 4194303 Time: 1.38297
[05/21/2022-02:57:00] [V] [TRT] Tactic: 4259839 Time: 1.80946
[05/21/2022-02:57:01] [V] [TRT] Tactic: 4325375 Time: 1.21145
[05/21/2022-02:57:01] [V] [TRT] Tactic: 4521983 Time: 1.22184
[05/21/2022-02:57:01] [V] [TRT] Tactic: 4587519 Time: 1.14367
[05/21/2022-02:57:01] [V] [TRT] Tactic: 4653055 Time: 1.1187
[05/21/2022-02:57:01] [V] [TRT] Tactic: 4915199 Time: 1.4083
[05/21/2022-02:57:01] [V] [TRT] Tactic: 4980735 Time: 1.20529
[05/21/2022-02:57:01] [V] [TRT] Tactic: 5177343 Time: 1.8122
[05/21/2022-02:57:01] [V] [TRT] Tactic: 5242879 Time: 1.29918
[05/21/2022-02:57:01] [V] [TRT] Tactic: 5373951 Time: 1.96564
[05/21/2022-02:57:01] [V] [TRT] Tactic: 5439487 Time: 1.67202
[05/21/2022-02:57:02] [V] [TRT] Tactic: 5570559 Time: 1.0791
[05/21/2022-02:57:02] [V] [TRT] Tactic: 5636095 Time: 1.36471
[05/21/2022-02:57:02] [V] [TRT] Tactic: 5701631 Time: 1.32304
[05/21/2022-02:57:02] [V] [TRT] Tactic: 5767167 Time: 2.81878
[05/21/2022-02:57:02] [V] [TRT] Tactic: 5832703 Time: 1.38738
[05/21/2022-02:57:02] [V] [TRT] Tactic: 5898239 Time: 1.22238
[05/21/2022-02:57:02] [V] [TRT] Tactic: 6029311 Time: 1.23837
[05/21/2022-02:57:02] [V] [TRT] Tactic: 6225919 Time: 1.41291
[05/21/2022-02:57:02] [V] [TRT] Tactic: 6291455 Time: 1.76648
[05/21/2022-02:57:02] [V] [TRT] Tactic: 6422527 Time: 1.25337
[05/21/2022-02:57:03] [V] [TRT] Tactic: 6750207 Time: 1.52524
[05/21/2022-02:57:03] [V] [TRT] Tactic: 6815743 Time: 1.42433
[05/21/2022-02:57:03] [V] [TRT] Tactic: 6946815 Time: 1.99891
[05/21/2022-02:57:03] [V] [TRT] Tactic: 7012351 Time: 1.72897
[05/21/2022-02:57:03] [V] [TRT] Tactic: 7077887 Time: 1.51527
[05/21/2022-02:57:03] [V] [TRT] Tactic: 7143423 Time: 2.34766
[05/21/2022-02:57:03] [V] [TRT] Tactic: 7208959 Time: 1.38438
[05/21/2022-02:57:03] [V] [TRT] Tactic: 7340031 Time: 1.32117
[05/21/2022-02:57:03] [V] [TRT] Tactic: 7405567 Time: 1.45753
[05/21/2022-02:57:03] [V] [TRT] Tactic: 7536639 Time: 1.6202
[05/21/2022-02:57:04] [V] [TRT] Tactic: 7602175 Time: 1.82801
[05/21/2022-02:57:04] [V] [TRT] Tactic: 7733247 Time: 1.32418
[05/21/2022-02:57:04] [V] [TRT] Tactic: 7798783 Time: 1.40231
[05/21/2022-02:57:04] [V] [TRT] Tactic: 8191999 Time: 2.27824
[05/21/2022-02:57:04] [V] [TRT] Tactic: 8257535 Time: 1.45642
[05/21/2022-02:57:04] [V] [TRT] Tactic: 8323071 Time: 1.36654
[05/21/2022-02:57:04] [V] [TRT] Tactic: 8650751 Time: 1.7785
[05/21/2022-02:57:04] [V] [TRT] Tactic: 8716287 Time: 1.65421
[05/21/2022-02:57:04] [V] [TRT] Tactic: 9109503 Time: 1.86877
[05/21/2022-02:57:04] [V] [TRT] Tactic: 9568255 Time: 1.40965
[05/21/2022-02:57:05] [V] [TRT] Tactic: 9895935 Time: 1.38387
[05/21/2022-02:57:05] [V] [TRT] Tactic: 10223615 Time: 0.978366
[05/21/2022-02:57:05] [V] [TRT] Tactic: 10354687 Time: 1.85432
[05/21/2022-02:57:05] [V] [TRT] Tactic: 10551295 Time: 1.34077
[05/21/2022-02:57:05] [V] [TRT] Tactic: 10747903 Time: 1.23568
[05/21/2022-02:57:05] [V] [TRT] Tactic: 10944511 Time: 1.20819
[05/21/2022-02:57:05] [V] [TRT] Fastest Tactic: 3670015 Time: 0.808626
[05/21/2022-02:57:05] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:57:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:05] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:05] [V] [TRT] Tactic: 0 Time: 1.14635
[05/21/2022-02:57:05] [V] [TRT] Tactic: 1 Time: 0.978776
[05/21/2022-02:57:05] [V] [TRT] Tactic: 2 Time: 1.05951
[05/21/2022-02:57:05] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1145831424, available: 536870912
[05/21/2022-02:57:05] [V] [TRT] Tactic: 5 Time: 9.13913
[05/21/2022-02:57:05] [V] [TRT] Fastest Tactic: 1 Time: 0.978776
[05/21/2022-02:57:05] [V] [TRT] Setting workspace to 1145831424enables more tactics for profiling
[05/21/2022-02:57:05] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:05] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:05] [V] [TRT] Tactic: 1062367460111450758 Time: 0.68944
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:57:05] [V] [TRT] Tactic: 1698681053543049347 Time: 0.691862
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:05] [V] [TRT] Tactic: 4501471010995462441 Time: 0.548672
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:05] [V] [TRT] Tactic: 5137655947464784826 Time: 0.570886
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:05] [V] [TRT] Tactic: 5288347012147084929 Time: 0.550801
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:57:05] [V] [TRT] Tactic: 5326823351883942011 Time: 0.528847
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:57:05] [V] [TRT] Tactic: 5500448035057547314 Time: 0.584265
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:05] [V] [TRT] Tactic: 6645123197870846056 Time: 0.574831
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:05] [V] [TRT] Tactic: 7144526460361122478 Time: 0.742572
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:05] [V] [TRT] Tactic: -8262349710178828730 Time: 0.557369
[05/21/2022-02:57:05] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:57:06] [V] [TRT] Tactic: -6576203419454146580 Time: 0.633945
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:06] [V] [TRT] Tactic: -4787320710726427159 Time: 0.769844
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:06] [V] [TRT] Tactic: -3456450830548107839 Time: 0.644076
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:06] [V] [TRT] Tactic: -1218658103698133241 Time: 0.624577
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:06] [V] [TRT] Tactic: -836875257600482091 Time: 0.601354
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:06] [V] [TRT] Tactic: -410470605513481746 Time: 0.542656
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:57:06] [V] [TRT] Tactic: -377491875521947884 Time: 0.544499
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:57:06] [V] [TRT] Tactic: -37215280111360163 Time: 0.545033
[05/21/2022-02:57:06] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.528847
[05/21/2022-02:57:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:57:06] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:06] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:57:06] [V] [TRT] Tactic: 3886731678879822788 Time: 0.554349
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:57:06] [V] [TRT] Tactic: 6629944304117643200 Time: 0.927663
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:57:06] [V] [TRT] Tactic: -9153228964338181824 Time: 0.928242
[05/21/2022-02:57:06] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:57:06] [V] [TRT] Tactic: -7394439838318485025 Time: 0.567793
[05/21/2022-02:57:06] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.554349
[05/21/2022-02:57:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:57:06] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:06] [V] [TRT] Tactic: 0 Time: 1.15535
[05/21/2022-02:57:06] [V] [TRT] Tactic: 1 Time: 1.03326
[05/21/2022-02:57:06] [V] [TRT] Tactic: 2 Time: 1.01363
[05/21/2022-02:57:06] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1145831424, available: 536870912
[05/21/2022-02:57:06] [V] [TRT] Tactic: 5 Time: 9.39981
[05/21/2022-02:57:06] [V] [TRT] Fastest Tactic: 2 Time: 1.01363
[05/21/2022-02:57:06] [V] [TRT] Setting workspace to 1145831424enables more tactics for profiling
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:57:06] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:06] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:06] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:06] [V] [TRT] Tactic: 589823 Time: 0.66638
[05/21/2022-02:57:06] [V] [TRT] Tactic: 655359 Time: 0.62429
[05/21/2022-02:57:06] [V] [TRT] Tactic: 786431 Time: 0.879922
[05/21/2022-02:57:06] [V] [TRT] Tactic: 851967 Time: 0.800703
[05/21/2022-02:57:06] [V] [TRT] Tactic: 1179647 Time: 0.72362
[05/21/2022-02:57:06] [V] [TRT] Tactic: 1310719 Time: 1.57233
[05/21/2022-02:57:06] [V] [TRT] Tactic: 1376255 Time: 0.531504
[05/21/2022-02:57:07] [V] [TRT] Tactic: 1441791 Time: 0.617005
[05/21/2022-02:57:07] [V] [TRT] Tactic: 1507327 Time: 0.569551
[05/21/2022-02:57:07] [V] [TRT] Tactic: 1638399 Time: 0.755104
[05/21/2022-02:57:07] [V] [TRT] Tactic: 1835007 Time: 0.87138
[05/21/2022-02:57:07] [V] [TRT] Tactic: 1900543 Time: 0.55459
[05/21/2022-02:57:07] [V] [TRT] Tactic: 2097151 Time: 1.16382
[05/21/2022-02:57:07] [V] [TRT] Tactic: 2162687 Time: 0.563971
[05/21/2022-02:57:07] [V] [TRT] Tactic: 2293759 Time: 0.450768
[05/21/2022-02:57:07] [V] [TRT] Tactic: 2359295 Time: 0.489141
[05/21/2022-02:57:07] [V] [TRT] Tactic: 2686975 Time: 0.756836
[05/21/2022-02:57:07] [V] [TRT] Tactic: 3080191 Time: 0.602728
[05/21/2022-02:57:07] [V] [TRT] Tactic: 3342335 Time: 0.589056
[05/21/2022-02:57:07] [V] [TRT] Tactic: 3407871 Time: 0.457989
[05/21/2022-02:57:07] [V] [TRT] Tactic: 3538943 Time: 0.492148
[05/21/2022-02:57:07] [V] [TRT] Tactic: 3670015 Time: 0.534603
[05/21/2022-02:57:07] [V] [TRT] Tactic: 3932159 Time: 0.569727
[05/21/2022-02:57:08] [V] [TRT] Tactic: 3997695 Time: 0.922292
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4063231 Time: 0.71569
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4194303 Time: 0.809303
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4259839 Time: 1.17776
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4325375 Time: 0.621042
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4521983 Time: 0.587201
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4587519 Time: 0.652402
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4653055 Time: 0.551458
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4915199 Time: 0.825137
[05/21/2022-02:57:08] [V] [TRT] Tactic: 4980735 Time: 0.623509
[05/21/2022-02:57:08] [V] [TRT] Tactic: 5177343 Time: 0.786947
[05/21/2022-02:57:08] [V] [TRT] Tactic: 5242879 Time: 0.616087
[05/21/2022-02:57:08] [V] [TRT] Tactic: 5373951 Time: 0.899811
[05/21/2022-02:57:08] [V] [TRT] Tactic: 5439487 Time: 0.933906
[05/21/2022-02:57:08] [V] [TRT] Tactic: 5570559 Time: 0.690137
[05/21/2022-02:57:08] [V] [TRT] Tactic: 5636095 Time: 0.729141
[05/21/2022-02:57:09] [V] [TRT] Tactic: 5701631 Time: 0.578828
[05/21/2022-02:57:09] [V] [TRT] Tactic: 5767167 Time: 1.23215
[05/21/2022-02:57:09] [V] [TRT] Tactic: 5832703 Time: 0.645723
[05/21/2022-02:57:09] [V] [TRT] Tactic: 5898239 Time: 0.701276
[05/21/2022-02:57:09] [V] [TRT] Tactic: 6029311 Time: 0.57666
[05/21/2022-02:57:09] [V] [TRT] Tactic: 6225919 Time: 0.636536
[05/21/2022-02:57:09] [V] [TRT] Tactic: 6291455 Time: 0.724648
[05/21/2022-02:57:09] [V] [TRT] Tactic: 6422527 Time: 0.61582
[05/21/2022-02:57:09] [V] [TRT] Tactic: 6750207 Time: 0.854004
[05/21/2022-02:57:09] [V] [TRT] Tactic: 6815743 Time: 0.648516
[05/21/2022-02:57:09] [V] [TRT] Tactic: 6946815 Time: 1.01666
[05/21/2022-02:57:09] [V] [TRT] Tactic: 7012351 Time: 1.15268
[05/21/2022-02:57:09] [V] [TRT] Tactic: 7077887 Time: 0.684336
[05/21/2022-02:57:09] [V] [TRT] Tactic: 7143423 Time: 1.18446
[05/21/2022-02:57:09] [V] [TRT] Tactic: 7208959 Time: 0.644421
[05/21/2022-02:57:10] [V] [TRT] Tactic: 7340031 Time: 0.797181
[05/21/2022-02:57:10] [V] [TRT] Tactic: 7405567 Time: 0.678236
[05/21/2022-02:57:10] [V] [TRT] Tactic: 7536639 Time: 0.747057
[05/21/2022-02:57:10] [V] [TRT] Tactic: 7602175 Time: 0.884114
[05/21/2022-02:57:10] [V] [TRT] Tactic: 7733247 Time: 0.726419
[05/21/2022-02:57:10] [V] [TRT] Tactic: 7798783 Time: 0.887545
[05/21/2022-02:57:10] [V] [TRT] Tactic: 8191999 Time: 1.13205
[05/21/2022-02:57:10] [V] [TRT] Tactic: 8257535 Time: 0.875658
[05/21/2022-02:57:10] [V] [TRT] Tactic: 8323071 Time: 0.79321
[05/21/2022-02:57:10] [V] [TRT] Tactic: 8650751 Time: 0.866107
[05/21/2022-02:57:10] [V] [TRT] Tactic: 8716287 Time: 0.731888
[05/21/2022-02:57:10] [V] [TRT] Tactic: 9109503 Time: 1.20796
[05/21/2022-02:57:10] [V] [TRT] Tactic: 9568255 Time: 0.812994
[05/21/2022-02:57:10] [V] [TRT] Tactic: 9895935 Time: 0.812578
[05/21/2022-02:57:10] [V] [TRT] Tactic: 10223615 Time: 0.746973
[05/21/2022-02:57:10] [V] [TRT] Tactic: 10354687 Time: 1.16514
[05/21/2022-02:57:11] [V] [TRT] Tactic: 10551295 Time: 0.673757
[05/21/2022-02:57:11] [V] [TRT] Tactic: 10747903 Time: 0.624017
[05/21/2022-02:57:11] [V] [TRT] Tactic: 10944511 Time: 0.613014
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: 2293759 Time: 0.450768
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:11] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:11] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:57:11] [V] [TRT] Tactic: 3066127711859985668 Time: 0.327936
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:11] [V] [TRT] Tactic: 3564772625446233998 Time: 0.37558
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:11] [V] [TRT] Tactic: 5319956359050645452 Time: 0.338366
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:11] [V] [TRT] Tactic: 7205456024582378848 Time: 0.297897
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:57:11] [V] [TRT] Tactic: 8163473458334948789 Time: 0.289779
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:11] [V] [TRT] Tactic: -4212163711445252890 Time: 0.288906
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:11] [V] [TRT] Tactic: -3898373634979201110 Time: 0.288399
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:11] [V] [TRT] Tactic: -2409163523992614473 Time: 0.290078
[05/21/2022-02:57:11] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:57:11] [V] [TRT] Tactic: -1716393687483585322 Time: 0.281015
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.281015
[05/21/2022-02:57:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:57:11] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:11] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 0 Time: 0.102252
[05/21/2022-02:57:11] [V] [TRT] Tactic: 1 Time: 0.0689906
[05/21/2022-02:57:11] [V] [TRT] Tactic: 2 Time: 0.0629687
[05/21/2022-02:57:11] [V] [TRT] Tactic: 3 Time: 0.0513343
[05/21/2022-02:57:11] [V] [TRT] Tactic: 4 Time: 0.044336
[05/21/2022-02:57:11] [V] [TRT] Tactic: 5 Time: 0.0414065
[05/21/2022-02:57:11] [V] [TRT] Tactic: 6 Time: 0.0490166
[05/21/2022-02:57:11] [V] [TRT] Tactic: 7 Time: 0.0401105
[05/21/2022-02:57:11] [V] [TRT] Tactic: 8 Time: 0.0386065
[05/21/2022-02:57:11] [V] [TRT] Tactic: 9 Time: 0.0379296
[05/21/2022-02:57:11] [V] [TRT] Tactic: 28 Time: 0.0995051
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: 9 Time: 0.0379296
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 128 Time: 0.21127
[05/21/2022-02:57:11] [V] [TRT] Tactic: 256 Time: 0.211732
[05/21/2022-02:57:11] [V] [TRT] Tactic: 512 Time: 0.212624
[05/21/2022-02:57:11] [V] [TRT] Tactic: -32 Time: 0.196647
[05/21/2022-02:57:11] [V] [TRT] Tactic: -64 Time: 0.185859
[05/21/2022-02:57:11] [V] [TRT] Tactic: -128 Time: 0.184831
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: -128 Time: 0.184831
[05/21/2022-02:57:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:11] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 0 Time: 0.101738
[05/21/2022-02:57:11] [V] [TRT] Tactic: 1 Time: 0.0679624
[05/21/2022-02:57:11] [V] [TRT] Tactic: 2 Time: 0.0629753
[05/21/2022-02:57:11] [V] [TRT] Tactic: 3 Time: 0.0519141
[05/21/2022-02:57:11] [V] [TRT] Tactic: 4 Time: 0.0447852
[05/21/2022-02:57:11] [V] [TRT] Tactic: 5 Time: 0.0415431
[05/21/2022-02:57:11] [V] [TRT] Tactic: 6 Time: 0.0496486
[05/21/2022-02:57:11] [V] [TRT] Tactic: 7 Time: 0.040293
[05/21/2022-02:57:11] [V] [TRT] Tactic: 8 Time: 0.0385872
[05/21/2022-02:57:11] [V] [TRT] Tactic: 9 Time: 0.0385415
[05/21/2022-02:57:11] [V] [TRT] Tactic: 28 Time: 0.0992513
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: 9 Time: 0.0385415
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 128 Time: 0.211269
[05/21/2022-02:57:11] [V] [TRT] Tactic: 256 Time: 0.211882
[05/21/2022-02:57:11] [V] [TRT] Tactic: 512 Time: 0.211927
[05/21/2022-02:57:11] [V] [TRT] Tactic: -32 Time: 0.188594
[05/21/2022-02:57:11] [V] [TRT] Tactic: -64 Time: 0.191471
[05/21/2022-02:57:11] [V] [TRT] Tactic: -128 Time: 0.209199
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: -32 Time: 0.188594
[05/21/2022-02:57:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:11] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 24 Time: 0.0475325
[05/21/2022-02:57:11] [V] [TRT] Tactic: 25 Time: 0.0458398
[05/21/2022-02:57:11] [V] [TRT] Tactic: 26 Time: 0.046367
[05/21/2022-02:57:11] [V] [TRT] Tactic: 27 Time: 0.0480469
[05/21/2022-02:57:11] [V] [TRT] Tactic: 31 Time: 0.0472395
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: 25 Time: 0.0458398
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 128 Time: 0.211282
[05/21/2022-02:57:11] [V] [TRT] Tactic: 256 Time: 0.211667
[05/21/2022-02:57:11] [V] [TRT] Tactic: 512 Time: 0.212721
[05/21/2022-02:57:11] [V] [TRT] Tactic: -32 Time: 0.197253
[05/21/2022-02:57:11] [V] [TRT] Tactic: -64 Time: 0.18612
[05/21/2022-02:57:11] [V] [TRT] Tactic: -128 Time: 0.185136
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: -128 Time: 0.185136
[05/21/2022-02:57:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:57:11] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 0 Time: 0.10209
[05/21/2022-02:57:11] [V] [TRT] Tactic: 1 Time: 0.0696746
[05/21/2022-02:57:11] [V] [TRT] Tactic: 2 Time: 0.0654946
[05/21/2022-02:57:11] [V] [TRT] Tactic: 3 Time: 0.0488801
[05/21/2022-02:57:11] [V] [TRT] Tactic: 4 Time: 0.0445767
[05/21/2022-02:57:11] [V] [TRT] Tactic: 5 Time: 0.0430341
[05/21/2022-02:57:11] [V] [TRT] Tactic: 6 Time: 0.0441471
[05/21/2022-02:57:11] [V] [TRT] Tactic: 7 Time: 0.0331705
[05/21/2022-02:57:11] [V] [TRT] Tactic: 8 Time: 0.0332291
[05/21/2022-02:57:11] [V] [TRT] Tactic: 9 Time: 0.0333855
[05/21/2022-02:57:11] [V] [TRT] Tactic: 28 Time: 0.100566
[05/21/2022-02:57:11] [V] [TRT] Fastest Tactic: 7 Time: 0.0331705
[05/21/2022-02:57:11] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:11] [V] [TRT] Tactic: 128 Time: 0.167962
[05/21/2022-02:57:12] [V] [TRT] Tactic: 256 Time: 0.167402
[05/21/2022-02:57:12] [V] [TRT] Tactic: 512 Time: 0.159818
[05/21/2022-02:57:12] [V] [TRT] Tactic: -32 Time: 0.187012
[05/21/2022-02:57:12] [V] [TRT] Tactic: -64 Time: 0.175222
[05/21/2022-02:57:12] [V] [TRT] Tactic: -128 Time: 0.17614
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 512 Time: 0.159818
[05/21/2022-02:57:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 0 Time: 0.0613736
[05/21/2022-02:57:12] [V] [TRT] Tactic: 1 Time: 0.044824
[05/21/2022-02:57:12] [V] [TRT] Tactic: 2 Time: 0.046491
[05/21/2022-02:57:12] [V] [TRT] Tactic: 3 Time: 0.0398176
[05/21/2022-02:57:12] [V] [TRT] Tactic: 4 Time: 0.040892
[05/21/2022-02:57:12] [V] [TRT] Tactic: 5 Time: 0.0450976
[05/21/2022-02:57:12] [V] [TRT] Tactic: 6 Time: 0.0387761
[05/21/2022-02:57:12] [V] [TRT] Tactic: 7 Time: 0.039707
[05/21/2022-02:57:12] [V] [TRT] Tactic: 8 Time: 0.0415624
[05/21/2022-02:57:12] [V] [TRT] Tactic: 9 Time: 0.0436134
[05/21/2022-02:57:12] [V] [TRT] Tactic: 10 Time: 0.10735
[05/21/2022-02:57:12] [V] [TRT] Tactic: 11 Time: 0.0737824
[05/21/2022-02:57:12] [V] [TRT] Tactic: 12 Time: 0.0691601
[05/21/2022-02:57:12] [V] [TRT] Tactic: 13 Time: 0.0503514
[05/21/2022-02:57:12] [V] [TRT] Tactic: 14 Time: 0.0456447
[05/21/2022-02:57:12] [V] [TRT] Tactic: 15 Time: 0.0465234
[05/21/2022-02:57:12] [V] [TRT] Tactic: 16 Time: 0.044069
[05/21/2022-02:57:12] [V] [TRT] Tactic: 17 Time: 0.0334571
[05/21/2022-02:57:12] [V] [TRT] Tactic: 18 Time: 0.0347916
[05/21/2022-02:57:12] [V] [TRT] Tactic: 19 Time: 0.0372396
[05/21/2022-02:57:12] [V] [TRT] Tactic: 28 Time: 0.0599869
[05/21/2022-02:57:12] [V] [TRT] Tactic: 29 Time: 0.106126
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 17 Time: 0.0334571
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 128 Time: 0.168639
[05/21/2022-02:57:12] [V] [TRT] Tactic: 256 Time: 0.166986
[05/21/2022-02:57:12] [V] [TRT] Tactic: 512 Time: 0.159779
[05/21/2022-02:57:12] [V] [TRT] Tactic: -32 Time: 0.186276
[05/21/2022-02:57:12] [V] [TRT] Tactic: -64 Time: 0.174759
[05/21/2022-02:57:12] [V] [TRT] Tactic: -128 Time: 0.175918
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 512 Time: 0.159779
[05/21/2022-02:57:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:57:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 0 Time: 0.0764774
[05/21/2022-02:57:12] [V] [TRT] Tactic: 1 Time: 0.056263
[05/21/2022-02:57:12] [V] [TRT] Tactic: 2 Time: 0.0496878
[05/21/2022-02:57:12] [V] [TRT] Tactic: 3 Time: 0.0497721
[05/21/2022-02:57:12] [V] [TRT] Tactic: 4 Time: 0.0401692
[05/21/2022-02:57:12] [V] [TRT] Tactic: 5 Time: 0.0377081
[05/21/2022-02:57:12] [V] [TRT] Tactic: 6 Time: 0.0493099
[05/21/2022-02:57:12] [V] [TRT] Tactic: 7 Time: 0.0386784
[05/21/2022-02:57:12] [V] [TRT] Tactic: 8 Time: 0.0383592
[05/21/2022-02:57:12] [V] [TRT] Tactic: 9 Time: 0.0375783
[05/21/2022-02:57:12] [V] [TRT] Tactic: 28 Time: 0.0742838
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 9 Time: 0.0375783
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 128 Time: 0.169375
[05/21/2022-02:57:12] [V] [TRT] Tactic: 256 Time: 0.170117
[05/21/2022-02:57:12] [V] [TRT] Tactic: 512 Time: 0.171016
[05/21/2022-02:57:12] [V] [TRT] Tactic: -32 Time: 0.195931
[05/21/2022-02:57:12] [V] [TRT] Tactic: -64 Time: 0.183347
[05/21/2022-02:57:12] [V] [TRT] Tactic: -128 Time: 0.179883
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 128 Time: 0.169375
[05/21/2022-02:57:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 0 Time: 0.0760808
[05/21/2022-02:57:12] [V] [TRT] Tactic: 1 Time: 0.0560873
[05/21/2022-02:57:12] [V] [TRT] Tactic: 2 Time: 0.0492706
[05/21/2022-02:57:12] [V] [TRT] Tactic: 3 Time: 0.0483856
[05/21/2022-02:57:12] [V] [TRT] Tactic: 4 Time: 0.0400259
[05/21/2022-02:57:12] [V] [TRT] Tactic: 5 Time: 0.0371485
[05/21/2022-02:57:12] [V] [TRT] Tactic: 6 Time: 0.0481968
[05/21/2022-02:57:12] [V] [TRT] Tactic: 7 Time: 0.0389259
[05/21/2022-02:57:12] [V] [TRT] Tactic: 8 Time: 0.0381186
[05/21/2022-02:57:12] [V] [TRT] Tactic: 9 Time: 0.0373895
[05/21/2022-02:57:12] [V] [TRT] Tactic: 28 Time: 0.0746813
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 5 Time: 0.0371485
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 128 Time: 0.169929
[05/21/2022-02:57:12] [V] [TRT] Tactic: 256 Time: 0.169844
[05/21/2022-02:57:12] [V] [TRT] Tactic: 512 Time: 0.171263
[05/21/2022-02:57:12] [V] [TRT] Tactic: -32 Time: 0.19554
[05/21/2022-02:57:12] [V] [TRT] Tactic: -64 Time: 0.183021
[05/21/2022-02:57:12] [V] [TRT] Tactic: -128 Time: 0.18013
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 256 Time: 0.169844
[05/21/2022-02:57:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 24 Time: 0.0489845
[05/21/2022-02:57:12] [V] [TRT] Tactic: 25 Time: 0.046426
[05/21/2022-02:57:12] [V] [TRT] Tactic: 26 Time: 0.0466796
[05/21/2022-02:57:12] [V] [TRT] Tactic: 27 Time: 0.0490755
[05/21/2022-02:57:12] [V] [TRT] Tactic: 31 Time: 0.048353
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 25 Time: 0.046426
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 128 Time: 0.169844
[05/21/2022-02:57:12] [V] [TRT] Tactic: 256 Time: 0.169896
[05/21/2022-02:57:12] [V] [TRT] Tactic: 512 Time: 0.170937
[05/21/2022-02:57:12] [V] [TRT] Tactic: -32 Time: 0.196067
[05/21/2022-02:57:12] [V] [TRT] Tactic: -64 Time: 0.183444
[05/21/2022-02:57:12] [V] [TRT] Tactic: -128 Time: 0.179727
[05/21/2022-02:57:12] [V] [TRT] Fastest Tactic: 128 Time: 0.169844
[05/21/2022-02:57:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:57:12] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:12] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:12] [V] [TRT] Tactic: 0 Time: 0.0756966
[05/21/2022-02:57:12] [V] [TRT] Tactic: 1 Time: 0.0547982
[05/21/2022-02:57:12] [V] [TRT] Tactic: 2 Time: 0.0525523
[05/21/2022-02:57:12] [V] [TRT] Tactic: 3 Time: 0.0444856
[05/21/2022-02:57:12] [V] [TRT] Tactic: 4 Time: 0.0352866
[05/21/2022-02:57:12] [V] [TRT] Tactic: 5 Time: 0.0371809
[05/21/2022-02:57:12] [V] [TRT] Tactic: 6 Time: 0.0412564
[05/21/2022-02:57:12] [V] [TRT] Tactic: 7 Time: 0.0302476
[05/21/2022-02:57:12] [V] [TRT] Tactic: 8 Time: 0.0273047
[05/21/2022-02:57:12] [V] [TRT] Tactic: 9 Time: 0.03084
[05/21/2022-02:57:13] [V] [TRT] Tactic: 28 Time: 0.0739844
[05/21/2022-02:57:13] [V] [TRT] Fastest Tactic: 8 Time: 0.0273047
[05/21/2022-02:57:13] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:13] [V] [TRT] Tactic: 128 Time: 0.153685
[05/21/2022-02:57:13] [V] [TRT] Tactic: 256 Time: 0.152546
[05/21/2022-02:57:13] [V] [TRT] Tactic: 512 Time: 0.149329
[05/21/2022-02:57:13] [V] [TRT] Tactic: -32 Time: 0.184922
[05/21/2022-02:57:13] [V] [TRT] Tactic: -64 Time: 0.171667
[05/21/2022-02:57:13] [V] [TRT] Tactic: -128 Time: 0.170521
[05/21/2022-02:57:13] [V] [TRT] Fastest Tactic: 512 Time: 0.149329
[05/21/2022-02:57:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:57:13] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:13] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:13] [V] [TRT] Tactic: 0 Time: 0.0501236
[05/21/2022-02:57:13] [V] [TRT] Tactic: 1 Time: 0.0415431
[05/21/2022-02:57:13] [V] [TRT] Tactic: 2 Time: 0.0438999
[05/21/2022-02:57:13] [V] [TRT] Tactic: 3 Time: 0.0382814
[05/21/2022-02:57:13] [V] [TRT] Tactic: 4 Time: 0.0392446
[05/21/2022-02:57:13] [V] [TRT] Tactic: 5 Time: 0.0427212
[05/21/2022-02:57:13] [V] [TRT] Tactic: 6 Time: 0.0378646
[05/21/2022-02:57:13] [V] [TRT] Tactic: 7 Time: 0.0383335
[05/21/2022-02:57:13] [V] [TRT] Tactic: 8 Time: 0.0396029
[05/21/2022-02:57:13] [V] [TRT] Tactic: 9 Time: 0.0424479
[05/21/2022-02:57:13] [V] [TRT] Tactic: 10 Time: 0.0818229
[05/21/2022-02:57:13] [V] [TRT] Tactic: 11 Time: 0.0583137
[05/21/2022-02:57:13] [V] [TRT] Tactic: 12 Time: 0.0561326
[05/21/2022-02:57:13] [V] [TRT] Tactic: 13 Time: 0.0448698
[05/21/2022-02:57:13] [V] [TRT] Tactic: 14 Time: 0.0376692
[05/21/2022-02:57:13] [V] [TRT] Tactic: 15 Time: 0.039362
[05/21/2022-02:57:13] [V] [TRT] Tactic: 16 Time: 0.042096
[05/21/2022-02:57:13] [V] [TRT] Tactic: 17 Time: 0.0314387
[05/21/2022-02:57:13] [V] [TRT] Tactic: 18 Time: 0.0289972
[05/21/2022-02:57:13] [V] [TRT] Tactic: 19 Time: 0.0332748
[05/21/2022-02:57:13] [V] [TRT] Tactic: 28 Time: 0.0488086
[05/21/2022-02:57:13] [V] [TRT] Tactic: 29 Time: 0.0799869
[05/21/2022-02:57:13] [V] [TRT] Fastest Tactic: 18 Time: 0.0289972
[05/21/2022-02:57:13] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:13] [V] [TRT] Tactic: 128 Time: 0.153984
[05/21/2022-02:57:13] [V] [TRT] Tactic: 256 Time: 0.152572
[05/21/2022-02:57:13] [V] [TRT] Tactic: 512 Time: 0.149577
[05/21/2022-02:57:13] [V] [TRT] Tactic: -32 Time: 0.18459
[05/21/2022-02:57:13] [V] [TRT] Tactic: -64 Time: 0.171575
[05/21/2022-02:57:13] [V] [TRT] Tactic: -128 Time: 0.170221
[05/21/2022-02:57:13] [V] [TRT] Fastest Tactic: 512 Time: 0.149577
[05/21/2022-02:57:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:57:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:13] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:57:13] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:13] [V] [TRT] Tactic: 0 Time: 8.18749
[05/21/2022-02:57:13] [V] [TRT] Tactic: 1 Time: 7.4919
[05/21/2022-02:57:13] [V] [TRT] Tactic: 2 Time: 6.94117
[05/21/2022-02:57:13] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1147797504, available: 536870912
[05/21/2022-02:57:13] [V] [TRT] Tactic: 5 skipped. Scratch requested: 573767680, available: 536870912
[05/21/2022-02:57:13] [V] [TRT] Tactic: 6 Time: 6.08706
[05/21/2022-02:57:13] [V] [TRT] Fastest Tactic: 6 Time: 6.08706
[05/21/2022-02:57:13] [V] [TRT] Setting workspace to 573767680enables more tactics for profiling
[05/21/2022-02:57:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:14] [V] [TRT] Tactic: 1062367460111450758 Time: 5.91582
[05/21/2022-02:57:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:57:14] [V] [TRT] Tactic: 1754984623894446479 Time: 7.03655
[05/21/2022-02:57:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:57:14] [V] [TRT] Tactic: 3611739942397549984 Time: 4.76018
[05/21/2022-02:57:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:57:14] [V] [TRT] Tactic: 3827454225649558724 Time: 6.86369
[05/21/2022-02:57:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:57:14] [V] [TRT] Tactic: 4337000649858996379 Time: 4.86637
[05/21/2022-02:57:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:14] [V] [TRT] Tactic: 4501471010995462441 Time: 4.7171
[05/21/2022-02:57:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:14] [V] [TRT] Tactic: 5137655947464784826 Time: 4.56055
[05/21/2022-02:57:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:14] [V] [TRT] Tactic: 5288347012147084929 Time: 4.60996
[05/21/2022-02:57:15] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:57:15] [V] [TRT] Tactic: 5921334924264294896 Time: 5.49464
[05/21/2022-02:57:15] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:15] [V] [TRT] Tactic: 6645123197870846056 Time: 4.81411
[05/21/2022-02:57:15] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:15] [V] [TRT] Tactic: 7144526460361122478 Time: 6.0994
[05/21/2022-02:57:15] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:57:15] [V] [TRT] Tactic: 7852627285308570038 Time: 7.29967
[05/21/2022-02:57:15] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:57:15] [V] [TRT] Tactic: -9137461792520977713 Time: 4.87773
[05/21/2022-02:57:15] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:57:15] [V] [TRT] Tactic: -8776506421218919509 Time: 7.08087
[05/21/2022-02:57:15] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:15] [V] [TRT] Tactic: -8262349710178828730 Time: 4.76707
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:57:16] [V] [TRT] Tactic: -8133971918129952780 Time: 5.16583
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:57:16] [V] [TRT] Tactic: -6092040395344634144 Time: 6.0125
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:16] [V] [TRT] Tactic: -4787320710726427159 Time: 7.00076
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:16] [V] [TRT] Tactic: -3456450830548107839 Time: 5.19021
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:57:16] [V] [TRT] Tactic: -2318106587342035239 Time: 7.14035
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:57:16] [V] [TRT] Tactic: -1343271414618805657 Time: 4.96414
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:16] [V] [TRT] Tactic: -1218658103698133241 Time: 5.2641
[05/21/2022-02:57:16] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:17] [V] [TRT] Tactic: -836875257600482091 Time: 5.01967
[05/21/2022-02:57:17] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:17] [V] [TRT] Tactic: -410470605513481746 Time: 4.52035
[05/21/2022-02:57:17] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 4.52035
[05/21/2022-02:57:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-02:57:17] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:17] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:17] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:17] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:17] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:57:17] [V] [TRT] Tactic: -9153228964338181824 Time: 5.6135
[05/21/2022-02:57:17] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:57:17] [V] [TRT] Tactic: -7394439838318485025 Time: 4.46495
[05/21/2022-02:57:17] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.46495
[05/21/2022-02:57:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:57:17] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:17] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:17] [V] [TRT] Tactic: 0 Time: 11.1775
[05/21/2022-02:57:17] [V] [TRT] Tactic: 1 Time: 11.0356
[05/21/2022-02:57:17] [V] [TRT] Tactic: 2 Time: 6.6504
[05/21/2022-02:57:17] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1147797504, available: 536870912
[05/21/2022-02:57:17] [V] [TRT] Tactic: 5 skipped. Scratch requested: 573767680, available: 536870912
[05/21/2022-02:57:18] [V] [TRT] Tactic: 6 Time: 7.55843
[05/21/2022-02:57:18] [V] [TRT] Fastest Tactic: 2 Time: 6.6504
[05/21/2022-02:57:18] [V] [TRT] Setting workspace to 573767680enables more tactics for profiling
[05/21/2022-02:57:18] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:18] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:57:18] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:18] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:18] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:18] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:18] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:18] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:18] [V] [TRT] Tactic: 3564772625446233998 Time: 2.93747
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:57:18] [V] [TRT] Tactic: 3650389455493082349 Time: 3.0305
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:57:18] [V] [TRT] Tactic: 4772821744921268633 Time: 2.85219
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:18] [V] [TRT] Tactic: 5319956359050645452 Time: 2.5723
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:18] [V] [TRT] Tactic: 7205456024582378848 Time: 2.39417
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:57:18] [V] [TRT] Tactic: -6490690591794140522 Time: 2.40953
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:57:18] [V] [TRT] Tactic: -4686027666808657977 Time: 2.35357
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:18] [V] [TRT] Tactic: -4212163711445252890 Time: 2.30667
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:18] [V] [TRT] Tactic: -3898373634979201110 Time: 2.30266
[05/21/2022-02:57:18] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:18] [V] [TRT] Tactic: -2409163523992614473 Time: 2.37082
[05/21/2022-02:57:18] [V] [TRT] Fastest Tactic: -3898373634979201110 Time: 2.30266
[05/21/2022-02:57:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -3898373634979201110
[05/21/2022-02:57:18] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:18] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:18] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:18] [V] [TRT] Tactic: 0 Time: 0.147669
[05/21/2022-02:57:18] [V] [TRT] Tactic: 1 Time: 0.109063
[05/21/2022-02:57:18] [V] [TRT] Tactic: 2 Time: 0.0942773
[05/21/2022-02:57:18] [V] [TRT] Tactic: 3 Time: 0.0937436
[05/21/2022-02:57:18] [V] [TRT] Tactic: 4 Time: 0.0760743
[05/21/2022-02:57:18] [V] [TRT] Tactic: 5 Time: 0.0747266
[05/21/2022-02:57:18] [V] [TRT] Tactic: 6 Time: 0.09763
[05/21/2022-02:57:18] [V] [TRT] Tactic: 7 Time: 0.0783464
[05/21/2022-02:57:19] [V] [TRT] Tactic: 8 Time: 0.0754102
[05/21/2022-02:57:19] [V] [TRT] Tactic: 9 Time: 0.0740167
[05/21/2022-02:57:19] [V] [TRT] Tactic: 28 Time: 0.145007
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 9 Time: 0.0740167
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 128 Time: 0.332116
[05/21/2022-02:57:19] [V] [TRT] Tactic: 256 Time: 0.333262
[05/21/2022-02:57:19] [V] [TRT] Tactic: 512 Time: 0.335397
[05/21/2022-02:57:19] [V] [TRT] Tactic: -32 Time: 0.376582
[05/21/2022-02:57:19] [V] [TRT] Tactic: -64 Time: 0.349102
[05/21/2022-02:57:19] [V] [TRT] Tactic: -128 Time: 0.349232
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 128 Time: 0.332116
[05/21/2022-02:57:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:19] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 0 Time: 0.147481
[05/21/2022-02:57:19] [V] [TRT] Tactic: 1 Time: 0.110801
[05/21/2022-02:57:19] [V] [TRT] Tactic: 2 Time: 0.09388
[05/21/2022-02:57:19] [V] [TRT] Tactic: 3 Time: 0.091048
[05/21/2022-02:57:19] [V] [TRT] Tactic: 4 Time: 0.073737
[05/21/2022-02:57:19] [V] [TRT] Tactic: 5 Time: 0.0704101
[05/21/2022-02:57:19] [V] [TRT] Tactic: 6 Time: 0.0888348
[05/21/2022-02:57:19] [V] [TRT] Tactic: 7 Time: 0.0722009
[05/21/2022-02:57:19] [V] [TRT] Tactic: 8 Time: 0.0706967
[05/21/2022-02:57:19] [V] [TRT] Tactic: 9 Time: 0.0727802
[05/21/2022-02:57:19] [V] [TRT] Tactic: 28 Time: 0.14418
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 5 Time: 0.0704101
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 128 Time: 0.332129
[05/21/2022-02:57:19] [V] [TRT] Tactic: 256 Time: 0.333236
[05/21/2022-02:57:19] [V] [TRT] Tactic: 512 Time: 0.335442
[05/21/2022-02:57:19] [V] [TRT] Tactic: -32 Time: 0.373555
[05/21/2022-02:57:19] [V] [TRT] Tactic: -64 Time: 0.349284
[05/21/2022-02:57:19] [V] [TRT] Tactic: -128 Time: 0.34929
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 128 Time: 0.332129
[05/21/2022-02:57:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:57:19] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 24 Time: 0.0925258
[05/21/2022-02:57:19] [V] [TRT] Tactic: 25 Time: 0.0866274
[05/21/2022-02:57:19] [V] [TRT] Tactic: 26 Time: 0.091569
[05/21/2022-02:57:19] [V] [TRT] Tactic: 27 Time: 0.0894726
[05/21/2022-02:57:19] [V] [TRT] Tactic: 31 Time: 0.0927536
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 25 Time: 0.0866274
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 128 Time: 0.331719
[05/21/2022-02:57:19] [V] [TRT] Tactic: 256 Time: 0.333106
[05/21/2022-02:57:19] [V] [TRT] Tactic: 512 Time: 0.335026
[05/21/2022-02:57:19] [V] [TRT] Tactic: -32 Time: 0.3747
[05/21/2022-02:57:19] [V] [TRT] Tactic: -64 Time: 0.348574
[05/21/2022-02:57:19] [V] [TRT] Tactic: -128 Time: 0.348998
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 128 Time: 0.331719
[05/21/2022-02:57:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:57:19] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 0 Time: 0.146302
[05/21/2022-02:57:19] [V] [TRT] Tactic: 1 Time: 0.10485
[05/21/2022-02:57:19] [V] [TRT] Tactic: 2 Time: 0.100189
[05/21/2022-02:57:19] [V] [TRT] Tactic: 3 Time: 0.0833789
[05/21/2022-02:57:19] [V] [TRT] Tactic: 4 Time: 0.0669079
[05/21/2022-02:57:19] [V] [TRT] Tactic: 5 Time: 0.0693229
[05/21/2022-02:57:19] [V] [TRT] Tactic: 6 Time: 0.0766924
[05/21/2022-02:57:19] [V] [TRT] Tactic: 7 Time: 0.0563086
[05/21/2022-02:57:19] [V] [TRT] Tactic: 8 Time: 0.050573
[05/21/2022-02:57:19] [V] [TRT] Tactic: 9 Time: 0.0558006
[05/21/2022-02:57:19] [V] [TRT] Tactic: 28 Time: 0.142181
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 8 Time: 0.050573
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 128 Time: 0.300521
[05/21/2022-02:57:19] [V] [TRT] Tactic: 256 Time: 0.299036
[05/21/2022-02:57:19] [V] [TRT] Tactic: 512 Time: 0.290814
[05/21/2022-02:57:19] [V] [TRT] Tactic: -32 Time: 0.360742
[05/21/2022-02:57:19] [V] [TRT] Tactic: -64 Time: 0.327962
[05/21/2022-02:57:19] [V] [TRT] Tactic: -128 Time: 0.329726
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 512 Time: 0.290814
[05/21/2022-02:57:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:57:19] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 0 Time: 0.0960678
[05/21/2022-02:57:19] [V] [TRT] Tactic: 1 Time: 0.079336
[05/21/2022-02:57:19] [V] [TRT] Tactic: 2 Time: 0.0840885
[05/21/2022-02:57:19] [V] [TRT] Tactic: 3 Time: 0.070332
[05/21/2022-02:57:19] [V] [TRT] Tactic: 4 Time: 0.0726759
[05/21/2022-02:57:19] [V] [TRT] Tactic: 5 Time: 0.0783854
[05/21/2022-02:57:19] [V] [TRT] Tactic: 6 Time: 0.0707035
[05/21/2022-02:57:19] [V] [TRT] Tactic: 7 Time: 0.0715299
[05/21/2022-02:57:19] [V] [TRT] Tactic: 8 Time: 0.0766993
[05/21/2022-02:57:19] [V] [TRT] Tactic: 9 Time: 0.0814973
[05/21/2022-02:57:19] [V] [TRT] Tactic: 10 Time: 0.158939
[05/21/2022-02:57:19] [V] [TRT] Tactic: 11 Time: 0.111725
[05/21/2022-02:57:19] [V] [TRT] Tactic: 12 Time: 0.107864
[05/21/2022-02:57:19] [V] [TRT] Tactic: 13 Time: 0.0848762
[05/21/2022-02:57:19] [V] [TRT] Tactic: 14 Time: 0.0709311
[05/21/2022-02:57:19] [V] [TRT] Tactic: 15 Time: 0.0748308
[05/21/2022-02:57:19] [V] [TRT] Tactic: 16 Time: 0.0783659
[05/21/2022-02:57:19] [V] [TRT] Tactic: 17 Time: 0.0573827
[05/21/2022-02:57:19] [V] [TRT] Tactic: 18 Time: 0.0539256
[05/21/2022-02:57:19] [V] [TRT] Tactic: 19 Time: 0.0629558
[05/21/2022-02:57:19] [V] [TRT] Tactic: 28 Time: 0.0940301
[05/21/2022-02:57:19] [V] [TRT] Tactic: 29 Time: 0.154525
[05/21/2022-02:57:19] [V] [TRT] Fastest Tactic: 18 Time: 0.0539256
[05/21/2022-02:57:19] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:19] [V] [TRT] Tactic: 128 Time: 0.300592
[05/21/2022-02:57:19] [V] [TRT] Tactic: 256 Time: 0.298776
[05/21/2022-02:57:19] [V] [TRT] Tactic: 512 Time: 0.29099
[05/21/2022-02:57:19] [V] [TRT] Tactic: -32 Time: 0.360065
[05/21/2022-02:57:20] [V] [TRT] Tactic: -64 Time: 0.328034
[05/21/2022-02:57:20] [V] [TRT] Tactic: -128 Time: 0.330267
[05/21/2022-02:57:20] [V] [TRT] Fastest Tactic: 512 Time: 0.29099
[05/21/2022-02:57:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:57:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:20] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:57:20] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:20] [V] [TRT] Tactic: 589823 Time: 0.433197
[05/21/2022-02:57:20] [V] [TRT] Tactic: 655359 Time: 0.271179
[05/21/2022-02:57:20] [V] [TRT] Tactic: 786431 Time: 0.409499
[05/21/2022-02:57:20] [V] [TRT] Tactic: 851967 Time: 0.376869
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1179647 Time: 0.395111
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1310719 Time: 0.884993
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1376255 Time: 0.300528
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1441791 Time: 0.367077
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1507327 Time: 0.319804
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1638399 Time: 0.395983
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1835007 Time: 0.398001
[05/21/2022-02:57:20] [V] [TRT] Tactic: 1900543 Time: 0.315365
[05/21/2022-02:57:20] [V] [TRT] Tactic: 2097151 Time: 0.471588
[05/21/2022-02:57:20] [V] [TRT] Tactic: 2162687 Time: 0.320391
[05/21/2022-02:57:20] [V] [TRT] Tactic: 2293759 Time: 0.285267
[05/21/2022-02:57:20] [V] [TRT] Tactic: 2359295 Time: 0.284883
[05/21/2022-02:57:20] [V] [TRT] Tactic: 2686975 Time: 0.278639
[05/21/2022-02:57:20] [V] [TRT] Tactic: 3080191 Time: 0.306517
[05/21/2022-02:57:20] [V] [TRT] Tactic: 3342335 Time: 0.32776
[05/21/2022-02:57:20] [V] [TRT] Tactic: 3407871 Time: 0.259707
[05/21/2022-02:57:20] [V] [TRT] Tactic: 3538943 Time: 0.254636
[05/21/2022-02:57:20] [V] [TRT] Tactic: 3670015 Time: 0.265091
[05/21/2022-02:57:20] [V] [TRT] Tactic: 3932159 Time: 0.348281
[05/21/2022-02:57:21] [V] [TRT] Tactic: 3997695 Time: 0.41235
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4063231 Time: 0.354114
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4194303 Time: 0.403483
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4259839 Time: 0.498848
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4325375 Time: 0.35877
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4521983 Time: 0.350189
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4587519 Time: 0.33653
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4653055 Time: 0.304687
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4915199 Time: 0.406094
[05/21/2022-02:57:21] [V] [TRT] Tactic: 4980735 Time: 0.359844
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5177343 Time: 0.428027
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5242879 Time: 0.306973
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5373951 Time: 0.486244
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5439487 Time: 0.441973
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5570559 Time: 0.282552
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5636095 Time: 0.352878
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5701631 Time: 0.367389
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5767167 Time: 0.607168
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5832703 Time: 0.328001
[05/21/2022-02:57:21] [V] [TRT] Tactic: 5898239 Time: 0.316198
[05/21/2022-02:57:21] [V] [TRT] Tactic: 6029311 Time: 0.312409
[05/21/2022-02:57:21] [V] [TRT] Tactic: 6225919 Time: 0.306367
[05/21/2022-02:57:21] [V] [TRT] Tactic: 6291455 Time: 0.39069
[05/21/2022-02:57:21] [V] [TRT] Tactic: 6422527 Time: 0.318542
[05/21/2022-02:57:21] [V] [TRT] Tactic: 6750207 Time: 0.389304
[05/21/2022-02:57:21] [V] [TRT] Tactic: 6815743 Time: 0.335996
[05/21/2022-02:57:21] [V] [TRT] Tactic: 6946815 Time: 0.522982
[05/21/2022-02:57:21] [V] [TRT] Tactic: 7012351 Time: 0.470306
[05/21/2022-02:57:21] [V] [TRT] Tactic: 7077887 Time: 0.331517
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7143423 Time: 0.623379
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7208959 Time: 0.331602
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7340031 Time: 0.349089
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7405567 Time: 0.354024
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7536639 Time: 0.356309
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7602175 Time: 0.482969
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7733247 Time: 0.35317
[05/21/2022-02:57:22] [V] [TRT] Tactic: 7798783 Time: 0.405944
[05/21/2022-02:57:22] [V] [TRT] Tactic: 8191999 Time: 0.591549
[05/21/2022-02:57:22] [V] [TRT] Tactic: 8257535 Time: 0.420872
[05/21/2022-02:57:22] [V] [TRT] Tactic: 8323071 Time: 0.386406
[05/21/2022-02:57:22] [V] [TRT] Tactic: 8650751 Time: 0.490996
[05/21/2022-02:57:22] [V] [TRT] Tactic: 8716287 Time: 0.352532
[05/21/2022-02:57:22] [V] [TRT] Tactic: 9109503 Time: 0.507187
[05/21/2022-02:57:22] [V] [TRT] Tactic: 9568255 Time: 0.409206
[05/21/2022-02:57:22] [V] [TRT] Tactic: 9895935 Time: 0.402337
[05/21/2022-02:57:22] [V] [TRT] Tactic: 10223615 Time: 0.278672
[05/21/2022-02:57:22] [V] [TRT] Tactic: 10354687 Time: 0.477441
[05/21/2022-02:57:22] [V] [TRT] Tactic: 10551295 Time: 0.370215
[05/21/2022-02:57:22] [V] [TRT] Tactic: 10747903 Time: 0.330455
[05/21/2022-02:57:22] [V] [TRT] Tactic: 10944511 Time: 0.359277
[05/21/2022-02:57:22] [V] [TRT] Fastest Tactic: 3538943 Time: 0.254636
[05/21/2022-02:57:22] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:57:22] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:22] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:22] [V] [TRT] Tactic: 0 Time: 0.329635
[05/21/2022-02:57:22] [V] [TRT] Tactic: 1 Time: 0.283769
[05/21/2022-02:57:22] [V] [TRT] Tactic: 2 Time: 0.450619
[05/21/2022-02:57:23] [V] [TRT] Tactic: 4 Time: 40.5618
[05/21/2022-02:57:23] [V] [TRT] Tactic: 5 Time: 2.59338
[05/21/2022-02:57:23] [V] [TRT] Fastest Tactic: 1 Time: 0.283769
[05/21/2022-02:57:23] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:23] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:23] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:23] [V] [TRT] Tactic: 1062367460111450758 Time: 0.211126
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:57:23] [V] [TRT] Tactic: 1698681053543049347 Time: 0.193027
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:23] [V] [TRT] Tactic: 4501471010995462441 Time: 0.170554
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:23] [V] [TRT] Tactic: 5137655947464784826 Time: 0.164961
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:23] [V] [TRT] Tactic: 5288347012147084929 Time: 0.163971
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:57:23] [V] [TRT] Tactic: 5326823351883942011 Time: 0.159375
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:57:23] [V] [TRT] Tactic: 5500448035057547314 Time: 0.184323
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:23] [V] [TRT] Tactic: 6645123197870846056 Time: 0.164902
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:23] [V] [TRT] Tactic: 7144526460361122478 Time: 0.222487
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:23] [V] [TRT] Tactic: -8262349710178828730 Time: 0.171803
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:57:23] [V] [TRT] Tactic: -6576203419454146580 Time: 0.187123
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:23] [V] [TRT] Tactic: -4787320710726427159 Time: 0.234407
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:23] [V] [TRT] Tactic: -3456450830548107839 Time: 0.193619
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:23] [V] [TRT] Tactic: -1218658103698133241 Time: 0.194681
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:23] [V] [TRT] Tactic: -836875257600482091 Time: 0.185697
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:23] [V] [TRT] Tactic: -410470605513481746 Time: 0.157728
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:57:23] [V] [TRT] Tactic: -377491875521947884 Time: 0.162129
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:57:23] [V] [TRT] Tactic: -37215280111360163 Time: 0.158086
[05/21/2022-02:57:23] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 0.157728
[05/21/2022-02:57:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-02:57:23] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(41472,1,2304,128) ***************
[05/21/2022-02:57:23] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:23] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:23] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:23] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:57:23] [V] [TRT] Tactic: 3886731678879822788 Time: 0.157376
[05/21/2022-02:57:23] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:57:24] [V] [TRT] Tactic: 6629944304117643200 Time: 0.267344
[05/21/2022-02:57:24] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:57:24] [V] [TRT] Tactic: -9153228964338181824 Time: 0.27278
[05/21/2022-02:57:24] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:57:24] [V] [TRT] Tactic: -7394439838318485025 Time: 0.162051
[05/21/2022-02:57:24] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.157376
[05/21/2022-02:57:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-02:57:24] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:57:24] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:24] [V] [TRT] Tactic: 0 Time: 0.352096
[05/21/2022-02:57:24] [V] [TRT] Tactic: 1 Time: 0.291048
[05/21/2022-02:57:24] [V] [TRT] Tactic: 2 Time: 0.438223
[05/21/2022-02:57:24] [V] [TRT] Tactic: 4 Time: 39.7844
[05/21/2022-02:57:24] [V] [TRT] Tactic: 5 Time: 2.55829
[05/21/2022-02:57:24] [V] [TRT] Fastest Tactic: 1 Time: 0.291048
[05/21/2022-02:57:24] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:24] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:24] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:24] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:57:25] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:57:25] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:25] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:25] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(20736,324:2,18,1) ***************
[05/21/2022-02:57:25] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:25] [V] [TRT] Tactic: 589823 Time: 0.199134
[05/21/2022-02:57:25] [V] [TRT] Tactic: 655359 Time: 0.187526
[05/21/2022-02:57:25] [V] [TRT] Tactic: 786431 Time: 0.241094
[05/21/2022-02:57:25] [V] [TRT] Tactic: 851967 Time: 0.187298
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1179647 Time: 0.187656
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1310719 Time: 0.455228
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1376255 Time: 0.154544
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1441791 Time: 0.182454
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1507327 Time: 0.161901
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1638399 Time: 0.207077
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1835007 Time: 0.232266
[05/21/2022-02:57:25] [V] [TRT] Tactic: 1900543 Time: 0.161263
[05/21/2022-02:57:25] [V] [TRT] Tactic: 2097151 Time: 0.306471
[05/21/2022-02:57:25] [V] [TRT] Tactic: 2162687 Time: 0.162741
[05/21/2022-02:57:25] [V] [TRT] Tactic: 2293759 Time: 0.140078
[05/21/2022-02:57:25] [V] [TRT] Tactic: 2359295 Time: 0.147995
[05/21/2022-02:57:25] [V] [TRT] Tactic: 2686975 Time: 0.237552
[05/21/2022-02:57:25] [V] [TRT] Tactic: 3080191 Time: 0.170423
[05/21/2022-02:57:25] [V] [TRT] Tactic: 3342335 Time: 0.163027
[05/21/2022-02:57:25] [V] [TRT] Tactic: 3407871 Time: 0.134577
[05/21/2022-02:57:25] [V] [TRT] Tactic: 3538943 Time: 0.133164
[05/21/2022-02:57:25] [V] [TRT] Tactic: 3670015 Time: 0.160345
[05/21/2022-02:57:25] [V] [TRT] Tactic: 3932159 Time: 0.140605
[05/21/2022-02:57:25] [V] [TRT] Tactic: 3997695 Time: 0.252786
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4063231 Time: 0.18181
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4194303 Time: 0.234688
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4259839 Time: 0.306979
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4325375 Time: 0.184303
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4521983 Time: 0.179316
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4587519 Time: 0.193288
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4653055 Time: 0.162155
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4915199 Time: 0.237266
[05/21/2022-02:57:25] [V] [TRT] Tactic: 4980735 Time: 0.190801
[05/21/2022-02:57:25] [V] [TRT] Tactic: 5177343 Time: 0.180391
[05/21/2022-02:57:25] [V] [TRT] Tactic: 5242879 Time: 0.153815
[05/21/2022-02:57:25] [V] [TRT] Tactic: 5373951 Time: 0.203828
[05/21/2022-02:57:25] [V] [TRT] Tactic: 5439487 Time: 0.236139
[05/21/2022-02:57:25] [V] [TRT] Tactic: 5570559 Time: 0.191237
[05/21/2022-02:57:25] [V] [TRT] Tactic: 5636095 Time: 0.181446
[05/21/2022-02:57:26] [V] [TRT] Tactic: 5701631 Time: 0.163848
[05/21/2022-02:57:26] [V] [TRT] Tactic: 5767167 Time: 0.288053
[05/21/2022-02:57:26] [V] [TRT] Tactic: 5832703 Time: 0.169043
[05/21/2022-02:57:26] [V] [TRT] Tactic: 5898239 Time: 0.198828
[05/21/2022-02:57:26] [V] [TRT] Tactic: 6029311 Time: 0.166842
[05/21/2022-02:57:26] [V] [TRT] Tactic: 6225919 Time: 0.154635
[05/21/2022-02:57:26] [V] [TRT] Tactic: 6291455 Time: 0.189219
[05/21/2022-02:57:26] [V] [TRT] Tactic: 6422527 Time: 0.162623
[05/21/2022-02:57:26] [V] [TRT] Tactic: 6750207 Time: 0.220495
[05/21/2022-02:57:26] [V] [TRT] Tactic: 6815743 Time: 0.16584
[05/21/2022-02:57:26] [V] [TRT] Tactic: 6946815 Time: 0.252826
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7012351 Time: 0.306204
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7077887 Time: 0.170384
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7143423 Time: 0.317057
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7208959 Time: 0.167702
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7340031 Time: 0.202357
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7405567 Time: 0.177721
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7536639 Time: 0.199453
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7602175 Time: 0.238652
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7733247 Time: 0.184603
[05/21/2022-02:57:26] [V] [TRT] Tactic: 7798783 Time: 0.242083
[05/21/2022-02:57:26] [V] [TRT] Tactic: 8191999 Time: 0.306087
[05/21/2022-02:57:26] [V] [TRT] Tactic: 8257535 Time: 0.234675
[05/21/2022-02:57:26] [V] [TRT] Tactic: 8323071 Time: 0.215058
[05/21/2022-02:57:26] [V] [TRT] Tactic: 8650751 Time: 0.227904
[05/21/2022-02:57:26] [V] [TRT] Tactic: 8716287 Time: 0.168021
[05/21/2022-02:57:26] [V] [TRT] Tactic: 9109503 Time: 0.299108
[05/21/2022-02:57:26] [V] [TRT] Tactic: 9568255 Time: 0.237897
[05/21/2022-02:57:26] [V] [TRT] Tactic: 9895935 Time: 0.234616
[05/21/2022-02:57:26] [V] [TRT] Tactic: 10223615 Time: 0.236673
[05/21/2022-02:57:26] [V] [TRT] Tactic: 10354687 Time: 0.295286
[05/21/2022-02:57:26] [V] [TRT] Tactic: 10551295 Time: 0.189863
[05/21/2022-02:57:26] [V] [TRT] Tactic: 10747903 Time: 0.174603
[05/21/2022-02:57:26] [V] [TRT] Tactic: 10944511 Time: 0.1911
[05/21/2022-02:57:26] [V] [TRT] Fastest Tactic: 3538943 Time: 0.133164
[05/21/2022-02:57:26] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:26] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:57:27] [V] [TRT] Tactic: 3066127711859985668 Time: 0.0998047
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:27] [V] [TRT] Tactic: 3564772625446233998 Time: 0.112617
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:27] [V] [TRT] Tactic: 5319956359050645452 Time: 0.10209
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:27] [V] [TRT] Tactic: 7205456024582378848 Time: 0.0906899
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:57:27] [V] [TRT] Tactic: 8163473458334948789 Time: 0.0880401
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:27] [V] [TRT] Tactic: -4212163711445252890 Time: 0.0833072
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:27] [V] [TRT] Tactic: -3898373634979201110 Time: 0.0848959
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:27] [V] [TRT] Tactic: -2409163523992614473 Time: 0.0878908
[05/21/2022-02:57:27] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:57:27] [V] [TRT] Tactic: -1716393687483585322 Time: 0.081758
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.081758
[05/21/2022-02:57:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:57:27] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:27] [V] [TRT] *************** Autotuning format combination: Float(41472,324,18,1) -> Float(41472,324,18,1) ***************
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 0 Time: 0.0402474
[05/21/2022-02:57:27] [V] [TRT] Tactic: 1 Time: 0.0302476
[05/21/2022-02:57:27] [V] [TRT] Tactic: 2 Time: 0.0264193
[05/21/2022-02:57:27] [V] [TRT] Tactic: 3 Time: 0.027578
[05/21/2022-02:57:27] [V] [TRT] Tactic: 4 Time: 0.0218751
[05/21/2022-02:57:27] [V] [TRT] Tactic: 5 Time: 0.0215559
[05/21/2022-02:57:27] [V] [TRT] Tactic: 6 Time: 0.0271741
[05/21/2022-02:57:27] [V] [TRT] Tactic: 7 Time: 0.0225584
[05/21/2022-02:57:27] [V] [TRT] Tactic: 8 Time: 0.0204752
[05/21/2022-02:57:27] [V] [TRT] Tactic: 9 Time: 0.0209373
[05/21/2022-02:57:27] [V] [TRT] Tactic: 28 Time: 0.038789
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 8 Time: 0.0204752
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 128 Time: 0.0875587
[05/21/2022-02:57:27] [V] [TRT] Tactic: 256 Time: 0.0877474
[05/21/2022-02:57:27] [V] [TRT] Tactic: 512 Time: 0.0883075
[05/21/2022-02:57:27] [V] [TRT] Tactic: -32 Time: 0.108144
[05/21/2022-02:57:27] [V] [TRT] Tactic: -64 Time: 0.102383
[05/21/2022-02:57:27] [V] [TRT] Tactic: -128 Time: 0.0950911
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 128 Time: 0.0875587
[05/21/2022-02:57:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:57:27] [V] [TRT] *************** Autotuning format combination: Float(41472,1,2304,128) -> Float(41472,1,2304,128) ***************
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 0 Time: 0.0399281
[05/21/2022-02:57:27] [V] [TRT] Tactic: 1 Time: 0.0302343
[05/21/2022-02:57:27] [V] [TRT] Tactic: 2 Time: 0.0264191
[05/21/2022-02:57:27] [V] [TRT] Tactic: 3 Time: 0.0273439
[05/21/2022-02:57:27] [V] [TRT] Tactic: 4 Time: 0.0223309
[05/21/2022-02:57:27] [V] [TRT] Tactic: 5 Time: 0.0206446
[05/21/2022-02:57:27] [V] [TRT] Tactic: 6 Time: 0.0270181
[05/21/2022-02:57:27] [V] [TRT] Tactic: 7 Time: 0.0224154
[05/21/2022-02:57:27] [V] [TRT] Tactic: 8 Time: 0.0205142
[05/21/2022-02:57:27] [V] [TRT] Tactic: 9 Time: 0.0205079
[05/21/2022-02:57:27] [V] [TRT] Tactic: 28 Time: 0.0388931
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 9 Time: 0.0205079
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 128 Time: 0.0874545
[05/21/2022-02:57:27] [V] [TRT] Tactic: 256 Time: 0.0883137
[05/21/2022-02:57:27] [V] [TRT] Tactic: 512 Time: 0.0882815
[05/21/2022-02:57:27] [V] [TRT] Tactic: -32 Time: 0.107767
[05/21/2022-02:57:27] [V] [TRT] Tactic: -64 Time: 0.102428
[05/21/2022-02:57:27] [V] [TRT] Tactic: -128 Time: 0.0948372
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 128 Time: 0.0874545
[05/21/2022-02:57:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:27] [V] [TRT] *************** Autotuning format combination: Float(1296,324:32,18,1) -> Float(1296,324:32,18,1) ***************
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 24 Time: 0.02806
[05/21/2022-02:57:27] [V] [TRT] Tactic: 25 Time: 0.0258333
[05/21/2022-02:57:27] [V] [TRT] Tactic: 26 Time: 0.0273566
[05/21/2022-02:57:27] [V] [TRT] Tactic: 27 Time: 0.0270313
[05/21/2022-02:57:27] [V] [TRT] Tactic: 31 Time: 0.0279164
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 25 Time: 0.0258333
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 128 Time: 0.0874999
[05/21/2022-02:57:27] [V] [TRT] Tactic: 256 Time: 0.0873891
[05/21/2022-02:57:27] [V] [TRT] Tactic: 512 Time: 0.0882748
[05/21/2022-02:57:27] [V] [TRT] Tactic: -32 Time: 0.108171
[05/21/2022-02:57:27] [V] [TRT] Tactic: -64 Time: 0.102396
[05/21/2022-02:57:27] [V] [TRT] Tactic: -128 Time: 0.0952019
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 256 Time: 0.0873891
[05/21/2022-02:57:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:57:27] [V] [TRT] *************** Autotuning format combination: Half(41472,324,18,1) -> Half(41472,324,18,1) ***************
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 0 Time: 0.0386394
[05/21/2022-02:57:27] [V] [TRT] Tactic: 1 Time: 0.0280273
[05/21/2022-02:57:27] [V] [TRT] Tactic: 2 Time: 0.0264714
[05/21/2022-02:57:27] [V] [TRT] Tactic: 3 Time: 0.0197264
[05/21/2022-02:57:27] [V] [TRT] Tactic: 4 Time: 0.0192773
[05/21/2022-02:57:27] [V] [TRT] Tactic: 5 Time: 0.0194532
[05/21/2022-02:57:27] [V] [TRT] Tactic: 6 Time: 0.0171745
[05/21/2022-02:57:27] [V] [TRT] Tactic: 7 Time: 0.0148764
[05/21/2022-02:57:27] [V] [TRT] Tactic: 8 Time: 0.014883
[05/21/2022-02:57:27] [V] [TRT] Tactic: 9 Time: 0.0171029
[05/21/2022-02:57:27] [V] [TRT] Tactic: 28 Time: 0.0380531
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 7 Time: 0.0148764
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 128 Time: 0.0793165
[05/21/2022-02:57:27] [V] [TRT] Tactic: 256 Time: 0.0777019
[05/21/2022-02:57:27] [V] [TRT] Tactic: 512 Time: 0.0774609
[05/21/2022-02:57:27] [V] [TRT] Tactic: -32 Time: 0.100527
[05/21/2022-02:57:27] [V] [TRT] Tactic: -64 Time: 0.0893814
[05/21/2022-02:57:27] [V] [TRT] Tactic: -128 Time: 0.093711
[05/21/2022-02:57:27] [V] [TRT] Fastest Tactic: 512 Time: 0.0774609
[05/21/2022-02:57:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-02:57:27] [V] [TRT] *************** Autotuning format combination: Half(20736,324:2,18,1) -> Half(20736,324:2,18,1) ***************
[05/21/2022-02:57:27] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:27] [V] [TRT] Tactic: 0 Time: 0.0257424
[05/21/2022-02:57:27] [V] [TRT] Tactic: 1 Time: 0.0191991
[05/21/2022-02:57:27] [V] [TRT] Tactic: 2 Time: 0.019759
[05/21/2022-02:57:27] [V] [TRT] Tactic: 3 Time: 0.0150585
[05/21/2022-02:57:27] [V] [TRT] Tactic: 4 Time: 0.0156574
[05/21/2022-02:57:27] [V] [TRT] Tactic: 5 Time: 0.0196483
[05/21/2022-02:57:27] [V] [TRT] Tactic: 6 Time: 0.014974
[05/21/2022-02:57:27] [V] [TRT] Tactic: 7 Time: 0.0156185
[05/21/2022-02:57:27] [V] [TRT] Tactic: 8 Time: 0.0201629
[05/21/2022-02:57:27] [V] [TRT] Tactic: 9 Time: 0.0225976
[05/21/2022-02:57:27] [V] [TRT] Tactic: 10 Time: 0.0426238
[05/21/2022-02:57:27] [V] [TRT] Tactic: 11 Time: 0.0305275
[05/21/2022-02:57:27] [V] [TRT] Tactic: 12 Time: 0.028789
[05/21/2022-02:57:27] [V] [TRT] Tactic: 13 Time: 0.0218425
[05/21/2022-02:57:27] [V] [TRT] Tactic: 14 Time: 0.0195835
[05/21/2022-02:57:28] [V] [TRT] Tactic: 15 Time: 0.0216536
[05/21/2022-02:57:28] [V] [TRT] Tactic: 16 Time: 0.0176366
[05/21/2022-02:57:28] [V] [TRT] Tactic: 17 Time: 0.014987
[05/21/2022-02:57:28] [V] [TRT] Tactic: 18 Time: 0.0159118
[05/21/2022-02:57:28] [V] [TRT] Tactic: 19 Time: 0.0179751
[05/21/2022-02:57:28] [V] [TRT] Tactic: 28 Time: 0.0244921
[05/21/2022-02:57:28] [V] [TRT] Tactic: 29 Time: 0.0404751
[05/21/2022-02:57:28] [V] [TRT] Fastest Tactic: 6 Time: 0.014974
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:28] [V] [TRT] Tactic: 128 Time: 0.0791472
[05/21/2022-02:57:28] [V] [TRT] Tactic: 256 Time: 0.0778906
[05/21/2022-02:57:28] [V] [TRT] Tactic: 512 Time: 0.0772656
[05/21/2022-02:57:28] [V] [TRT] Tactic: -32 Time: 0.100834
[05/21/2022-02:57:28] [V] [TRT] Tactic: -64 Time: 0.0900324
[05/21/2022-02:57:28] [V] [TRT] Tactic: -128 Time: 0.0937239
[05/21/2022-02:57:28] [V] [TRT] Fastest Tactic: 512 Time: 0.0772656
[05/21/2022-02:57:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 6
[05/21/2022-02:57:28] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:28] [V] [TRT] *************** Autotuning format combination: Float(41472,324,18,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 129_upsample (Resize)
[05/21/2022-02:57:28] [V] [TRT] Tactic: 0 Time: 0.147799
[05/21/2022-02:57:28] [V] [TRT] Fastest Tactic: 0 Time: 0.147799
[05/21/2022-02:57:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-02:57:28] [V] [TRT] *************** Autotuning format combination: Half(41472,324,18,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 129_upsample (Resize)
[05/21/2022-02:57:28] [V] [TRT] Tactic: 0 Time: 0.153255
[05/21/2022-02:57:28] [V] [TRT] Fastest Tactic: 0 Time: 0.153255
[05/21/2022-02:57:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-02:57:28] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:28] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:28] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:57:28] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:28] [V] [TRT] Tactic: 0 Time: 1.0901
[05/21/2022-02:57:28] [V] [TRT] Tactic: 1 Time: 0.905632
[05/21/2022-02:57:28] [V] [TRT] Tactic: 2 Time: 1.05017
[05/21/2022-02:57:28] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1116078080, available: 536870912
[05/21/2022-02:57:28] [V] [TRT] Tactic: 5 Time: 4.61237
[05/21/2022-02:57:28] [V] [TRT] Fastest Tactic: 1 Time: 0.905632
[05/21/2022-02:57:28] [V] [TRT] Setting workspace to 1116078080enables more tactics for profiling
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:28] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:28] [V] [TRT] Tactic: 1062367460111450758 Time: 0.69694
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:57:28] [V] [TRT] Tactic: 1698681053543049347 Time: 0.658437
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:28] [V] [TRT] Tactic: 4501471010995462441 Time: 0.547083
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:28] [V] [TRT] Tactic: 5137655947464784826 Time: 0.539928
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:28] [V] [TRT] Tactic: 5288347012147084929 Time: 0.548529
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:57:28] [V] [TRT] Tactic: 5326823351883942011 Time: 0.533235
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:57:28] [V] [TRT] Tactic: 5500448035057547314 Time: 0.586771
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:28] [V] [TRT] Tactic: 6645123197870846056 Time: 0.546771
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:28] [V] [TRT] Tactic: 7144526460361122478 Time: 0.741933
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:28] [V] [TRT] Tactic: -8262349710178828730 Time: 0.556211
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:57:28] [V] [TRT] Tactic: -6576203419454146580 Time: 0.624596
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:28] [V] [TRT] Tactic: -4787320710726427159 Time: 0.777168
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:28] [V] [TRT] Tactic: -3456450830548107839 Time: 0.653255
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:28] [V] [TRT] Tactic: -1218658103698133241 Time: 0.607455
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:28] [V] [TRT] Tactic: -836875257600482091 Time: 0.598919
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:28] [V] [TRT] Tactic: -410470605513481746 Time: 0.539336
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:57:28] [V] [TRT] Tactic: -377491875521947884 Time: 0.537734
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:57:28] [V] [TRT] Tactic: -37215280111360163 Time: 0.525963
[05/21/2022-02:57:28] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.525963
[05/21/2022-02:57:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-02:57:28] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:28] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:28] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-02:57:28] [V] [TRT] Tactic: 3886731678879822788 Time: 0.563346
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-02:57:28] [V] [TRT] Tactic: 6629944304117643200 Time: 1.02346
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:57:28] [V] [TRT] Tactic: -9153228964338181824 Time: 1.03926
[05/21/2022-02:57:28] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:57:28] [V] [TRT] Tactic: -7394439838318485025 Time: 0.563014
[05/21/2022-02:57:28] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.563014
[05/21/2022-02:57:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:57:28] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:28] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:28] [V] [TRT] Tactic: 0 Time: 1.10454
[05/21/2022-02:57:28] [V] [TRT] Tactic: 1 Time: 0.950215
[05/21/2022-02:57:28] [V] [TRT] Tactic: 2 Time: 0.986946
[05/21/2022-02:57:28] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1116078080, available: 536870912
[05/21/2022-02:57:29] [V] [TRT] Tactic: 5 Time: 4.49074
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: 1 Time: 0.950215
[05/21/2022-02:57:29] [V] [TRT] Setting workspace to 1116078080enables more tactics for profiling
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:29] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:57:29] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:29] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:29] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:29] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:29] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-02:57:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:57:29] [V] [TRT] Tactic: 3066127711859985668 Time: 0.340899
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:29] [V] [TRT] Tactic: 3564772625446233998 Time: 0.371751
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:29] [V] [TRT] Tactic: 5319956359050645452 Time: 0.358548
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:29] [V] [TRT] Tactic: 7205456024582378848 Time: 0.291348
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:57:29] [V] [TRT] Tactic: 8163473458334948789 Time: 0.279596
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:29] [V] [TRT] Tactic: -4212163711445252890 Time: 0.275951
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:29] [V] [TRT] Tactic: -3898373634979201110 Time: 0.283796
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:29] [V] [TRT] Tactic: -2409163523992614473 Time: 0.28235
[05/21/2022-02:57:29] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:57:29] [V] [TRT] Tactic: -1716393687483585322 Time: 0.275495
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.275495
[05/21/2022-02:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:57:29] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:29] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 0 Time: 0.196393
[05/21/2022-02:57:29] [V] [TRT] Tactic: 1 Time: 0.129531
[05/21/2022-02:57:29] [V] [TRT] Tactic: 2 Time: 0.120768
[05/21/2022-02:57:29] [V] [TRT] Tactic: 3 Time: 0.0963737
[05/21/2022-02:57:29] [V] [TRT] Tactic: 4 Time: 0.0828777
[05/21/2022-02:57:29] [V] [TRT] Tactic: 5 Time: 0.0781642
[05/21/2022-02:57:29] [V] [TRT] Tactic: 6 Time: 0.0915168
[05/21/2022-02:57:29] [V] [TRT] Tactic: 7 Time: 0.075319
[05/21/2022-02:57:29] [V] [TRT] Tactic: 8 Time: 0.0719664
[05/21/2022-02:57:29] [V] [TRT] Tactic: 9 Time: 0.0707747
[05/21/2022-02:57:29] [V] [TRT] Tactic: 28 Time: 0.192148
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: 9 Time: 0.0707747
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 128 Time: 0.414609
[05/21/2022-02:57:29] [V] [TRT] Tactic: 256 Time: 0.415808
[05/21/2022-02:57:29] [V] [TRT] Tactic: 512 Time: 0.417415
[05/21/2022-02:57:29] [V] [TRT] Tactic: -32 Time: 0.376588
[05/21/2022-02:57:29] [V] [TRT] Tactic: -64 Time: 0.353893
[05/21/2022-02:57:29] [V] [TRT] Tactic: -128 Time: 0.358646
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: -64 Time: 0.353893
[05/21/2022-02:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:29] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 0 Time: 0.195872
[05/21/2022-02:57:29] [V] [TRT] Tactic: 1 Time: 0.129955
[05/21/2022-02:57:29] [V] [TRT] Tactic: 2 Time: 0.12069
[05/21/2022-02:57:29] [V] [TRT] Tactic: 3 Time: 0.0993034
[05/21/2022-02:57:29] [V] [TRT] Tactic: 4 Time: 0.083776
[05/21/2022-02:57:29] [V] [TRT] Tactic: 5 Time: 0.0779883
[05/21/2022-02:57:29] [V] [TRT] Tactic: 6 Time: 0.117396
[05/21/2022-02:57:29] [V] [TRT] Tactic: 7 Time: 0.102962
[05/21/2022-02:57:29] [V] [TRT] Tactic: 8 Time: 0.0987106
[05/21/2022-02:57:29] [V] [TRT] Tactic: 9 Time: 0.0922264
[05/21/2022-02:57:29] [V] [TRT] Tactic: 28 Time: 0.191419
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: 5 Time: 0.0779883
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 128 Time: 0.414349
[05/21/2022-02:57:29] [V] [TRT] Tactic: 256 Time: 0.415124
[05/21/2022-02:57:29] [V] [TRT] Tactic: 512 Time: 0.416934
[05/21/2022-02:57:29] [V] [TRT] Tactic: -32 Time: 0.377363
[05/21/2022-02:57:29] [V] [TRT] Tactic: -64 Time: 0.409349
[05/21/2022-02:57:29] [V] [TRT] Tactic: -128 Time: 0.484095
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: -32 Time: 0.377363
[05/21/2022-02:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:57:29] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 24 Time: 0.0875975
[05/21/2022-02:57:29] [V] [TRT] Tactic: 25 Time: 0.0869401
[05/21/2022-02:57:29] [V] [TRT] Tactic: 26 Time: 0.0878256
[05/21/2022-02:57:29] [V] [TRT] Tactic: 27 Time: 0.0883268
[05/21/2022-02:57:29] [V] [TRT] Tactic: 31 Time: 0.0877734
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: 25 Time: 0.0869401
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 128 Time: 0.414193
[05/21/2022-02:57:29] [V] [TRT] Tactic: 256 Time: 0.415299
[05/21/2022-02:57:29] [V] [TRT] Tactic: 512 Time: 0.417546
[05/21/2022-02:57:29] [V] [TRT] Tactic: -32 Time: 0.376074
[05/21/2022-02:57:29] [V] [TRT] Tactic: -64 Time: 0.353646
[05/21/2022-02:57:29] [V] [TRT] Tactic: -128 Time: 0.358093
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: -64 Time: 0.353646
[05/21/2022-02:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:57:29] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 0 Time: 0.197233
[05/21/2022-02:57:29] [V] [TRT] Tactic: 1 Time: 0.133164
[05/21/2022-02:57:29] [V] [TRT] Tactic: 2 Time: 0.125183
[05/21/2022-02:57:29] [V] [TRT] Tactic: 3 Time: 0.091426
[05/21/2022-02:57:29] [V] [TRT] Tactic: 4 Time: 0.0838347
[05/21/2022-02:57:29] [V] [TRT] Tactic: 5 Time: 0.0809114
[05/21/2022-02:57:29] [V] [TRT] Tactic: 6 Time: 0.0809961
[05/21/2022-02:57:29] [V] [TRT] Tactic: 7 Time: 0.0616081
[05/21/2022-02:57:29] [V] [TRT] Tactic: 8 Time: 0.0613218
[05/21/2022-02:57:29] [V] [TRT] Tactic: 9 Time: 0.0624805
[05/21/2022-02:57:29] [V] [TRT] Tactic: 28 Time: 0.194512
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: 8 Time: 0.0613218
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 128 Time: 0.329538
[05/21/2022-02:57:29] [V] [TRT] Tactic: 256 Time: 0.326914
[05/21/2022-02:57:29] [V] [TRT] Tactic: 512 Time: 0.31166
[05/21/2022-02:57:29] [V] [TRT] Tactic: -32 Time: 0.362546
[05/21/2022-02:57:29] [V] [TRT] Tactic: -64 Time: 0.333692
[05/21/2022-02:57:29] [V] [TRT] Tactic: -128 Time: 0.340944
[05/21/2022-02:57:29] [V] [TRT] Fastest Tactic: 512 Time: 0.31166
[05/21/2022-02:57:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:57:29] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:29] [V] [TRT] Tactic: 0 Time: 0.116843
[05/21/2022-02:57:30] [V] [TRT] Tactic: 1 Time: 0.0840688
[05/21/2022-02:57:30] [V] [TRT] Tactic: 2 Time: 0.0868428
[05/21/2022-02:57:30] [V] [TRT] Tactic: 3 Time: 0.0721351
[05/21/2022-02:57:30] [V] [TRT] Tactic: 4 Time: 0.0748111
[05/21/2022-02:57:30] [V] [TRT] Tactic: 5 Time: 0.0840693
[05/21/2022-02:57:30] [V] [TRT] Tactic: 6 Time: 0.0712173
[05/21/2022-02:57:30] [V] [TRT] Tactic: 7 Time: 0.0725328
[05/21/2022-02:57:30] [V] [TRT] Tactic: 8 Time: 0.0799999
[05/21/2022-02:57:30] [V] [TRT] Tactic: 9 Time: 0.0832619
[05/21/2022-02:57:30] [V] [TRT] Tactic: 10 Time: 0.207552
[05/21/2022-02:57:30] [V] [TRT] Tactic: 11 Time: 0.14084
[05/21/2022-02:57:30] [V] [TRT] Tactic: 12 Time: 0.132988
[05/21/2022-02:57:30] [V] [TRT] Tactic: 13 Time: 0.0948697
[05/21/2022-02:57:30] [V] [TRT] Tactic: 14 Time: 0.0855405
[05/21/2022-02:57:30] [V] [TRT] Tactic: 15 Time: 0.0885939
[05/21/2022-02:57:30] [V] [TRT] Tactic: 16 Time: 0.0820575
[05/21/2022-02:57:30] [V] [TRT] Tactic: 17 Time: 0.0613086
[05/21/2022-02:57:30] [V] [TRT] Tactic: 18 Time: 0.06528
[05/21/2022-02:57:30] [V] [TRT] Tactic: 19 Time: 0.0691601
[05/21/2022-02:57:30] [V] [TRT] Tactic: 28 Time: 0.115326
[05/21/2022-02:57:30] [V] [TRT] Tactic: 29 Time: 0.204883
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 17 Time: 0.0613086
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 128 Time: 0.329102
[05/21/2022-02:57:30] [V] [TRT] Tactic: 256 Time: 0.326732
[05/21/2022-02:57:30] [V] [TRT] Tactic: 512 Time: 0.311569
[05/21/2022-02:57:30] [V] [TRT] Tactic: -32 Time: 0.362617
[05/21/2022-02:57:30] [V] [TRT] Tactic: -64 Time: 0.33347
[05/21/2022-02:57:30] [V] [TRT] Tactic: -128 Time: 0.341634
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 512 Time: 0.311569
[05/21/2022-02:57:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-02:57:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:57:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 0 Time: 0.1464
[05/21/2022-02:57:30] [V] [TRT] Tactic: 1 Time: 0.106159
[05/21/2022-02:57:30] [V] [TRT] Tactic: 2 Time: 0.0944271
[05/21/2022-02:57:30] [V] [TRT] Tactic: 3 Time: 0.091139
[05/21/2022-02:57:30] [V] [TRT] Tactic: 4 Time: 0.0746289
[05/21/2022-02:57:30] [V] [TRT] Tactic: 5 Time: 0.0704556
[05/21/2022-02:57:30] [V] [TRT] Tactic: 6 Time: 0.0899805
[05/21/2022-02:57:30] [V] [TRT] Tactic: 7 Time: 0.0721876
[05/21/2022-02:57:30] [V] [TRT] Tactic: 8 Time: 0.0711068
[05/21/2022-02:57:30] [V] [TRT] Tactic: 9 Time: 0.070117
[05/21/2022-02:57:30] [V] [TRT] Tactic: 28 Time: 0.143633
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 9 Time: 0.070117
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 128 Time: 0.331816
[05/21/2022-02:57:30] [V] [TRT] Tactic: 256 Time: 0.33265
[05/21/2022-02:57:30] [V] [TRT] Tactic: 512 Time: 0.335644
[05/21/2022-02:57:30] [V] [TRT] Tactic: -32 Time: 0.373815
[05/21/2022-02:57:30] [V] [TRT] Tactic: -64 Time: 0.348529
[05/21/2022-02:57:30] [V] [TRT] Tactic: -128 Time: 0.348757
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 128 Time: 0.331816
[05/21/2022-02:57:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 0 Time: 0.147025
[05/21/2022-02:57:30] [V] [TRT] Tactic: 1 Time: 0.10612
[05/21/2022-02:57:30] [V] [TRT] Tactic: 2 Time: 0.0934569
[05/21/2022-02:57:30] [V] [TRT] Tactic: 3 Time: 0.0908657
[05/21/2022-02:57:30] [V] [TRT] Tactic: 4 Time: 0.0741472
[05/21/2022-02:57:30] [V] [TRT] Tactic: 5 Time: 0.0697199
[05/21/2022-02:57:30] [V] [TRT] Tactic: 6 Time: 0.0893946
[05/21/2022-02:57:30] [V] [TRT] Tactic: 7 Time: 0.0720704
[05/21/2022-02:57:30] [V] [TRT] Tactic: 8 Time: 0.0705271
[05/21/2022-02:57:30] [V] [TRT] Tactic: 9 Time: 0.070892
[05/21/2022-02:57:30] [V] [TRT] Tactic: 28 Time: 0.143633
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 5 Time: 0.0697199
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 128 Time: 0.332148
[05/21/2022-02:57:30] [V] [TRT] Tactic: 256 Time: 0.332513
[05/21/2022-02:57:30] [V] [TRT] Tactic: 512 Time: 0.335091
[05/21/2022-02:57:30] [V] [TRT] Tactic: -32 Time: 0.373874
[05/21/2022-02:57:30] [V] [TRT] Tactic: -64 Time: 0.348503
[05/21/2022-02:57:30] [V] [TRT] Tactic: -128 Time: 0.348783
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 128 Time: 0.332148
[05/21/2022-02:57:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 24 Time: 0.0908266
[05/21/2022-02:57:30] [V] [TRT] Tactic: 25 Time: 0.0867318
[05/21/2022-02:57:30] [V] [TRT] Tactic: 26 Time: 0.0913674
[05/21/2022-02:57:30] [V] [TRT] Tactic: 27 Time: 0.0892055
[05/21/2022-02:57:30] [V] [TRT] Tactic: 31 Time: 0.0920963
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 25 Time: 0.0867318
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 128 Time: 0.331654
[05/21/2022-02:57:30] [V] [TRT] Tactic: 256 Time: 0.33261
[05/21/2022-02:57:30] [V] [TRT] Tactic: 512 Time: 0.335397
[05/21/2022-02:57:30] [V] [TRT] Tactic: -32 Time: 0.373659
[05/21/2022-02:57:30] [V] [TRT] Tactic: -64 Time: 0.348529
[05/21/2022-02:57:30] [V] [TRT] Tactic: -128 Time: 0.348665
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 128 Time: 0.331654
[05/21/2022-02:57:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:57:30] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:30] [V] [TRT] Tactic: 0 Time: 0.145859
[05/21/2022-02:57:30] [V] [TRT] Tactic: 1 Time: 0.10459
[05/21/2022-02:57:30] [V] [TRT] Tactic: 2 Time: 0.0997461
[05/21/2022-02:57:30] [V] [TRT] Tactic: 3 Time: 0.0827406
[05/21/2022-02:57:30] [V] [TRT] Tactic: 4 Time: 0.0668487
[05/21/2022-02:57:30] [V] [TRT] Tactic: 5 Time: 0.0692641
[05/21/2022-02:57:30] [V] [TRT] Tactic: 6 Time: 0.0763932
[05/21/2022-02:57:30] [V] [TRT] Tactic: 7 Time: 0.056328
[05/21/2022-02:57:30] [V] [TRT] Tactic: 8 Time: 0.0508984
[05/21/2022-02:57:30] [V] [TRT] Tactic: 9 Time: 0.0559116
[05/21/2022-02:57:30] [V] [TRT] Tactic: 28 Time: 0.14222
[05/21/2022-02:57:30] [V] [TRT] Fastest Tactic: 8 Time: 0.0508984
[05/21/2022-02:57:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:31] [V] [TRT] Tactic: 128 Time: 0.300326
[05/21/2022-02:57:31] [V] [TRT] Tactic: 256 Time: 0.298509
[05/21/2022-02:57:31] [V] [TRT] Tactic: 512 Time: 0.29041
[05/21/2022-02:57:31] [V] [TRT] Tactic: -32 Time: 0.360553
[05/21/2022-02:57:31] [V] [TRT] Tactic: -64 Time: 0.328301
[05/21/2022-02:57:31] [V] [TRT] Tactic: -128 Time: 0.329935
[05/21/2022-02:57:31] [V] [TRT] Fastest Tactic: 512 Time: 0.29041
[05/21/2022-02:57:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:57:31] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:57:31] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:31] [V] [TRT] Tactic: 0 Time: 0.0960939
[05/21/2022-02:57:31] [V] [TRT] Tactic: 1 Time: 0.0782815
[05/21/2022-02:57:31] [V] [TRT] Tactic: 2 Time: 0.0826626
[05/21/2022-02:57:31] [V] [TRT] Tactic: 3 Time: 0.0705076
[05/21/2022-02:57:31] [V] [TRT] Tactic: 4 Time: 0.0722136
[05/21/2022-02:57:31] [V] [TRT] Tactic: 5 Time: 0.0783136
[05/21/2022-02:57:31] [V] [TRT] Tactic: 6 Time: 0.070586
[05/21/2022-02:57:31] [V] [TRT] Tactic: 7 Time: 0.0717252
[05/21/2022-02:57:31] [V] [TRT] Tactic: 8 Time: 0.0764516
[05/21/2022-02:57:31] [V] [TRT] Tactic: 9 Time: 0.081341
[05/21/2022-02:57:31] [V] [TRT] Tactic: 10 Time: 0.158568
[05/21/2022-02:57:31] [V] [TRT] Tactic: 11 Time: 0.111524
[05/21/2022-02:57:31] [V] [TRT] Tactic: 12 Time: 0.107194
[05/21/2022-02:57:31] [V] [TRT] Tactic: 13 Time: 0.0845962
[05/21/2022-02:57:31] [V] [TRT] Tactic: 14 Time: 0.0713995
[05/21/2022-02:57:31] [V] [TRT] Tactic: 15 Time: 0.0746616
[05/21/2022-02:57:31] [V] [TRT] Tactic: 16 Time: 0.0777863
[05/21/2022-02:57:31] [V] [TRT] Tactic: 17 Time: 0.0573375
[05/21/2022-02:57:31] [V] [TRT] Tactic: 18 Time: 0.053776
[05/21/2022-02:57:31] [V] [TRT] Tactic: 19 Time: 0.0624542
[05/21/2022-02:57:31] [V] [TRT] Tactic: 28 Time: 0.0937369
[05/21/2022-02:57:31] [V] [TRT] Tactic: 29 Time: 0.154173
[05/21/2022-02:57:31] [V] [TRT] Fastest Tactic: 18 Time: 0.053776
[05/21/2022-02:57:31] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:31] [V] [TRT] Tactic: 128 Time: 0.300684
[05/21/2022-02:57:31] [V] [TRT] Tactic: 256 Time: 0.298984
[05/21/2022-02:57:31] [V] [TRT] Tactic: 512 Time: 0.290977
[05/21/2022-02:57:31] [V] [TRT] Tactic: -32 Time: 0.360436
[05/21/2022-02:57:31] [V] [TRT] Tactic: -64 Time: 0.328014
[05/21/2022-02:57:31] [V] [TRT] Tactic: -128 Time: 0.329219
[05/21/2022-02:57:31] [V] [TRT] Fastest Tactic: 512 Time: 0.290977
[05/21/2022-02:57:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:57:31] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:31] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:57:31] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:31] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:31] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:57:31] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:31] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:31] [V] [TRT] Tactic: 0 Time: 7.32307
[05/21/2022-02:57:31] [V] [TRT] Tactic: 1 Time: 5.33477
[05/21/2022-02:57:31] [V] [TRT] Tactic: 2 Time: 6.60107
[05/21/2022-02:57:31] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1112801280, available: 536870912
[05/21/2022-02:57:33] [V] [TRT] Tactic: 5 Time: 84.6313
[05/21/2022-02:57:33] [V] [TRT] Tactic: 6 Time: 4.08089
[05/21/2022-02:57:33] [V] [TRT] Fastest Tactic: 6 Time: 4.08089
[05/21/2022-02:57:33] [V] [TRT] Setting workspace to 1112801280enables more tactics for profiling
[05/21/2022-02:57:33] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:33] [V] [TRT] Tactic: 1062367460111450758 Time: 5.36831
[05/21/2022-02:57:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:57:33] [V] [TRT] Tactic: 1754984623894446479 Time: 6.21867
[05/21/2022-02:57:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:57:33] [V] [TRT] Tactic: 3611739942397549984 Time: 4.35122
[05/21/2022-02:57:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-02:57:33] [V] [TRT] Tactic: 3827454225649558724 Time: 5.20808
[05/21/2022-02:57:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:57:33] [V] [TRT] Tactic: 4337000649858996379 Time: 4.40408
[05/21/2022-02:57:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:34] [V] [TRT] Tactic: 4501471010995462441 Time: 4.36233
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:34] [V] [TRT] Tactic: 5137655947464784826 Time: 4.22587
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:34] [V] [TRT] Tactic: 5288347012147084929 Time: 4.28464
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-02:57:34] [V] [TRT] Tactic: 5921334924264294896 Time: 3.60238
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:34] [V] [TRT] Tactic: 6645123197870846056 Time: 4.43365
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:34] [V] [TRT] Tactic: 7144526460361122478 Time: 5.6319
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-02:57:34] [V] [TRT] Tactic: 7852627285308570038 Time: 5.44912
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:57:34] [V] [TRT] Tactic: -9137461792520977713 Time: 4.3704
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-02:57:34] [V] [TRT] Tactic: -8776506421218919509 Time: 5.19635
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:34] [V] [TRT] Tactic: -8262349710178828730 Time: 4.33222
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:57:34] [V] [TRT] Tactic: -8133971918129952780 Time: 4.92928
[05/21/2022-02:57:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:57:35] [V] [TRT] Tactic: -6092040395344634144 Time: 5.68813
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:35] [V] [TRT] Tactic: -4787320710726427159 Time: 6.2011
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:35] [V] [TRT] Tactic: -3456450830548107839 Time: 4.97174
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-02:57:35] [V] [TRT] Tactic: -2318106587342035239 Time: 5.33569
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-02:57:35] [V] [TRT] Tactic: -1343271414618805657 Time: 3.48924
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:35] [V] [TRT] Tactic: -1218658103698133241 Time: 4.91505
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:35] [V] [TRT] Tactic: -836875257600482091 Time: 4.72751
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:35] [V] [TRT] Tactic: -410470605513481746 Time: 4.18569
[05/21/2022-02:57:35] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 3.48924
[05/21/2022-02:57:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-02:57:35] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:57:35] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:35] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:57:35] [V] [TRT] Tactic: -9153228964338181824 Time: 5.38212
[05/21/2022-02:57:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:57:36] [V] [TRT] Tactic: -7394439838318485025 Time: 4.22059
[05/21/2022-02:57:36] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.22059
[05/21/2022-02:57:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:57:36] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:57:36] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:36] [V] [TRT] Tactic: 0 Time: 7.51614
[05/21/2022-02:57:36] [V] [TRT] Tactic: 1 Time: 8.4315
[05/21/2022-02:57:36] [V] [TRT] Tactic: 2 Time: 6.33689
[05/21/2022-02:57:36] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1112801280, available: 536870912
[05/21/2022-02:57:37] [V] [TRT] Tactic: 5 Time: 83.6537
[05/21/2022-02:57:38] [V] [TRT] Tactic: 6 Time: 5.28363
[05/21/2022-02:57:38] [V] [TRT] Fastest Tactic: 6 Time: 5.28363
[05/21/2022-02:57:38] [V] [TRT] Setting workspace to 1112801280enables more tactics for profiling
[05/21/2022-02:57:38] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:38] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-02:57:38] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:38] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:38] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:38] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:38] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:38] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:38] [V] [TRT] Tactic: 3564772625446233998 Time: 2.74448
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:57:38] [V] [TRT] Tactic: 3650389455493082349 Time: 2.85594
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:57:38] [V] [TRT] Tactic: 4772821744921268633 Time: 2.08079
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:38] [V] [TRT] Tactic: 5319956359050645452 Time: 2.48463
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:38] [V] [TRT] Tactic: 7205456024582378848 Time: 2.19073
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:57:38] [V] [TRT] Tactic: -6490690591794140522 Time: 2.25072
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:57:38] [V] [TRT] Tactic: -4686027666808657977 Time: 2.22334
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:38] [V] [TRT] Tactic: -4212163711445252890 Time: 2.11934
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:38] [V] [TRT] Tactic: -3898373634979201110 Time: 2.14625
[05/21/2022-02:57:38] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:38] [V] [TRT] Tactic: -2409163523992614473 Time: 2.1407
[05/21/2022-02:57:38] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 2.08079
[05/21/2022-02:57:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-02:57:38] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:38] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:57:38] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:38] [V] [TRT] Tactic: 0 Time: 0.289394
[05/21/2022-02:57:38] [V] [TRT] Tactic: 1 Time: 0.210612
[05/21/2022-02:57:38] [V] [TRT] Tactic: 2 Time: 0.182467
[05/21/2022-02:57:38] [V] [TRT] Tactic: 3 Time: 0.179915
[05/21/2022-02:57:38] [V] [TRT] Tactic: 4 Time: 0.152246
[05/21/2022-02:57:38] [V] [TRT] Tactic: 5 Time: 0.154212
[05/21/2022-02:57:38] [V] [TRT] Tactic: 6 Time: 0.177122
[05/21/2022-02:57:38] [V] [TRT] Tactic: 7 Time: 0.148926
[05/21/2022-02:57:38] [V] [TRT] Tactic: 8 Time: 0.139805
[05/21/2022-02:57:39] [V] [TRT] Tactic: 9 Time: 0.141341
[05/21/2022-02:57:39] [V] [TRT] Tactic: 28 Time: 0.281549
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 8 Time: 0.139805
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 128 Time: 0.656224
[05/21/2022-02:57:39] [V] [TRT] Tactic: 256 Time: 0.658366
[05/21/2022-02:57:39] [V] [TRT] Tactic: 512 Time: 0.662136
[05/21/2022-02:57:39] [V] [TRT] Tactic: -32 Time: 0.697461
[05/21/2022-02:57:39] [V] [TRT] Tactic: -64 Time: 0.681015
[05/21/2022-02:57:39] [V] [TRT] Tactic: -128 Time: 0.685638
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 128 Time: 0.656224
[05/21/2022-02:57:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:57:39] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 0 Time: 0.285534
[05/21/2022-02:57:39] [V] [TRT] Tactic: 1 Time: 0.206634
[05/21/2022-02:57:39] [V] [TRT] Tactic: 2 Time: 0.181204
[05/21/2022-02:57:39] [V] [TRT] Tactic: 3 Time: 0.176816
[05/21/2022-02:57:39] [V] [TRT] Tactic: 4 Time: 0.147754
[05/21/2022-02:57:39] [V] [TRT] Tactic: 5 Time: 0.140716
[05/21/2022-02:57:39] [V] [TRT] Tactic: 6 Time: 0.175534
[05/21/2022-02:57:39] [V] [TRT] Tactic: 7 Time: 0.138958
[05/21/2022-02:57:39] [V] [TRT] Tactic: 8 Time: 0.142585
[05/21/2022-02:57:39] [V] [TRT] Tactic: 9 Time: 0.135221
[05/21/2022-02:57:39] [V] [TRT] Tactic: 28 Time: 0.279779
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 9 Time: 0.135221
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 128 Time: 0.656204
[05/21/2022-02:57:39] [V] [TRT] Tactic: 256 Time: 0.65864
[05/21/2022-02:57:39] [V] [TRT] Tactic: 512 Time: 0.66319
[05/21/2022-02:57:39] [V] [TRT] Tactic: -32 Time: 0.698106
[05/21/2022-02:57:39] [V] [TRT] Tactic: -64 Time: 0.680384
[05/21/2022-02:57:39] [V] [TRT] Tactic: -128 Time: 0.685879
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 128 Time: 0.656204
[05/21/2022-02:57:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-02:57:39] [V] [TRT] *************** Autotuning format combination: Float(10368,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 24 Time: 0.176829
[05/21/2022-02:57:39] [V] [TRT] Tactic: 25 Time: 0.16793
[05/21/2022-02:57:39] [V] [TRT] Tactic: 26 Time: 0.169655
[05/21/2022-02:57:39] [V] [TRT] Tactic: 27 Time: 0.170963
[05/21/2022-02:57:39] [V] [TRT] Tactic: 31 Time: 0.179225
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 25 Time: 0.16793
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 128 Time: 0.655814
[05/21/2022-02:57:39] [V] [TRT] Tactic: 256 Time: 0.657904
[05/21/2022-02:57:39] [V] [TRT] Tactic: 512 Time: 0.662597
[05/21/2022-02:57:39] [V] [TRT] Tactic: -32 Time: 0.697734
[05/21/2022-02:57:39] [V] [TRT] Tactic: -64 Time: 0.681009
[05/21/2022-02:57:39] [V] [TRT] Tactic: -128 Time: 0.686276
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 128 Time: 0.655814
[05/21/2022-02:57:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-02:57:39] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 0 Time: 0.284811
[05/21/2022-02:57:39] [V] [TRT] Tactic: 1 Time: 0.202728
[05/21/2022-02:57:39] [V] [TRT] Tactic: 2 Time: 0.194577
[05/21/2022-02:57:39] [V] [TRT] Tactic: 3 Time: 0.158463
[05/21/2022-02:57:39] [V] [TRT] Tactic: 4 Time: 0.126986
[05/21/2022-02:57:39] [V] [TRT] Tactic: 5 Time: 0.132845
[05/21/2022-02:57:39] [V] [TRT] Tactic: 6 Time: 0.146185
[05/21/2022-02:57:39] [V] [TRT] Tactic: 7 Time: 0.106146
[05/21/2022-02:57:39] [V] [TRT] Tactic: 8 Time: 0.0957225
[05/21/2022-02:57:39] [V] [TRT] Tactic: 9 Time: 0.106719
[05/21/2022-02:57:39] [V] [TRT] Tactic: 28 Time: 0.277057
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 8 Time: 0.0957225
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 128 Time: 0.592454
[05/21/2022-02:57:39] [V] [TRT] Tactic: 256 Time: 0.588978
[05/21/2022-02:57:39] [V] [TRT] Tactic: 512 Time: 0.572643
[05/21/2022-02:57:39] [V] [TRT] Tactic: -32 Time: 0.671406
[05/21/2022-02:57:39] [V] [TRT] Tactic: -64 Time: 0.640983
[05/21/2022-02:57:39] [V] [TRT] Tactic: -128 Time: 0.648079
[05/21/2022-02:57:39] [V] [TRT] Fastest Tactic: 512 Time: 0.572643
[05/21/2022-02:57:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-02:57:39] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:39] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-02:57:39] [V] [TRT] Tactic: 0 Time: 0.184753
[05/21/2022-02:57:39] [V] [TRT] Tactic: 1 Time: 0.149323
[05/21/2022-02:57:39] [V] [TRT] Tactic: 2 Time: 0.160222
[05/21/2022-02:57:39] [V] [TRT] Tactic: 3 Time: 0.132943
[05/21/2022-02:57:39] [V] [TRT] Tactic: 4 Time: 0.137877
[05/21/2022-02:57:39] [V] [TRT] Tactic: 5 Time: 0.14739
[05/21/2022-02:57:39] [V] [TRT] Tactic: 6 Time: 0.130547
[05/21/2022-02:57:40] [V] [TRT] Tactic: 7 Time: 0.135332
[05/21/2022-02:57:40] [V] [TRT] Tactic: 8 Time: 0.142096
[05/21/2022-02:57:40] [V] [TRT] Tactic: 9 Time: 0.153848
[05/21/2022-02:57:40] [V] [TRT] Tactic: 10 Time: 0.309824
[05/21/2022-02:57:40] [V] [TRT] Tactic: 11 Time: 0.215631
[05/21/2022-02:57:40] [V] [TRT] Tactic: 12 Time: 0.207962
[05/21/2022-02:57:40] [V] [TRT] Tactic: 13 Time: 0.16108
[05/21/2022-02:57:40] [V] [TRT] Tactic: 14 Time: 0.135391
[05/21/2022-02:57:40] [V] [TRT] Tactic: 15 Time: 0.143691
[05/21/2022-02:57:40] [V] [TRT] Tactic: 16 Time: 0.14679
[05/21/2022-02:57:40] [V] [TRT] Tactic: 17 Time: 0.107012
[05/21/2022-02:57:40] [V] [TRT] Tactic: 18 Time: 0.101393
[05/21/2022-02:57:40] [V] [TRT] Tactic: 19 Time: 0.118958
[05/21/2022-02:57:40] [V] [TRT] Tactic: 28 Time: 0.180788
[05/21/2022-02:57:40] [V] [TRT] Tactic: 29 Time: 0.300143
[05/21/2022-02:57:40] [V] [TRT] Fastest Tactic: 18 Time: 0.101393
[05/21/2022-02:57:40] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-02:57:40] [V] [TRT] Tactic: 128 Time: 0.592239
[05/21/2022-02:57:40] [V] [TRT] Tactic: 256 Time: 0.58944
[05/21/2022-02:57:40] [V] [TRT] Tactic: 512 Time: 0.573047
[05/21/2022-02:57:40] [V] [TRT] Tactic: -32 Time: 0.670977
[05/21/2022-02:57:40] [V] [TRT] Tactic: -64 Time: 0.640566
[05/21/2022-02:57:40] [V] [TRT] Tactic: -128 Time: 0.647611
[05/21/2022-02:57:40] [V] [TRT] Fastest Tactic: 512 Time: 0.573047
[05/21/2022-02:57:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(10368,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(165888,1,4608,128) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(5184,1296:32,36,1) -> Float(5184,1296:32,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(165888,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(82944,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(331776,1,9216,256) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(10368,1296:32,36,1) -> Float(10368,1296:32,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(331776,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:40] [V] [TRT] *************** Autotuning format combination: Float(331776,1296,36,1) -> Float(330480,1296,36,1) ***************
[05/21/2022-02:57:40] [V] [TRT] --------------- Timing Runner: 139_convolutional (FusedConvActConvolution)
[05/21/2022-02:57:40] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:40] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudaDepthwiseConvolution)
[05/21/2022-02:57:40] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:40] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-02:57:40] [V] [TRT] Tactic: 0 Time: 2.14218
[05/21/2022-02:57:40] [V] [TRT] Tactic: 1 Time: 1.49208
[05/21/2022-02:57:40] [V] [TRT] Tactic: 2 Time: 1.78085
[05/21/2022-02:57:40] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2214853632, available: 536870912
[05/21/2022-02:57:40] [V] [TRT] Tactic: 5 Time: 8.38121
[05/21/2022-02:57:40] [V] [TRT] Fastest Tactic: 1 Time: 1.49208
[05/21/2022-02:57:40] [V] [TRT] Setting workspace to 2214853632enables more tactics for profiling
[05/21/2022-02:57:40] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-02:57:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:40] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:40] [V] [TRT] Tactic: 1062367460111450758 Time: 1.43452
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:57:40] [V] [TRT] Tactic: 1698681053543049347 Time: 1.3043
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:40] [V] [TRT] Tactic: 4501471010995462441 Time: 1.07226
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:40] [V] [TRT] Tactic: 5137655947464784826 Time: 1.04207
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:40] [V] [TRT] Tactic: 5288347012147084929 Time: 1.07714
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:57:40] [V] [TRT] Tactic: 5326823351883942011 Time: 1.02971
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:57:40] [V] [TRT] Tactic: 5500448035057547314 Time: 1.14672
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:40] [V] [TRT] Tactic: 6645123197870846056 Time: 1.0688
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:40] [V] [TRT] Tactic: 7144526460361122478 Time: 1.45102
[05/21/2022-02:57:40] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:41] [V] [TRT] Tactic: -8262349710178828730 Time: 1.08758
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:57:41] [V] [TRT] Tactic: -6576203419454146580 Time: 1.23626
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:41] [V] [TRT] Tactic: -4787320710726427159 Time: 1.52142
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:41] [V] [TRT] Tactic: -3456450830548107839 Time: 1.28842
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:41] [V] [TRT] Tactic: -1218658103698133241 Time: 1.21196
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:41] [V] [TRT] Tactic: -836875257600482091 Time: 1.18158
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:41] [V] [TRT] Tactic: -410470605513481746 Time: 1.04805
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:57:41] [V] [TRT] Tactic: -377491875521947884 Time: 1.06497
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:57:41] [V] [TRT] Tactic: -37215280111360163 Time: 1.03165
[05/21/2022-02:57:41] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 1.02971
[05/21/2022-02:57:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:57:41] [V] [TRT] *************** Autotuning format combination: Float(331776,1,9216,256) -> Float(330480,1,9180,255) ***************
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-02:57:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-02:57:41] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-02:57:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] *************** Autotuning format combination: Half(331776,1296,36,1) -> Half(330480,1296,36,1) ***************
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-02:57:41] [V] [TRT] Tactic: 0 Time: 1.82815
[05/21/2022-02:57:41] [V] [TRT] Tactic: 1 Time: 1.82637
[05/21/2022-02:57:41] [V] [TRT] Tactic: 2 Time: 1.68204
[05/21/2022-02:57:41] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2214853632, available: 536870912
[05/21/2022-02:57:41] [V] [TRT] Tactic: 5 Time: 8.09256
[05/21/2022-02:57:41] [V] [TRT] Fastest Tactic: 2 Time: 1.68204
[05/21/2022-02:57:41] [V] [TRT] Setting workspace to 2214853632enables more tactics for profiling
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-02:57:41] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-02:57:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:57:41] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(330480,1296,36,1) ***************
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-02:57:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] *************** Autotuning format combination: Half(165888,1296:2,36,1) -> Half(165888,1296:2,36,1) ***************
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (FusedConvActConvolution)
[05/21/2022-02:57:41] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-02:57:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-02:57:41] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:57:41] [V] [TRT] Tactic: 3066127711859985668 Time: 0.663718
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:41] [V] [TRT] Tactic: 3564772625446233998 Time: 0.736901
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:41] [V] [TRT] Tactic: 5319956359050645452 Time: 0.685749
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:41] [V] [TRT] Tactic: 7205456024582378848 Time: 0.55875
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:57:41] [V] [TRT] Tactic: 8163473458334948789 Time: 0.541224
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:41] [V] [TRT] Tactic: -4212163711445252890 Time: 0.544668
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:41] [V] [TRT] Tactic: -3898373634979201110 Time: 0.553112
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:41] [V] [TRT] Tactic: -2409163523992614473 Time: 0.547461
[05/21/2022-02:57:41] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:57:41] [V] [TRT] Tactic: -1716393687483585322 Time: 0.533079
[05/21/2022-02:57:41] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.533079
[05/21/2022-02:57:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:57:41] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:41] [V] [TRT] *************** Autotuning format combination: Float(165888,1296,36,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:41] [V] [TRT] Tactic: 458751 Time: 1.91851
[05/21/2022-02:57:41] [V] [TRT] Fastest Tactic: 458751 Time: 1.91851
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:57:41] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:41] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:41] [V] [TRT] Tactic: 0 Time: 2.73529
[05/21/2022-02:57:42] [V] [TRT] Tactic: 1 Time: 2.19678
[05/21/2022-02:57:42] [V] [TRT] Tactic: 2 Time: 2.14104
[05/21/2022-02:57:43] [V] [TRT] Tactic: 5 Time: 82.778
[05/21/2022-02:57:43] [V] [TRT] Fastest Tactic: 2 Time: 2.14104
[05/21/2022-02:57:43] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:43] [V] [TRT] Tactic: 1062367460111450758 Time: 1.49663
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:57:43] [V] [TRT] Tactic: 1754984623894446479 Time: 1.72979
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:57:43] [V] [TRT] Tactic: 3611739942397549984 Time: 1.19872
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:57:43] [V] [TRT] Tactic: 4337000649858996379 Time: 1.21645
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:43] [V] [TRT] Tactic: 4501471010995462441 Time: 1.19378
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:43] [V] [TRT] Tactic: 5137655947464784826 Time: 1.18021
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:43] [V] [TRT] Tactic: 5288347012147084929 Time: 1.17906
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:43] [V] [TRT] Tactic: 6645123197870846056 Time: 1.20698
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:43] [V] [TRT] Tactic: 7144526460361122478 Time: 1.55878
[05/21/2022-02:57:43] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:57:44] [V] [TRT] Tactic: -9137461792520977713 Time: 1.20495
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:44] [V] [TRT] Tactic: -8262349710178828730 Time: 1.20104
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:57:44] [V] [TRT] Tactic: -8133971918129952780 Time: 1.31286
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:57:44] [V] [TRT] Tactic: -6092040395344634144 Time: 1.50872
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:44] [V] [TRT] Tactic: -4787320710726427159 Time: 1.67889
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:44] [V] [TRT] Tactic: -3456450830548107839 Time: 1.4057
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:44] [V] [TRT] Tactic: -1218658103698133241 Time: 1.30734
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:44] [V] [TRT] Tactic: -836875257600482091 Time: 1.29088
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:44] [V] [TRT] Tactic: -410470605513481746 Time: 1.16132
[05/21/2022-02:57:44] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 1.16132
[05/21/2022-02:57:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-02:57:44] [V] [TRT] *************** Autotuning format combination: Float(165888,1,4608,128) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:44] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:44] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:57:44] [V] [TRT] Tactic: -9153228964338181824 Time: 1.67342
[05/21/2022-02:57:44] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:57:44] [V] [TRT] Tactic: -7394439838318485025 Time: 1.15193
[05/21/2022-02:57:44] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.15193
[05/21/2022-02:57:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:57:44] [V] [TRT] *************** Autotuning format combination: Half(165888,1296,36,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:44] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:44] [V] [TRT] Tactic: 0 Time: 2.78766
[05/21/2022-02:57:44] [V] [TRT] Tactic: 1 Time: 2.27986
[05/21/2022-02:57:44] [V] [TRT] Tactic: 2 Time: 2.06619
[05/21/2022-02:57:46] [V] [TRT] Tactic: 5 Time: 82.6918
[05/21/2022-02:57:46] [V] [TRT] Fastest Tactic: 2 Time: 2.06619
[05/21/2022-02:57:46] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,1296:2,36,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:46] [V] [TRT] Tactic: 458751 Time: 1.54568
[05/21/2022-02:57:46] [V] [TRT] Fastest Tactic: 458751 Time: 1.54568
[05/21/2022-02:57:46] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:46] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:46] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:46] [V] [TRT] Tactic: 3564772625446233998 Time: 0.740163
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:57:46] [V] [TRT] Tactic: 3650389455493082349 Time: 0.814577
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:46] [V] [TRT] Tactic: 5319956359050645452 Time: 0.689479
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:46] [V] [TRT] Tactic: 7205456024582378848 Time: 0.617311
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:57:46] [V] [TRT] Tactic: -6490690591794140522 Time: 0.629141
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:57:46] [V] [TRT] Tactic: -4686027666808657977 Time: 0.613548
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:46] [V] [TRT] Tactic: -4212163711445252890 Time: 0.588294
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:46] [V] [TRT] Tactic: -3898373634979201110 Time: 0.602663
[05/21/2022-02:57:46] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:46] [V] [TRT] Tactic: -2409163523992614473 Time: 0.602487
[05/21/2022-02:57:46] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 0.588294
[05/21/2022-02:57:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(82944,1,4608,256) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(2592,324:32,18,1) -> Float(2592,324:32,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(82944,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(165888,1,9216,512) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(5184,324:32,18,1) -> Float(5184,324:32,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(165888,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82944,324:2,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:46] [V] [TRT] *************** Autotuning format combination: Float(165888,324,18,1) -> Float(82620,324,18,1) ***************
[05/21/2022-02:57:46] [V] [TRT] --------------- Timing Runner: 150_convolutional (FusedConvActConvolution)
[05/21/2022-02:57:46] [V] [TRT] Tactic: 589823 Time: 1.38754
[05/21/2022-02:57:46] [V] [TRT] Tactic: 786431 Time: 1.39715
[05/21/2022-02:57:46] [V] [TRT] Tactic: 1310719 Time: 3.10052
[05/21/2022-02:57:47] [V] [TRT] Tactic: 1638399 Time: 1.52697
[05/21/2022-02:57:47] [V] [TRT] Tactic: 1835007 Time: 1.38598
[05/21/2022-02:57:47] [V] [TRT] Tactic: 2097151 Time: 1.75653
[05/21/2022-02:57:47] [V] [TRT] Tactic: 3997695 Time: 1.52195
[05/21/2022-02:57:47] [V] [TRT] Tactic: 4194303 Time: 1.39294
[05/21/2022-02:57:47] [V] [TRT] Tactic: 4259839 Time: 1.84211
[05/21/2022-02:57:47] [V] [TRT] Tactic: 4325375 Time: 1.21658
[05/21/2022-02:57:47] [V] [TRT] Tactic: 4521983 Time: 1.2202
[05/21/2022-02:57:47] [V] [TRT] Tactic: 4587519 Time: 1.15596
[05/21/2022-02:57:47] [V] [TRT] Tactic: 4915199 Time: 1.44619
[05/21/2022-02:57:47] [V] [TRT] Tactic: 4980735 Time: 1.21732
[05/21/2022-02:57:48] [V] [TRT] Tactic: 5439487 Time: 1.70492
[05/21/2022-02:57:48] [V] [TRT] Tactic: 5767167 Time: 2.88234
[05/21/2022-02:57:48] [V] [TRT] Tactic: 6750207 Time: 1.64038
[05/21/2022-02:57:48] [V] [TRT] Tactic: 6946815 Time: 2.00892
[05/21/2022-02:57:48] [V] [TRT] Tactic: 7012351 Time: 1.76507
[05/21/2022-02:57:48] [V] [TRT] Tactic: 7143423 Time: 2.35207
[05/21/2022-02:57:48] [V] [TRT] Tactic: 7602175 Time: 1.8814
[05/21/2022-02:57:48] [V] [TRT] Tactic: 7798783 Time: 1.39678
[05/21/2022-02:57:48] [V] [TRT] Tactic: 8191999 Time: 2.302
[05/21/2022-02:57:49] [V] [TRT] Tactic: 8257535 Time: 1.46202
[05/21/2022-02:57:49] [V] [TRT] Tactic: 8323071 Time: 1.40135
[05/21/2022-02:57:49] [V] [TRT] Tactic: 8650751 Time: 1.78871
[05/21/2022-02:57:49] [V] [TRT] Tactic: 9109503 Time: 1.95684
[05/21/2022-02:57:49] [V] [TRT] Tactic: 9568255 Time: 1.44464
[05/21/2022-02:57:49] [V] [TRT] Tactic: 9895935 Time: 1.39684
[05/21/2022-02:57:49] [V] [TRT] Tactic: 10354687 Time: 1.90796
[05/21/2022-02:57:49] [V] [TRT] Tactic: 10551295 Time: 1.36344
[05/21/2022-02:57:49] [V] [TRT] Tactic: 10944511 Time: 1.21932
[05/21/2022-02:57:49] [V] [TRT] Fastest Tactic: 4587519 Time: 1.15596
[05/21/2022-02:57:49] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudaDepthwiseConvolution)
[05/21/2022-02:57:49] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:49] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-02:57:49] [V] [TRT] Tactic: 0 Time: 1.13857
[05/21/2022-02:57:49] [V] [TRT] Tactic: 1 Time: 0.941497
[05/21/2022-02:57:49] [V] [TRT] Tactic: 2 Time: 1.0772
[05/21/2022-02:57:49] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1141372928, available: 536870912
[05/21/2022-02:57:50] [V] [TRT] Tactic: 5 Time: 9.05176
[05/21/2022-02:57:50] [V] [TRT] Fastest Tactic: 1 Time: 0.941497
[05/21/2022-02:57:50] [V] [TRT] Setting workspace to 1141372928enables more tactics for profiling
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-02:57:50] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:50] [V] [TRT] Tactic: 1062367460111450758 Time: 0.683262
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:57:50] [V] [TRT] Tactic: 1698681053543049347 Time: 0.688958
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:50] [V] [TRT] Tactic: 4501471010995462441 Time: 0.550899
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:50] [V] [TRT] Tactic: 5137655947464784826 Time: 0.567207
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:50] [V] [TRT] Tactic: 5288347012147084929 Time: 0.549922
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:57:50] [V] [TRT] Tactic: 5326823351883942011 Time: 0.52875
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:57:50] [V] [TRT] Tactic: 5500448035057547314 Time: 0.580026
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:50] [V] [TRT] Tactic: 6645123197870846056 Time: 0.571556
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:50] [V] [TRT] Tactic: 7144526460361122478 Time: 0.738594
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:50] [V] [TRT] Tactic: -8262349710178828730 Time: 0.55528
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:57:50] [V] [TRT] Tactic: -6576203419454146580 Time: 0.642722
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:50] [V] [TRT] Tactic: -4787320710726427159 Time: 0.772064
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:50] [V] [TRT] Tactic: -3456450830548107839 Time: 0.650553
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:50] [V] [TRT] Tactic: -1218658103698133241 Time: 0.624401
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:50] [V] [TRT] Tactic: -836875257600482091 Time: 0.604662
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:50] [V] [TRT] Tactic: -410470605513481746 Time: 0.536705
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:57:50] [V] [TRT] Tactic: -377491875521947884 Time: 0.542448
[05/21/2022-02:57:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:57:50] [V] [TRT] Tactic: -37215280111360163 Time: 0.547168
[05/21/2022-02:57:50] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.52875
[05/21/2022-02:57:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:57:50] [V] [TRT] *************** Autotuning format combination: Float(165888,1,9216,512) -> Float(82620,1,4590,255) ***************
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-02:57:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-02:57:50] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-02:57:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:50] [V] [TRT] *************** Autotuning format combination: Half(165888,324,18,1) -> Half(82620,324,18,1) ***************
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-02:57:50] [V] [TRT] Tactic: 0 Time: 1.16368
[05/21/2022-02:57:50] [V] [TRT] Tactic: 1 Time: 1
[05/21/2022-02:57:50] [V] [TRT] Tactic: 2 Time: 1.01308
[05/21/2022-02:57:50] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1141372928, available: 536870912
[05/21/2022-02:57:50] [V] [TRT] Tactic: 5 Time: 9.24436
[05/21/2022-02:57:50] [V] [TRT] Fastest Tactic: 1 Time: 1
[05/21/2022-02:57:50] [V] [TRT] Setting workspace to 1141372928enables more tactics for profiling
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-02:57:50] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-02:57:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:57:50] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(82620,324,18,1) ***************
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-02:57:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:50] [V] [TRT] *************** Autotuning format combination: Half(82944,324:2,18,1) -> Half(41472,324:2,18,1) ***************
[05/21/2022-02:57:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (FusedConvActConvolution)
[05/21/2022-02:57:50] [V] [TRT] Tactic: 589823 Time: 0.68086
[05/21/2022-02:57:50] [V] [TRT] Tactic: 786431 Time: 0.909023
[05/21/2022-02:57:50] [V] [TRT] Tactic: 1310719 Time: 1.58614
[05/21/2022-02:57:51] [V] [TRT] Tactic: 1638399 Time: 0.782188
[05/21/2022-02:57:51] [V] [TRT] Tactic: 1835007 Time: 0.883516
[05/21/2022-02:57:51] [V] [TRT] Tactic: 2097151 Time: 1.16462
[05/21/2022-02:57:51] [V] [TRT] Tactic: 3997695 Time: 0.941673
[05/21/2022-02:57:51] [V] [TRT] Tactic: 4194303 Time: 0.835632
[05/21/2022-02:57:51] [V] [TRT] Tactic: 4259839 Time: 1.15549
[05/21/2022-02:57:51] [V] [TRT] Tactic: 4325375 Time: 0.630436
[05/21/2022-02:57:51] [V] [TRT] Tactic: 4521983 Time: 0.600911
[05/21/2022-02:57:51] [V] [TRT] Tactic: 4587519 Time: 0.667526
[05/21/2022-02:57:51] [V] [TRT] Tactic: 4915199 Time: 0.838841
[05/21/2022-02:57:51] [V] [TRT] Tactic: 4980735 Time: 0.618919
[05/21/2022-02:57:51] [V] [TRT] Tactic: 5439487 Time: 0.965651
[05/21/2022-02:57:51] [V] [TRT] Tactic: 5767167 Time: 1.276
[05/21/2022-02:57:51] [V] [TRT] Tactic: 6750207 Time: 0.878196
[05/21/2022-02:57:51] [V] [TRT] Tactic: 6946815 Time: 1.04048
[05/21/2022-02:57:51] [V] [TRT] Tactic: 7012351 Time: 1.16445
[05/21/2022-02:57:52] [V] [TRT] Tactic: 7143423 Time: 1.17128
[05/21/2022-02:57:52] [V] [TRT] Tactic: 7602175 Time: 0.904805
[05/21/2022-02:57:52] [V] [TRT] Tactic: 7798783 Time: 0.918073
[05/21/2022-02:57:52] [V] [TRT] Tactic: 8191999 Time: 1.13559
[05/21/2022-02:57:52] [V] [TRT] Tactic: 8257535 Time: 0.873854
[05/21/2022-02:57:52] [V] [TRT] Tactic: 8323071 Time: 0.805469
[05/21/2022-02:57:52] [V] [TRT] Tactic: 8650751 Time: 0.889531
[05/21/2022-02:57:52] [V] [TRT] Tactic: 9109503 Time: 1.25189
[05/21/2022-02:57:52] [V] [TRT] Tactic: 9568255 Time: 0.838353
[05/21/2022-02:57:52] [V] [TRT] Tactic: 9895935 Time: 0.832389
[05/21/2022-02:57:52] [V] [TRT] Tactic: 10354687 Time: 1.18005
[05/21/2022-02:57:52] [V] [TRT] Tactic: 10551295 Time: 0.688249
[05/21/2022-02:57:52] [V] [TRT] Tactic: 10944511 Time: 0.623613
[05/21/2022-02:57:52] [V] [TRT] Fastest Tactic: 4521983 Time: 0.600911
[05/21/2022-02:57:52] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-02:57:52] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:52] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-02:57:52] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:52] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-02:57:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:57:52] [V] [TRT] Tactic: 3066127711859985668 Time: 0.345651
[05/21/2022-02:57:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:52] [V] [TRT] Tactic: 3564772625446233998 Time: 0.377253
[05/21/2022-02:57:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:52] [V] [TRT] Tactic: 5319956359050645452 Time: 0.342025
[05/21/2022-02:57:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:52] [V] [TRT] Tactic: 7205456024582378848 Time: 0.297572
[05/21/2022-02:57:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:57:52] [V] [TRT] Tactic: 8163473458334948789 Time: 0.283978
[05/21/2022-02:57:53] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:53] [V] [TRT] Tactic: -4212163711445252890 Time: 0.283815
[05/21/2022-02:57:53] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:53] [V] [TRT] Tactic: -3898373634979201110 Time: 0.306855
[05/21/2022-02:57:53] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:53] [V] [TRT] Tactic: -2409163523992614473 Time: 0.291315
[05/21/2022-02:57:53] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:57:53] [V] [TRT] Tactic: -1716393687483585322 Time: 0.283542
[05/21/2022-02:57:53] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.283542
[05/21/2022-02:57:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:57:53] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:53] [V] [TRT] *************** Autotuning format combination: Float(82944,324,18,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:57:53] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:53] [V] [TRT] Tactic: 458751 Time: 2.9963
[05/21/2022-02:57:53] [V] [TRT] Fastest Tactic: 458751 Time: 2.9963
[05/21/2022-02:57:53] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-02:57:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:53] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:53] [V] [TRT] Tactic: 0 Time: 3.00081
[05/21/2022-02:57:53] [V] [TRT] Tactic: 1 Time: 2.33141
[05/21/2022-02:57:53] [V] [TRT] Tactic: 2 Time: 2.63495
[05/21/2022-02:57:53] [V] [TRT] Tactic: 5 skipped. Scratch requested: 574137344, available: 536870912
[05/21/2022-02:57:53] [V] [TRT] Fastest Tactic: 1 Time: 2.33141
[05/21/2022-02:57:53] [V] [TRT] Setting workspace to 574137344enables more tactics for profiling
[05/21/2022-02:57:53] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:53] [V] [TRT] Tactic: 1062367460111450758 Time: 2.06493
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-02:57:53] [V] [TRT] Tactic: 1754984623894446479 Time: 2.69794
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-02:57:53] [V] [TRT] Tactic: 3611739942397549984 Time: 1.58029
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-02:57:53] [V] [TRT] Tactic: 4337000649858996379 Time: 1.61012
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:53] [V] [TRT] Tactic: 4501471010995462441 Time: 1.57853
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:53] [V] [TRT] Tactic: 5137655947464784826 Time: 1.54128
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:53] [V] [TRT] Tactic: 5288347012147084929 Time: 1.55328
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:53] [V] [TRT] Tactic: 6645123197870846056 Time: 1.57932
[05/21/2022-02:57:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:54] [V] [TRT] Tactic: 7144526460361122478 Time: 2.37314
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-02:57:54] [V] [TRT] Tactic: -9137461792520977713 Time: 1.59249
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:54] [V] [TRT] Tactic: -8262349710178828730 Time: 1.59375
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-02:57:54] [V] [TRT] Tactic: -8133971918129952780 Time: 1.79867
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-02:57:54] [V] [TRT] Tactic: -6092040395344634144 Time: 2.16784
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:54] [V] [TRT] Tactic: -4787320710726427159 Time: 2.62859
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:54] [V] [TRT] Tactic: -3456450830548107839 Time: 1.85908
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:54] [V] [TRT] Tactic: -1218658103698133241 Time: 1.80498
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:54] [V] [TRT] Tactic: -836875257600482091 Time: 1.80494
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:54] [V] [TRT] Tactic: -410470605513481746 Time: 1.51783
[05/21/2022-02:57:54] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 1.51783
[05/21/2022-02:57:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-02:57:54] [V] [TRT] *************** Autotuning format combination: Float(82944,1,4608,256) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:57:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-02:57:54] [V] [TRT] Tactic: -9153228964338181824 Time: 2.03645
[05/21/2022-02:57:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-02:57:54] [V] [TRT] Tactic: -7394439838318485025 Time: 1.50791
[05/21/2022-02:57:54] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.50791
[05/21/2022-02:57:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-02:57:54] [V] [TRT] *************** Autotuning format combination: Half(82944,324,18,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:54] [V] [TRT] Tactic: 0 Time: 3.02543
[05/21/2022-02:57:54] [V] [TRT] Tactic: 1 Time: 2.31686
[05/21/2022-02:57:54] [V] [TRT] Tactic: 2 Time: 2.56382
[05/21/2022-02:57:54] [V] [TRT] Tactic: 5 skipped. Scratch requested: 573952512, available: 536870912
[05/21/2022-02:57:54] [V] [TRT] Fastest Tactic: 1 Time: 2.31686
[05/21/2022-02:57:54] [V] [TRT] Setting workspace to 573952512enables more tactics for profiling
[05/21/2022-02:57:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:57:54] [V] [TRT] *************** Autotuning format combination: Half(41472,324:2,18,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:57:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (FusedConvActConvolution)
[05/21/2022-02:57:55] [V] [TRT] Tactic: 458751 Time: 2.35272
[05/21/2022-02:57:55] [V] [TRT] Fastest Tactic: 458751 Time: 2.35272
[05/21/2022-02:57:55] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-02:57:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:55] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:57:55] [V] [TRT] Tactic: 3564772625446233998 Time: 1.04531
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-02:57:55] [V] [TRT] Tactic: 3650389455493082349 Time: 1.08139
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:57:55] [V] [TRT] Tactic: 5319956359050645452 Time: 0.932747
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:57:55] [V] [TRT] Tactic: 7205456024582378848 Time: 0.801543
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-02:57:55] [V] [TRT] Tactic: -6490690591794140522 Time: 0.812285
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-02:57:55] [V] [TRT] Tactic: -4686027666808657977 Time: 0.801328
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:57:55] [V] [TRT] Tactic: -4212163711445252890 Time: 0.771575
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:57:55] [V] [TRT] Tactic: -3898373634979201110 Time: 0.795274
[05/21/2022-02:57:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:57:55] [V] [TRT] Tactic: -2409163523992614473 Time: 0.780514
[05/21/2022-02:57:55] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 0.771575
[05/21/2022-02:57:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(41472,1,4608,512) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(1296,81:32,9,1) -> Float(1296,81:32,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(41472,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(20736,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(41472,1,4608,512) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(20736,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(82944,1,9216,1024) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(2592,81:32,9,1) -> Float(2592,81:32,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(82944,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(41472,81:2,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-02:57:55] [V] [TRT] *************** Autotuning format combination: Float(82944,81,9,1) -> Float(20655,81,9,1) ***************
[05/21/2022-02:57:55] [V] [TRT] --------------- Timing Runner: 161_convolutional (FusedConvActConvolution)
[05/21/2022-02:57:55] [V] [TRT] Tactic: 589823 Time: 0.993646
[05/21/2022-02:57:55] [V] [TRT] Tactic: 786431 Time: 0.716771
[05/21/2022-02:57:56] [V] [TRT] Tactic: 1310719 Time: 2.29284
[05/21/2022-02:57:56] [V] [TRT] Tactic: 1638399 Time: 0.685951
[05/21/2022-02:57:56] [V] [TRT] Tactic: 1835007 Time: 0.790957
[05/21/2022-02:57:56] [V] [TRT] Tactic: 2097151 Time: 1.21921
[05/21/2022-02:57:56] [V] [TRT] Tactic: 3997695 Time: 0.687838
[05/21/2022-02:57:56] [V] [TRT] Tactic: 4194303 Time: 1.01252
[05/21/2022-02:57:56] [V] [TRT] Tactic: 4259839 Time: 1.2812
[05/21/2022-02:57:56] [V] [TRT] Tactic: 4325375 Time: 0.581484
[05/21/2022-02:57:56] [V] [TRT] Tactic: 4521983 Time: 0.565404
[05/21/2022-02:57:56] [V] [TRT] Tactic: 4587519 Time: 0.526256
[05/21/2022-02:57:56] [V] [TRT] Tactic: 4915199 Time: 1.0385
[05/21/2022-02:57:56] [V] [TRT] Tactic: 4980735 Time: 0.627038
[05/21/2022-02:57:56] [V] [TRT] Tactic: 5439487 Time: 0.953047
[05/21/2022-02:57:56] [V] [TRT] Tactic: 5767167 Time: 1.34294
[05/21/2022-02:57:56] [V] [TRT] Tactic: 6750207 Time: 1.00621
[05/21/2022-02:57:57] [V] [TRT] Tactic: 6946815 Time: 1.3285
[05/21/2022-02:57:57] [V] [TRT] Tactic: 7012351 Time: 1.23036
[05/21/2022-02:57:57] [V] [TRT] Tactic: 7143423 Time: 1.45657
[05/21/2022-02:57:57] [V] [TRT] Tactic: 7602175 Time: 1.28166
[05/21/2022-02:57:57] [V] [TRT] Tactic: 7798783 Time: 0.714707
[05/21/2022-02:57:57] [V] [TRT] Tactic: 8191999 Time: 1.44478
[05/21/2022-02:57:57] [V] [TRT] Tactic: 8257535 Time: 1.0359
[05/21/2022-02:57:57] [V] [TRT] Tactic: 8323071 Time: 0.950052
[05/21/2022-02:57:57] [V] [TRT] Tactic: 8650751 Time: 1.14196
[05/21/2022-02:57:57] [V] [TRT] Tactic: 9109503 Time: 1.23697
[05/21/2022-02:57:57] [V] [TRT] Tactic: 9568255 Time: 1.03515
[05/21/2022-02:57:57] [V] [TRT] Tactic: 9895935 Time: 1.01465
[05/21/2022-02:57:58] [V] [TRT] Tactic: 10354687 Time: 1.3686
[05/21/2022-02:57:58] [V] [TRT] Tactic: 10551295 Time: 0.917415
[05/21/2022-02:57:58] [V] [TRT] Tactic: 10944511 Time: 0.627864
[05/21/2022-02:57:58] [V] [TRT] Fastest Tactic: 4587519 Time: 0.526256
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudaDepthwiseConvolution)
[05/21/2022-02:57:58] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-02:57:58] [V] [TRT] Tactic: 0 Time: 0.671224
[05/21/2022-02:57:58] [V] [TRT] Tactic: 1 Time: 0.582741
[05/21/2022-02:57:58] [V] [TRT] Tactic: 2 Time: 1.01186
[05/21/2022-02:57:58] [V] [TRT] Tactic: 4 skipped. Scratch requested: 605024256, available: 536870912
[05/21/2022-02:57:58] [V] [TRT] Tactic: 5 Time: 17.4318
[05/21/2022-02:57:58] [V] [TRT] Fastest Tactic: 1 Time: 0.582741
[05/21/2022-02:57:58] [V] [TRT] Setting workspace to 605024256enables more tactics for profiling
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-02:57:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-02:57:58] [V] [TRT] Tactic: 1062367460111450758 Time: 0.534525
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-02:57:58] [V] [TRT] Tactic: 1698681053543049347 Time: 0.502357
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-02:57:58] [V] [TRT] Tactic: 4501471010995462441 Time: 0.357402
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-02:57:58] [V] [TRT] Tactic: 5137655947464784826 Time: 0.356113
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-02:57:58] [V] [TRT] Tactic: 5288347012147084929 Time: 0.356237
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-02:57:58] [V] [TRT] Tactic: 5326823351883942011 Time: 0.342988
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-02:57:58] [V] [TRT] Tactic: 5500448035057547314 Time: 0.38418
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-02:57:58] [V] [TRT] Tactic: 6645123197870846056 Time: 0.362591
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-02:57:58] [V] [TRT] Tactic: 7144526460361122478 Time: 0.527923
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-02:57:58] [V] [TRT] Tactic: -8262349710178828730 Time: 0.360632
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-02:57:58] [V] [TRT] Tactic: -6576203419454146580 Time: 0.45472
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-02:57:58] [V] [TRT] Tactic: -4787320710726427159 Time: 0.554903
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-02:57:58] [V] [TRT] Tactic: -3456450830548107839 Time: 0.481432
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-02:57:58] [V] [TRT] Tactic: -1218658103698133241 Time: 0.409434
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-02:57:58] [V] [TRT] Tactic: -836875257600482091 Time: 0.387598
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-02:57:58] [V] [TRT] Tactic: -410470605513481746 Time: 0.350065
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-02:57:58] [V] [TRT] Tactic: -377491875521947884 Time: 0.354863
[05/21/2022-02:57:58] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-02:57:58] [V] [TRT] Tactic: -37215280111360163 Time: 0.349557
[05/21/2022-02:57:58] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.342988
[05/21/2022-02:57:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-02:57:58] [V] [TRT] *************** Autotuning format combination: Float(82944,1,9216,1024) -> Float(20655,1,2295,255) ***************
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-02:57:58] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-02:57:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-02:57:58] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:58] [V] [TRT] *************** Autotuning format combination: Half(82944,81,9,1) -> Half(20655,81,9,1) ***************
[05/21/2022-02:57:58] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-02:57:58] [V] [TRT] Tactic: 0 Time: 0.6736
[05/21/2022-02:57:58] [V] [TRT] Tactic: 1 Time: 0.568861
[05/21/2022-02:57:58] [V] [TRT] Tactic: 2 Time: 0.956471
[05/21/2022-02:57:58] [V] [TRT] Tactic: 4 skipped. Scratch requested: 605024256, available: 536870912
[05/21/2022-02:57:59] [V] [TRT] Tactic: 5 Time: 17.1052
[05/21/2022-02:57:59] [V] [TRT] Fastest Tactic: 1 Time: 0.568861
[05/21/2022-02:57:59] [V] [TRT] Setting workspace to 605024256enables more tactics for profiling
[05/21/2022-02:57:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-02:57:59] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-02:57:59] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-02:57:59] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(20655,81,9,1) ***************
[05/21/2022-02:57:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-02:57:59] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-02:57:59] [V] [TRT] *************** Autotuning format combination: Half(41472,81:2,9,1) -> Half(10368,81:2,9,1) ***************
[05/21/2022-02:57:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (FusedConvActConvolution)
[05/21/2022-02:57:59] [V] [TRT] Tactic: 589823 Time: 0.503477
[05/21/2022-02:57:59] [V] [TRT] Tactic: 786431 Time: 0.414271
[05/21/2022-02:57:59] [V] [TRT] Tactic: 1310719 Time: 1.15691
[05/21/2022-02:57:59] [V] [TRT] Tactic: 1638399 Time: 0.365482
[05/21/2022-02:57:59] [V] [TRT] Tactic: 1835007 Time: 0.487155
[05/21/2022-02:57:59] [V] [TRT] Tactic: 2097151 Time: 0.867207
[05/21/2022-02:57:59] [V] [TRT] Tactic: 3997695 Time: 0.441745
[05/21/2022-02:57:59] [V] [TRT] Tactic: 4194303 Time: 0.612122
[05/21/2022-02:57:59] [V] [TRT] Tactic: 4259839 Time: 0.884674
[05/21/2022-02:57:59] [V] [TRT] Tactic: 4325375 Time: 0.316882
[05/21/2022-02:57:59] [V] [TRT] Tactic: 4521983 Time: 0.292442
[05/21/2022-02:57:59] [V] [TRT] Tactic: 4587519 Time: 0.304395
[05/21/2022-02:58:00] [V] [TRT] Tactic: 4915199 Time: 0.616836
[05/21/2022-02:58:00] [V] [TRT] Tactic: 4980735 Time: 0.309284
[05/21/2022-02:58:00] [V] [TRT] Tactic: 5439487 Time: 0.545202
[05/21/2022-02:58:00] [V] [TRT] Tactic: 5767167 Time: 0.68222
[05/21/2022-02:58:00] [V] [TRT] Tactic: 6750207 Time: 0.609544
[05/21/2022-02:58:00] [V] [TRT] Tactic: 6946815 Time: 0.658776
[05/21/2022-02:58:00] [V] [TRT] Tactic: 7012351 Time: 0.873047
[05/21/2022-02:58:00] [V] [TRT] Tactic: 7143423 Time: 0.724114
[05/21/2022-02:58:00] [V] [TRT] Tactic: 7602175 Time: 0.627891
[05/21/2022-02:58:00] [V] [TRT] Tactic: 7798783 Time: 0.424655
[05/21/2022-02:58:00] [V] [TRT] Tactic: 8191999 Time: 0.734075
[05/21/2022-02:58:00] [V] [TRT] Tactic: 8257535 Time: 0.619258
[05/21/2022-02:58:00] [V] [TRT] Tactic: 8323071 Time: 0.54334
[05/21/2022-02:58:00] [V] [TRT] Tactic: 8650751 Time: 0.583333
[05/21/2022-02:58:00] [V] [TRT] Tactic: 9109503 Time: 0.896432
[05/21/2022-02:58:01] [V] [TRT] Tactic: 9568255 Time: 0.626764
[05/21/2022-02:58:01] [V] [TRT] Tactic: 9895935 Time: 0.598399
[05/21/2022-02:58:01] [V] [TRT] Tactic: 10354687 Time: 0.890612
[05/21/2022-02:58:01] [V] [TRT] Tactic: 10551295 Time: 0.480931
[05/21/2022-02:58:01] [V] [TRT] Tactic: 10944511 Time: 0.306133
[05/21/2022-02:58:01] [V] [TRT] Fastest Tactic: 4521983 Time: 0.292442
[05/21/2022-02:58:01] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-02:58:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-02:58:01] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-02:58:01] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-02:58:01] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:58:01] [V] [TRT] Tactic: 3066127711859985668 Time: 0.237995
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-02:58:01] [V] [TRT] Tactic: 3564772625446233998 Time: 0.280521
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:58:01] [V] [TRT] Tactic: 5319956359050645452 Time: 0.242617
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-02:58:01] [V] [TRT] Tactic: 7205456024582378848 Time: 0.200592
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] Tactic: 8163473458334948789 Time: 0.189199
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] Tactic: -4212163711445252890 Time: 0.18319
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:58:01] [V] [TRT] Tactic: -3898373634979201110 Time: 0.186172
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:58:01] [V] [TRT] Tactic: -2409163523992614473 Time: 0.196439
[05/21/2022-02:58:01] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] Tactic: -1716393687483585322 Time: 0.178926
[05/21/2022-02:58:01] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.178926
[05/21/2022-02:58:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 001_convolutional + 001_convolutional_bn (000_net) from Float(248832,82944,288,1) to Half(165888,82944:2,288,1)
[05/21/2022-02:58:01] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(118_convolutional_lrelu) (118_convolutional_bn) from Half(10368,81:2,9,1) to Float(20736,81,9,1)
[05/21/2022-02:58:01] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 129_upsample (128_convolutional_lrelu) from Half(20736,324:2,18,1) to Float(41472,324,18,1)
[05/21/2022-02:58:01] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to 139_convolutional (139_convolutional) from Half(165888,1296:2,36,1) to Float(330480,1296,36,1)
[05/21/2022-02:58:01] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to 150_convolutional (150_convolutional) from Half(41472,324:2,18,1) to Float(82620,324,18,1)
[05/21/2022-02:58:01] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to 161_convolutional (161_convolutional) from Half(10368,81:2,9,1) to Float(20655,81,9,1)
[05/21/2022-02:58:01] [V] [TRT] Formats and tactics selection completed in 640.97 seconds.
[05/21/2022-02:58:01] [V] [TRT] After reformat layers: 229 layers
[05/21/2022-02:58:01] [V] [TRT] Pre-optimized block assignment.
[05/21/2022-02:58:01] [V] [TRT] Block size 5308416
[05/21/2022-02:58:01] [V] [TRT] Block size 5308416
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 5308416
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 2654208
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 41472
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 5308416
[05/21/2022-02:58:01] [V] [TRT] Block size 1327104
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 331776
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 82944
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 663552
[05/21/2022-02:58:01] [V] [TRT] Block size 165888
[05/21/2022-02:58:01] [V] [TRT] Block size 41472
[05/21/2022-02:58:01] [V] [TRT] Block size 536870912
[05/21/2022-02:58:01] [V] [TRT] Total Activation Memory: 641712128
[05/21/2022-02:58:01] [I] [TRT] Detected 1 inputs and 3 output network tensors.
[05/21/2022-02:58:01] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-02:58:01] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:58:01] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-02:58:01] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-02:58:01] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 019_convolutional + 019_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 020_convolutional + 020_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 022_convolutional + 022_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 024_convolutional + 024_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 032_convolutional + 032_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 033_convolutional + 033_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 035_convolutional + 035_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 036_convolutional + 036_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 038_convolutional + 038_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 039_convolutional + 039_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 041_convolutional + 041_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 042_convolutional + 042_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 044_convolutional + 044_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 045_convolutional + 045_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 047_convolutional + 047_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 048_convolutional + 048_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 050_convolutional + 050_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 051_convolutional + 051_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:01] [V] [TRT] 053_convolutional + 053_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 055_convolutional + 055_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-02:58:01] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 063_convolutional + 063_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 064_convolutional + 064_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 066_convolutional + 066_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 067_convolutional + 067_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 069_convolutional + 069_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 070_convolutional + 070_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 072_convolutional + 072_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 073_convolutional + 073_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 075_convolutional + 075_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 076_convolutional + 076_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 078_convolutional + 078_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 079_convolutional + 079_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 081_convolutional + 081_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 082_convolutional + 082_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:01] [V] [TRT] 084_convolutional + 084_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:01] [V] [TRT] 086_convolutional + 086_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:02] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 094_convolutional + 094_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 097_convolutional + 097_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 100_convolutional + 100_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 103_convolutional + 103_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 105_convolutional + 105_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:02] [V] [TRT] 108_convolutional + 108_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 116_convolutional + 116_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:02] [V] [TRT] 117_convolutional + 117_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 123_convolutional + 123_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:02] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:58:03] [V] [TRT] 125_convolutional + 125_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 126_convolutional + 126_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:58:03] [V] [TRT] 127_convolutional + 127_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 133_convolutional + 133_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:03] [V] [TRT] 135_convolutional + 135_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 136_convolutional + 136_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:03] [V] [TRT] 137_convolutional + 137_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 138_convolutional + 138_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-02:58:03] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:03] [V] [TRT] 144_convolutional + 144_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 145_convolutional + 145_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:58:03] [V] [TRT] 146_convolutional + 146_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 147_convolutional + 147_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:58:03] [V] [TRT] 148_convolutional + 148_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 149_convolutional + 149_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-02:58:03] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:03] [V] [TRT] 155_convolutional + 155_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 156_convolutional + 156_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:03] [V] [TRT] 157_convolutional + 157_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 158_convolutional + 158_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:03] [V] [TRT] 159_convolutional + 159_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] 160_convolutional + 160_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-02:58:03] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-02:58:03] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 001_convolutional + 001_convolutional_bn Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 001_convolutional + 001_convolutional_bn Host Persistent: 1664 Device Persistent: 500224 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 002_convolutional + 002_convolutional_bn Host Persistent: 1664 Device Persistent: 161792 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Host Persistent: 1664 Device Persistent: 141312 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 006_convolutional + 006_convolutional_bn Host Persistent: 3200 Device Persistent: 129024 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 007_convolutional + 007_convolutional_bn Host Persistent: 512 Device Persistent: 102912 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 009_convolutional + 009_convolutional_bn Host Persistent: 3200 Device Persistent: 133120 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 011_convolutional + 011_convolutional_bn Host Persistent: 3200 Device Persistent: 141312 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 012_convolutional + 012_convolutional_bn Host Persistent: 1664 Device Persistent: 179200 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Host Persistent: 3200 Device Persistent: 64512 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 016_convolutional + 016_convolutional_bn Host Persistent: 3200 Device Persistent: 39936 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 017_convolutional + 017_convolutional_bn Host Persistent: 512 Device Persistent: 205312 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 019_convolutional + 019_convolutional_bn Host Persistent: 3200 Device Persistent: 39936 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 020_convolutional + 020_convolutional_bn Host Persistent: 512 Device Persistent: 205312 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 022_convolutional + 022_convolutional_bn Host Persistent: 3200 Device Persistent: 39936 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 024_convolutional + 024_convolutional_bn Host Persistent: 3200 Device Persistent: 64512 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 025_convolutional + 025_convolutional_bn Host Persistent: 1664 Device Persistent: 598528 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Host Persistent: 3200 Device Persistent: 139776 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 029_convolutional + 029_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 030_convolutional + 030_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 032_convolutional + 032_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 033_convolutional + 033_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 035_convolutional + 035_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 036_convolutional + 036_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 038_convolutional + 038_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 039_convolutional + 039_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 041_convolutional + 041_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 042_convolutional + 042_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 044_convolutional + 044_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 045_convolutional + 045_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 047_convolutional + 047_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 048_convolutional + 048_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 050_convolutional + 050_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 051_convolutional + 051_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 053_convolutional + 053_convolutional_bn Host Persistent: 3200 Device Persistent: 40960 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 055_convolutional + 055_convolutional_bn Host Persistent: 3200 Device Persistent: 139776 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 056_convolutional + 056_convolutional_bn Host Persistent: 1664 Device Persistent: 2362368 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Host Persistent: 3200 Device Persistent: 527360 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 060_convolutional + 060_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 061_convolutional + 061_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 063_convolutional + 063_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 064_convolutional + 064_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 066_convolutional + 066_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 067_convolutional + 067_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 069_convolutional + 069_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 070_convolutional + 070_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 072_convolutional + 072_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 073_convolutional + 073_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 075_convolutional + 075_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 076_convolutional + 076_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 078_convolutional + 078_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 079_convolutional + 079_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 081_convolutional + 081_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 082_convolutional + 082_convolutional_bn Host Persistent: 1664 Device Persistent: 1182208 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 084_convolutional + 084_convolutional_bn Host Persistent: 3200 Device Persistent: 133632 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 086_convolutional + 086_convolutional_bn Host Persistent: 3200 Device Persistent: 527360 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 087_convolutional + 087_convolutional_bn Host Persistent: 1664 Device Persistent: 9439744 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Host Persistent: 3200 Device Persistent: 2099712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 091_convolutional + 091_convolutional_bn Host Persistent: 3200 Device Persistent: 525824 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 092_convolutional + 092_convolutional_bn Host Persistent: 2192 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 094_convolutional + 094_convolutional_bn Host Persistent: 3200 Device Persistent: 525824 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 095_convolutional + 095_convolutional_bn Host Persistent: 2192 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 097_convolutional + 097_convolutional_bn Host Persistent: 3200 Device Persistent: 525824 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 098_convolutional + 098_convolutional_bn Host Persistent: 2192 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 100_convolutional + 100_convolutional_bn Host Persistent: 3200 Device Persistent: 525824 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 101_convolutional + 101_convolutional_bn Host Persistent: 2192 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 103_convolutional + 103_convolutional_bn Host Persistent: 3200 Device Persistent: 525824 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 105_convolutional + 105_convolutional_bn Host Persistent: 3200 Device Persistent: 2099712 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 106_convolutional + 106_convolutional_bn Host Persistent: 3200 Device Persistent: 1050112 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(106_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 107_convolutional + 107_convolutional_bn Host Persistent: 1664 Device Persistent: 9439744 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(107_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 108_convolutional + 108_convolutional_bn Host Persistent: 3200 Device Persistent: 1050112 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(108_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 109_maxpool Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 111_maxpool Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 113_maxpool Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 113_maxpool copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 111_maxpool copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 109_maxpool copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 108_convolutional_lrelu copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 115_convolutional + 115_convolutional_bn Host Persistent: 3200 Device Persistent: 2098688 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(115_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 116_convolutional + 116_convolutional_bn Host Persistent: 1664 Device Persistent: 9439744 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(116_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 117_convolutional + 117_convolutional_bn Host Persistent: 3200 Device Persistent: 1050112 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(117_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 118_convolutional + 118_convolutional_bn Host Persistent: 3200 Device Persistent: 263168 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(118_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(118_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 119_upsample Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 121_convolutional + 121_convolutional_bn Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(121_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 119_upsample copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 123_convolutional + 123_convolutional_bn Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(123_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 124_convolutional + 124_convolutional_bn Host Persistent: 2176 Device Persistent: 2362368 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(124_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 125_convolutional + 125_convolutional_bn Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(125_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 126_convolutional + 126_convolutional_bn Host Persistent: 2176 Device Persistent: 2362368 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(126_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 127_convolutional + 127_convolutional_bn Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(127_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 128_convolutional + 128_convolutional_bn Host Persistent: 3200 Device Persistent: 68096 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(128_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 129_upsample Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 129_upsample Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 131_convolutional + 131_convolutional_bn Host Persistent: 3200 Device Persistent: 73728 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(131_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 129_upsample copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 133_convolutional + 133_convolutional_bn Host Persistent: 3200 Device Persistent: 73728 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(133_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 134_convolutional + 134_convolutional_bn Host Persistent: 512 Device Persistent: 1638912 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(134_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 135_convolutional + 135_convolutional_bn Host Persistent: 3200 Device Persistent: 73728 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(135_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 136_convolutional + 136_convolutional_bn Host Persistent: 512 Device Persistent: 1638912 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(136_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 137_convolutional + 137_convolutional_bn Host Persistent: 3200 Device Persistent: 73728 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(137_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 138_convolutional + 138_convolutional_bn Host Persistent: 512 Device Persistent: 1638912 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(138_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 139_convolutional Host Persistent: 3200 Device Persistent: 139776 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to 139_convolutional Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 142_convolutional + 142_convolutional_bn Host Persistent: 1664 Device Persistent: 592384 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(142_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 144_convolutional + 144_convolutional_bn Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(144_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 145_convolutional + 145_convolutional_bn Host Persistent: 2176 Device Persistent: 2362368 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(145_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 146_convolutional + 146_convolutional_bn Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(146_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 147_convolutional + 147_convolutional_bn Host Persistent: 2176 Device Persistent: 2362368 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(147_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 148_convolutional + 148_convolutional_bn Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(148_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 149_convolutional + 149_convolutional_bn Host Persistent: 2176 Device Persistent: 2362368 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(149_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 150_convolutional Host Persistent: 3200 Device Persistent: 264704 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to 150_convolutional Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 153_convolutional + 153_convolutional_bn Host Persistent: 1664 Device Persistent: 2360832 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(153_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 155_convolutional + 155_convolutional_bn Host Persistent: 3200 Device Persistent: 1050112 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(155_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 156_convolutional + 156_convolutional_bn Host Persistent: 1664 Device Persistent: 9439744 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(156_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 157_convolutional + 157_convolutional_bn Host Persistent: 3200 Device Persistent: 1050112 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(157_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 158_convolutional + 158_convolutional_bn Host Persistent: 1664 Device Persistent: 9439744 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(158_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 159_convolutional + 159_convolutional_bn Host Persistent: 3200 Device Persistent: 1050112 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(159_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 160_convolutional + 160_convolutional_bn Host Persistent: 1664 Device Persistent: 9439744 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: PWN(160_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: 161_convolutional Host Persistent: 3200 Device Persistent: 525312 Scratch Memory: 0
[05/21/2022-02:58:03] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to 161_convolutional Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-02:58:03] [I] [TRT] Total Host Persistent Memory: 285024
[05/21/2022-02:58:03] [I] [TRT] Total Device Persistent Memory: 118987264
[05/21/2022-02:58:03] [I] [TRT] Total Scratch Memory: 0
[05/21/2022-02:58:03] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 375 MiB, GPU 384 MiB
[05/21/2022-02:58:04] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 188.951ms to assign 7 blocks to 214 nodes requiring 16257024 bytes.
[05/21/2022-02:58:04] [V] [TRT] Optimized block assignment.
[05/21/2022-02:58:04] [V] [TRT] Block size 5308416
[05/21/2022-02:58:04] [V] [TRT] Block size 5308416
[05/21/2022-02:58:04] [V] [TRT] Block size 2654208
[05/21/2022-02:58:04] [V] [TRT] Block size 2654208
[05/21/2022-02:58:04] [V] [TRT] Block size 165888
[05/21/2022-02:58:04] [V] [TRT] Block size 82944
[05/21/2022-02:58:04] [V] [TRT] Block size 82944
[05/21/2022-02:58:04] [I] [TRT] Total Activation Memory: 16257024
[05/21/2022-02:58:04] [V] [TRT] Using cublas as a tactic source
[05/21/2022-02:58:04] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +7, now: CPU 1558, GPU 3882 (MiB)
[05/21/2022-02:58:04] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-02:58:04] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +3, now: CPU 1558, GPU 3885 (MiB)
[05/21/2022-02:58:04] [V] [TRT] Engine generation completed in 647.229 seconds.
[05/21/2022-02:58:04] [V] [TRT] Deleting timing cache: 1076 entries, 5233 hits
[05/21/2022-02:58:04] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 001_convolutional + 001_convolutional_bn, Tactic: 0, 000_net[Float(1,3,288,288)] -> Reformatted Input Tensor 0 to 001_convolutional + 001_convolutional_bn[Half(1,3,288,288)]
Layer(CaskConvolution): 001_convolutional + 001_convolutional_bn, Tactic: 5319956359050645452, Reformatted Input Tensor 0 to 001_convolutional + 001_convolutional_bn[Half(1,3,288,288)] -> 001_convolutional_bn[Half(1,32,288,288)]
Layer(PointWiseV2): PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish), Tactic: 14, 001_convolutional_bn[Half(1,32,288,288)] -> 001_convolutional_mish[Half(1,32,288,288)]
Layer(CaskConvolution): 002_convolutional + 002_convolutional_bn, Tactic: -2409163523992614473, 001_convolutional_mish[Half(1,32,288,288)] -> 002_convolutional_bn[Half(1,64,144,144)]
Layer(PointWiseV2): PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish), Tactic: 18, 002_convolutional_bn[Half(1,64,144,144)] -> 002_convolutional_mish[Half(1,64,144,144)]
Layer(CaskConvolution): 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn, Tactic: -2409163523992614473, 002_convolutional_mish[Half(1,64,144,144)] -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn[Half(1,128,144,144)]
Layer(PointWiseV2): PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish), Tactic: 7, 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn[Half(1,64,144,144)] -> 010_route[Half(1,64,144,144)]
Layer(PointWiseV2): PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish), Tactic: 17, 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn[Half(1,64,144,144)] -> 005_convolutional_mish[Half(1,64,144,144)]
Layer(CaskConvolution): 006_convolutional + 006_convolutional_bn, Tactic: 3066127711859985668, 005_convolutional_mish[Half(1,64,144,144)] -> 006_convolutional_bn[Half(1,32,144,144)]
Layer(PointWiseV2): PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish), Tactic: 18, 006_convolutional_bn[Half(1,32,144,144)] -> 006_convolutional_mish[Half(1,32,144,144)]
Layer(CaskConvolution): 007_convolutional + 007_convolutional_bn, Tactic: 4772821744921268633, 006_convolutional_mish[Half(1,32,144,144)] -> 007_convolutional_bn[Half(1,64,144,144)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut), Tactic: 3, 007_convolutional_bn[Half(1,64,144,144)], 005_convolutional_mish[Half(1,64,144,144)] -> 008_shortcut[Half(1,64,144,144)]
Layer(CaskConvolution): 009_convolutional + 009_convolutional_bn, Tactic: 8163473458334948789, 008_shortcut[Half(1,64,144,144)] -> 009_convolutional_bn[Half(1,64,144,144)]
Layer(PointWiseV2): PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish), Tactic: 17, 009_convolutional_bn[Half(1,64,144,144)] -> 010_route[Half(1,64,144,144)]
Layer(CaskConvolution): 011_convolutional + 011_convolutional_bn, Tactic: 8163473458334948789, 010_route[Half(1,128,144,144)] -> 011_convolutional_bn[Half(1,64,144,144)]
Layer(PointWiseV2): PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish), Tactic: 18, 011_convolutional_bn[Half(1,64,144,144)] -> 011_convolutional_mish[Half(1,64,144,144)]
Layer(CaskConvolution): 012_convolutional + 012_convolutional_bn, Tactic: -4212163711445252890, 011_convolutional_mish[Half(1,64,144,144)] -> 012_convolutional_bn[Half(1,128,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish), Tactic: 18, 012_convolutional_bn[Half(1,128,72,72)] -> 012_convolutional_mish[Half(1,128,72,72)]
Layer(CaskConvolution): 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn, Tactic: 8163473458334948789, 012_convolutional_mish[Half(1,128,72,72)] -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn[Half(1,128,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish), Tactic: 17, 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn[Half(1,64,72,72)] -> 023_route[Half(1,64,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish), Tactic: 17, 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn[Half(1,64,72,72)] -> 015_convolutional_mish[Half(1,64,72,72)]
Layer(CaskConvolution): 016_convolutional + 016_convolutional_bn, Tactic: 8163473458334948789, 015_convolutional_mish[Half(1,64,72,72)] -> 016_convolutional_bn[Half(1,64,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish), Tactic: 18, 016_convolutional_bn[Half(1,64,72,72)] -> 016_convolutional_mish[Half(1,64,72,72)]
Layer(CaskConvolution): 017_convolutional + 017_convolutional_bn, Tactic: 4772821744921268633, 016_convolutional_mish[Half(1,64,72,72)] -> 017_convolutional_bn[Half(1,64,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut), Tactic: 18, 017_convolutional_bn[Half(1,64,72,72)], 015_convolutional_mish[Half(1,64,72,72)] -> 018_shortcut[Half(1,64,72,72)]
Layer(CaskConvolution): 019_convolutional + 019_convolutional_bn, Tactic: 8163473458334948789, 018_shortcut[Half(1,64,72,72)] -> 019_convolutional_bn[Half(1,64,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish), Tactic: 18, 019_convolutional_bn[Half(1,64,72,72)] -> 019_convolutional_mish[Half(1,64,72,72)]
Layer(CaskConvolution): 020_convolutional + 020_convolutional_bn, Tactic: 4772821744921268633, 019_convolutional_mish[Half(1,64,72,72)] -> 020_convolutional_bn[Half(1,64,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut), Tactic: 18, 020_convolutional_bn[Half(1,64,72,72)], 018_shortcut[Half(1,64,72,72)] -> 021_shortcut[Half(1,64,72,72)]
Layer(CaskConvolution): 022_convolutional + 022_convolutional_bn, Tactic: 8163473458334948789, 021_shortcut[Half(1,64,72,72)] -> 022_convolutional_bn[Half(1,64,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish), Tactic: 17, 022_convolutional_bn[Half(1,64,72,72)] -> 023_route[Half(1,64,72,72)]
Layer(CaskConvolution): 024_convolutional + 024_convolutional_bn, Tactic: 8163473458334948789, 023_route[Half(1,128,72,72)] -> 024_convolutional_bn[Half(1,128,72,72)]
Layer(PointWiseV2): PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish), Tactic: 18, 024_convolutional_bn[Half(1,128,72,72)] -> 024_convolutional_mish[Half(1,128,72,72)]
Layer(CaskConvolution): 025_convolutional + 025_convolutional_bn, Tactic: -4212163711445252890, 024_convolutional_mish[Half(1,128,72,72)] -> 025_convolutional_bn[Half(1,256,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish), Tactic: 18, 025_convolutional_bn[Half(1,256,36,36)] -> 025_convolutional_mish[Half(1,256,36,36)]
Layer(CaskConvolution): 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn, Tactic: 8163473458334948789, 025_convolutional_mish[Half(1,256,36,36)] -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn[Half(1,256,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish), Tactic: 17, 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn[Half(1,128,36,36)] -> 054_route[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish), Tactic: 17, 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn[Half(1,128,36,36)] -> 028_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 029_convolutional + 029_convolutional_bn, Tactic: -1716393687483585322, 028_convolutional_mish[Half(1,128,36,36)] -> 029_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish), Tactic: 18, 029_convolutional_bn[Half(1,128,36,36)] -> 029_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 030_convolutional + 030_convolutional_bn, Tactic: 4772821744921268633, 029_convolutional_mish[Half(1,128,36,36)] -> 030_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut), Tactic: 18, 030_convolutional_bn[Half(1,128,36,36)], 028_convolutional_mish[Half(1,128,36,36)] -> 031_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 032_convolutional + 032_convolutional_bn, Tactic: -1716393687483585322, 031_shortcut[Half(1,128,36,36)] -> 032_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish), Tactic: 18, 032_convolutional_bn[Half(1,128,36,36)] -> 032_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 033_convolutional + 033_convolutional_bn, Tactic: 4772821744921268633, 032_convolutional_mish[Half(1,128,36,36)] -> 033_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut), Tactic: 18, 033_convolutional_bn[Half(1,128,36,36)], 031_shortcut[Half(1,128,36,36)] -> 034_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 035_convolutional + 035_convolutional_bn, Tactic: -1716393687483585322, 034_shortcut[Half(1,128,36,36)] -> 035_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish), Tactic: 18, 035_convolutional_bn[Half(1,128,36,36)] -> 035_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 036_convolutional + 036_convolutional_bn, Tactic: 4772821744921268633, 035_convolutional_mish[Half(1,128,36,36)] -> 036_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut), Tactic: 18, 036_convolutional_bn[Half(1,128,36,36)], 034_shortcut[Half(1,128,36,36)] -> 037_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 038_convolutional + 038_convolutional_bn, Tactic: -1716393687483585322, 037_shortcut[Half(1,128,36,36)] -> 038_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish), Tactic: 18, 038_convolutional_bn[Half(1,128,36,36)] -> 038_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 039_convolutional + 039_convolutional_bn, Tactic: 4772821744921268633, 038_convolutional_mish[Half(1,128,36,36)] -> 039_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut), Tactic: 18, 039_convolutional_bn[Half(1,128,36,36)], 037_shortcut[Half(1,128,36,36)] -> 040_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 041_convolutional + 041_convolutional_bn, Tactic: -1716393687483585322, 040_shortcut[Half(1,128,36,36)] -> 041_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish), Tactic: 18, 041_convolutional_bn[Half(1,128,36,36)] -> 041_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 042_convolutional + 042_convolutional_bn, Tactic: 4772821744921268633, 041_convolutional_mish[Half(1,128,36,36)] -> 042_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut), Tactic: 18, 042_convolutional_bn[Half(1,128,36,36)], 040_shortcut[Half(1,128,36,36)] -> 043_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 044_convolutional + 044_convolutional_bn, Tactic: -1716393687483585322, 043_shortcut[Half(1,128,36,36)] -> 044_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish), Tactic: 18, 044_convolutional_bn[Half(1,128,36,36)] -> 044_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 045_convolutional + 045_convolutional_bn, Tactic: 4772821744921268633, 044_convolutional_mish[Half(1,128,36,36)] -> 045_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut), Tactic: 18, 045_convolutional_bn[Half(1,128,36,36)], 043_shortcut[Half(1,128,36,36)] -> 046_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 047_convolutional + 047_convolutional_bn, Tactic: -1716393687483585322, 046_shortcut[Half(1,128,36,36)] -> 047_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish), Tactic: 18, 047_convolutional_bn[Half(1,128,36,36)] -> 047_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 048_convolutional + 048_convolutional_bn, Tactic: 4772821744921268633, 047_convolutional_mish[Half(1,128,36,36)] -> 048_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut), Tactic: 18, 048_convolutional_bn[Half(1,128,36,36)], 046_shortcut[Half(1,128,36,36)] -> 049_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 050_convolutional + 050_convolutional_bn, Tactic: -1716393687483585322, 049_shortcut[Half(1,128,36,36)] -> 050_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish), Tactic: 18, 050_convolutional_bn[Half(1,128,36,36)] -> 050_convolutional_mish[Half(1,128,36,36)]
Layer(CaskConvolution): 051_convolutional + 051_convolutional_bn, Tactic: 4772821744921268633, 050_convolutional_mish[Half(1,128,36,36)] -> 051_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut), Tactic: 18, 051_convolutional_bn[Half(1,128,36,36)], 049_shortcut[Half(1,128,36,36)] -> 052_shortcut[Half(1,128,36,36)]
Layer(CaskConvolution): 053_convolutional + 053_convolutional_bn, Tactic: -1716393687483585322, 052_shortcut[Half(1,128,36,36)] -> 053_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish), Tactic: 17, 053_convolutional_bn[Half(1,128,36,36)] -> 054_route[Half(1,128,36,36)]
Layer(CaskConvolution): 055_convolutional + 055_convolutional_bn, Tactic: 8163473458334948789, 054_route[Half(1,256,36,36)] -> 055_convolutional_bn[Half(1,256,36,36)]
Layer(PointWiseV2): PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish), Tactic: 18, 055_convolutional_bn[Half(1,256,36,36)] -> 055_convolutional_mish[Half(1,256,36,36)]
Layer(CaskConvolution): 056_convolutional + 056_convolutional_bn, Tactic: -4212163711445252890, 055_convolutional_mish[Half(1,256,36,36)] -> 056_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish), Tactic: 18, 056_convolutional_bn[Half(1,512,18,18)] -> 056_convolutional_mish[Half(1,512,18,18)]
Layer(CaskConvolution): 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn, Tactic: -1716393687483585322, 056_convolutional_mish[Half(1,512,18,18)] -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish), Tactic: 17, 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn[Half(1,256,18,18)] -> 085_route[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish), Tactic: 17, 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn[Half(1,256,18,18)] -> 059_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 060_convolutional + 060_convolutional_bn, Tactic: -1716393687483585322, 059_convolutional_mish[Half(1,256,18,18)] -> 060_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish), Tactic: 18, 060_convolutional_bn[Half(1,256,18,18)] -> 060_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 061_convolutional + 061_convolutional_bn, Tactic: -4212163711445252890, 060_convolutional_mish[Half(1,256,18,18)] -> 061_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut), Tactic: 18, 061_convolutional_bn[Half(1,256,18,18)], 059_convolutional_mish[Half(1,256,18,18)] -> 062_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 063_convolutional + 063_convolutional_bn, Tactic: -1716393687483585322, 062_shortcut[Half(1,256,18,18)] -> 063_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish), Tactic: 18, 063_convolutional_bn[Half(1,256,18,18)] -> 063_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 064_convolutional + 064_convolutional_bn, Tactic: -4212163711445252890, 063_convolutional_mish[Half(1,256,18,18)] -> 064_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut), Tactic: 18, 064_convolutional_bn[Half(1,256,18,18)], 062_shortcut[Half(1,256,18,18)] -> 065_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 066_convolutional + 066_convolutional_bn, Tactic: -1716393687483585322, 065_shortcut[Half(1,256,18,18)] -> 066_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish), Tactic: 18, 066_convolutional_bn[Half(1,256,18,18)] -> 066_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 067_convolutional + 067_convolutional_bn, Tactic: -4212163711445252890, 066_convolutional_mish[Half(1,256,18,18)] -> 067_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut), Tactic: 18, 067_convolutional_bn[Half(1,256,18,18)], 065_shortcut[Half(1,256,18,18)] -> 068_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 069_convolutional + 069_convolutional_bn, Tactic: -1716393687483585322, 068_shortcut[Half(1,256,18,18)] -> 069_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish), Tactic: 18, 069_convolutional_bn[Half(1,256,18,18)] -> 069_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 070_convolutional + 070_convolutional_bn, Tactic: -4212163711445252890, 069_convolutional_mish[Half(1,256,18,18)] -> 070_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut), Tactic: 18, 070_convolutional_bn[Half(1,256,18,18)], 068_shortcut[Half(1,256,18,18)] -> 071_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 072_convolutional + 072_convolutional_bn, Tactic: -1716393687483585322, 071_shortcut[Half(1,256,18,18)] -> 072_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish), Tactic: 18, 072_convolutional_bn[Half(1,256,18,18)] -> 072_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 073_convolutional + 073_convolutional_bn, Tactic: -4212163711445252890, 072_convolutional_mish[Half(1,256,18,18)] -> 073_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut), Tactic: 18, 073_convolutional_bn[Half(1,256,18,18)], 071_shortcut[Half(1,256,18,18)] -> 074_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 075_convolutional + 075_convolutional_bn, Tactic: -1716393687483585322, 074_shortcut[Half(1,256,18,18)] -> 075_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish), Tactic: 18, 075_convolutional_bn[Half(1,256,18,18)] -> 075_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 076_convolutional + 076_convolutional_bn, Tactic: -4212163711445252890, 075_convolutional_mish[Half(1,256,18,18)] -> 076_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut), Tactic: 18, 076_convolutional_bn[Half(1,256,18,18)], 074_shortcut[Half(1,256,18,18)] -> 077_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 078_convolutional + 078_convolutional_bn, Tactic: -1716393687483585322, 077_shortcut[Half(1,256,18,18)] -> 078_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish), Tactic: 18, 078_convolutional_bn[Half(1,256,18,18)] -> 078_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 079_convolutional + 079_convolutional_bn, Tactic: -4212163711445252890, 078_convolutional_mish[Half(1,256,18,18)] -> 079_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut), Tactic: 18, 079_convolutional_bn[Half(1,256,18,18)], 077_shortcut[Half(1,256,18,18)] -> 080_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 081_convolutional + 081_convolutional_bn, Tactic: -1716393687483585322, 080_shortcut[Half(1,256,18,18)] -> 081_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish), Tactic: 18, 081_convolutional_bn[Half(1,256,18,18)] -> 081_convolutional_mish[Half(1,256,18,18)]
Layer(CaskConvolution): 082_convolutional + 082_convolutional_bn, Tactic: -4212163711445252890, 081_convolutional_mish[Half(1,256,18,18)] -> 082_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut), Tactic: 18, 082_convolutional_bn[Half(1,256,18,18)], 080_shortcut[Half(1,256,18,18)] -> 083_shortcut[Half(1,256,18,18)]
Layer(CaskConvolution): 084_convolutional + 084_convolutional_bn, Tactic: -1716393687483585322, 083_shortcut[Half(1,256,18,18)] -> 084_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish), Tactic: 17, 084_convolutional_bn[Half(1,256,18,18)] -> 085_route[Half(1,256,18,18)]
Layer(CaskConvolution): 086_convolutional + 086_convolutional_bn, Tactic: -1716393687483585322, 085_route[Half(1,512,18,18)] -> 086_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish), Tactic: 18, 086_convolutional_bn[Half(1,512,18,18)] -> 086_convolutional_mish[Half(1,512,18,18)]
Layer(CaskConvolution): 087_convolutional + 087_convolutional_bn, Tactic: -4212163711445252890, 086_convolutional_mish[Half(1,512,18,18)] -> 087_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish), Tactic: 18, 087_convolutional_bn[Half(1,1024,9,9)] -> 087_convolutional_mish[Half(1,1024,9,9)]
Layer(CaskConvolution): 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn, Tactic: -1716393687483585322, 087_convolutional_mish[Half(1,1024,9,9)] -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish), Tactic: 7, 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn[Half(1,512,9,9)] -> 104_route[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish), Tactic: 7, 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn[Half(1,512,9,9)] -> 090_convolutional_mish[Half(1,512,9,9)]
Layer(CaskConvolution): 091_convolutional + 091_convolutional_bn, Tactic: -1716393687483585322, 090_convolutional_mish[Half(1,512,9,9)] -> 091_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish), Tactic: 7, 091_convolutional_bn[Half(1,512,9,9)] -> 091_convolutional_mish[Half(1,512,9,9)]
Layer(FusedConvActConvolution): 092_convolutional + 092_convolutional_bn, Tactic: 2031615, 091_convolutional_mish[Half(1,512,9,9)] -> 092_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut), Tactic: 16, 092_convolutional_bn[Half(1,512,9,9)], 090_convolutional_mish[Half(1,512,9,9)] -> 093_shortcut[Half(1,512,9,9)]
Layer(CaskConvolution): 094_convolutional + 094_convolutional_bn, Tactic: -1716393687483585322, 093_shortcut[Half(1,512,9,9)] -> 094_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish), Tactic: 7, 094_convolutional_bn[Half(1,512,9,9)] -> 094_convolutional_mish[Half(1,512,9,9)]
Layer(FusedConvActConvolution): 095_convolutional + 095_convolutional_bn, Tactic: 2031615, 094_convolutional_mish[Half(1,512,9,9)] -> 095_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut), Tactic: 16, 095_convolutional_bn[Half(1,512,9,9)], 093_shortcut[Half(1,512,9,9)] -> 096_shortcut[Half(1,512,9,9)]
Layer(CaskConvolution): 097_convolutional + 097_convolutional_bn, Tactic: -1716393687483585322, 096_shortcut[Half(1,512,9,9)] -> 097_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish), Tactic: 7, 097_convolutional_bn[Half(1,512,9,9)] -> 097_convolutional_mish[Half(1,512,9,9)]
Layer(FusedConvActConvolution): 098_convolutional + 098_convolutional_bn, Tactic: 2031615, 097_convolutional_mish[Half(1,512,9,9)] -> 098_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut), Tactic: 16, 098_convolutional_bn[Half(1,512,9,9)], 096_shortcut[Half(1,512,9,9)] -> 099_shortcut[Half(1,512,9,9)]
Layer(CaskConvolution): 100_convolutional + 100_convolutional_bn, Tactic: -1716393687483585322, 099_shortcut[Half(1,512,9,9)] -> 100_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish), Tactic: 7, 100_convolutional_bn[Half(1,512,9,9)] -> 100_convolutional_mish[Half(1,512,9,9)]
Layer(FusedConvActConvolution): 101_convolutional + 101_convolutional_bn, Tactic: 2031615, 100_convolutional_mish[Half(1,512,9,9)] -> 101_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut), Tactic: 16, 101_convolutional_bn[Half(1,512,9,9)], 099_shortcut[Half(1,512,9,9)] -> 102_shortcut[Half(1,512,9,9)]
Layer(CaskConvolution): 103_convolutional + 103_convolutional_bn, Tactic: -1716393687483585322, 102_shortcut[Half(1,512,9,9)] -> 103_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish), Tactic: 7, 103_convolutional_bn[Half(1,512,9,9)] -> 104_route[Half(1,512,9,9)]
Layer(CaskConvolution): 105_convolutional + 105_convolutional_bn, Tactic: -1716393687483585322, 104_route[Half(1,1024,9,9)] -> 105_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish), Tactic: 18, 105_convolutional_bn[Half(1,1024,9,9)] -> 105_convolutional_mish[Half(1,1024,9,9)]
Layer(CaskConvolution): 106_convolutional + 106_convolutional_bn, Tactic: -1716393687483585322, 105_convolutional_mish[Half(1,1024,9,9)] -> 106_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(106_convolutional_lrelu), Tactic: 1, 106_convolutional_bn[Half(1,512,9,9)] -> 106_convolutional_lrelu[Half(1,512,9,9)]
Layer(CaskConvolution): 107_convolutional + 107_convolutional_bn, Tactic: -4212163711445252890, 106_convolutional_lrelu[Half(1,512,9,9)] -> 107_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(107_convolutional_lrelu), Tactic: 18, 107_convolutional_bn[Half(1,1024,9,9)] -> 107_convolutional_lrelu[Half(1,1024,9,9)]
Layer(CaskConvolution): 108_convolutional + 108_convolutional_bn, Tactic: -1716393687483585322, 107_convolutional_lrelu[Half(1,1024,9,9)] -> 108_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(108_convolutional_lrelu), Tactic: 1, 108_convolutional_bn[Half(1,512,9,9)] -> 108_convolutional_lrelu[Half(1,512,9,9)]
Layer(TiledPooling): 109_maxpool, Tactic: 7735561, 108_convolutional_lrelu[Half(1,512,9,9)] -> 109_maxpool[Half(1,512,9,9)]
Layer(CudaPooling): 111_maxpool, Tactic: -3, 108_convolutional_lrelu[Half(1,512,9,9)] -> 111_maxpool[Half(1,512,9,9)]
Layer(CudaPooling): 113_maxpool, Tactic: -3, 108_convolutional_lrelu[Half(1,512,9,9)] -> 113_maxpool[Half(1,512,9,9)]
Layer(Reformat): 113_maxpool copy, Tactic: 0, 113_maxpool[Half(1,512,9,9)] -> 114_route[Half(1,512,9,9)]
Layer(Reformat): 111_maxpool copy, Tactic: 0, 111_maxpool[Half(1,512,9,9)] -> 114_route[Half(1,512,9,9)]
Layer(Reformat): 109_maxpool copy, Tactic: 0, 109_maxpool[Half(1,512,9,9)] -> 114_route[Half(1,512,9,9)]
Layer(Reformat): 108_convolutional_lrelu copy, Tactic: 0, 108_convolutional_lrelu[Half(1,512,9,9)] -> 114_route[Half(1,512,9,9)]
Layer(CaskConvolution): 115_convolutional + 115_convolutional_bn, Tactic: -1716393687483585322, 114_route[Half(1,2048,9,9)] -> 115_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(115_convolutional_lrelu), Tactic: 1, 115_convolutional_bn[Half(1,512,9,9)] -> 115_convolutional_lrelu[Half(1,512,9,9)]
Layer(CaskConvolution): 116_convolutional + 116_convolutional_bn, Tactic: -4212163711445252890, 115_convolutional_lrelu[Half(1,512,9,9)] -> 116_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(116_convolutional_lrelu), Tactic: 18, 116_convolutional_bn[Half(1,1024,9,9)] -> 116_convolutional_lrelu[Half(1,1024,9,9)]
Layer(CaskConvolution): 117_convolutional + 117_convolutional_bn, Tactic: -1716393687483585322, 116_convolutional_lrelu[Half(1,1024,9,9)] -> 117_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(117_convolutional_lrelu), Tactic: 2, 117_convolutional_bn[Half(1,512,9,9)] -> 154_route[Half(1,512,9,9)]
Layer(CaskConvolution): 118_convolutional + 118_convolutional_bn, Tactic: -1716393687483585322, 154_route[Half(1,512,9,9)] -> 118_convolutional_bn[Half(1,256,9,9)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to PWN(118_convolutional_lrelu), Tactic: 0, 118_convolutional_bn[Half(1,256,9,9)] -> Reformatted Input Tensor 0 to PWN(118_convolutional_lrelu)[Float(1,256,9,9)]
Layer(PointWiseV2): PWN(118_convolutional_lrelu), Tactic: 8, Reformatted Input Tensor 0 to PWN(118_convolutional_lrelu)[Float(1,256,9,9)] -> 118_convolutional_lrelu[Float(1,256,9,9)]
Layer(Resize): 119_upsample, Tactic: 0, 118_convolutional_lrelu[Float(1,256,9,9)] -> 119_upsample[Float(1,256,18,18)]
Layer(CaskConvolution): 121_convolutional + 121_convolutional_bn, Tactic: -1716393687483585322, 086_convolutional_mish[Half(1,512,18,18)] -> 121_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(121_convolutional_lrelu), Tactic: 17, 121_convolutional_bn[Half(1,256,18,18)] -> 122_route[Half(1,256,18,18)]
Layer(Reformat): 119_upsample copy, Tactic: 0, 119_upsample[Float(1,256,18,18)] -> 122_route[Half(1,256,18,18)]
Layer(CaskConvolution): 123_convolutional + 123_convolutional_bn, Tactic: -1716393687483585322, 122_route[Half(1,512,18,18)] -> 123_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(123_convolutional_lrelu), Tactic: 18, 123_convolutional_bn[Half(1,256,18,18)] -> 123_convolutional_lrelu[Half(1,256,18,18)]
Layer(CaskConvolution): 124_convolutional + 124_convolutional_bn, Tactic: -3898373634979201110, 123_convolutional_lrelu[Half(1,256,18,18)] -> 124_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(124_convolutional_lrelu), Tactic: 18, 124_convolutional_bn[Half(1,512,18,18)] -> 124_convolutional_lrelu[Half(1,512,18,18)]
Layer(CaskConvolution): 125_convolutional + 125_convolutional_bn, Tactic: -1716393687483585322, 124_convolutional_lrelu[Half(1,512,18,18)] -> 125_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(125_convolutional_lrelu), Tactic: 18, 125_convolutional_bn[Half(1,256,18,18)] -> 125_convolutional_lrelu[Half(1,256,18,18)]
Layer(CaskConvolution): 126_convolutional + 126_convolutional_bn, Tactic: -3898373634979201110, 125_convolutional_lrelu[Half(1,256,18,18)] -> 126_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(126_convolutional_lrelu), Tactic: 18, 126_convolutional_bn[Half(1,512,18,18)] -> 126_convolutional_lrelu[Half(1,512,18,18)]
Layer(CaskConvolution): 127_convolutional + 127_convolutional_bn, Tactic: -1716393687483585322, 126_convolutional_lrelu[Half(1,512,18,18)] -> 127_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(127_convolutional_lrelu), Tactic: 17, 127_convolutional_bn[Half(1,256,18,18)] -> 143_route[Half(1,256,18,18)]
Layer(CaskConvolution): 128_convolutional + 128_convolutional_bn, Tactic: -1716393687483585322, 143_route[Half(1,256,18,18)] -> 128_convolutional_bn[Half(1,128,18,18)]
Layer(PointWiseV2): PWN(128_convolutional_lrelu), Tactic: 6, 128_convolutional_bn[Half(1,128,18,18)] -> 128_convolutional_lrelu[Half(1,128,18,18)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 129_upsample, Tactic: 0, 128_convolutional_lrelu[Half(1,128,18,18)] -> Reformatted Input Tensor 0 to 129_upsample[Float(1,128,18,18)]
Layer(Resize): 129_upsample, Tactic: 0, Reformatted Input Tensor 0 to 129_upsample[Float(1,128,18,18)] -> 129_upsample[Float(1,128,36,36)]
Layer(CaskConvolution): 131_convolutional + 131_convolutional_bn, Tactic: -1716393687483585322, 055_convolutional_mish[Half(1,256,36,36)] -> 131_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(131_convolutional_lrelu), Tactic: 17, 131_convolutional_bn[Half(1,128,36,36)] -> 132_route[Half(1,128,36,36)]
Layer(Reformat): 129_upsample copy, Tactic: 0, 129_upsample[Float(1,128,36,36)] -> 132_route[Half(1,128,36,36)]
Layer(CaskConvolution): 133_convolutional + 133_convolutional_bn, Tactic: -1716393687483585322, 132_route[Half(1,256,36,36)] -> 133_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(133_convolutional_lrelu), Tactic: 18, 133_convolutional_bn[Half(1,128,36,36)] -> 133_convolutional_lrelu[Half(1,128,36,36)]
Layer(CaskConvolution): 134_convolutional + 134_convolutional_bn, Tactic: 4772821744921268633, 133_convolutional_lrelu[Half(1,128,36,36)] -> 134_convolutional_bn[Half(1,256,36,36)]
Layer(PointWiseV2): PWN(134_convolutional_lrelu), Tactic: 18, 134_convolutional_bn[Half(1,256,36,36)] -> 134_convolutional_lrelu[Half(1,256,36,36)]
Layer(CaskConvolution): 135_convolutional + 135_convolutional_bn, Tactic: -1716393687483585322, 134_convolutional_lrelu[Half(1,256,36,36)] -> 135_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(135_convolutional_lrelu), Tactic: 18, 135_convolutional_bn[Half(1,128,36,36)] -> 135_convolutional_lrelu[Half(1,128,36,36)]
Layer(CaskConvolution): 136_convolutional + 136_convolutional_bn, Tactic: 4772821744921268633, 135_convolutional_lrelu[Half(1,128,36,36)] -> 136_convolutional_bn[Half(1,256,36,36)]
Layer(PointWiseV2): PWN(136_convolutional_lrelu), Tactic: 18, 136_convolutional_bn[Half(1,256,36,36)] -> 136_convolutional_lrelu[Half(1,256,36,36)]
Layer(CaskConvolution): 137_convolutional + 137_convolutional_bn, Tactic: -1716393687483585322, 136_convolutional_lrelu[Half(1,256,36,36)] -> 137_convolutional_bn[Half(1,128,36,36)]
Layer(PointWiseV2): PWN(137_convolutional_lrelu), Tactic: 18, 137_convolutional_bn[Half(1,128,36,36)] -> 137_convolutional_lrelu[Half(1,128,36,36)]
Layer(CaskConvolution): 138_convolutional + 138_convolutional_bn, Tactic: 4772821744921268633, 137_convolutional_lrelu[Half(1,128,36,36)] -> 138_convolutional_bn[Half(1,256,36,36)]
Layer(PointWiseV2): PWN(138_convolutional_lrelu), Tactic: 18, 138_convolutional_bn[Half(1,256,36,36)] -> 138_convolutional_lrelu[Half(1,256,36,36)]
Layer(CaskConvolution): 139_convolutional, Tactic: -1716393687483585322, 138_convolutional_lrelu[Half(1,256,36,36)] -> Reformatted Output Tensor 0 to 139_convolutional[Half(1,255,36,36)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to 139_convolutional, Tactic: 0, Reformatted Output Tensor 0 to 139_convolutional[Half(1,255,36,36)] -> 139_convolutional[Float(1,255,36,36)]
Layer(CaskConvolution): 142_convolutional + 142_convolutional_bn, Tactic: -4212163711445252890, 137_convolutional_lrelu[Half(1,128,36,36)] -> 142_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(142_convolutional_lrelu), Tactic: 17, 142_convolutional_bn[Half(1,256,18,18)] -> 143_route[Half(1,256,18,18)]
Layer(CaskConvolution): 144_convolutional + 144_convolutional_bn, Tactic: -1716393687483585322, 143_route[Half(1,512,18,18)] -> 144_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(144_convolutional_lrelu), Tactic: 18, 144_convolutional_bn[Half(1,256,18,18)] -> 144_convolutional_lrelu[Half(1,256,18,18)]
Layer(CaskConvolution): 145_convolutional + 145_convolutional_bn, Tactic: -3898373634979201110, 144_convolutional_lrelu[Half(1,256,18,18)] -> 145_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(145_convolutional_lrelu), Tactic: 18, 145_convolutional_bn[Half(1,512,18,18)] -> 145_convolutional_lrelu[Half(1,512,18,18)]
Layer(CaskConvolution): 146_convolutional + 146_convolutional_bn, Tactic: -1716393687483585322, 145_convolutional_lrelu[Half(1,512,18,18)] -> 146_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(146_convolutional_lrelu), Tactic: 18, 146_convolutional_bn[Half(1,256,18,18)] -> 146_convolutional_lrelu[Half(1,256,18,18)]
Layer(CaskConvolution): 147_convolutional + 147_convolutional_bn, Tactic: -3898373634979201110, 146_convolutional_lrelu[Half(1,256,18,18)] -> 147_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(147_convolutional_lrelu), Tactic: 18, 147_convolutional_bn[Half(1,512,18,18)] -> 147_convolutional_lrelu[Half(1,512,18,18)]
Layer(CaskConvolution): 148_convolutional + 148_convolutional_bn, Tactic: -1716393687483585322, 147_convolutional_lrelu[Half(1,512,18,18)] -> 148_convolutional_bn[Half(1,256,18,18)]
Layer(PointWiseV2): PWN(148_convolutional_lrelu), Tactic: 18, 148_convolutional_bn[Half(1,256,18,18)] -> 148_convolutional_lrelu[Half(1,256,18,18)]
Layer(CaskConvolution): 149_convolutional + 149_convolutional_bn, Tactic: -3898373634979201110, 148_convolutional_lrelu[Half(1,256,18,18)] -> 149_convolutional_bn[Half(1,512,18,18)]
Layer(PointWiseV2): PWN(149_convolutional_lrelu), Tactic: 18, 149_convolutional_bn[Half(1,512,18,18)] -> 149_convolutional_lrelu[Half(1,512,18,18)]
Layer(CaskConvolution): 150_convolutional, Tactic: -1716393687483585322, 149_convolutional_lrelu[Half(1,512,18,18)] -> Reformatted Output Tensor 0 to 150_convolutional[Half(1,255,18,18)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to 150_convolutional, Tactic: 0, Reformatted Output Tensor 0 to 150_convolutional[Half(1,255,18,18)] -> 150_convolutional[Float(1,255,18,18)]
Layer(CaskConvolution): 153_convolutional + 153_convolutional_bn, Tactic: -4212163711445252890, 148_convolutional_lrelu[Half(1,256,18,18)] -> 153_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(153_convolutional_lrelu), Tactic: 2, 153_convolutional_bn[Half(1,512,9,9)] -> 154_route[Half(1,512,9,9)]
Layer(CaskConvolution): 155_convolutional + 155_convolutional_bn, Tactic: -1716393687483585322, 154_route[Half(1,1024,9,9)] -> 155_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(155_convolutional_lrelu), Tactic: 1, 155_convolutional_bn[Half(1,512,9,9)] -> 155_convolutional_lrelu[Half(1,512,9,9)]
Layer(CaskConvolution): 156_convolutional + 156_convolutional_bn, Tactic: -4212163711445252890, 155_convolutional_lrelu[Half(1,512,9,9)] -> 156_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(156_convolutional_lrelu), Tactic: 18, 156_convolutional_bn[Half(1,1024,9,9)] -> 156_convolutional_lrelu[Half(1,1024,9,9)]
Layer(CaskConvolution): 157_convolutional + 157_convolutional_bn, Tactic: -1716393687483585322, 156_convolutional_lrelu[Half(1,1024,9,9)] -> 157_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(157_convolutional_lrelu), Tactic: 1, 157_convolutional_bn[Half(1,512,9,9)] -> 157_convolutional_lrelu[Half(1,512,9,9)]
Layer(CaskConvolution): 158_convolutional + 158_convolutional_bn, Tactic: -4212163711445252890, 157_convolutional_lrelu[Half(1,512,9,9)] -> 158_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(158_convolutional_lrelu), Tactic: 18, 158_convolutional_bn[Half(1,1024,9,9)] -> 158_convolutional_lrelu[Half(1,1024,9,9)]
Layer(CaskConvolution): 159_convolutional + 159_convolutional_bn, Tactic: -1716393687483585322, 158_convolutional_lrelu[Half(1,1024,9,9)] -> 159_convolutional_bn[Half(1,512,9,9)]
Layer(PointWiseV2): PWN(159_convolutional_lrelu), Tactic: 1, 159_convolutional_bn[Half(1,512,9,9)] -> 159_convolutional_lrelu[Half(1,512,9,9)]
Layer(CaskConvolution): 160_convolutional + 160_convolutional_bn, Tactic: -4212163711445252890, 159_convolutional_lrelu[Half(1,512,9,9)] -> 160_convolutional_bn[Half(1,1024,9,9)]
Layer(PointWiseV2): PWN(160_convolutional_lrelu), Tactic: 18, 160_convolutional_bn[Half(1,1024,9,9)] -> 160_convolutional_lrelu[Half(1,1024,9,9)]
Layer(CaskConvolution): 161_convolutional, Tactic: -1716393687483585322, 160_convolutional_lrelu[Half(1,1024,9,9)] -> Reformatted Output Tensor 0 to 161_convolutional[Half(1,255,9,9)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to 161_convolutional, Tactic: 0, Reformatted Output Tensor 0 to 161_convolutional[Half(1,255,9,9)] -> 161_convolutional[Float(1,255,9,9)]
[05/21/2022-02:58:04] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +123, GPU +256, now: CPU 123, GPU 256 (MiB)
[05/21/2022-02:58:04] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1313, GPU 3862 (MiB)
[05/21/2022-02:58:04] [I] [TRT] Loaded engine size: 133 MiB
[05/21/2022-02:58:04] [V] [TRT] Using cublas as a tactic source
[05/21/2022-02:58:04] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 1324, GPU 3868 (MiB)
[05/21/2022-02:58:04] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-02:58:04] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +1, now: CPU 1324, GPU 3869 (MiB)
[05/21/2022-02:58:04] [V] [TRT] Deserialization required 423152 microseconds.
[05/21/2022-02:58:04] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +131, now: CPU 0, GPU 131 (MiB)
[05/21/2022-02:58:05] [I] Engine built in 654.883 sec.
[05/21/2022-02:58:05] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 913, GPU 3738 (MiB)
[05/21/2022-02:58:05] [I] [TRT] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/21/2022-02:58:05] [V] [TRT] Using cublas as a tactic source
[05/21/2022-02:58:05] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 913, GPU 3739 (MiB)
[05/21/2022-02:58:05] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-02:58:05] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +1, now: CPU 913, GPU 3741 (MiB)
[05/21/2022-02:58:05] [V] [TRT] Total per-runner device persistent memory is 118987264
[05/21/2022-02:58:05] [V] [TRT] Total per-runner host persistent memory is 285024
[05/21/2022-02:58:05] [V] [TRT] Allocated activation device memory of size 16257024
[05/21/2022-02:58:05] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +129, now: CPU 0, GPU 260 (MiB)
[05/21/2022-02:58:05] [I] Using random values for input 000_net
[05/21/2022-02:58:05] [I] Created input binding for 000_net with dimensions 1x3x288x288
[05/21/2022-02:58:05] [I] Using random values for output 139_convolutional
[05/21/2022-02:58:05] [I] Created output binding for 139_convolutional with dimensions 1x255x36x36
[05/21/2022-02:58:05] [I] Using random values for output 150_convolutional
[05/21/2022-02:58:05] [I] Created output binding for 150_convolutional with dimensions 1x255x18x18
[05/21/2022-02:58:05] [I] Using random values for output 161_convolutional
[05/21/2022-02:58:05] [I] Created output binding for 161_convolutional with dimensions 1x255x9x9
[05/21/2022-02:58:05] [I] Starting inference
[05/21/2022-02:58:09] [I] Warmup completed 2 queries over 200 ms
[05/21/2022-02:58:09] [I] Timing trace has 29 queries over 3.26552 s
[05/21/2022-02:58:09] [I] 
[05/21/2022-02:58:09] [I] === Trace details ===
[05/21/2022-02:58:09] [I] Trace averages of 10 runs:
[05/21/2022-02:58:09] [I] Average on 10 runs - GPU latency: 112.2 ms - Host latency: 112.479 ms (end to end 112.488 ms, enqueue 11.4416 ms)
[05/21/2022-02:58:09] [I] Average on 10 runs - GPU latency: 112.432 ms - Host latency: 112.713 ms (end to end 112.727 ms, enqueue 7.94609 ms)
[05/21/2022-02:58:09] [I] 
[05/21/2022-02:58:09] [I] === Performance summary ===
[05/21/2022-02:58:09] [I] Throughput: 8.88067 qps
[05/21/2022-02:58:09] [I] Latency: min = 112.149 ms, max = 114.128 ms, mean = 112.572 ms, median = 112.4 ms, percentile(99%) = 114.128 ms
[05/21/2022-02:58:09] [I] End-to-End Host Latency: min = 112.159 ms, max = 114.138 ms, mean = 112.603 ms, median = 112.409 ms, percentile(99%) = 114.138 ms
[05/21/2022-02:58:09] [I] Enqueue Time: min = 7.27844 ms, max = 14.6394 ms, mean = 10.1955 ms, median = 10.3503 ms, percentile(99%) = 14.6394 ms
[05/21/2022-02:58:09] [I] H2D Latency: min = 0.0944824 ms, max = 0.100586 ms, mean = 0.0969228 ms, median = 0.0966797 ms, percentile(99%) = 0.100586 ms
[05/21/2022-02:58:09] [I] GPU Compute Time: min = 111.875 ms, max = 113.847 ms, mean = 112.292 ms, median = 112.122 ms, percentile(99%) = 113.847 ms
[05/21/2022-02:58:09] [I] D2H Latency: min = 0.177917 ms, max = 0.187622 ms, mean = 0.182636 ms, median = 0.182373 ms, percentile(99%) = 0.187622 ms
[05/21/2022-02:58:09] [I] Total Host Walltime: 3.26552 s
[05/21/2022-02:58:09] [I] Total GPU Compute Time: 3.25648 s
[05/21/2022-02:58:09] [I] Explanations of the performance metrics are printed in the verbose logs.
[05/21/2022-02:58:09] [V] 
[05/21/2022-02:58:09] [V] === Explanations of the performance metrics ===
[05/21/2022-02:58:09] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[05/21/2022-02:58:09] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[05/21/2022-02:58:09] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[05/21/2022-02:58:09] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[05/21/2022-02:58:09] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[05/21/2022-02:58:09] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[05/21/2022-02:58:09] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[05/21/2022-02:58:09] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[05/21/2022-02:58:09] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.
[05/21/2022-02:58:09] [I] 
[05/21/2022-02:58:13] [I] 
[05/21/2022-02:58:13] [I] === Profile (30 iterations ) ===
[05/21/2022-02:58:13] [I]                                                                                                              Layer   Time (ms)   Avg. Time (ms)   Time %
[05/21/2022-02:58:13] [I]                               Reformatting CopyNode for Input Tensor 0 to 001_convolutional + 001_convolutional_bn       16.23           0.5410      0.5
[05/21/2022-02:58:13] [I]                                                                           001_convolutional + 001_convolutional_bn       64.71           2.1572      1.9
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish)       65.53           2.1843      1.9
[05/21/2022-02:58:13] [I]                                                                           002_convolutional + 002_convolutional_bn       68.68           2.2892      2.0
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish)       25.88           0.8626      0.7
[05/21/2022-02:58:13] [I]                               003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn       45.82           1.5273      1.3
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish)       27.28           0.9093      0.8
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish)       27.58           0.9194      0.8
[05/21/2022-02:58:13] [I]                                                                           006_convolutional + 006_convolutional_bn       15.58           0.5192      0.5
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish)       13.04           0.4347      0.4
[05/21/2022-02:58:13] [I]                                                                           007_convolutional + 007_convolutional_bn       60.77           2.0256      1.8
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut)       37.48           1.2493      1.1
[05/21/2022-02:58:13] [I]                                                                           009_convolutional + 009_convolutional_bn       23.32           0.7772      0.7
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish)       27.89           0.9297      0.8
[05/21/2022-02:58:13] [I]                                                                           011_convolutional + 011_convolutional_bn       35.95           1.1983      1.0
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish)       25.95           0.8650      0.8
[05/21/2022-02:58:13] [I]                                                                           012_convolutional + 012_convolutional_bn       64.75           2.1583      1.9
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish)       13.01           0.4338      0.4
[05/21/2022-02:58:13] [I]                               013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn       18.65           0.6218      0.5
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish)        7.04           0.2347      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish)        7.02           0.2339      0.2
[05/21/2022-02:58:13] [I]                                                                           016_convolutional + 016_convolutional_bn        6.11           0.2038      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish)        6.64           0.2213      0.2
[05/21/2022-02:58:13] [I]                                                                           017_convolutional + 017_convolutional_bn       26.52           0.8841      0.8
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut)        8.13           0.2709      0.2
[05/21/2022-02:58:13] [I]                                                                           019_convolutional + 019_convolutional_bn        6.45           0.2151      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish)        6.67           0.2222      0.2
[05/21/2022-02:58:13] [I]                                                                           020_convolutional + 020_convolutional_bn       26.38           0.8793      0.8
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut)        8.09           0.2698      0.2
[05/21/2022-02:58:13] [I]                                                                           022_convolutional + 022_convolutional_bn        6.44           0.2147      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish)        7.05           0.2349      0.2
[05/21/2022-02:58:13] [I]                                                                           024_convolutional + 024_convolutional_bn       18.36           0.6119      0.5
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish)       13.01           0.4338      0.4
[05/21/2022-02:58:13] [I]                                                                           025_convolutional + 025_convolutional_bn       66.86           2.2287      1.9
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish)        6.59           0.2196      0.2
[05/21/2022-02:58:13] [I]                               026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn       17.23           0.5742      0.5
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish)        3.58           0.1193      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish)        3.46           0.1153      0.1
[05/21/2022-02:58:13] [I]                                                                           029_convolutional + 029_convolutional_bn        5.46           0.1819      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish)        3.39           0.1131      0.1
[05/21/2022-02:58:13] [I]                                                                           030_convolutional + 030_convolutional_bn       31.74           1.0582      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut)        4.09           0.1362      0.1
[05/21/2022-02:58:13] [I]                                                                           032_convolutional + 032_convolutional_bn        5.40           0.1798      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish)        3.37           0.1122      0.1
[05/21/2022-02:58:13] [I]                                                                           033_convolutional + 033_convolutional_bn       30.99           1.0330      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut)        3.97           0.1323      0.1
[05/21/2022-02:58:13] [I]                                                                           035_convolutional + 035_convolutional_bn        5.25           0.1748      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish)        3.29           0.1097      0.1
[05/21/2022-02:58:13] [I]                                                                           036_convolutional + 036_convolutional_bn       30.77           1.0257      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut)        4.04           0.1346      0.1
[05/21/2022-02:58:13] [I]                                                                           038_convolutional + 038_convolutional_bn        5.24           0.1747      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish)        3.31           0.1103      0.1
[05/21/2022-02:58:13] [I]                                                                           039_convolutional + 039_convolutional_bn       30.94           1.0313      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut)        4.04           0.1346      0.1
[05/21/2022-02:58:13] [I]                                                                           041_convolutional + 041_convolutional_bn        5.23           0.1745      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish)        3.27           0.1089      0.1
[05/21/2022-02:58:13] [I]                                                                           042_convolutional + 042_convolutional_bn       30.86           1.0287      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut)        4.05           0.1349      0.1
[05/21/2022-02:58:13] [I]                                                                           044_convolutional + 044_convolutional_bn        5.24           0.1745      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish)        3.27           0.1091      0.1
[05/21/2022-02:58:13] [I]                                                                           045_convolutional + 045_convolutional_bn       30.91           1.0302      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut)        4.06           0.1355      0.1
[05/21/2022-02:58:13] [I]                                                                           047_convolutional + 047_convolutional_bn        5.25           0.1751      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish)        3.24           0.1081      0.1
[05/21/2022-02:58:13] [I]                                                                           048_convolutional + 048_convolutional_bn       30.76           1.0253      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut)        4.05           0.1351      0.1
[05/21/2022-02:58:13] [I]                                                                           050_convolutional + 050_convolutional_bn        5.25           0.1751      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish)        3.22           0.1073      0.1
[05/21/2022-02:58:13] [I]                                                                           051_convolutional + 051_convolutional_bn       30.92           1.0305      0.9
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut)        4.04           0.1348      0.1
[05/21/2022-02:58:13] [I]                                                                           053_convolutional + 053_convolutional_bn        5.20           0.1735      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish)        3.51           0.1168      0.1
[05/21/2022-02:58:13] [I]                                                                           055_convolutional + 055_convolutional_bn       16.74           0.5582      0.5
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish)        6.04           0.2014      0.2
[05/21/2022-02:58:13] [I]                                                                           056_convolutional + 056_convolutional_bn       69.87           2.3290      2.0
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish)        3.18           0.1059      0.1
[05/21/2022-02:58:13] [I]                               057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn       16.81           0.5603      0.5
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish)        1.80           0.0601      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish)        1.78           0.0593      0.1
[05/21/2022-02:58:13] [I]                                                                           060_convolutional + 060_convolutional_bn        4.63           0.1545      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish)        1.70           0.0568      0.0
[05/21/2022-02:58:13] [I]                                                                           061_convolutional + 061_convolutional_bn       34.89           1.1630      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut)        2.03           0.0678      0.1
[05/21/2022-02:58:13] [I]                                                                           063_convolutional + 063_convolutional_bn        4.95           0.1651      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish)        1.70           0.0567      0.0
[05/21/2022-02:58:13] [I]                                                                           064_convolutional + 064_convolutional_bn       34.92           1.1641      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut)        2.08           0.0693      0.1
[05/21/2022-02:58:13] [I]                                                                           066_convolutional + 066_convolutional_bn        4.96           0.1654      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish)        1.68           0.0559      0.0
[05/21/2022-02:58:13] [I]                                                                           067_convolutional + 067_convolutional_bn       34.90           1.1633      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut)        2.09           0.0696      0.1
[05/21/2022-02:58:13] [I]                                                                           069_convolutional + 069_convolutional_bn        4.95           0.1649      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish)        1.66           0.0555      0.0
[05/21/2022-02:58:13] [I]                                                                           070_convolutional + 070_convolutional_bn       35.02           1.1674      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut)        2.12           0.0708      0.1
[05/21/2022-02:58:13] [I]                                                                           072_convolutional + 072_convolutional_bn        4.94           0.1648      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish)        1.67           0.0557      0.0
[05/21/2022-02:58:13] [I]                                                                           073_convolutional + 073_convolutional_bn       34.89           1.1631      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut)        2.11           0.0703      0.1
[05/21/2022-02:58:13] [I]                                                                           075_convolutional + 075_convolutional_bn        4.93           0.1644      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish)        1.67           0.0557      0.0
[05/21/2022-02:58:13] [I]                                                                           076_convolutional + 076_convolutional_bn       34.95           1.1651      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut)        2.13           0.0709      0.1
[05/21/2022-02:58:13] [I]                                                                           078_convolutional + 078_convolutional_bn        4.93           0.1644      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish)        1.69           0.0565      0.0
[05/21/2022-02:58:13] [I]                                                                           079_convolutional + 079_convolutional_bn       34.95           1.1650      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut)        2.12           0.0707      0.1
[05/21/2022-02:58:13] [I]                                                                           081_convolutional + 081_convolutional_bn        4.93           0.1644      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish)        1.69           0.0563      0.0
[05/21/2022-02:58:13] [I]                                                                           082_convolutional + 082_convolutional_bn       34.92           1.1641      1.0
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut)        2.13           0.0711      0.1
[05/21/2022-02:58:13] [I]                                                                           084_convolutional + 084_convolutional_bn        4.93           0.1644      0.1
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish)        1.84           0.0613      0.1
[05/21/2022-02:58:13] [I]                                                                           086_convolutional + 086_convolutional_bn       16.47           0.5490      0.5
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish)        3.02           0.1008      0.1
[05/21/2022-02:58:13] [I]                                                                           087_convolutional + 087_convolutional_bn       92.29           3.0762      2.7
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish)        1.61           0.0537      0.0
[05/21/2022-02:58:13] [I]                               088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn       21.08           0.7025      0.6
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish)        1.07           0.0357      0.0
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish)        1.09           0.0363      0.0
[05/21/2022-02:58:13] [I]                                                                           091_convolutional + 091_convolutional_bn        5.73           0.1910      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish)        1.03           0.0343      0.0
[05/21/2022-02:58:13] [I]                                                                           092_convolutional + 092_convolutional_bn       41.08           1.3695      1.2
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut)        1.15           0.0385      0.0
[05/21/2022-02:58:13] [I]                                                                           094_convolutional + 094_convolutional_bn        6.00           0.2000      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish)        1.02           0.0340      0.0
[05/21/2022-02:58:13] [I]                                                                           095_convolutional + 095_convolutional_bn       40.87           1.3623      1.2
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut)        1.15           0.0384      0.0
[05/21/2022-02:58:13] [I]                                                                           097_convolutional + 097_convolutional_bn        6.01           0.2003      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish)        1.00           0.0332      0.0
[05/21/2022-02:58:13] [I]                                                                           098_convolutional + 098_convolutional_bn       40.77           1.3589      1.2
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut)        1.17           0.0391      0.0
[05/21/2022-02:58:13] [I]                                                                           100_convolutional + 100_convolutional_bn        5.98           0.1992      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish)        1.03           0.0343      0.0
[05/21/2022-02:58:13] [I]                                                                           101_convolutional + 101_convolutional_bn       40.78           1.3595      1.2
[05/21/2022-02:58:13] [I]  PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut)        1.18           0.0393      0.0
[05/21/2022-02:58:13] [I]                                                                           103_convolutional + 103_convolutional_bn        5.98           0.1992      0.2
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish)        0.96           0.0320      0.0
[05/21/2022-02:58:13] [I]                                                                           105_convolutional + 105_convolutional_bn       20.71           0.6903      0.6
[05/21/2022-02:58:13] [I]                     PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish)        1.72           0.0572      0.0
[05/21/2022-02:58:13] [I]                                                                           106_convolutional + 106_convolutional_bn       10.50           0.3500      0.3
[05/21/2022-02:58:13] [I]                                                                                       PWN(106_convolutional_lrelu)        0.66           0.0219      0.0
[05/21/2022-02:58:13] [I]                                                                           107_convolutional + 107_convolutional_bn       91.21           3.0405      2.6
[05/21/2022-02:58:13] [I]                                                                                       PWN(107_convolutional_lrelu)        0.87           0.0289      0.0
[05/21/2022-02:58:13] [I]                                                                           108_convolutional + 108_convolutional_bn       10.74           0.3580      0.3
[05/21/2022-02:58:13] [I]                                                                                       PWN(108_convolutional_lrelu)        0.69           0.0229      0.0
[05/21/2022-02:58:13] [I]                                                                                                        109_maxpool        3.37           0.1122      0.1
[05/21/2022-02:58:13] [I]                                                                                                        111_maxpool        7.77           0.2589      0.2
[05/21/2022-02:58:13] [I]                                                                                                        113_maxpool       12.75           0.4250      0.4
[05/21/2022-02:58:13] [I]                                                                                                   113_maxpool copy        0.34           0.0114      0.0
[05/21/2022-02:58:13] [I]                                                                                                   111_maxpool copy        0.43           0.0142      0.0
[05/21/2022-02:58:13] [I]                                                                                                   109_maxpool copy        0.42           0.0139      0.0
[05/21/2022-02:58:13] [I]                                                                                       108_convolutional_lrelu copy        0.42           0.0139      0.0
[05/21/2022-02:58:13] [I]                                                                           115_convolutional + 115_convolutional_bn       20.36           0.6788      0.6
[05/21/2022-02:58:13] [I]                                                                                       PWN(115_convolutional_lrelu)        0.67           0.0223      0.0
[05/21/2022-02:58:13] [I]                                                                           116_convolutional + 116_convolutional_bn       91.37           3.0456      2.6
[05/21/2022-02:58:13] [I]                                                                                       PWN(116_convolutional_lrelu)        0.87           0.0289      0.0
[05/21/2022-02:58:13] [I]                                                                           117_convolutional + 117_convolutional_bn       10.69           0.3562      0.3
[05/21/2022-02:58:13] [I]                                                                                       PWN(117_convolutional_lrelu)        0.74           0.0246      0.0
[05/21/2022-02:58:13] [I]                                                                           118_convolutional + 118_convolutional_bn        3.21           0.1070      0.1
[05/21/2022-02:58:13] [I]                                           Reformatting CopyNode for Input Tensor 0 to PWN(118_convolutional_lrelu)        0.56           0.0188      0.0
[05/21/2022-02:58:13] [I]                                                                                       PWN(118_convolutional_lrelu)        0.28           0.0095      0.0
[05/21/2022-02:58:13] [I]                                                                                                       119_upsample        2.26           0.0754      0.1
[05/21/2022-02:58:13] [I]                                                                           121_convolutional + 121_convolutional_bn        8.47           0.2822      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(121_convolutional_lrelu)        1.01           0.0335      0.0
[05/21/2022-02:58:13] [I]                                                                                                  119_upsample copy        2.17           0.0724      0.1
[05/21/2022-02:58:13] [I]                                                                           123_convolutional + 123_convolutional_bn        8.38           0.2794      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(123_convolutional_lrelu)        0.88           0.0292      0.0
[05/21/2022-02:58:13] [I]                                                                           124_convolutional + 124_convolutional_bn       70.86           2.3621      2.1
[05/21/2022-02:58:13] [I]                                                                                       PWN(124_convolutional_lrelu)        1.58           0.0527      0.0
[05/21/2022-02:58:13] [I]                                                                           125_convolutional + 125_convolutional_bn        8.63           0.2876      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(125_convolutional_lrelu)        0.88           0.0295      0.0
[05/21/2022-02:58:13] [I]                                                                           126_convolutional + 126_convolutional_bn       70.38           2.3460      2.0
[05/21/2022-02:58:13] [I]                                                                                       PWN(126_convolutional_lrelu)        1.58           0.0528      0.0
[05/21/2022-02:58:13] [I]                                                                           127_convolutional + 127_convolutional_bn        8.61           0.2871      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(127_convolutional_lrelu)        0.98           0.0327      0.0
[05/21/2022-02:58:13] [I]                                                                           128_convolutional + 128_convolutional_bn        2.46           0.0822      0.1
[05/21/2022-02:58:13] [I]                                                                                       PWN(128_convolutional_lrelu)        0.57           0.0191      0.0
[05/21/2022-02:58:13] [I]                                                           Reformatting CopyNode for Input Tensor 0 to 129_upsample        0.99           0.0329      0.0
[05/21/2022-02:58:13] [I]                                                                                                       129_upsample        4.36           0.1455      0.1
[05/21/2022-02:58:13] [I]                                                                           131_convolutional + 131_convolutional_bn        8.31           0.2771      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(131_convolutional_lrelu)        1.82           0.0608      0.1
[05/21/2022-02:58:13] [I]                                                                                                  129_upsample copy        4.22           0.1406      0.1
[05/21/2022-02:58:13] [I]                                                                           133_convolutional + 133_convolutional_bn        8.26           0.2754      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(133_convolutional_lrelu)        1.62           0.0539      0.0
[05/21/2022-02:58:13] [I]                                                                           134_convolutional + 134_convolutional_bn       61.11           2.0370      1.8
[05/21/2022-02:58:13] [I]                                                                                       PWN(134_convolutional_lrelu)        2.99           0.0997      0.1
[05/21/2022-02:58:13] [I]                                                                           135_convolutional + 135_convolutional_bn        8.50           0.2833      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(135_convolutional_lrelu)        1.62           0.0540      0.0
[05/21/2022-02:58:13] [I]                                                                           136_convolutional + 136_convolutional_bn       61.83           2.0611      1.8
[05/21/2022-02:58:13] [I]                                                                                       PWN(136_convolutional_lrelu)        3.02           0.1008      0.1
[05/21/2022-02:58:13] [I]                                                                           137_convolutional + 137_convolutional_bn        8.43           0.2811      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(137_convolutional_lrelu)        1.59           0.0531      0.0
[05/21/2022-02:58:13] [I]                                                                           138_convolutional + 138_convolutional_bn       60.80           2.0266      1.8
[05/21/2022-02:58:13] [I]                                                                                       PWN(138_convolutional_lrelu)        2.96           0.0987      0.1
[05/21/2022-02:58:13] [I]                                                                                                  139_convolutional       16.22           0.5406      0.5
[05/21/2022-02:58:13] [I]                                                     Reformatting CopyNode for Output Tensor 0 to 139_convolutional        7.13           0.2375      0.2
[05/21/2022-02:58:13] [I]                                                                           142_convolutional + 142_convolutional_bn       17.69           0.5898      0.5
[05/21/2022-02:58:13] [I]                                                                                       PWN(142_convolutional_lrelu)        0.98           0.0327      0.0
[05/21/2022-02:58:13] [I]                                                                           144_convolutional + 144_convolutional_bn        8.83           0.2944      0.3
[05/21/2022-02:58:13] [I]                                                                                       PWN(144_convolutional_lrelu)        0.87           0.0291      0.0
[05/21/2022-02:58:13] [I]                                                                           145_convolutional + 145_convolutional_bn       69.46           2.3154      2.0
[05/21/2022-02:58:13] [I]                                                                                       PWN(145_convolutional_lrelu)        1.56           0.0519      0.0
[05/21/2022-02:58:13] [I]                                                                           146_convolutional + 146_convolutional_bn        8.50           0.2832      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(146_convolutional_lrelu)        0.88           0.0293      0.0
[05/21/2022-02:58:13] [I]                                                                           147_convolutional + 147_convolutional_bn       69.42           2.3139      2.0
[05/21/2022-02:58:13] [I]                                                                                       PWN(147_convolutional_lrelu)        1.56           0.0520      0.0
[05/21/2022-02:58:13] [I]                                                                           148_convolutional + 148_convolutional_bn        8.51           0.2838      0.2
[05/21/2022-02:58:13] [I]                                                                                       PWN(148_convolutional_lrelu)        0.87           0.0290      0.0
[05/21/2022-02:58:13] [I]                                                                           149_convolutional + 149_convolutional_bn       69.63           2.3209      2.0
[05/21/2022-02:58:13] [I]                                                                                       PWN(149_convolutional_lrelu)        1.57           0.0523      0.0
[05/21/2022-02:58:13] [I]                                                                                                  150_convolutional        8.53           0.2842      0.2
[05/21/2022-02:58:13] [I]                                                     Reformatting CopyNode for Output Tensor 0 to 150_convolutional        1.89           0.0630      0.1
[05/21/2022-02:58:13] [I]                                                                           153_convolutional + 153_convolutional_bn       23.06           0.7686      0.7
[05/21/2022-02:58:13] [I]                                                                                       PWN(153_convolutional_lrelu)        0.73           0.0244      0.0
[05/21/2022-02:58:13] [I]                                                                           155_convolutional + 155_convolutional_bn       10.63           0.3544      0.3
[05/21/2022-02:58:13] [I]                                                                                       PWN(155_convolutional_lrelu)        0.65           0.0218      0.0
[05/21/2022-02:58:13] [I]                                                                           156_convolutional + 156_convolutional_bn       90.26           3.0086      2.6
[05/21/2022-02:58:13] [I]                                                                                       PWN(156_convolutional_lrelu)        0.86           0.0286      0.0
[05/21/2022-02:58:13] [I]                                                                           157_convolutional + 157_convolutional_bn       10.58           0.3527      0.3
[05/21/2022-02:58:13] [I]                                                                                       PWN(157_convolutional_lrelu)        0.65           0.0218      0.0
[05/21/2022-02:58:13] [I]                                                                           158_convolutional + 158_convolutional_bn       90.20           3.0067      2.6
[05/21/2022-02:58:13] [I]                                                                                       PWN(158_convolutional_lrelu)        0.86           0.0286      0.0
[05/21/2022-02:58:13] [I]                                                                           159_convolutional + 159_convolutional_bn       10.58           0.3528      0.3
[05/21/2022-02:58:13] [I]                                                                                       PWN(159_convolutional_lrelu)        0.65           0.0218      0.0
[05/21/2022-02:58:13] [I]                                                                           160_convolutional + 160_convolutional_bn       90.77           3.0258      2.6
[05/21/2022-02:58:13] [I]                                                                                       PWN(160_convolutional_lrelu)        0.86           0.0287      0.0
[05/21/2022-02:58:13] [I]                                                                                                  161_convolutional        5.48           0.1826      0.2
[05/21/2022-02:58:13] [I]                                                     Reformatting CopyNode for Output Tensor 0 to 161_convolutional        0.54           0.0182      0.0
[05/21/2022-02:58:13] [I]                                                                                                              Total     3453.78         115.1260    100.0
[05/21/2022-02:58:13] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=yolov4-288.onnx --saveEngine=yolov4-288.trt --fp16 --dumpProfile --verbose --separateProfileRun --exportProfile=yolov4-288/recordProfile.json --exportOutput=yolov4-288/recordOutput.json --exportTimes=yolov4-288/recordTimes.json --exportLayerInfo=yolov4-288/recordLayer.json --workspace=512
