&&&& RUNNING TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=yolov4-416.onnx --saveEngine=yolov4-416.trt --fp16 --dumpProfile --verbose --separateProfileRun --exportProfile=yolov4-416/recordProfile.json --exportOutput=yolov4-416/recordOutput.json --exportTimes=yolov4-416/recordTimes.json --exportLayerInfo=yolov4-416/recordLayer.json --workspace=512
[05/21/2022-03:01:48] [I] === Model Options ===
[05/21/2022-03:01:48] [I] Format: ONNX
[05/21/2022-03:01:48] [I] Model: yolov4-416.onnx
[05/21/2022-03:01:48] [I] Output:
[05/21/2022-03:01:48] [I] === Build Options ===
[05/21/2022-03:01:48] [I] Max batch: explicit batch
[05/21/2022-03:01:48] [I] Workspace: 512 MiB
[05/21/2022-03:01:48] [I] minTiming: 1
[05/21/2022-03:01:48] [I] avgTiming: 8
[05/21/2022-03:01:48] [I] Precision: FP32+FP16
[05/21/2022-03:01:48] [I] Calibration: 
[05/21/2022-03:01:48] [I] Refit: Disabled
[05/21/2022-03:01:48] [I] Sparsity: Disabled
[05/21/2022-03:01:48] [I] Safe mode: Disabled
[05/21/2022-03:01:48] [I] DirectIO mode: Disabled
[05/21/2022-03:01:48] [I] Restricted mode: Disabled
[05/21/2022-03:01:48] [I] Save engine: yolov4-416.trt
[05/21/2022-03:01:48] [I] Load engine: 
[05/21/2022-03:01:48] [I] Profiling verbosity: 0
[05/21/2022-03:01:48] [I] Tactic sources: Using default tactic sources
[05/21/2022-03:01:48] [I] timingCacheMode: local
[05/21/2022-03:01:48] [I] timingCacheFile: 
[05/21/2022-03:01:48] [I] Input(s)s format: fp32:CHW
[05/21/2022-03:01:48] [I] Output(s)s format: fp32:CHW
[05/21/2022-03:01:48] [I] Input build shapes: model
[05/21/2022-03:01:48] [I] Input calibration shapes: model
[05/21/2022-03:01:48] [I] === System Options ===
[05/21/2022-03:01:48] [I] Device: 0
[05/21/2022-03:01:48] [I] DLACore: 
[05/21/2022-03:01:48] [I] Plugins:
[05/21/2022-03:01:48] [I] === Inference Options ===
[05/21/2022-03:01:48] [I] Batch: Explicit
[05/21/2022-03:01:48] [I] Input inference shapes: model
[05/21/2022-03:01:48] [I] Iterations: 10
[05/21/2022-03:01:48] [I] Duration: 3s (+ 200ms warm up)
[05/21/2022-03:01:48] [I] Sleep time: 0ms
[05/21/2022-03:01:48] [I] Idle time: 0ms
[05/21/2022-03:01:48] [I] Streams: 1
[05/21/2022-03:01:48] [I] ExposeDMA: Disabled
[05/21/2022-03:01:48] [I] Data transfers: Enabled
[05/21/2022-03:01:48] [I] Spin-wait: Disabled
[05/21/2022-03:01:48] [I] Multithreading: Disabled
[05/21/2022-03:01:48] [I] CUDA Graph: Disabled
[05/21/2022-03:01:48] [I] Separate profiling: Enabled
[05/21/2022-03:01:48] [I] Time Deserialize: Disabled
[05/21/2022-03:01:48] [I] Time Refit: Disabled
[05/21/2022-03:01:48] [I] Skip inference: Disabled
[05/21/2022-03:01:48] [I] Inputs:
[05/21/2022-03:01:48] [I] === Reporting Options ===
[05/21/2022-03:01:48] [I] Verbose: Enabled
[05/21/2022-03:01:48] [I] Averages: 10 inferences
[05/21/2022-03:01:48] [I] Percentile: 99
[05/21/2022-03:01:48] [I] Dump refittable layers:Disabled
[05/21/2022-03:01:48] [I] Dump output: Disabled
[05/21/2022-03:01:48] [I] Profile: Enabled
[05/21/2022-03:01:48] [I] Export timing to JSON file: yolov4-416/recordTimes.json
[05/21/2022-03:01:48] [I] Export output to JSON file: yolov4-416/recordOutput.json
[05/21/2022-03:01:48] [I] Export profile to JSON file: yolov4-416/recordProfile.json
[05/21/2022-03:01:48] [I] 
[05/21/2022-03:01:48] [I] === Device Information ===
[05/21/2022-03:01:48] [I] Selected Device: NVIDIA Tegra X1
[05/21/2022-03:01:48] [I] Compute Capability: 5.3
[05/21/2022-03:01:48] [I] SMs: 1
[05/21/2022-03:01:48] [I] Compute Clock Rate: 0.9216 GHz
[05/21/2022-03:01:48] [I] Device Global Memory: 3964 MiB
[05/21/2022-03:01:48] [I] Shared Memory per SM: 64 KiB
[05/21/2022-03:01:48] [I] Memory Bus Width: 64 bits (ECC disabled)
[05/21/2022-03:01:48] [I] Memory Clock Rate: 0.01275 GHz
[05/21/2022-03:01:48] [I] 
[05/21/2022-03:01:48] [I] TensorRT version: 8.2.1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::GridAnchor_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::GridAnchorRect_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::NMS_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::Reorg_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::Region_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::Clip_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::LReLU_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::PriorBox_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::Normalize_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::ScatterND version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::RPROI_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::BatchedNMS_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::BatchedNMSDynamic_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::FlattenConcat_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::CropAndResize version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::DetectionLayer_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::EfficientNMS_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::EfficientNMS_ONNX_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::EfficientNMS_TFTRT_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::Proposal version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::ProposalLayer_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::PyramidROIAlign_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::ResizeNearest_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::Split version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::SpecialSlice_TRT version 1
[05/21/2022-03:01:48] [V] [TRT] Registered plugin creator - ::InstanceNormalization_TRT version 1
[05/21/2022-03:01:50] [I] [TRT] [MemUsageChange] Init CUDA: CPU +230, GPU +0, now: CPU 248, GPU 2617 (MiB)
[05/21/2022-03:01:51] [I] [TRT] [MemUsageSnapshot] Begin constructing builder kernel library: CPU 248 MiB, GPU 2652 MiB
[05/21/2022-03:01:51] [I] [TRT] [MemUsageSnapshot] End constructing builder kernel library: CPU 278 MiB, GPU 2683 MiB
[05/21/2022-03:01:51] [I] Start parsing network model
[05/21/2022-03:01:54] [I] [TRT] ----------------------------------------------------------------
[05/21/2022-03:01:54] [I] [TRT] Input filename:   yolov4-416.onnx
[05/21/2022-03:01:54] [I] [TRT] ONNX IR version:  0.0.4
[05/21/2022-03:01:54] [I] [TRT] Opset version:    9
[05/21/2022-03:01:54] [I] [TRT] Producer name:    NVIDIA TensorRT sample
[05/21/2022-03:01:54] [I] [TRT] Producer version: 
[05/21/2022-03:01:54] [I] [TRT] Domain:           
[05/21/2022-03:01:54] [I] [TRT] Model version:    0
[05/21/2022-03:01:54] [I] [TRT] Doc string:       
[05/21/2022-03:01:54] [I] [TRT] ----------------------------------------------------------------
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::GridAnchor_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::GridAnchorRect_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::NMS_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::Reorg_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::Region_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::Clip_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::LReLU_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::PriorBox_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::Normalize_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::ScatterND version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::RPROI_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::BatchedNMS_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::BatchedNMSDynamic_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::FlattenConcat_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::CropAndResize version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::DetectionLayer_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::EfficientNMS_ONNX_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::EfficientNMS_TFTRT_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::Proposal version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::ProposalLayer_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::PyramidROIAlign_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::ResizeNearest_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::Split version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::SpecialSlice_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Plugin creator already registered - ::InstanceNormalization_TRT version 1
[05/21/2022-03:01:54] [V] [TRT] Adding network input: 000_net with dtype: float32, dimensions: (1, 3, 416, 416)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 000_net for ONNX tensor: 000_net
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 001_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 001_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 001_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 001_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 001_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 002_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 002_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 002_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 002_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 002_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 003_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 003_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 003_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 003_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 003_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 005_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 005_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 005_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 005_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 005_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 006_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 006_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 006_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 006_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 006_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 007_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 007_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 007_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 007_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 007_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 009_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 009_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 009_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 009_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 009_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 011_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 011_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 011_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 011_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 011_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 012_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 012_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 012_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 012_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 012_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 013_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 013_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 013_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 013_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 013_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 015_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 015_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 015_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 015_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 015_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 016_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 016_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 016_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 016_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 016_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 017_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 017_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 017_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 017_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 017_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 019_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 019_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 019_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 019_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 019_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 020_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 020_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 020_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 020_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 020_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 022_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 022_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 022_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 022_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 022_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 024_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 024_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 024_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 024_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 024_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 025_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 025_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 025_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 025_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 025_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 026_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 026_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 026_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 026_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 026_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 028_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 028_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 028_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 028_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 028_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 029_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 029_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 029_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 029_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 029_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 030_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 030_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 030_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 030_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 030_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 032_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 032_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 032_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 032_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 032_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 033_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 033_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 033_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 033_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 033_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 035_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 035_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 035_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 035_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 035_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 036_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 036_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 036_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 036_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 036_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 038_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 038_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 038_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 038_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 038_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 039_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 039_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 039_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 039_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 039_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 041_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 041_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 041_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 041_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 041_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 042_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 042_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 042_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 042_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 042_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 044_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 044_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 044_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 044_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 044_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 045_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 045_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 045_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 045_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 045_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 047_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 047_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 047_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 047_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 047_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 048_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 048_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 048_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 048_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 048_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 050_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 050_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 050_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 050_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 050_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 051_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 051_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 051_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 051_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 051_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 053_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 053_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 053_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 053_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 053_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 055_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 055_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 055_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 055_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 055_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 056_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 056_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 056_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 056_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 056_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 057_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 057_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 057_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 057_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 057_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 059_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 059_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 059_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 059_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 059_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 060_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 060_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 060_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 060_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 060_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 061_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 061_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 061_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 061_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 061_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 063_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 063_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 063_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 063_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 063_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 064_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 064_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 064_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 064_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 064_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 066_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 066_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 066_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 066_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 066_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 067_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 067_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 067_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 067_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 067_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 069_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 069_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 069_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 069_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 069_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 070_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 070_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 070_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 070_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 070_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 072_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 072_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 072_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 072_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 072_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 073_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 073_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 073_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 073_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 073_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 075_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 075_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 075_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 075_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 075_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 076_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 076_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 076_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 076_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 076_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 078_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 078_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 078_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 078_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 078_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 079_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 079_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 079_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 079_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 079_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 081_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 081_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 081_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 081_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 081_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 082_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 082_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 082_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 082_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 082_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 084_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 084_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 084_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 084_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 084_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 086_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 086_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 086_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 086_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 086_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 087_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 087_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 087_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 087_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 087_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 088_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 088_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 088_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 088_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 088_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 090_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 090_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 090_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 090_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 090_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 091_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 091_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 091_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 091_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 091_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 092_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 092_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 092_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 092_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 092_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 094_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 094_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 094_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 094_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 094_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 095_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 095_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 095_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 095_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 095_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 097_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 097_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 097_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 097_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 097_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 098_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 098_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 098_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 098_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 098_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 100_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 100_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 100_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 100_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 100_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 101_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 101_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 101_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 101_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 101_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 103_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 103_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 103_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 103_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 103_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 105_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 105_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 105_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 105_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 105_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 106_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 106_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 106_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 106_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 106_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 107_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 107_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 107_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 107_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 107_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 108_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 108_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 108_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 108_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 108_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 115_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 115_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 115_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 115_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 115_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 116_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 116_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 116_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 116_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 116_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 117_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 117_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 117_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 117_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 117_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 118_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 118_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 118_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 118_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 118_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 119_upsample_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 121_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 121_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 121_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 121_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 121_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 123_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 123_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 123_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 123_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 123_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 124_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 124_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 124_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 124_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 124_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 125_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 125_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 125_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 125_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 125_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 126_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 126_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 126_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 126_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 126_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 127_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 127_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 127_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 127_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 127_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 128_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 128_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 128_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 128_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 128_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 129_upsample_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 131_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 131_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 131_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 131_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 131_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 133_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 133_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 133_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 133_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 133_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 134_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 134_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 134_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 134_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 134_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 135_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 135_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 135_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 135_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 135_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 136_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 136_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 136_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 136_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 136_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 137_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 137_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 137_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 137_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 137_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 138_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 138_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 138_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 138_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 138_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 139_convolutional_conv_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 139_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 142_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 142_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 142_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 142_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 142_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 144_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 144_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 144_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 144_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 144_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 145_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 145_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 145_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 145_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 145_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 146_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 146_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 146_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 146_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 146_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 147_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 147_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 147_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 147_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 147_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 148_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 148_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 148_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 148_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 148_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 149_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 149_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 149_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 149_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 149_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 150_convolutional_conv_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 150_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 153_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 153_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 153_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 153_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 153_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 155_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 155_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 155_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 155_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 155_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 156_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 156_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 156_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 156_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 156_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 157_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 157_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 157_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 157_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 157_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 158_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 158_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 158_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 158_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 158_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 159_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 159_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 159_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 159_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 159_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 160_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 160_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 160_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 160_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 160_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 161_convolutional_conv_bias
[05/21/2022-03:01:54] [V] [TRT] Importing initializer: 161_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 001_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 000_net
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional [Conv] inputs: [000_net -> (1, 3, 416, 416)[FLOAT]], [001_convolutional_conv_weights -> (32, 3, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 3, 416, 416)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 001_convolutional for ONNX node: 001_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 32
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 32, 416, 416)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 001_convolutional for ONNX tensor: 001_convolutional
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional [Conv] outputs: [001_convolutional -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 001_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_bn [BatchNormalization] inputs: [001_convolutional -> (1, 32, 416, 416)[FLOAT]], [001_convolutional_bn_scale -> (32)[FLOAT]], [001_convolutional_bn_bias -> (32)[FLOAT]], [001_convolutional_bn_mean -> (32)[FLOAT]], [001_convolutional_bn_var -> (32)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 001_convolutional_bn for ONNX node: 001_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 001_convolutional_bn for ONNX tensor: 001_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_bn [BatchNormalization] outputs: [001_convolutional_bn -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 001_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_softplus [Softplus] inputs: [001_convolutional_bn -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 001_convolutional_softplus for ONNX node: 001_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 001_convolutional_softplus for ONNX tensor: 001_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_softplus [Softplus] outputs: [001_convolutional_softplus -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 001_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_tanh [Tanh] inputs: [001_convolutional_softplus -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 001_convolutional_tanh for ONNX node: 001_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 001_convolutional_tanh for ONNX tensor: 001_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_tanh [Tanh] outputs: [001_convolutional_tanh -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 001_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_mish [Mul] inputs: [001_convolutional_bn -> (1, 32, 416, 416)[FLOAT]], [001_convolutional_tanh -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 001_convolutional_mish for ONNX node: 001_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 001_convolutional_mish for ONNX tensor: 001_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 001_convolutional_mish [Mul] outputs: [001_convolutional_mish -> (1, 32, 416, 416)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 002_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 001_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional [Conv] inputs: [001_convolutional_mish -> (1, 32, 416, 416)[FLOAT]], [002_convolutional_conv_weights -> (64, 32, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 32, 416, 416)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 002_convolutional for ONNX node: 002_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 002_convolutional for ONNX tensor: 002_convolutional
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional [Conv] outputs: [002_convolutional -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 002_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_bn [BatchNormalization] inputs: [002_convolutional -> (1, 64, 208, 208)[FLOAT]], [002_convolutional_bn_scale -> (64)[FLOAT]], [002_convolutional_bn_bias -> (64)[FLOAT]], [002_convolutional_bn_mean -> (64)[FLOAT]], [002_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 002_convolutional_bn for ONNX node: 002_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 002_convolutional_bn for ONNX tensor: 002_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_bn [BatchNormalization] outputs: [002_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 002_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_softplus [Softplus] inputs: [002_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 002_convolutional_softplus for ONNX node: 002_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 002_convolutional_softplus for ONNX tensor: 002_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_softplus [Softplus] outputs: [002_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 002_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_tanh [Tanh] inputs: [002_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 002_convolutional_tanh for ONNX node: 002_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 002_convolutional_tanh for ONNX tensor: 002_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_tanh [Tanh] outputs: [002_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 002_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_mish [Mul] inputs: [002_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], [002_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 002_convolutional_mish for ONNX node: 002_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 002_convolutional_mish for ONNX tensor: 002_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 002_convolutional_mish [Mul] outputs: [002_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 003_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional [Conv] inputs: [002_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], [003_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 003_convolutional for ONNX node: 003_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 003_convolutional for ONNX tensor: 003_convolutional
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional [Conv] outputs: [003_convolutional -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 003_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_bn [BatchNormalization] inputs: [003_convolutional -> (1, 64, 208, 208)[FLOAT]], [003_convolutional_bn_scale -> (64)[FLOAT]], [003_convolutional_bn_bias -> (64)[FLOAT]], [003_convolutional_bn_mean -> (64)[FLOAT]], [003_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 003_convolutional_bn for ONNX node: 003_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 003_convolutional_bn for ONNX tensor: 003_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_bn [BatchNormalization] outputs: [003_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 003_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_softplus [Softplus] inputs: [003_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 003_convolutional_softplus for ONNX node: 003_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 003_convolutional_softplus for ONNX tensor: 003_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_softplus [Softplus] outputs: [003_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 003_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_tanh [Tanh] inputs: [003_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 003_convolutional_tanh for ONNX node: 003_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 003_convolutional_tanh for ONNX tensor: 003_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_tanh [Tanh] outputs: [003_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 003_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_mish [Mul] inputs: [003_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], [003_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 003_convolutional_mish for ONNX node: 003_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 003_convolutional_mish for ONNX tensor: 003_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 003_convolutional_mish [Mul] outputs: [003_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 005_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 002_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional [Conv] inputs: [002_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], [005_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 005_convolutional for ONNX node: 005_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 005_convolutional for ONNX tensor: 005_convolutional
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional [Conv] outputs: [005_convolutional -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 005_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_bn [BatchNormalization] inputs: [005_convolutional -> (1, 64, 208, 208)[FLOAT]], [005_convolutional_bn_scale -> (64)[FLOAT]], [005_convolutional_bn_bias -> (64)[FLOAT]], [005_convolutional_bn_mean -> (64)[FLOAT]], [005_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 005_convolutional_bn for ONNX node: 005_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 005_convolutional_bn for ONNX tensor: 005_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_bn [BatchNormalization] outputs: [005_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 005_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_softplus [Softplus] inputs: [005_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 005_convolutional_softplus for ONNX node: 005_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 005_convolutional_softplus for ONNX tensor: 005_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_softplus [Softplus] outputs: [005_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 005_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_tanh [Tanh] inputs: [005_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 005_convolutional_tanh for ONNX node: 005_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 005_convolutional_tanh for ONNX tensor: 005_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_tanh [Tanh] outputs: [005_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 005_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_mish [Mul] inputs: [005_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], [005_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 005_convolutional_mish for ONNX node: 005_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 005_convolutional_mish for ONNX tensor: 005_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 005_convolutional_mish [Mul] outputs: [005_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 006_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional [Conv] inputs: [005_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], [006_convolutional_conv_weights -> (32, 64, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 006_convolutional for ONNX node: 006_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 32
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 32, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 006_convolutional for ONNX tensor: 006_convolutional
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional [Conv] outputs: [006_convolutional -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 006_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_bn [BatchNormalization] inputs: [006_convolutional -> (1, 32, 208, 208)[FLOAT]], [006_convolutional_bn_scale -> (32)[FLOAT]], [006_convolutional_bn_bias -> (32)[FLOAT]], [006_convolutional_bn_mean -> (32)[FLOAT]], [006_convolutional_bn_var -> (32)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 006_convolutional_bn for ONNX node: 006_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 006_convolutional_bn for ONNX tensor: 006_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_bn [BatchNormalization] outputs: [006_convolutional_bn -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 006_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_softplus [Softplus] inputs: [006_convolutional_bn -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 006_convolutional_softplus for ONNX node: 006_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 006_convolutional_softplus for ONNX tensor: 006_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_softplus [Softplus] outputs: [006_convolutional_softplus -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 006_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_tanh [Tanh] inputs: [006_convolutional_softplus -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 006_convolutional_tanh for ONNX node: 006_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 006_convolutional_tanh for ONNX tensor: 006_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_tanh [Tanh] outputs: [006_convolutional_tanh -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 006_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_mish [Mul] inputs: [006_convolutional_bn -> (1, 32, 208, 208)[FLOAT]], [006_convolutional_tanh -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 006_convolutional_mish for ONNX node: 006_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 006_convolutional_mish for ONNX tensor: 006_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 006_convolutional_mish [Mul] outputs: [006_convolutional_mish -> (1, 32, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 007_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 006_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional [Conv] inputs: [006_convolutional_mish -> (1, 32, 208, 208)[FLOAT]], [007_convolutional_conv_weights -> (64, 32, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 32, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 007_convolutional for ONNX node: 007_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 007_convolutional for ONNX tensor: 007_convolutional
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional [Conv] outputs: [007_convolutional -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 007_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_bn [BatchNormalization] inputs: [007_convolutional -> (1, 64, 208, 208)[FLOAT]], [007_convolutional_bn_scale -> (64)[FLOAT]], [007_convolutional_bn_bias -> (64)[FLOAT]], [007_convolutional_bn_mean -> (64)[FLOAT]], [007_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 007_convolutional_bn for ONNX node: 007_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 007_convolutional_bn for ONNX tensor: 007_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_bn [BatchNormalization] outputs: [007_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 007_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_softplus [Softplus] inputs: [007_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 007_convolutional_softplus for ONNX node: 007_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 007_convolutional_softplus for ONNX tensor: 007_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_softplus [Softplus] outputs: [007_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 007_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_tanh [Tanh] inputs: [007_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 007_convolutional_tanh for ONNX node: 007_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 007_convolutional_tanh for ONNX tensor: 007_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_tanh [Tanh] outputs: [007_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 007_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_mish [Mul] inputs: [007_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], [007_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 007_convolutional_mish for ONNX node: 007_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 007_convolutional_mish for ONNX tensor: 007_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 007_convolutional_mish [Mul] outputs: [007_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 008_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 007_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 005_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 008_shortcut [Add] inputs: [007_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], [005_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 008_shortcut for ONNX node: 008_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 008_shortcut for ONNX tensor: 008_shortcut
[05/21/2022-03:01:54] [V] [TRT] 008_shortcut [Add] outputs: [008_shortcut -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 009_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 008_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional [Conv] inputs: [008_shortcut -> (1, 64, 208, 208)[FLOAT]], [009_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 009_convolutional for ONNX node: 009_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 009_convolutional for ONNX tensor: 009_convolutional
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional [Conv] outputs: [009_convolutional -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 009_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_bn [BatchNormalization] inputs: [009_convolutional -> (1, 64, 208, 208)[FLOAT]], [009_convolutional_bn_scale -> (64)[FLOAT]], [009_convolutional_bn_bias -> (64)[FLOAT]], [009_convolutional_bn_mean -> (64)[FLOAT]], [009_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 009_convolutional_bn for ONNX node: 009_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 009_convolutional_bn for ONNX tensor: 009_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_bn [BatchNormalization] outputs: [009_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 009_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_softplus [Softplus] inputs: [009_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 009_convolutional_softplus for ONNX node: 009_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 009_convolutional_softplus for ONNX tensor: 009_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_softplus [Softplus] outputs: [009_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 009_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_tanh [Tanh] inputs: [009_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 009_convolutional_tanh for ONNX node: 009_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 009_convolutional_tanh for ONNX tensor: 009_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_tanh [Tanh] outputs: [009_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 009_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_mish [Mul] inputs: [009_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], [009_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 009_convolutional_mish for ONNX node: 009_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 009_convolutional_mish for ONNX tensor: 009_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 009_convolutional_mish [Mul] outputs: [009_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 010_route [Concat]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 009_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 003_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 010_route [Concat] inputs: [009_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], [003_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 010_route for ONNX node: 010_route
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 010_route for ONNX tensor: 010_route
[05/21/2022-03:01:54] [V] [TRT] 010_route [Concat] outputs: [010_route -> (1, 128, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 011_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 010_route
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional [Conv] inputs: [010_route -> (1, 128, 208, 208)[FLOAT]], [011_convolutional_conv_weights -> (64, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 011_convolutional for ONNX node: 011_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 011_convolutional for ONNX tensor: 011_convolutional
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional [Conv] outputs: [011_convolutional -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 011_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_bn [BatchNormalization] inputs: [011_convolutional -> (1, 64, 208, 208)[FLOAT]], [011_convolutional_bn_scale -> (64)[FLOAT]], [011_convolutional_bn_bias -> (64)[FLOAT]], [011_convolutional_bn_mean -> (64)[FLOAT]], [011_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 011_convolutional_bn for ONNX node: 011_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 011_convolutional_bn for ONNX tensor: 011_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_bn [BatchNormalization] outputs: [011_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 011_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_softplus [Softplus] inputs: [011_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 011_convolutional_softplus for ONNX node: 011_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 011_convolutional_softplus for ONNX tensor: 011_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_softplus [Softplus] outputs: [011_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 011_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_tanh [Tanh] inputs: [011_convolutional_softplus -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 011_convolutional_tanh for ONNX node: 011_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 011_convolutional_tanh for ONNX tensor: 011_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_tanh [Tanh] outputs: [011_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 011_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_mish [Mul] inputs: [011_convolutional_bn -> (1, 64, 208, 208)[FLOAT]], [011_convolutional_tanh -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 011_convolutional_mish for ONNX node: 011_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 011_convolutional_mish for ONNX tensor: 011_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 011_convolutional_mish [Mul] outputs: [011_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 012_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 011_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional [Conv] inputs: [011_convolutional_mish -> (1, 64, 208, 208)[FLOAT]], [012_convolutional_conv_weights -> (128, 64, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 208, 208)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 012_convolutional for ONNX node: 012_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 012_convolutional for ONNX tensor: 012_convolutional
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional [Conv] outputs: [012_convolutional -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 012_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_bn [BatchNormalization] inputs: [012_convolutional -> (1, 128, 104, 104)[FLOAT]], [012_convolutional_bn_scale -> (128)[FLOAT]], [012_convolutional_bn_bias -> (128)[FLOAT]], [012_convolutional_bn_mean -> (128)[FLOAT]], [012_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 012_convolutional_bn for ONNX node: 012_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 012_convolutional_bn for ONNX tensor: 012_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_bn [BatchNormalization] outputs: [012_convolutional_bn -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 012_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_softplus [Softplus] inputs: [012_convolutional_bn -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 012_convolutional_softplus for ONNX node: 012_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 012_convolutional_softplus for ONNX tensor: 012_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_softplus [Softplus] outputs: [012_convolutional_softplus -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 012_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_tanh [Tanh] inputs: [012_convolutional_softplus -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 012_convolutional_tanh for ONNX node: 012_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 012_convolutional_tanh for ONNX tensor: 012_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_tanh [Tanh] outputs: [012_convolutional_tanh -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 012_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_mish [Mul] inputs: [012_convolutional_bn -> (1, 128, 104, 104)[FLOAT]], [012_convolutional_tanh -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 012_convolutional_mish for ONNX node: 012_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 012_convolutional_mish for ONNX tensor: 012_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 012_convolutional_mish [Mul] outputs: [012_convolutional_mish -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 013_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional [Conv] inputs: [012_convolutional_mish -> (1, 128, 104, 104)[FLOAT]], [013_convolutional_conv_weights -> (64, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 013_convolutional for ONNX node: 013_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 013_convolutional for ONNX tensor: 013_convolutional
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional [Conv] outputs: [013_convolutional -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 013_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_bn [BatchNormalization] inputs: [013_convolutional -> (1, 64, 104, 104)[FLOAT]], [013_convolutional_bn_scale -> (64)[FLOAT]], [013_convolutional_bn_bias -> (64)[FLOAT]], [013_convolutional_bn_mean -> (64)[FLOAT]], [013_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 013_convolutional_bn for ONNX node: 013_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 013_convolutional_bn for ONNX tensor: 013_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_bn [BatchNormalization] outputs: [013_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 013_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_softplus [Softplus] inputs: [013_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 013_convolutional_softplus for ONNX node: 013_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 013_convolutional_softplus for ONNX tensor: 013_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_softplus [Softplus] outputs: [013_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 013_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_tanh [Tanh] inputs: [013_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 013_convolutional_tanh for ONNX node: 013_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 013_convolutional_tanh for ONNX tensor: 013_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_tanh [Tanh] outputs: [013_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 013_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_mish [Mul] inputs: [013_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], [013_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 013_convolutional_mish for ONNX node: 013_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 013_convolutional_mish for ONNX tensor: 013_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 013_convolutional_mish [Mul] outputs: [013_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 015_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 012_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional [Conv] inputs: [012_convolutional_mish -> (1, 128, 104, 104)[FLOAT]], [015_convolutional_conv_weights -> (64, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 015_convolutional for ONNX node: 015_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 015_convolutional for ONNX tensor: 015_convolutional
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional [Conv] outputs: [015_convolutional -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 015_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_bn [BatchNormalization] inputs: [015_convolutional -> (1, 64, 104, 104)[FLOAT]], [015_convolutional_bn_scale -> (64)[FLOAT]], [015_convolutional_bn_bias -> (64)[FLOAT]], [015_convolutional_bn_mean -> (64)[FLOAT]], [015_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 015_convolutional_bn for ONNX node: 015_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 015_convolutional_bn for ONNX tensor: 015_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_bn [BatchNormalization] outputs: [015_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 015_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_softplus [Softplus] inputs: [015_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 015_convolutional_softplus for ONNX node: 015_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 015_convolutional_softplus for ONNX tensor: 015_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_softplus [Softplus] outputs: [015_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 015_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_tanh [Tanh] inputs: [015_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 015_convolutional_tanh for ONNX node: 015_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 015_convolutional_tanh for ONNX tensor: 015_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_tanh [Tanh] outputs: [015_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 015_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_mish [Mul] inputs: [015_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], [015_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 015_convolutional_mish for ONNX node: 015_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 015_convolutional_mish for ONNX tensor: 015_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 015_convolutional_mish [Mul] outputs: [015_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 016_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional [Conv] inputs: [015_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], [016_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 016_convolutional for ONNX node: 016_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 016_convolutional for ONNX tensor: 016_convolutional
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional [Conv] outputs: [016_convolutional -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 016_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_bn [BatchNormalization] inputs: [016_convolutional -> (1, 64, 104, 104)[FLOAT]], [016_convolutional_bn_scale -> (64)[FLOAT]], [016_convolutional_bn_bias -> (64)[FLOAT]], [016_convolutional_bn_mean -> (64)[FLOAT]], [016_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 016_convolutional_bn for ONNX node: 016_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 016_convolutional_bn for ONNX tensor: 016_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_bn [BatchNormalization] outputs: [016_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 016_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_softplus [Softplus] inputs: [016_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 016_convolutional_softplus for ONNX node: 016_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 016_convolutional_softplus for ONNX tensor: 016_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_softplus [Softplus] outputs: [016_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 016_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_tanh [Tanh] inputs: [016_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 016_convolutional_tanh for ONNX node: 016_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 016_convolutional_tanh for ONNX tensor: 016_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_tanh [Tanh] outputs: [016_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 016_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_mish [Mul] inputs: [016_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], [016_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 016_convolutional_mish for ONNX node: 016_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 016_convolutional_mish for ONNX tensor: 016_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 016_convolutional_mish [Mul] outputs: [016_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 017_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 016_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional [Conv] inputs: [016_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], [017_convolutional_conv_weights -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 017_convolutional for ONNX node: 017_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 017_convolutional for ONNX tensor: 017_convolutional
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional [Conv] outputs: [017_convolutional -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 017_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_bn [BatchNormalization] inputs: [017_convolutional -> (1, 64, 104, 104)[FLOAT]], [017_convolutional_bn_scale -> (64)[FLOAT]], [017_convolutional_bn_bias -> (64)[FLOAT]], [017_convolutional_bn_mean -> (64)[FLOAT]], [017_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 017_convolutional_bn for ONNX node: 017_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 017_convolutional_bn for ONNX tensor: 017_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_bn [BatchNormalization] outputs: [017_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 017_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_softplus [Softplus] inputs: [017_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 017_convolutional_softplus for ONNX node: 017_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 017_convolutional_softplus for ONNX tensor: 017_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_softplus [Softplus] outputs: [017_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 017_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_tanh [Tanh] inputs: [017_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 017_convolutional_tanh for ONNX node: 017_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 017_convolutional_tanh for ONNX tensor: 017_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_tanh [Tanh] outputs: [017_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 017_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_mish [Mul] inputs: [017_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], [017_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 017_convolutional_mish for ONNX node: 017_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 017_convolutional_mish for ONNX tensor: 017_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 017_convolutional_mish [Mul] outputs: [017_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 018_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 017_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 015_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 018_shortcut [Add] inputs: [017_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], [015_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 018_shortcut for ONNX node: 018_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 018_shortcut for ONNX tensor: 018_shortcut
[05/21/2022-03:01:54] [V] [TRT] 018_shortcut [Add] outputs: [018_shortcut -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 019_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 018_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional [Conv] inputs: [018_shortcut -> (1, 64, 104, 104)[FLOAT]], [019_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 019_convolutional for ONNX node: 019_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 019_convolutional for ONNX tensor: 019_convolutional
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional [Conv] outputs: [019_convolutional -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 019_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_bn [BatchNormalization] inputs: [019_convolutional -> (1, 64, 104, 104)[FLOAT]], [019_convolutional_bn_scale -> (64)[FLOAT]], [019_convolutional_bn_bias -> (64)[FLOAT]], [019_convolutional_bn_mean -> (64)[FLOAT]], [019_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 019_convolutional_bn for ONNX node: 019_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 019_convolutional_bn for ONNX tensor: 019_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_bn [BatchNormalization] outputs: [019_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 019_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_softplus [Softplus] inputs: [019_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 019_convolutional_softplus for ONNX node: 019_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 019_convolutional_softplus for ONNX tensor: 019_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_softplus [Softplus] outputs: [019_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 019_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_tanh [Tanh] inputs: [019_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 019_convolutional_tanh for ONNX node: 019_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 019_convolutional_tanh for ONNX tensor: 019_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_tanh [Tanh] outputs: [019_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 019_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_mish [Mul] inputs: [019_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], [019_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 019_convolutional_mish for ONNX node: 019_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 019_convolutional_mish for ONNX tensor: 019_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 019_convolutional_mish [Mul] outputs: [019_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 020_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 019_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional [Conv] inputs: [019_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], [020_convolutional_conv_weights -> (64, 64, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 020_convolutional for ONNX node: 020_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 020_convolutional for ONNX tensor: 020_convolutional
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional [Conv] outputs: [020_convolutional -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 020_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_bn [BatchNormalization] inputs: [020_convolutional -> (1, 64, 104, 104)[FLOAT]], [020_convolutional_bn_scale -> (64)[FLOAT]], [020_convolutional_bn_bias -> (64)[FLOAT]], [020_convolutional_bn_mean -> (64)[FLOAT]], [020_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 020_convolutional_bn for ONNX node: 020_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 020_convolutional_bn for ONNX tensor: 020_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_bn [BatchNormalization] outputs: [020_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 020_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_softplus [Softplus] inputs: [020_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 020_convolutional_softplus for ONNX node: 020_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 020_convolutional_softplus for ONNX tensor: 020_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_softplus [Softplus] outputs: [020_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 020_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_tanh [Tanh] inputs: [020_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 020_convolutional_tanh for ONNX node: 020_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 020_convolutional_tanh for ONNX tensor: 020_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_tanh [Tanh] outputs: [020_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 020_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_mish [Mul] inputs: [020_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], [020_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 020_convolutional_mish for ONNX node: 020_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 020_convolutional_mish for ONNX tensor: 020_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 020_convolutional_mish [Mul] outputs: [020_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 021_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 020_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 018_shortcut
[05/21/2022-03:01:54] [V] [TRT] 021_shortcut [Add] inputs: [020_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], [018_shortcut -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 021_shortcut for ONNX node: 021_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 021_shortcut for ONNX tensor: 021_shortcut
[05/21/2022-03:01:54] [V] [TRT] 021_shortcut [Add] outputs: [021_shortcut -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 022_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 021_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional [Conv] inputs: [021_shortcut -> (1, 64, 104, 104)[FLOAT]], [022_convolutional_conv_weights -> (64, 64, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 022_convolutional for ONNX node: 022_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 64
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 64, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 022_convolutional for ONNX tensor: 022_convolutional
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional [Conv] outputs: [022_convolutional -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 022_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_bn [BatchNormalization] inputs: [022_convolutional -> (1, 64, 104, 104)[FLOAT]], [022_convolutional_bn_scale -> (64)[FLOAT]], [022_convolutional_bn_bias -> (64)[FLOAT]], [022_convolutional_bn_mean -> (64)[FLOAT]], [022_convolutional_bn_var -> (64)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 022_convolutional_bn for ONNX node: 022_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 022_convolutional_bn for ONNX tensor: 022_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_bn [BatchNormalization] outputs: [022_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 022_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_softplus [Softplus] inputs: [022_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 022_convolutional_softplus for ONNX node: 022_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 022_convolutional_softplus for ONNX tensor: 022_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_softplus [Softplus] outputs: [022_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 022_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_tanh [Tanh] inputs: [022_convolutional_softplus -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 022_convolutional_tanh for ONNX node: 022_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 022_convolutional_tanh for ONNX tensor: 022_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_tanh [Tanh] outputs: [022_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 022_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_mish [Mul] inputs: [022_convolutional_bn -> (1, 64, 104, 104)[FLOAT]], [022_convolutional_tanh -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 022_convolutional_mish for ONNX node: 022_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 022_convolutional_mish for ONNX tensor: 022_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 022_convolutional_mish [Mul] outputs: [022_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 023_route [Concat]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 022_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 013_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 023_route [Concat] inputs: [022_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], [013_convolutional_mish -> (1, 64, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 023_route for ONNX node: 023_route
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 023_route for ONNX tensor: 023_route
[05/21/2022-03:01:54] [V] [TRT] 023_route [Concat] outputs: [023_route -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 024_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 023_route
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional [Conv] inputs: [023_route -> (1, 128, 104, 104)[FLOAT]], [024_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 024_convolutional for ONNX node: 024_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 024_convolutional for ONNX tensor: 024_convolutional
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional [Conv] outputs: [024_convolutional -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 024_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_bn [BatchNormalization] inputs: [024_convolutional -> (1, 128, 104, 104)[FLOAT]], [024_convolutional_bn_scale -> (128)[FLOAT]], [024_convolutional_bn_bias -> (128)[FLOAT]], [024_convolutional_bn_mean -> (128)[FLOAT]], [024_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 024_convolutional_bn for ONNX node: 024_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 024_convolutional_bn for ONNX tensor: 024_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_bn [BatchNormalization] outputs: [024_convolutional_bn -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 024_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_softplus [Softplus] inputs: [024_convolutional_bn -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 024_convolutional_softplus for ONNX node: 024_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 024_convolutional_softplus for ONNX tensor: 024_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_softplus [Softplus] outputs: [024_convolutional_softplus -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 024_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_tanh [Tanh] inputs: [024_convolutional_softplus -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 024_convolutional_tanh for ONNX node: 024_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 024_convolutional_tanh for ONNX tensor: 024_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_tanh [Tanh] outputs: [024_convolutional_tanh -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 024_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_mish [Mul] inputs: [024_convolutional_bn -> (1, 128, 104, 104)[FLOAT]], [024_convolutional_tanh -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 024_convolutional_mish for ONNX node: 024_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 024_convolutional_mish for ONNX tensor: 024_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 024_convolutional_mish [Mul] outputs: [024_convolutional_mish -> (1, 128, 104, 104)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 025_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 024_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional [Conv] inputs: [024_convolutional_mish -> (1, 128, 104, 104)[FLOAT]], [025_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 104, 104)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 025_convolutional for ONNX node: 025_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 025_convolutional for ONNX tensor: 025_convolutional
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional [Conv] outputs: [025_convolutional -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 025_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_bn [BatchNormalization] inputs: [025_convolutional -> (1, 256, 52, 52)[FLOAT]], [025_convolutional_bn_scale -> (256)[FLOAT]], [025_convolutional_bn_bias -> (256)[FLOAT]], [025_convolutional_bn_mean -> (256)[FLOAT]], [025_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 025_convolutional_bn for ONNX node: 025_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 025_convolutional_bn for ONNX tensor: 025_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_bn [BatchNormalization] outputs: [025_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 025_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_softplus [Softplus] inputs: [025_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 025_convolutional_softplus for ONNX node: 025_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 025_convolutional_softplus for ONNX tensor: 025_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_softplus [Softplus] outputs: [025_convolutional_softplus -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 025_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_tanh [Tanh] inputs: [025_convolutional_softplus -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 025_convolutional_tanh for ONNX node: 025_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 025_convolutional_tanh for ONNX tensor: 025_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_tanh [Tanh] outputs: [025_convolutional_tanh -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 025_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_mish [Mul] inputs: [025_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], [025_convolutional_tanh -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 025_convolutional_mish for ONNX node: 025_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 025_convolutional_mish for ONNX tensor: 025_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 025_convolutional_mish [Mul] outputs: [025_convolutional_mish -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 026_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional [Conv] inputs: [025_convolutional_mish -> (1, 256, 52, 52)[FLOAT]], [026_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 026_convolutional for ONNX node: 026_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 026_convolutional for ONNX tensor: 026_convolutional
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional [Conv] outputs: [026_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 026_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_bn [BatchNormalization] inputs: [026_convolutional -> (1, 128, 52, 52)[FLOAT]], [026_convolutional_bn_scale -> (128)[FLOAT]], [026_convolutional_bn_bias -> (128)[FLOAT]], [026_convolutional_bn_mean -> (128)[FLOAT]], [026_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 026_convolutional_bn for ONNX node: 026_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 026_convolutional_bn for ONNX tensor: 026_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_bn [BatchNormalization] outputs: [026_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 026_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_softplus [Softplus] inputs: [026_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 026_convolutional_softplus for ONNX node: 026_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 026_convolutional_softplus for ONNX tensor: 026_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_softplus [Softplus] outputs: [026_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 026_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_tanh [Tanh] inputs: [026_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 026_convolutional_tanh for ONNX node: 026_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 026_convolutional_tanh for ONNX tensor: 026_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_tanh [Tanh] outputs: [026_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 026_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_mish [Mul] inputs: [026_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [026_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 026_convolutional_mish for ONNX node: 026_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 026_convolutional_mish for ONNX tensor: 026_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 026_convolutional_mish [Mul] outputs: [026_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 028_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 025_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional [Conv] inputs: [025_convolutional_mish -> (1, 256, 52, 52)[FLOAT]], [028_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 028_convolutional for ONNX node: 028_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 028_convolutional for ONNX tensor: 028_convolutional
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional [Conv] outputs: [028_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 028_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_bn [BatchNormalization] inputs: [028_convolutional -> (1, 128, 52, 52)[FLOAT]], [028_convolutional_bn_scale -> (128)[FLOAT]], [028_convolutional_bn_bias -> (128)[FLOAT]], [028_convolutional_bn_mean -> (128)[FLOAT]], [028_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 028_convolutional_bn for ONNX node: 028_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 028_convolutional_bn for ONNX tensor: 028_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_bn [BatchNormalization] outputs: [028_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 028_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_softplus [Softplus] inputs: [028_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 028_convolutional_softplus for ONNX node: 028_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 028_convolutional_softplus for ONNX tensor: 028_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_softplus [Softplus] outputs: [028_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 028_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_tanh [Tanh] inputs: [028_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 028_convolutional_tanh for ONNX node: 028_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 028_convolutional_tanh for ONNX tensor: 028_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_tanh [Tanh] outputs: [028_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 028_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_mish [Mul] inputs: [028_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [028_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 028_convolutional_mish for ONNX node: 028_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 028_convolutional_mish for ONNX tensor: 028_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 028_convolutional_mish [Mul] outputs: [028_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 029_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional [Conv] inputs: [028_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [029_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 029_convolutional for ONNX node: 029_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 029_convolutional for ONNX tensor: 029_convolutional
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional [Conv] outputs: [029_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 029_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_bn [BatchNormalization] inputs: [029_convolutional -> (1, 128, 52, 52)[FLOAT]], [029_convolutional_bn_scale -> (128)[FLOAT]], [029_convolutional_bn_bias -> (128)[FLOAT]], [029_convolutional_bn_mean -> (128)[FLOAT]], [029_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 029_convolutional_bn for ONNX node: 029_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 029_convolutional_bn for ONNX tensor: 029_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_bn [BatchNormalization] outputs: [029_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 029_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_softplus [Softplus] inputs: [029_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 029_convolutional_softplus for ONNX node: 029_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 029_convolutional_softplus for ONNX tensor: 029_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_softplus [Softplus] outputs: [029_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 029_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_tanh [Tanh] inputs: [029_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 029_convolutional_tanh for ONNX node: 029_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 029_convolutional_tanh for ONNX tensor: 029_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_tanh [Tanh] outputs: [029_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 029_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_mish [Mul] inputs: [029_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [029_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 029_convolutional_mish for ONNX node: 029_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 029_convolutional_mish for ONNX tensor: 029_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 029_convolutional_mish [Mul] outputs: [029_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 030_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 029_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional [Conv] inputs: [029_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [030_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 030_convolutional for ONNX node: 030_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 030_convolutional for ONNX tensor: 030_convolutional
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional [Conv] outputs: [030_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 030_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_bn [BatchNormalization] inputs: [030_convolutional -> (1, 128, 52, 52)[FLOAT]], [030_convolutional_bn_scale -> (128)[FLOAT]], [030_convolutional_bn_bias -> (128)[FLOAT]], [030_convolutional_bn_mean -> (128)[FLOAT]], [030_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 030_convolutional_bn for ONNX node: 030_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 030_convolutional_bn for ONNX tensor: 030_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_bn [BatchNormalization] outputs: [030_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 030_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_softplus [Softplus] inputs: [030_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 030_convolutional_softplus for ONNX node: 030_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 030_convolutional_softplus for ONNX tensor: 030_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_softplus [Softplus] outputs: [030_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 030_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_tanh [Tanh] inputs: [030_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 030_convolutional_tanh for ONNX node: 030_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 030_convolutional_tanh for ONNX tensor: 030_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_tanh [Tanh] outputs: [030_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 030_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_mish [Mul] inputs: [030_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [030_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 030_convolutional_mish for ONNX node: 030_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 030_convolutional_mish for ONNX tensor: 030_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 030_convolutional_mish [Mul] outputs: [030_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 031_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 030_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 028_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 031_shortcut [Add] inputs: [030_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [028_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 031_shortcut for ONNX node: 031_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 031_shortcut for ONNX tensor: 031_shortcut
[05/21/2022-03:01:54] [V] [TRT] 031_shortcut [Add] outputs: [031_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 032_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 031_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional [Conv] inputs: [031_shortcut -> (1, 128, 52, 52)[FLOAT]], [032_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 032_convolutional for ONNX node: 032_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 032_convolutional for ONNX tensor: 032_convolutional
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional [Conv] outputs: [032_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 032_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_bn [BatchNormalization] inputs: [032_convolutional -> (1, 128, 52, 52)[FLOAT]], [032_convolutional_bn_scale -> (128)[FLOAT]], [032_convolutional_bn_bias -> (128)[FLOAT]], [032_convolutional_bn_mean -> (128)[FLOAT]], [032_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 032_convolutional_bn for ONNX node: 032_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 032_convolutional_bn for ONNX tensor: 032_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_bn [BatchNormalization] outputs: [032_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 032_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_softplus [Softplus] inputs: [032_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 032_convolutional_softplus for ONNX node: 032_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 032_convolutional_softplus for ONNX tensor: 032_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_softplus [Softplus] outputs: [032_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 032_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_tanh [Tanh] inputs: [032_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 032_convolutional_tanh for ONNX node: 032_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 032_convolutional_tanh for ONNX tensor: 032_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_tanh [Tanh] outputs: [032_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 032_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_mish [Mul] inputs: [032_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [032_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 032_convolutional_mish for ONNX node: 032_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 032_convolutional_mish for ONNX tensor: 032_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 032_convolutional_mish [Mul] outputs: [032_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 033_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 032_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional [Conv] inputs: [032_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [033_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 033_convolutional for ONNX node: 033_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 033_convolutional for ONNX tensor: 033_convolutional
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional [Conv] outputs: [033_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 033_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_bn [BatchNormalization] inputs: [033_convolutional -> (1, 128, 52, 52)[FLOAT]], [033_convolutional_bn_scale -> (128)[FLOAT]], [033_convolutional_bn_bias -> (128)[FLOAT]], [033_convolutional_bn_mean -> (128)[FLOAT]], [033_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 033_convolutional_bn for ONNX node: 033_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 033_convolutional_bn for ONNX tensor: 033_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_bn [BatchNormalization] outputs: [033_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 033_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_softplus [Softplus] inputs: [033_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 033_convolutional_softplus for ONNX node: 033_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 033_convolutional_softplus for ONNX tensor: 033_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_softplus [Softplus] outputs: [033_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 033_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_tanh [Tanh] inputs: [033_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 033_convolutional_tanh for ONNX node: 033_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 033_convolutional_tanh for ONNX tensor: 033_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_tanh [Tanh] outputs: [033_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 033_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_mish [Mul] inputs: [033_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [033_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 033_convolutional_mish for ONNX node: 033_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 033_convolutional_mish for ONNX tensor: 033_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 033_convolutional_mish [Mul] outputs: [033_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 034_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 033_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 031_shortcut
[05/21/2022-03:01:54] [V] [TRT] 034_shortcut [Add] inputs: [033_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [031_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 034_shortcut for ONNX node: 034_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 034_shortcut for ONNX tensor: 034_shortcut
[05/21/2022-03:01:54] [V] [TRT] 034_shortcut [Add] outputs: [034_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 035_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 034_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional [Conv] inputs: [034_shortcut -> (1, 128, 52, 52)[FLOAT]], [035_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 035_convolutional for ONNX node: 035_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 035_convolutional for ONNX tensor: 035_convolutional
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional [Conv] outputs: [035_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 035_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_bn [BatchNormalization] inputs: [035_convolutional -> (1, 128, 52, 52)[FLOAT]], [035_convolutional_bn_scale -> (128)[FLOAT]], [035_convolutional_bn_bias -> (128)[FLOAT]], [035_convolutional_bn_mean -> (128)[FLOAT]], [035_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 035_convolutional_bn for ONNX node: 035_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 035_convolutional_bn for ONNX tensor: 035_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_bn [BatchNormalization] outputs: [035_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 035_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_softplus [Softplus] inputs: [035_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 035_convolutional_softplus for ONNX node: 035_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 035_convolutional_softplus for ONNX tensor: 035_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_softplus [Softplus] outputs: [035_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 035_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_tanh [Tanh] inputs: [035_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 035_convolutional_tanh for ONNX node: 035_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 035_convolutional_tanh for ONNX tensor: 035_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_tanh [Tanh] outputs: [035_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 035_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_mish [Mul] inputs: [035_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [035_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 035_convolutional_mish for ONNX node: 035_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 035_convolutional_mish for ONNX tensor: 035_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 035_convolutional_mish [Mul] outputs: [035_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 036_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 035_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional [Conv] inputs: [035_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [036_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 036_convolutional for ONNX node: 036_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 036_convolutional for ONNX tensor: 036_convolutional
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional [Conv] outputs: [036_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 036_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_bn [BatchNormalization] inputs: [036_convolutional -> (1, 128, 52, 52)[FLOAT]], [036_convolutional_bn_scale -> (128)[FLOAT]], [036_convolutional_bn_bias -> (128)[FLOAT]], [036_convolutional_bn_mean -> (128)[FLOAT]], [036_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 036_convolutional_bn for ONNX node: 036_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 036_convolutional_bn for ONNX tensor: 036_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_bn [BatchNormalization] outputs: [036_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 036_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_softplus [Softplus] inputs: [036_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 036_convolutional_softplus for ONNX node: 036_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 036_convolutional_softplus for ONNX tensor: 036_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_softplus [Softplus] outputs: [036_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 036_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_tanh [Tanh] inputs: [036_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 036_convolutional_tanh for ONNX node: 036_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 036_convolutional_tanh for ONNX tensor: 036_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_tanh [Tanh] outputs: [036_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 036_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_mish [Mul] inputs: [036_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [036_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 036_convolutional_mish for ONNX node: 036_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 036_convolutional_mish for ONNX tensor: 036_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 036_convolutional_mish [Mul] outputs: [036_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 037_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 036_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 034_shortcut
[05/21/2022-03:01:54] [V] [TRT] 037_shortcut [Add] inputs: [036_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [034_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 037_shortcut for ONNX node: 037_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 037_shortcut for ONNX tensor: 037_shortcut
[05/21/2022-03:01:54] [V] [TRT] 037_shortcut [Add] outputs: [037_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 038_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 037_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional [Conv] inputs: [037_shortcut -> (1, 128, 52, 52)[FLOAT]], [038_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 038_convolutional for ONNX node: 038_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 038_convolutional for ONNX tensor: 038_convolutional
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional [Conv] outputs: [038_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 038_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_bn [BatchNormalization] inputs: [038_convolutional -> (1, 128, 52, 52)[FLOAT]], [038_convolutional_bn_scale -> (128)[FLOAT]], [038_convolutional_bn_bias -> (128)[FLOAT]], [038_convolutional_bn_mean -> (128)[FLOAT]], [038_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 038_convolutional_bn for ONNX node: 038_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 038_convolutional_bn for ONNX tensor: 038_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_bn [BatchNormalization] outputs: [038_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 038_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_softplus [Softplus] inputs: [038_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 038_convolutional_softplus for ONNX node: 038_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 038_convolutional_softplus for ONNX tensor: 038_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_softplus [Softplus] outputs: [038_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 038_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_tanh [Tanh] inputs: [038_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 038_convolutional_tanh for ONNX node: 038_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 038_convolutional_tanh for ONNX tensor: 038_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_tanh [Tanh] outputs: [038_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 038_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_mish [Mul] inputs: [038_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [038_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 038_convolutional_mish for ONNX node: 038_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 038_convolutional_mish for ONNX tensor: 038_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 038_convolutional_mish [Mul] outputs: [038_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 039_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 038_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional [Conv] inputs: [038_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [039_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 039_convolutional for ONNX node: 039_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 039_convolutional for ONNX tensor: 039_convolutional
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional [Conv] outputs: [039_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 039_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_bn [BatchNormalization] inputs: [039_convolutional -> (1, 128, 52, 52)[FLOAT]], [039_convolutional_bn_scale -> (128)[FLOAT]], [039_convolutional_bn_bias -> (128)[FLOAT]], [039_convolutional_bn_mean -> (128)[FLOAT]], [039_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 039_convolutional_bn for ONNX node: 039_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 039_convolutional_bn for ONNX tensor: 039_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_bn [BatchNormalization] outputs: [039_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 039_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_softplus [Softplus] inputs: [039_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 039_convolutional_softplus for ONNX node: 039_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 039_convolutional_softplus for ONNX tensor: 039_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_softplus [Softplus] outputs: [039_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 039_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_tanh [Tanh] inputs: [039_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 039_convolutional_tanh for ONNX node: 039_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 039_convolutional_tanh for ONNX tensor: 039_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_tanh [Tanh] outputs: [039_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 039_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_mish [Mul] inputs: [039_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [039_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 039_convolutional_mish for ONNX node: 039_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 039_convolutional_mish for ONNX tensor: 039_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 039_convolutional_mish [Mul] outputs: [039_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 040_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 039_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 037_shortcut
[05/21/2022-03:01:54] [V] [TRT] 040_shortcut [Add] inputs: [039_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [037_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 040_shortcut for ONNX node: 040_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 040_shortcut for ONNX tensor: 040_shortcut
[05/21/2022-03:01:54] [V] [TRT] 040_shortcut [Add] outputs: [040_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 041_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 040_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional [Conv] inputs: [040_shortcut -> (1, 128, 52, 52)[FLOAT]], [041_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 041_convolutional for ONNX node: 041_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 041_convolutional for ONNX tensor: 041_convolutional
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional [Conv] outputs: [041_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 041_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_bn [BatchNormalization] inputs: [041_convolutional -> (1, 128, 52, 52)[FLOAT]], [041_convolutional_bn_scale -> (128)[FLOAT]], [041_convolutional_bn_bias -> (128)[FLOAT]], [041_convolutional_bn_mean -> (128)[FLOAT]], [041_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 041_convolutional_bn for ONNX node: 041_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 041_convolutional_bn for ONNX tensor: 041_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_bn [BatchNormalization] outputs: [041_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 041_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_softplus [Softplus] inputs: [041_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 041_convolutional_softplus for ONNX node: 041_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 041_convolutional_softplus for ONNX tensor: 041_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_softplus [Softplus] outputs: [041_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 041_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_tanh [Tanh] inputs: [041_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 041_convolutional_tanh for ONNX node: 041_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 041_convolutional_tanh for ONNX tensor: 041_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_tanh [Tanh] outputs: [041_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 041_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_mish [Mul] inputs: [041_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [041_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 041_convolutional_mish for ONNX node: 041_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 041_convolutional_mish for ONNX tensor: 041_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 041_convolutional_mish [Mul] outputs: [041_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 042_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 041_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional [Conv] inputs: [041_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [042_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 042_convolutional for ONNX node: 042_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 042_convolutional for ONNX tensor: 042_convolutional
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional [Conv] outputs: [042_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 042_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_bn [BatchNormalization] inputs: [042_convolutional -> (1, 128, 52, 52)[FLOAT]], [042_convolutional_bn_scale -> (128)[FLOAT]], [042_convolutional_bn_bias -> (128)[FLOAT]], [042_convolutional_bn_mean -> (128)[FLOAT]], [042_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 042_convolutional_bn for ONNX node: 042_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 042_convolutional_bn for ONNX tensor: 042_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_bn [BatchNormalization] outputs: [042_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 042_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_softplus [Softplus] inputs: [042_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 042_convolutional_softplus for ONNX node: 042_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 042_convolutional_softplus for ONNX tensor: 042_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_softplus [Softplus] outputs: [042_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 042_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_tanh [Tanh] inputs: [042_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 042_convolutional_tanh for ONNX node: 042_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 042_convolutional_tanh for ONNX tensor: 042_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_tanh [Tanh] outputs: [042_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 042_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_mish [Mul] inputs: [042_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [042_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 042_convolutional_mish for ONNX node: 042_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 042_convolutional_mish for ONNX tensor: 042_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 042_convolutional_mish [Mul] outputs: [042_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 043_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 042_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 040_shortcut
[05/21/2022-03:01:54] [V] [TRT] 043_shortcut [Add] inputs: [042_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [040_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 043_shortcut for ONNX node: 043_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 043_shortcut for ONNX tensor: 043_shortcut
[05/21/2022-03:01:54] [V] [TRT] 043_shortcut [Add] outputs: [043_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 044_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 043_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional [Conv] inputs: [043_shortcut -> (1, 128, 52, 52)[FLOAT]], [044_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 044_convolutional for ONNX node: 044_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 044_convolutional for ONNX tensor: 044_convolutional
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional [Conv] outputs: [044_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 044_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_bn [BatchNormalization] inputs: [044_convolutional -> (1, 128, 52, 52)[FLOAT]], [044_convolutional_bn_scale -> (128)[FLOAT]], [044_convolutional_bn_bias -> (128)[FLOAT]], [044_convolutional_bn_mean -> (128)[FLOAT]], [044_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 044_convolutional_bn for ONNX node: 044_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 044_convolutional_bn for ONNX tensor: 044_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_bn [BatchNormalization] outputs: [044_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 044_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_softplus [Softplus] inputs: [044_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 044_convolutional_softplus for ONNX node: 044_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 044_convolutional_softplus for ONNX tensor: 044_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_softplus [Softplus] outputs: [044_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 044_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_tanh [Tanh] inputs: [044_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 044_convolutional_tanh for ONNX node: 044_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 044_convolutional_tanh for ONNX tensor: 044_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_tanh [Tanh] outputs: [044_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 044_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_mish [Mul] inputs: [044_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [044_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 044_convolutional_mish for ONNX node: 044_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 044_convolutional_mish for ONNX tensor: 044_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 044_convolutional_mish [Mul] outputs: [044_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 045_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 044_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional [Conv] inputs: [044_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [045_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 045_convolutional for ONNX node: 045_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 045_convolutional for ONNX tensor: 045_convolutional
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional [Conv] outputs: [045_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 045_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_bn [BatchNormalization] inputs: [045_convolutional -> (1, 128, 52, 52)[FLOAT]], [045_convolutional_bn_scale -> (128)[FLOAT]], [045_convolutional_bn_bias -> (128)[FLOAT]], [045_convolutional_bn_mean -> (128)[FLOAT]], [045_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 045_convolutional_bn for ONNX node: 045_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 045_convolutional_bn for ONNX tensor: 045_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_bn [BatchNormalization] outputs: [045_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 045_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_softplus [Softplus] inputs: [045_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 045_convolutional_softplus for ONNX node: 045_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 045_convolutional_softplus for ONNX tensor: 045_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_softplus [Softplus] outputs: [045_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 045_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_tanh [Tanh] inputs: [045_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 045_convolutional_tanh for ONNX node: 045_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 045_convolutional_tanh for ONNX tensor: 045_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_tanh [Tanh] outputs: [045_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 045_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_mish [Mul] inputs: [045_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [045_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 045_convolutional_mish for ONNX node: 045_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 045_convolutional_mish for ONNX tensor: 045_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 045_convolutional_mish [Mul] outputs: [045_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 046_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 045_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 043_shortcut
[05/21/2022-03:01:54] [V] [TRT] 046_shortcut [Add] inputs: [045_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [043_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 046_shortcut for ONNX node: 046_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 046_shortcut for ONNX tensor: 046_shortcut
[05/21/2022-03:01:54] [V] [TRT] 046_shortcut [Add] outputs: [046_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 047_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 046_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional [Conv] inputs: [046_shortcut -> (1, 128, 52, 52)[FLOAT]], [047_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 047_convolutional for ONNX node: 047_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 047_convolutional for ONNX tensor: 047_convolutional
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional [Conv] outputs: [047_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 047_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_bn [BatchNormalization] inputs: [047_convolutional -> (1, 128, 52, 52)[FLOAT]], [047_convolutional_bn_scale -> (128)[FLOAT]], [047_convolutional_bn_bias -> (128)[FLOAT]], [047_convolutional_bn_mean -> (128)[FLOAT]], [047_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 047_convolutional_bn for ONNX node: 047_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 047_convolutional_bn for ONNX tensor: 047_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_bn [BatchNormalization] outputs: [047_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 047_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_softplus [Softplus] inputs: [047_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 047_convolutional_softplus for ONNX node: 047_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 047_convolutional_softplus for ONNX tensor: 047_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_softplus [Softplus] outputs: [047_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 047_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_tanh [Tanh] inputs: [047_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 047_convolutional_tanh for ONNX node: 047_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 047_convolutional_tanh for ONNX tensor: 047_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_tanh [Tanh] outputs: [047_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 047_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_mish [Mul] inputs: [047_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [047_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 047_convolutional_mish for ONNX node: 047_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 047_convolutional_mish for ONNX tensor: 047_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 047_convolutional_mish [Mul] outputs: [047_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 048_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 047_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional [Conv] inputs: [047_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [048_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 048_convolutional for ONNX node: 048_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 048_convolutional for ONNX tensor: 048_convolutional
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional [Conv] outputs: [048_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 048_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_bn [BatchNormalization] inputs: [048_convolutional -> (1, 128, 52, 52)[FLOAT]], [048_convolutional_bn_scale -> (128)[FLOAT]], [048_convolutional_bn_bias -> (128)[FLOAT]], [048_convolutional_bn_mean -> (128)[FLOAT]], [048_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 048_convolutional_bn for ONNX node: 048_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 048_convolutional_bn for ONNX tensor: 048_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_bn [BatchNormalization] outputs: [048_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 048_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_softplus [Softplus] inputs: [048_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 048_convolutional_softplus for ONNX node: 048_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 048_convolutional_softplus for ONNX tensor: 048_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_softplus [Softplus] outputs: [048_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 048_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_tanh [Tanh] inputs: [048_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 048_convolutional_tanh for ONNX node: 048_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 048_convolutional_tanh for ONNX tensor: 048_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_tanh [Tanh] outputs: [048_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 048_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_mish [Mul] inputs: [048_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [048_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 048_convolutional_mish for ONNX node: 048_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 048_convolutional_mish for ONNX tensor: 048_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 048_convolutional_mish [Mul] outputs: [048_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 049_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 048_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 046_shortcut
[05/21/2022-03:01:54] [V] [TRT] 049_shortcut [Add] inputs: [048_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [046_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 049_shortcut for ONNX node: 049_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 049_shortcut for ONNX tensor: 049_shortcut
[05/21/2022-03:01:54] [V] [TRT] 049_shortcut [Add] outputs: [049_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 050_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 049_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional [Conv] inputs: [049_shortcut -> (1, 128, 52, 52)[FLOAT]], [050_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 050_convolutional for ONNX node: 050_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 050_convolutional for ONNX tensor: 050_convolutional
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional [Conv] outputs: [050_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 050_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_bn [BatchNormalization] inputs: [050_convolutional -> (1, 128, 52, 52)[FLOAT]], [050_convolutional_bn_scale -> (128)[FLOAT]], [050_convolutional_bn_bias -> (128)[FLOAT]], [050_convolutional_bn_mean -> (128)[FLOAT]], [050_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 050_convolutional_bn for ONNX node: 050_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 050_convolutional_bn for ONNX tensor: 050_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_bn [BatchNormalization] outputs: [050_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 050_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_softplus [Softplus] inputs: [050_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 050_convolutional_softplus for ONNX node: 050_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 050_convolutional_softplus for ONNX tensor: 050_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_softplus [Softplus] outputs: [050_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 050_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_tanh [Tanh] inputs: [050_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 050_convolutional_tanh for ONNX node: 050_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 050_convolutional_tanh for ONNX tensor: 050_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_tanh [Tanh] outputs: [050_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 050_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_mish [Mul] inputs: [050_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [050_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 050_convolutional_mish for ONNX node: 050_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 050_convolutional_mish for ONNX tensor: 050_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 050_convolutional_mish [Mul] outputs: [050_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 051_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 050_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional [Conv] inputs: [050_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [051_convolutional_conv_weights -> (128, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 051_convolutional for ONNX node: 051_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 051_convolutional for ONNX tensor: 051_convolutional
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional [Conv] outputs: [051_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 051_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_bn [BatchNormalization] inputs: [051_convolutional -> (1, 128, 52, 52)[FLOAT]], [051_convolutional_bn_scale -> (128)[FLOAT]], [051_convolutional_bn_bias -> (128)[FLOAT]], [051_convolutional_bn_mean -> (128)[FLOAT]], [051_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 051_convolutional_bn for ONNX node: 051_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 051_convolutional_bn for ONNX tensor: 051_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_bn [BatchNormalization] outputs: [051_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 051_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_softplus [Softplus] inputs: [051_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 051_convolutional_softplus for ONNX node: 051_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 051_convolutional_softplus for ONNX tensor: 051_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_softplus [Softplus] outputs: [051_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 051_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_tanh [Tanh] inputs: [051_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 051_convolutional_tanh for ONNX node: 051_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 051_convolutional_tanh for ONNX tensor: 051_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_tanh [Tanh] outputs: [051_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 051_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_mish [Mul] inputs: [051_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [051_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 051_convolutional_mish for ONNX node: 051_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 051_convolutional_mish for ONNX tensor: 051_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 051_convolutional_mish [Mul] outputs: [051_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 052_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 051_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 049_shortcut
[05/21/2022-03:01:54] [V] [TRT] 052_shortcut [Add] inputs: [051_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [049_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 052_shortcut for ONNX node: 052_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 052_shortcut for ONNX tensor: 052_shortcut
[05/21/2022-03:01:54] [V] [TRT] 052_shortcut [Add] outputs: [052_shortcut -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 053_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 052_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional [Conv] inputs: [052_shortcut -> (1, 128, 52, 52)[FLOAT]], [053_convolutional_conv_weights -> (128, 128, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 053_convolutional for ONNX node: 053_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 053_convolutional for ONNX tensor: 053_convolutional
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional [Conv] outputs: [053_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 053_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_bn [BatchNormalization] inputs: [053_convolutional -> (1, 128, 52, 52)[FLOAT]], [053_convolutional_bn_scale -> (128)[FLOAT]], [053_convolutional_bn_bias -> (128)[FLOAT]], [053_convolutional_bn_mean -> (128)[FLOAT]], [053_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 053_convolutional_bn for ONNX node: 053_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 053_convolutional_bn for ONNX tensor: 053_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_bn [BatchNormalization] outputs: [053_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 053_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_softplus [Softplus] inputs: [053_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 053_convolutional_softplus for ONNX node: 053_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 053_convolutional_softplus for ONNX tensor: 053_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_softplus [Softplus] outputs: [053_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 053_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_tanh [Tanh] inputs: [053_convolutional_softplus -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 053_convolutional_tanh for ONNX node: 053_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 053_convolutional_tanh for ONNX tensor: 053_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_tanh [Tanh] outputs: [053_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 053_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_mish [Mul] inputs: [053_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], [053_convolutional_tanh -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 053_convolutional_mish for ONNX node: 053_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 053_convolutional_mish for ONNX tensor: 053_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 053_convolutional_mish [Mul] outputs: [053_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 054_route [Concat]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 053_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 026_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 054_route [Concat] inputs: [053_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], [026_convolutional_mish -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 054_route for ONNX node: 054_route
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 054_route for ONNX tensor: 054_route
[05/21/2022-03:01:54] [V] [TRT] 054_route [Concat] outputs: [054_route -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 055_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 054_route
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional [Conv] inputs: [054_route -> (1, 256, 52, 52)[FLOAT]], [055_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 055_convolutional for ONNX node: 055_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 055_convolutional for ONNX tensor: 055_convolutional
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional [Conv] outputs: [055_convolutional -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 055_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_bn [BatchNormalization] inputs: [055_convolutional -> (1, 256, 52, 52)[FLOAT]], [055_convolutional_bn_scale -> (256)[FLOAT]], [055_convolutional_bn_bias -> (256)[FLOAT]], [055_convolutional_bn_mean -> (256)[FLOAT]], [055_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 055_convolutional_bn for ONNX node: 055_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 055_convolutional_bn for ONNX tensor: 055_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_bn [BatchNormalization] outputs: [055_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 055_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_softplus [Softplus] inputs: [055_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 055_convolutional_softplus for ONNX node: 055_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 055_convolutional_softplus for ONNX tensor: 055_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_softplus [Softplus] outputs: [055_convolutional_softplus -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 055_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_tanh [Tanh] inputs: [055_convolutional_softplus -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 055_convolutional_tanh for ONNX node: 055_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 055_convolutional_tanh for ONNX tensor: 055_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_tanh [Tanh] outputs: [055_convolutional_tanh -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 055_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_mish [Mul] inputs: [055_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], [055_convolutional_tanh -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 055_convolutional_mish for ONNX node: 055_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 055_convolutional_mish for ONNX tensor: 055_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 055_convolutional_mish [Mul] outputs: [055_convolutional_mish -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 056_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 055_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional [Conv] inputs: [055_convolutional_mish -> (1, 256, 52, 52)[FLOAT]], [056_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 056_convolutional for ONNX node: 056_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 056_convolutional for ONNX tensor: 056_convolutional
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional [Conv] outputs: [056_convolutional -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 056_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_bn [BatchNormalization] inputs: [056_convolutional -> (1, 512, 26, 26)[FLOAT]], [056_convolutional_bn_scale -> (512)[FLOAT]], [056_convolutional_bn_bias -> (512)[FLOAT]], [056_convolutional_bn_mean -> (512)[FLOAT]], [056_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 056_convolutional_bn for ONNX node: 056_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 056_convolutional_bn for ONNX tensor: 056_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_bn [BatchNormalization] outputs: [056_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 056_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_softplus [Softplus] inputs: [056_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 056_convolutional_softplus for ONNX node: 056_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 056_convolutional_softplus for ONNX tensor: 056_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_softplus [Softplus] outputs: [056_convolutional_softplus -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 056_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_tanh [Tanh] inputs: [056_convolutional_softplus -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 056_convolutional_tanh for ONNX node: 056_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 056_convolutional_tanh for ONNX tensor: 056_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_tanh [Tanh] outputs: [056_convolutional_tanh -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 056_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_mish [Mul] inputs: [056_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], [056_convolutional_tanh -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 056_convolutional_mish for ONNX node: 056_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 056_convolutional_mish for ONNX tensor: 056_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 056_convolutional_mish [Mul] outputs: [056_convolutional_mish -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 057_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional [Conv] inputs: [056_convolutional_mish -> (1, 512, 26, 26)[FLOAT]], [057_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 057_convolutional for ONNX node: 057_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 057_convolutional for ONNX tensor: 057_convolutional
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional [Conv] outputs: [057_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 057_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_bn [BatchNormalization] inputs: [057_convolutional -> (1, 256, 26, 26)[FLOAT]], [057_convolutional_bn_scale -> (256)[FLOAT]], [057_convolutional_bn_bias -> (256)[FLOAT]], [057_convolutional_bn_mean -> (256)[FLOAT]], [057_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 057_convolutional_bn for ONNX node: 057_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 057_convolutional_bn for ONNX tensor: 057_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_bn [BatchNormalization] outputs: [057_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 057_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_softplus [Softplus] inputs: [057_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 057_convolutional_softplus for ONNX node: 057_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 057_convolutional_softplus for ONNX tensor: 057_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_softplus [Softplus] outputs: [057_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 057_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_tanh [Tanh] inputs: [057_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 057_convolutional_tanh for ONNX node: 057_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 057_convolutional_tanh for ONNX tensor: 057_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_tanh [Tanh] outputs: [057_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 057_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_mish [Mul] inputs: [057_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [057_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 057_convolutional_mish for ONNX node: 057_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 057_convolutional_mish for ONNX tensor: 057_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 057_convolutional_mish [Mul] outputs: [057_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 059_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 056_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional [Conv] inputs: [056_convolutional_mish -> (1, 512, 26, 26)[FLOAT]], [059_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 059_convolutional for ONNX node: 059_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 059_convolutional for ONNX tensor: 059_convolutional
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional [Conv] outputs: [059_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 059_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_bn [BatchNormalization] inputs: [059_convolutional -> (1, 256, 26, 26)[FLOAT]], [059_convolutional_bn_scale -> (256)[FLOAT]], [059_convolutional_bn_bias -> (256)[FLOAT]], [059_convolutional_bn_mean -> (256)[FLOAT]], [059_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 059_convolutional_bn for ONNX node: 059_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 059_convolutional_bn for ONNX tensor: 059_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_bn [BatchNormalization] outputs: [059_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 059_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_softplus [Softplus] inputs: [059_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 059_convolutional_softplus for ONNX node: 059_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 059_convolutional_softplus for ONNX tensor: 059_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_softplus [Softplus] outputs: [059_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 059_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_tanh [Tanh] inputs: [059_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 059_convolutional_tanh for ONNX node: 059_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 059_convolutional_tanh for ONNX tensor: 059_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_tanh [Tanh] outputs: [059_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 059_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_mish [Mul] inputs: [059_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [059_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 059_convolutional_mish for ONNX node: 059_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 059_convolutional_mish for ONNX tensor: 059_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 059_convolutional_mish [Mul] outputs: [059_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 060_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional [Conv] inputs: [059_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [060_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 060_convolutional for ONNX node: 060_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 060_convolutional for ONNX tensor: 060_convolutional
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional [Conv] outputs: [060_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 060_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_bn [BatchNormalization] inputs: [060_convolutional -> (1, 256, 26, 26)[FLOAT]], [060_convolutional_bn_scale -> (256)[FLOAT]], [060_convolutional_bn_bias -> (256)[FLOAT]], [060_convolutional_bn_mean -> (256)[FLOAT]], [060_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 060_convolutional_bn for ONNX node: 060_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 060_convolutional_bn for ONNX tensor: 060_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_bn [BatchNormalization] outputs: [060_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 060_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_softplus [Softplus] inputs: [060_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 060_convolutional_softplus for ONNX node: 060_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 060_convolutional_softplus for ONNX tensor: 060_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_softplus [Softplus] outputs: [060_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 060_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_tanh [Tanh] inputs: [060_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 060_convolutional_tanh for ONNX node: 060_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 060_convolutional_tanh for ONNX tensor: 060_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_tanh [Tanh] outputs: [060_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 060_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_mish [Mul] inputs: [060_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [060_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 060_convolutional_mish for ONNX node: 060_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 060_convolutional_mish for ONNX tensor: 060_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 060_convolutional_mish [Mul] outputs: [060_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 061_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 060_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional [Conv] inputs: [060_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [061_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 061_convolutional for ONNX node: 061_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 061_convolutional for ONNX tensor: 061_convolutional
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional [Conv] outputs: [061_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 061_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_bn [BatchNormalization] inputs: [061_convolutional -> (1, 256, 26, 26)[FLOAT]], [061_convolutional_bn_scale -> (256)[FLOAT]], [061_convolutional_bn_bias -> (256)[FLOAT]], [061_convolutional_bn_mean -> (256)[FLOAT]], [061_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 061_convolutional_bn for ONNX node: 061_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 061_convolutional_bn for ONNX tensor: 061_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_bn [BatchNormalization] outputs: [061_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 061_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_softplus [Softplus] inputs: [061_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 061_convolutional_softplus for ONNX node: 061_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 061_convolutional_softplus for ONNX tensor: 061_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_softplus [Softplus] outputs: [061_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 061_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_tanh [Tanh] inputs: [061_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 061_convolutional_tanh for ONNX node: 061_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 061_convolutional_tanh for ONNX tensor: 061_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_tanh [Tanh] outputs: [061_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 061_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_mish [Mul] inputs: [061_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [061_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 061_convolutional_mish for ONNX node: 061_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 061_convolutional_mish for ONNX tensor: 061_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 061_convolutional_mish [Mul] outputs: [061_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 062_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 061_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 059_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 062_shortcut [Add] inputs: [061_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [059_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 062_shortcut for ONNX node: 062_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 062_shortcut for ONNX tensor: 062_shortcut
[05/21/2022-03:01:54] [V] [TRT] 062_shortcut [Add] outputs: [062_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 063_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 062_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional [Conv] inputs: [062_shortcut -> (1, 256, 26, 26)[FLOAT]], [063_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 063_convolutional for ONNX node: 063_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 063_convolutional for ONNX tensor: 063_convolutional
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional [Conv] outputs: [063_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 063_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_bn [BatchNormalization] inputs: [063_convolutional -> (1, 256, 26, 26)[FLOAT]], [063_convolutional_bn_scale -> (256)[FLOAT]], [063_convolutional_bn_bias -> (256)[FLOAT]], [063_convolutional_bn_mean -> (256)[FLOAT]], [063_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 063_convolutional_bn for ONNX node: 063_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 063_convolutional_bn for ONNX tensor: 063_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_bn [BatchNormalization] outputs: [063_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 063_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_softplus [Softplus] inputs: [063_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 063_convolutional_softplus for ONNX node: 063_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 063_convolutional_softplus for ONNX tensor: 063_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_softplus [Softplus] outputs: [063_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 063_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_tanh [Tanh] inputs: [063_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 063_convolutional_tanh for ONNX node: 063_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 063_convolutional_tanh for ONNX tensor: 063_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_tanh [Tanh] outputs: [063_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 063_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_mish [Mul] inputs: [063_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [063_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 063_convolutional_mish for ONNX node: 063_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 063_convolutional_mish for ONNX tensor: 063_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 063_convolutional_mish [Mul] outputs: [063_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 064_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 063_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional [Conv] inputs: [063_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [064_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 064_convolutional for ONNX node: 064_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 064_convolutional for ONNX tensor: 064_convolutional
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional [Conv] outputs: [064_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 064_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_bn [BatchNormalization] inputs: [064_convolutional -> (1, 256, 26, 26)[FLOAT]], [064_convolutional_bn_scale -> (256)[FLOAT]], [064_convolutional_bn_bias -> (256)[FLOAT]], [064_convolutional_bn_mean -> (256)[FLOAT]], [064_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 064_convolutional_bn for ONNX node: 064_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 064_convolutional_bn for ONNX tensor: 064_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_bn [BatchNormalization] outputs: [064_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 064_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_softplus [Softplus] inputs: [064_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 064_convolutional_softplus for ONNX node: 064_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 064_convolutional_softplus for ONNX tensor: 064_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_softplus [Softplus] outputs: [064_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 064_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_tanh [Tanh] inputs: [064_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 064_convolutional_tanh for ONNX node: 064_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 064_convolutional_tanh for ONNX tensor: 064_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_tanh [Tanh] outputs: [064_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 064_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_mish [Mul] inputs: [064_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [064_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 064_convolutional_mish for ONNX node: 064_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 064_convolutional_mish for ONNX tensor: 064_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 064_convolutional_mish [Mul] outputs: [064_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 065_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 064_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 062_shortcut
[05/21/2022-03:01:54] [V] [TRT] 065_shortcut [Add] inputs: [064_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [062_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 065_shortcut for ONNX node: 065_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 065_shortcut for ONNX tensor: 065_shortcut
[05/21/2022-03:01:54] [V] [TRT] 065_shortcut [Add] outputs: [065_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 066_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 065_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional [Conv] inputs: [065_shortcut -> (1, 256, 26, 26)[FLOAT]], [066_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 066_convolutional for ONNX node: 066_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 066_convolutional for ONNX tensor: 066_convolutional
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional [Conv] outputs: [066_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 066_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_bn [BatchNormalization] inputs: [066_convolutional -> (1, 256, 26, 26)[FLOAT]], [066_convolutional_bn_scale -> (256)[FLOAT]], [066_convolutional_bn_bias -> (256)[FLOAT]], [066_convolutional_bn_mean -> (256)[FLOAT]], [066_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 066_convolutional_bn for ONNX node: 066_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 066_convolutional_bn for ONNX tensor: 066_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_bn [BatchNormalization] outputs: [066_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 066_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_softplus [Softplus] inputs: [066_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 066_convolutional_softplus for ONNX node: 066_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 066_convolutional_softplus for ONNX tensor: 066_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_softplus [Softplus] outputs: [066_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 066_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_tanh [Tanh] inputs: [066_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 066_convolutional_tanh for ONNX node: 066_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 066_convolutional_tanh for ONNX tensor: 066_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_tanh [Tanh] outputs: [066_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 066_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_mish [Mul] inputs: [066_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [066_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 066_convolutional_mish for ONNX node: 066_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 066_convolutional_mish for ONNX tensor: 066_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 066_convolutional_mish [Mul] outputs: [066_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 067_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 066_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional [Conv] inputs: [066_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [067_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 067_convolutional for ONNX node: 067_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 067_convolutional for ONNX tensor: 067_convolutional
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional [Conv] outputs: [067_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 067_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_bn [BatchNormalization] inputs: [067_convolutional -> (1, 256, 26, 26)[FLOAT]], [067_convolutional_bn_scale -> (256)[FLOAT]], [067_convolutional_bn_bias -> (256)[FLOAT]], [067_convolutional_bn_mean -> (256)[FLOAT]], [067_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 067_convolutional_bn for ONNX node: 067_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 067_convolutional_bn for ONNX tensor: 067_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_bn [BatchNormalization] outputs: [067_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 067_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_softplus [Softplus] inputs: [067_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 067_convolutional_softplus for ONNX node: 067_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 067_convolutional_softplus for ONNX tensor: 067_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_softplus [Softplus] outputs: [067_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 067_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_tanh [Tanh] inputs: [067_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 067_convolutional_tanh for ONNX node: 067_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 067_convolutional_tanh for ONNX tensor: 067_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_tanh [Tanh] outputs: [067_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 067_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_mish [Mul] inputs: [067_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [067_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 067_convolutional_mish for ONNX node: 067_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 067_convolutional_mish for ONNX tensor: 067_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 067_convolutional_mish [Mul] outputs: [067_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 068_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 067_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 065_shortcut
[05/21/2022-03:01:54] [V] [TRT] 068_shortcut [Add] inputs: [067_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [065_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 068_shortcut for ONNX node: 068_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 068_shortcut for ONNX tensor: 068_shortcut
[05/21/2022-03:01:54] [V] [TRT] 068_shortcut [Add] outputs: [068_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 069_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 068_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional [Conv] inputs: [068_shortcut -> (1, 256, 26, 26)[FLOAT]], [069_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 069_convolutional for ONNX node: 069_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 069_convolutional for ONNX tensor: 069_convolutional
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional [Conv] outputs: [069_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 069_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_bn [BatchNormalization] inputs: [069_convolutional -> (1, 256, 26, 26)[FLOAT]], [069_convolutional_bn_scale -> (256)[FLOAT]], [069_convolutional_bn_bias -> (256)[FLOAT]], [069_convolutional_bn_mean -> (256)[FLOAT]], [069_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 069_convolutional_bn for ONNX node: 069_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 069_convolutional_bn for ONNX tensor: 069_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_bn [BatchNormalization] outputs: [069_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 069_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_softplus [Softplus] inputs: [069_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 069_convolutional_softplus for ONNX node: 069_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 069_convolutional_softplus for ONNX tensor: 069_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_softplus [Softplus] outputs: [069_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 069_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_tanh [Tanh] inputs: [069_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 069_convolutional_tanh for ONNX node: 069_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 069_convolutional_tanh for ONNX tensor: 069_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_tanh [Tanh] outputs: [069_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 069_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_mish [Mul] inputs: [069_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [069_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 069_convolutional_mish for ONNX node: 069_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 069_convolutional_mish for ONNX tensor: 069_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 069_convolutional_mish [Mul] outputs: [069_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 070_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 069_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional [Conv] inputs: [069_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [070_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 070_convolutional for ONNX node: 070_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 070_convolutional for ONNX tensor: 070_convolutional
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional [Conv] outputs: [070_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 070_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_bn [BatchNormalization] inputs: [070_convolutional -> (1, 256, 26, 26)[FLOAT]], [070_convolutional_bn_scale -> (256)[FLOAT]], [070_convolutional_bn_bias -> (256)[FLOAT]], [070_convolutional_bn_mean -> (256)[FLOAT]], [070_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 070_convolutional_bn for ONNX node: 070_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 070_convolutional_bn for ONNX tensor: 070_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_bn [BatchNormalization] outputs: [070_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 070_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_softplus [Softplus] inputs: [070_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 070_convolutional_softplus for ONNX node: 070_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 070_convolutional_softplus for ONNX tensor: 070_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_softplus [Softplus] outputs: [070_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 070_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_tanh [Tanh] inputs: [070_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 070_convolutional_tanh for ONNX node: 070_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 070_convolutional_tanh for ONNX tensor: 070_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_tanh [Tanh] outputs: [070_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 070_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_mish [Mul] inputs: [070_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [070_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 070_convolutional_mish for ONNX node: 070_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 070_convolutional_mish for ONNX tensor: 070_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 070_convolutional_mish [Mul] outputs: [070_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 071_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 070_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 068_shortcut
[05/21/2022-03:01:54] [V] [TRT] 071_shortcut [Add] inputs: [070_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [068_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 071_shortcut for ONNX node: 071_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 071_shortcut for ONNX tensor: 071_shortcut
[05/21/2022-03:01:54] [V] [TRT] 071_shortcut [Add] outputs: [071_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 072_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 071_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional [Conv] inputs: [071_shortcut -> (1, 256, 26, 26)[FLOAT]], [072_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 072_convolutional for ONNX node: 072_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 072_convolutional for ONNX tensor: 072_convolutional
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional [Conv] outputs: [072_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 072_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_bn [BatchNormalization] inputs: [072_convolutional -> (1, 256, 26, 26)[FLOAT]], [072_convolutional_bn_scale -> (256)[FLOAT]], [072_convolutional_bn_bias -> (256)[FLOAT]], [072_convolutional_bn_mean -> (256)[FLOAT]], [072_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 072_convolutional_bn for ONNX node: 072_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 072_convolutional_bn for ONNX tensor: 072_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_bn [BatchNormalization] outputs: [072_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 072_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_softplus [Softplus] inputs: [072_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 072_convolutional_softplus for ONNX node: 072_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 072_convolutional_softplus for ONNX tensor: 072_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_softplus [Softplus] outputs: [072_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 072_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_tanh [Tanh] inputs: [072_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 072_convolutional_tanh for ONNX node: 072_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 072_convolutional_tanh for ONNX tensor: 072_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_tanh [Tanh] outputs: [072_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 072_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_mish [Mul] inputs: [072_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [072_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 072_convolutional_mish for ONNX node: 072_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 072_convolutional_mish for ONNX tensor: 072_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 072_convolutional_mish [Mul] outputs: [072_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 073_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 072_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional [Conv] inputs: [072_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [073_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 073_convolutional for ONNX node: 073_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 073_convolutional for ONNX tensor: 073_convolutional
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional [Conv] outputs: [073_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 073_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_bn [BatchNormalization] inputs: [073_convolutional -> (1, 256, 26, 26)[FLOAT]], [073_convolutional_bn_scale -> (256)[FLOAT]], [073_convolutional_bn_bias -> (256)[FLOAT]], [073_convolutional_bn_mean -> (256)[FLOAT]], [073_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 073_convolutional_bn for ONNX node: 073_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 073_convolutional_bn for ONNX tensor: 073_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_bn [BatchNormalization] outputs: [073_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 073_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_softplus [Softplus] inputs: [073_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 073_convolutional_softplus for ONNX node: 073_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 073_convolutional_softplus for ONNX tensor: 073_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_softplus [Softplus] outputs: [073_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 073_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_tanh [Tanh] inputs: [073_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 073_convolutional_tanh for ONNX node: 073_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 073_convolutional_tanh for ONNX tensor: 073_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_tanh [Tanh] outputs: [073_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 073_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_mish [Mul] inputs: [073_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [073_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 073_convolutional_mish for ONNX node: 073_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 073_convolutional_mish for ONNX tensor: 073_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 073_convolutional_mish [Mul] outputs: [073_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 074_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 073_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 071_shortcut
[05/21/2022-03:01:54] [V] [TRT] 074_shortcut [Add] inputs: [073_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [071_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 074_shortcut for ONNX node: 074_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 074_shortcut for ONNX tensor: 074_shortcut
[05/21/2022-03:01:54] [V] [TRT] 074_shortcut [Add] outputs: [074_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 075_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 074_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional [Conv] inputs: [074_shortcut -> (1, 256, 26, 26)[FLOAT]], [075_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 075_convolutional for ONNX node: 075_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 075_convolutional for ONNX tensor: 075_convolutional
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional [Conv] outputs: [075_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 075_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_bn [BatchNormalization] inputs: [075_convolutional -> (1, 256, 26, 26)[FLOAT]], [075_convolutional_bn_scale -> (256)[FLOAT]], [075_convolutional_bn_bias -> (256)[FLOAT]], [075_convolutional_bn_mean -> (256)[FLOAT]], [075_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 075_convolutional_bn for ONNX node: 075_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 075_convolutional_bn for ONNX tensor: 075_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_bn [BatchNormalization] outputs: [075_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 075_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_softplus [Softplus] inputs: [075_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 075_convolutional_softplus for ONNX node: 075_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 075_convolutional_softplus for ONNX tensor: 075_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_softplus [Softplus] outputs: [075_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 075_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_tanh [Tanh] inputs: [075_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 075_convolutional_tanh for ONNX node: 075_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 075_convolutional_tanh for ONNX tensor: 075_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_tanh [Tanh] outputs: [075_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 075_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_mish [Mul] inputs: [075_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [075_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 075_convolutional_mish for ONNX node: 075_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 075_convolutional_mish for ONNX tensor: 075_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 075_convolutional_mish [Mul] outputs: [075_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 076_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 075_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional [Conv] inputs: [075_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [076_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 076_convolutional for ONNX node: 076_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 076_convolutional for ONNX tensor: 076_convolutional
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional [Conv] outputs: [076_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 076_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_bn [BatchNormalization] inputs: [076_convolutional -> (1, 256, 26, 26)[FLOAT]], [076_convolutional_bn_scale -> (256)[FLOAT]], [076_convolutional_bn_bias -> (256)[FLOAT]], [076_convolutional_bn_mean -> (256)[FLOAT]], [076_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 076_convolutional_bn for ONNX node: 076_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 076_convolutional_bn for ONNX tensor: 076_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_bn [BatchNormalization] outputs: [076_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 076_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_softplus [Softplus] inputs: [076_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 076_convolutional_softplus for ONNX node: 076_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 076_convolutional_softplus for ONNX tensor: 076_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_softplus [Softplus] outputs: [076_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 076_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_tanh [Tanh] inputs: [076_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 076_convolutional_tanh for ONNX node: 076_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 076_convolutional_tanh for ONNX tensor: 076_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_tanh [Tanh] outputs: [076_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 076_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_mish [Mul] inputs: [076_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [076_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 076_convolutional_mish for ONNX node: 076_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 076_convolutional_mish for ONNX tensor: 076_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 076_convolutional_mish [Mul] outputs: [076_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 077_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 076_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 074_shortcut
[05/21/2022-03:01:54] [V] [TRT] 077_shortcut [Add] inputs: [076_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [074_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 077_shortcut for ONNX node: 077_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 077_shortcut for ONNX tensor: 077_shortcut
[05/21/2022-03:01:54] [V] [TRT] 077_shortcut [Add] outputs: [077_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 078_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 077_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional [Conv] inputs: [077_shortcut -> (1, 256, 26, 26)[FLOAT]], [078_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 078_convolutional for ONNX node: 078_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 078_convolutional for ONNX tensor: 078_convolutional
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional [Conv] outputs: [078_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 078_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_bn [BatchNormalization] inputs: [078_convolutional -> (1, 256, 26, 26)[FLOAT]], [078_convolutional_bn_scale -> (256)[FLOAT]], [078_convolutional_bn_bias -> (256)[FLOAT]], [078_convolutional_bn_mean -> (256)[FLOAT]], [078_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 078_convolutional_bn for ONNX node: 078_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 078_convolutional_bn for ONNX tensor: 078_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_bn [BatchNormalization] outputs: [078_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 078_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_softplus [Softplus] inputs: [078_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 078_convolutional_softplus for ONNX node: 078_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 078_convolutional_softplus for ONNX tensor: 078_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_softplus [Softplus] outputs: [078_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 078_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_tanh [Tanh] inputs: [078_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 078_convolutional_tanh for ONNX node: 078_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 078_convolutional_tanh for ONNX tensor: 078_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_tanh [Tanh] outputs: [078_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 078_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_mish [Mul] inputs: [078_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [078_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 078_convolutional_mish for ONNX node: 078_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 078_convolutional_mish for ONNX tensor: 078_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 078_convolutional_mish [Mul] outputs: [078_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 079_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 078_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional [Conv] inputs: [078_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [079_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 079_convolutional for ONNX node: 079_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 079_convolutional for ONNX tensor: 079_convolutional
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional [Conv] outputs: [079_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 079_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_bn [BatchNormalization] inputs: [079_convolutional -> (1, 256, 26, 26)[FLOAT]], [079_convolutional_bn_scale -> (256)[FLOAT]], [079_convolutional_bn_bias -> (256)[FLOAT]], [079_convolutional_bn_mean -> (256)[FLOAT]], [079_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 079_convolutional_bn for ONNX node: 079_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 079_convolutional_bn for ONNX tensor: 079_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_bn [BatchNormalization] outputs: [079_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 079_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_softplus [Softplus] inputs: [079_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 079_convolutional_softplus for ONNX node: 079_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 079_convolutional_softplus for ONNX tensor: 079_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_softplus [Softplus] outputs: [079_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 079_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_tanh [Tanh] inputs: [079_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 079_convolutional_tanh for ONNX node: 079_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 079_convolutional_tanh for ONNX tensor: 079_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_tanh [Tanh] outputs: [079_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 079_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_mish [Mul] inputs: [079_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [079_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 079_convolutional_mish for ONNX node: 079_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 079_convolutional_mish for ONNX tensor: 079_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 079_convolutional_mish [Mul] outputs: [079_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 080_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 079_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 077_shortcut
[05/21/2022-03:01:54] [V] [TRT] 080_shortcut [Add] inputs: [079_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [077_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 080_shortcut for ONNX node: 080_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 080_shortcut for ONNX tensor: 080_shortcut
[05/21/2022-03:01:54] [V] [TRT] 080_shortcut [Add] outputs: [080_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 081_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 080_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional [Conv] inputs: [080_shortcut -> (1, 256, 26, 26)[FLOAT]], [081_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 081_convolutional for ONNX node: 081_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 081_convolutional for ONNX tensor: 081_convolutional
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional [Conv] outputs: [081_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 081_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_bn [BatchNormalization] inputs: [081_convolutional -> (1, 256, 26, 26)[FLOAT]], [081_convolutional_bn_scale -> (256)[FLOAT]], [081_convolutional_bn_bias -> (256)[FLOAT]], [081_convolutional_bn_mean -> (256)[FLOAT]], [081_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 081_convolutional_bn for ONNX node: 081_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 081_convolutional_bn for ONNX tensor: 081_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_bn [BatchNormalization] outputs: [081_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 081_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_softplus [Softplus] inputs: [081_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 081_convolutional_softplus for ONNX node: 081_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 081_convolutional_softplus for ONNX tensor: 081_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_softplus [Softplus] outputs: [081_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 081_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_tanh [Tanh] inputs: [081_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 081_convolutional_tanh for ONNX node: 081_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 081_convolutional_tanh for ONNX tensor: 081_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_tanh [Tanh] outputs: [081_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 081_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_mish [Mul] inputs: [081_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [081_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 081_convolutional_mish for ONNX node: 081_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 081_convolutional_mish for ONNX tensor: 081_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 081_convolutional_mish [Mul] outputs: [081_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 082_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 081_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional [Conv] inputs: [081_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [082_convolutional_conv_weights -> (256, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 082_convolutional for ONNX node: 082_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 082_convolutional for ONNX tensor: 082_convolutional
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional [Conv] outputs: [082_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 082_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_bn [BatchNormalization] inputs: [082_convolutional -> (1, 256, 26, 26)[FLOAT]], [082_convolutional_bn_scale -> (256)[FLOAT]], [082_convolutional_bn_bias -> (256)[FLOAT]], [082_convolutional_bn_mean -> (256)[FLOAT]], [082_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 082_convolutional_bn for ONNX node: 082_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 082_convolutional_bn for ONNX tensor: 082_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_bn [BatchNormalization] outputs: [082_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 082_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_softplus [Softplus] inputs: [082_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 082_convolutional_softplus for ONNX node: 082_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 082_convolutional_softplus for ONNX tensor: 082_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_softplus [Softplus] outputs: [082_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 082_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_tanh [Tanh] inputs: [082_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 082_convolutional_tanh for ONNX node: 082_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 082_convolutional_tanh for ONNX tensor: 082_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_tanh [Tanh] outputs: [082_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 082_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_mish [Mul] inputs: [082_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [082_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 082_convolutional_mish for ONNX node: 082_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 082_convolutional_mish for ONNX tensor: 082_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 082_convolutional_mish [Mul] outputs: [082_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 083_shortcut [Add]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 082_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 080_shortcut
[05/21/2022-03:01:54] [V] [TRT] 083_shortcut [Add] inputs: [082_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [080_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 083_shortcut for ONNX node: 083_shortcut
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 083_shortcut for ONNX tensor: 083_shortcut
[05/21/2022-03:01:54] [V] [TRT] 083_shortcut [Add] outputs: [083_shortcut -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 084_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 083_shortcut
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional [Conv] inputs: [083_shortcut -> (1, 256, 26, 26)[FLOAT]], [084_convolutional_conv_weights -> (256, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 084_convolutional for ONNX node: 084_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 084_convolutional for ONNX tensor: 084_convolutional
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional [Conv] outputs: [084_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 084_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_bn [BatchNormalization] inputs: [084_convolutional -> (1, 256, 26, 26)[FLOAT]], [084_convolutional_bn_scale -> (256)[FLOAT]], [084_convolutional_bn_bias -> (256)[FLOAT]], [084_convolutional_bn_mean -> (256)[FLOAT]], [084_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 084_convolutional_bn for ONNX node: 084_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 084_convolutional_bn for ONNX tensor: 084_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_bn [BatchNormalization] outputs: [084_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 084_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_softplus [Softplus] inputs: [084_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 084_convolutional_softplus for ONNX node: 084_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 084_convolutional_softplus for ONNX tensor: 084_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_softplus [Softplus] outputs: [084_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 084_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_tanh [Tanh] inputs: [084_convolutional_softplus -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 084_convolutional_tanh for ONNX node: 084_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 084_convolutional_tanh for ONNX tensor: 084_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_tanh [Tanh] outputs: [084_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 084_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_mish [Mul] inputs: [084_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], [084_convolutional_tanh -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 084_convolutional_mish for ONNX node: 084_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 084_convolutional_mish for ONNX tensor: 084_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 084_convolutional_mish [Mul] outputs: [084_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 085_route [Concat]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 084_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 057_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 085_route [Concat] inputs: [084_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], [057_convolutional_mish -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 085_route for ONNX node: 085_route
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 085_route for ONNX tensor: 085_route
[05/21/2022-03:01:54] [V] [TRT] 085_route [Concat] outputs: [085_route -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 086_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 085_route
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional [Conv] inputs: [085_route -> (1, 512, 26, 26)[FLOAT]], [086_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 086_convolutional for ONNX node: 086_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 086_convolutional for ONNX tensor: 086_convolutional
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional [Conv] outputs: [086_convolutional -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 086_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_bn [BatchNormalization] inputs: [086_convolutional -> (1, 512, 26, 26)[FLOAT]], [086_convolutional_bn_scale -> (512)[FLOAT]], [086_convolutional_bn_bias -> (512)[FLOAT]], [086_convolutional_bn_mean -> (512)[FLOAT]], [086_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 086_convolutional_bn for ONNX node: 086_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 086_convolutional_bn for ONNX tensor: 086_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_bn [BatchNormalization] outputs: [086_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 086_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_softplus [Softplus] inputs: [086_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 086_convolutional_softplus for ONNX node: 086_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 086_convolutional_softplus for ONNX tensor: 086_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_softplus [Softplus] outputs: [086_convolutional_softplus -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 086_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_tanh [Tanh] inputs: [086_convolutional_softplus -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 086_convolutional_tanh for ONNX node: 086_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 086_convolutional_tanh for ONNX tensor: 086_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_tanh [Tanh] outputs: [086_convolutional_tanh -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 086_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_mish [Mul] inputs: [086_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], [086_convolutional_tanh -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 086_convolutional_mish for ONNX node: 086_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 086_convolutional_mish for ONNX tensor: 086_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 086_convolutional_mish [Mul] outputs: [086_convolutional_mish -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 087_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 086_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional [Conv] inputs: [086_convolutional_mish -> (1, 512, 26, 26)[FLOAT]], [087_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 087_convolutional for ONNX node: 087_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 087_convolutional for ONNX tensor: 087_convolutional
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional [Conv] outputs: [087_convolutional -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 087_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_bn [BatchNormalization] inputs: [087_convolutional -> (1, 1024, 13, 13)[FLOAT]], [087_convolutional_bn_scale -> (1024)[FLOAT]], [087_convolutional_bn_bias -> (1024)[FLOAT]], [087_convolutional_bn_mean -> (1024)[FLOAT]], [087_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 087_convolutional_bn for ONNX node: 087_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 087_convolutional_bn for ONNX tensor: 087_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_bn [BatchNormalization] outputs: [087_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 087_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_softplus [Softplus] inputs: [087_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 087_convolutional_softplus for ONNX node: 087_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 087_convolutional_softplus for ONNX tensor: 087_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_softplus [Softplus] outputs: [087_convolutional_softplus -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 087_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_tanh [Tanh] inputs: [087_convolutional_softplus -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 087_convolutional_tanh for ONNX node: 087_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 087_convolutional_tanh for ONNX tensor: 087_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_tanh [Tanh] outputs: [087_convolutional_tanh -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 087_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_mish [Mul] inputs: [087_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], [087_convolutional_tanh -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 087_convolutional_mish for ONNX node: 087_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 087_convolutional_mish for ONNX tensor: 087_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 087_convolutional_mish [Mul] outputs: [087_convolutional_mish -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 088_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional [Conv] inputs: [087_convolutional_mish -> (1, 1024, 13, 13)[FLOAT]], [088_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 088_convolutional for ONNX node: 088_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 088_convolutional for ONNX tensor: 088_convolutional
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional [Conv] outputs: [088_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 088_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_bn [BatchNormalization] inputs: [088_convolutional -> (1, 512, 13, 13)[FLOAT]], [088_convolutional_bn_scale -> (512)[FLOAT]], [088_convolutional_bn_bias -> (512)[FLOAT]], [088_convolutional_bn_mean -> (512)[FLOAT]], [088_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 088_convolutional_bn for ONNX node: 088_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 088_convolutional_bn for ONNX tensor: 088_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_bn [BatchNormalization] outputs: [088_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 088_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_softplus [Softplus] inputs: [088_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 088_convolutional_softplus for ONNX node: 088_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 088_convolutional_softplus for ONNX tensor: 088_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_softplus [Softplus] outputs: [088_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 088_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_tanh [Tanh] inputs: [088_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 088_convolutional_tanh for ONNX node: 088_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 088_convolutional_tanh for ONNX tensor: 088_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_tanh [Tanh] outputs: [088_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 088_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 088_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_mish [Mul] inputs: [088_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [088_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 088_convolutional_mish for ONNX node: 088_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 088_convolutional_mish for ONNX tensor: 088_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 088_convolutional_mish [Mul] outputs: [088_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 090_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 087_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional [Conv] inputs: [087_convolutional_mish -> (1, 1024, 13, 13)[FLOAT]], [090_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 090_convolutional for ONNX node: 090_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 090_convolutional for ONNX tensor: 090_convolutional
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional [Conv] outputs: [090_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 090_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_bn [BatchNormalization] inputs: [090_convolutional -> (1, 512, 13, 13)[FLOAT]], [090_convolutional_bn_scale -> (512)[FLOAT]], [090_convolutional_bn_bias -> (512)[FLOAT]], [090_convolutional_bn_mean -> (512)[FLOAT]], [090_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 090_convolutional_bn for ONNX node: 090_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 090_convolutional_bn for ONNX tensor: 090_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_bn [BatchNormalization] outputs: [090_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 090_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_softplus [Softplus] inputs: [090_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 090_convolutional_softplus for ONNX node: 090_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 090_convolutional_softplus for ONNX tensor: 090_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_softplus [Softplus] outputs: [090_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 090_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_tanh [Tanh] inputs: [090_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 090_convolutional_tanh for ONNX node: 090_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 090_convolutional_tanh for ONNX tensor: 090_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_tanh [Tanh] outputs: [090_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 090_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_mish [Mul] inputs: [090_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [090_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 090_convolutional_mish for ONNX node: 090_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 090_convolutional_mish for ONNX tensor: 090_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 090_convolutional_mish [Mul] outputs: [090_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 091_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 090_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional [Conv] inputs: [090_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [091_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 091_convolutional for ONNX node: 091_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 091_convolutional for ONNX tensor: 091_convolutional
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional [Conv] outputs: [091_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 091_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_bn [BatchNormalization] inputs: [091_convolutional -> (1, 512, 13, 13)[FLOAT]], [091_convolutional_bn_scale -> (512)[FLOAT]], [091_convolutional_bn_bias -> (512)[FLOAT]], [091_convolutional_bn_mean -> (512)[FLOAT]], [091_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 091_convolutional_bn for ONNX node: 091_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 091_convolutional_bn for ONNX tensor: 091_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_bn [BatchNormalization] outputs: [091_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 091_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_softplus [Softplus] inputs: [091_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 091_convolutional_softplus for ONNX node: 091_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 091_convolutional_softplus for ONNX tensor: 091_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_softplus [Softplus] outputs: [091_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 091_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_tanh [Tanh] inputs: [091_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 091_convolutional_tanh for ONNX node: 091_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 091_convolutional_tanh for ONNX tensor: 091_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_tanh [Tanh] outputs: [091_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 091_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_mish [Mul] inputs: [091_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [091_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 091_convolutional_mish for ONNX node: 091_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 091_convolutional_mish for ONNX tensor: 091_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 091_convolutional_mish [Mul] outputs: [091_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 092_convolutional [Conv]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 091_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_conv_weights
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional [Conv] inputs: [091_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [092_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 092_convolutional for ONNX node: 092_convolutional
[05/21/2022-03:01:54] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:54] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 092_convolutional for ONNX tensor: 092_convolutional
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional [Conv] outputs: [092_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 092_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_bn_scale
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_bn_bias
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_bn_mean
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_bn_var
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_bn [BatchNormalization] inputs: [092_convolutional -> (1, 512, 13, 13)[FLOAT]], [092_convolutional_bn_scale -> (512)[FLOAT]], [092_convolutional_bn_bias -> (512)[FLOAT]], [092_convolutional_bn_mean -> (512)[FLOAT]], [092_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 092_convolutional_bn for ONNX node: 092_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 092_convolutional_bn for ONNX tensor: 092_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_bn [BatchNormalization] outputs: [092_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 092_convolutional_softplus [Softplus]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_softplus [Softplus] inputs: [092_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 092_convolutional_softplus for ONNX node: 092_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 092_convolutional_softplus for ONNX tensor: 092_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_softplus [Softplus] outputs: [092_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 092_convolutional_tanh [Tanh]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_softplus
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_tanh [Tanh] inputs: [092_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 092_convolutional_tanh for ONNX node: 092_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 092_convolutional_tanh for ONNX tensor: 092_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_tanh [Tanh] outputs: [092_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Parsing node: 092_convolutional_mish [Mul]
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_bn
[05/21/2022-03:01:54] [V] [TRT] Searching for input: 092_convolutional_tanh
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_mish [Mul] inputs: [092_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [092_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:54] [V] [TRT] Registering layer: 092_convolutional_mish for ONNX node: 092_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] Registering tensor: 092_convolutional_mish for ONNX tensor: 092_convolutional_mish
[05/21/2022-03:01:54] [V] [TRT] 092_convolutional_mish [Mul] outputs: [092_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 093_shortcut [Add]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 092_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 090_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 093_shortcut [Add] inputs: [092_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [090_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 093_shortcut for ONNX node: 093_shortcut
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 093_shortcut for ONNX tensor: 093_shortcut
[05/21/2022-03:01:55] [V] [TRT] 093_shortcut [Add] outputs: [093_shortcut -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 094_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 093_shortcut
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional [Conv] inputs: [093_shortcut -> (1, 512, 13, 13)[FLOAT]], [094_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 094_convolutional for ONNX node: 094_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 094_convolutional for ONNX tensor: 094_convolutional
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional [Conv] outputs: [094_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 094_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_bn [BatchNormalization] inputs: [094_convolutional -> (1, 512, 13, 13)[FLOAT]], [094_convolutional_bn_scale -> (512)[FLOAT]], [094_convolutional_bn_bias -> (512)[FLOAT]], [094_convolutional_bn_mean -> (512)[FLOAT]], [094_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 094_convolutional_bn for ONNX node: 094_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 094_convolutional_bn for ONNX tensor: 094_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_bn [BatchNormalization] outputs: [094_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 094_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_softplus [Softplus] inputs: [094_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 094_convolutional_softplus for ONNX node: 094_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 094_convolutional_softplus for ONNX tensor: 094_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_softplus [Softplus] outputs: [094_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 094_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_tanh [Tanh] inputs: [094_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 094_convolutional_tanh for ONNX node: 094_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 094_convolutional_tanh for ONNX tensor: 094_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_tanh [Tanh] outputs: [094_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 094_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_mish [Mul] inputs: [094_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [094_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 094_convolutional_mish for ONNX node: 094_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 094_convolutional_mish for ONNX tensor: 094_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 094_convolutional_mish [Mul] outputs: [094_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 095_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 094_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional [Conv] inputs: [094_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [095_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 095_convolutional for ONNX node: 095_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 095_convolutional for ONNX tensor: 095_convolutional
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional [Conv] outputs: [095_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 095_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_bn [BatchNormalization] inputs: [095_convolutional -> (1, 512, 13, 13)[FLOAT]], [095_convolutional_bn_scale -> (512)[FLOAT]], [095_convolutional_bn_bias -> (512)[FLOAT]], [095_convolutional_bn_mean -> (512)[FLOAT]], [095_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 095_convolutional_bn for ONNX node: 095_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 095_convolutional_bn for ONNX tensor: 095_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_bn [BatchNormalization] outputs: [095_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 095_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_softplus [Softplus] inputs: [095_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 095_convolutional_softplus for ONNX node: 095_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 095_convolutional_softplus for ONNX tensor: 095_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_softplus [Softplus] outputs: [095_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 095_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_tanh [Tanh] inputs: [095_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 095_convolutional_tanh for ONNX node: 095_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 095_convolutional_tanh for ONNX tensor: 095_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_tanh [Tanh] outputs: [095_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 095_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_mish [Mul] inputs: [095_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [095_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 095_convolutional_mish for ONNX node: 095_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 095_convolutional_mish for ONNX tensor: 095_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 095_convolutional_mish [Mul] outputs: [095_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 096_shortcut [Add]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 095_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 093_shortcut
[05/21/2022-03:01:55] [V] [TRT] 096_shortcut [Add] inputs: [095_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [093_shortcut -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 096_shortcut for ONNX node: 096_shortcut
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 096_shortcut for ONNX tensor: 096_shortcut
[05/21/2022-03:01:55] [V] [TRT] 096_shortcut [Add] outputs: [096_shortcut -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 097_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 096_shortcut
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional [Conv] inputs: [096_shortcut -> (1, 512, 13, 13)[FLOAT]], [097_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 097_convolutional for ONNX node: 097_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 097_convolutional for ONNX tensor: 097_convolutional
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional [Conv] outputs: [097_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 097_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_bn [BatchNormalization] inputs: [097_convolutional -> (1, 512, 13, 13)[FLOAT]], [097_convolutional_bn_scale -> (512)[FLOAT]], [097_convolutional_bn_bias -> (512)[FLOAT]], [097_convolutional_bn_mean -> (512)[FLOAT]], [097_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 097_convolutional_bn for ONNX node: 097_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 097_convolutional_bn for ONNX tensor: 097_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_bn [BatchNormalization] outputs: [097_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 097_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_softplus [Softplus] inputs: [097_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 097_convolutional_softplus for ONNX node: 097_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 097_convolutional_softplus for ONNX tensor: 097_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_softplus [Softplus] outputs: [097_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 097_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_tanh [Tanh] inputs: [097_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 097_convolutional_tanh for ONNX node: 097_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 097_convolutional_tanh for ONNX tensor: 097_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_tanh [Tanh] outputs: [097_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 097_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_mish [Mul] inputs: [097_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [097_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 097_convolutional_mish for ONNX node: 097_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 097_convolutional_mish for ONNX tensor: 097_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 097_convolutional_mish [Mul] outputs: [097_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 098_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 097_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional [Conv] inputs: [097_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [098_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 098_convolutional for ONNX node: 098_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 098_convolutional for ONNX tensor: 098_convolutional
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional [Conv] outputs: [098_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 098_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_bn [BatchNormalization] inputs: [098_convolutional -> (1, 512, 13, 13)[FLOAT]], [098_convolutional_bn_scale -> (512)[FLOAT]], [098_convolutional_bn_bias -> (512)[FLOAT]], [098_convolutional_bn_mean -> (512)[FLOAT]], [098_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 098_convolutional_bn for ONNX node: 098_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 098_convolutional_bn for ONNX tensor: 098_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_bn [BatchNormalization] outputs: [098_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 098_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_softplus [Softplus] inputs: [098_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 098_convolutional_softplus for ONNX node: 098_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 098_convolutional_softplus for ONNX tensor: 098_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_softplus [Softplus] outputs: [098_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 098_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_tanh [Tanh] inputs: [098_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 098_convolutional_tanh for ONNX node: 098_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 098_convolutional_tanh for ONNX tensor: 098_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_tanh [Tanh] outputs: [098_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 098_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_mish [Mul] inputs: [098_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [098_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 098_convolutional_mish for ONNX node: 098_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 098_convolutional_mish for ONNX tensor: 098_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 098_convolutional_mish [Mul] outputs: [098_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 099_shortcut [Add]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 098_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 096_shortcut
[05/21/2022-03:01:55] [V] [TRT] 099_shortcut [Add] inputs: [098_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [096_shortcut -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 099_shortcut for ONNX node: 099_shortcut
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 099_shortcut for ONNX tensor: 099_shortcut
[05/21/2022-03:01:55] [V] [TRT] 099_shortcut [Add] outputs: [099_shortcut -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 100_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 099_shortcut
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional [Conv] inputs: [099_shortcut -> (1, 512, 13, 13)[FLOAT]], [100_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 100_convolutional for ONNX node: 100_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 100_convolutional for ONNX tensor: 100_convolutional
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional [Conv] outputs: [100_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 100_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_bn [BatchNormalization] inputs: [100_convolutional -> (1, 512, 13, 13)[FLOAT]], [100_convolutional_bn_scale -> (512)[FLOAT]], [100_convolutional_bn_bias -> (512)[FLOAT]], [100_convolutional_bn_mean -> (512)[FLOAT]], [100_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 100_convolutional_bn for ONNX node: 100_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 100_convolutional_bn for ONNX tensor: 100_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_bn [BatchNormalization] outputs: [100_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 100_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_softplus [Softplus] inputs: [100_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 100_convolutional_softplus for ONNX node: 100_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 100_convolutional_softplus for ONNX tensor: 100_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_softplus [Softplus] outputs: [100_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 100_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_tanh [Tanh] inputs: [100_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 100_convolutional_tanh for ONNX node: 100_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 100_convolutional_tanh for ONNX tensor: 100_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_tanh [Tanh] outputs: [100_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 100_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_mish [Mul] inputs: [100_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [100_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 100_convolutional_mish for ONNX node: 100_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 100_convolutional_mish for ONNX tensor: 100_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 100_convolutional_mish [Mul] outputs: [100_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 101_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 100_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional [Conv] inputs: [100_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [101_convolutional_conv_weights -> (512, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 101_convolutional for ONNX node: 101_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 101_convolutional for ONNX tensor: 101_convolutional
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional [Conv] outputs: [101_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 101_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_bn [BatchNormalization] inputs: [101_convolutional -> (1, 512, 13, 13)[FLOAT]], [101_convolutional_bn_scale -> (512)[FLOAT]], [101_convolutional_bn_bias -> (512)[FLOAT]], [101_convolutional_bn_mean -> (512)[FLOAT]], [101_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 101_convolutional_bn for ONNX node: 101_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 101_convolutional_bn for ONNX tensor: 101_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_bn [BatchNormalization] outputs: [101_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 101_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_softplus [Softplus] inputs: [101_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 101_convolutional_softplus for ONNX node: 101_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 101_convolutional_softplus for ONNX tensor: 101_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_softplus [Softplus] outputs: [101_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 101_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_tanh [Tanh] inputs: [101_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 101_convolutional_tanh for ONNX node: 101_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 101_convolutional_tanh for ONNX tensor: 101_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_tanh [Tanh] outputs: [101_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 101_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_mish [Mul] inputs: [101_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [101_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 101_convolutional_mish for ONNX node: 101_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 101_convolutional_mish for ONNX tensor: 101_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 101_convolutional_mish [Mul] outputs: [101_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 102_shortcut [Add]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 101_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 099_shortcut
[05/21/2022-03:01:55] [V] [TRT] 102_shortcut [Add] inputs: [101_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [099_shortcut -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 102_shortcut for ONNX node: 102_shortcut
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 102_shortcut for ONNX tensor: 102_shortcut
[05/21/2022-03:01:55] [V] [TRT] 102_shortcut [Add] outputs: [102_shortcut -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 103_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 102_shortcut
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional [Conv] inputs: [102_shortcut -> (1, 512, 13, 13)[FLOAT]], [103_convolutional_conv_weights -> (512, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 103_convolutional for ONNX node: 103_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 103_convolutional for ONNX tensor: 103_convolutional
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional [Conv] outputs: [103_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 103_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_bn [BatchNormalization] inputs: [103_convolutional -> (1, 512, 13, 13)[FLOAT]], [103_convolutional_bn_scale -> (512)[FLOAT]], [103_convolutional_bn_bias -> (512)[FLOAT]], [103_convolutional_bn_mean -> (512)[FLOAT]], [103_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 103_convolutional_bn for ONNX node: 103_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 103_convolutional_bn for ONNX tensor: 103_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_bn [BatchNormalization] outputs: [103_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 103_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_softplus [Softplus] inputs: [103_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 103_convolutional_softplus for ONNX node: 103_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 103_convolutional_softplus for ONNX tensor: 103_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_softplus [Softplus] outputs: [103_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 103_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_tanh [Tanh] inputs: [103_convolutional_softplus -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 103_convolutional_tanh for ONNX node: 103_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 103_convolutional_tanh for ONNX tensor: 103_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_tanh [Tanh] outputs: [103_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 103_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_mish [Mul] inputs: [103_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], [103_convolutional_tanh -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 103_convolutional_mish for ONNX node: 103_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 103_convolutional_mish for ONNX tensor: 103_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 103_convolutional_mish [Mul] outputs: [103_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 104_route [Concat]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 103_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 088_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 104_route [Concat] inputs: [103_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], [088_convolutional_mish -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 104_route for ONNX node: 104_route
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 104_route for ONNX tensor: 104_route
[05/21/2022-03:01:55] [V] [TRT] 104_route [Concat] outputs: [104_route -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 105_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 104_route
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional [Conv] inputs: [104_route -> (1, 1024, 13, 13)[FLOAT]], [105_convolutional_conv_weights -> (1024, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 105_convolutional for ONNX node: 105_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 105_convolutional for ONNX tensor: 105_convolutional
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional [Conv] outputs: [105_convolutional -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 105_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_bn [BatchNormalization] inputs: [105_convolutional -> (1, 1024, 13, 13)[FLOAT]], [105_convolutional_bn_scale -> (1024)[FLOAT]], [105_convolutional_bn_bias -> (1024)[FLOAT]], [105_convolutional_bn_mean -> (1024)[FLOAT]], [105_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 105_convolutional_bn for ONNX node: 105_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 105_convolutional_bn for ONNX tensor: 105_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_bn [BatchNormalization] outputs: [105_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 105_convolutional_softplus [Softplus]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_softplus [Softplus] inputs: [105_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 105_convolutional_softplus for ONNX node: 105_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 105_convolutional_softplus for ONNX tensor: 105_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_softplus [Softplus] outputs: [105_convolutional_softplus -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 105_convolutional_tanh [Tanh]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_softplus
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_tanh [Tanh] inputs: [105_convolutional_softplus -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 105_convolutional_tanh for ONNX node: 105_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 105_convolutional_tanh for ONNX tensor: 105_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_tanh [Tanh] outputs: [105_convolutional_tanh -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 105_convolutional_mish [Mul]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_tanh
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_mish [Mul] inputs: [105_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], [105_convolutional_tanh -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 105_convolutional_mish for ONNX node: 105_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 105_convolutional_mish for ONNX tensor: 105_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] 105_convolutional_mish [Mul] outputs: [105_convolutional_mish -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 106_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 105_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 106_convolutional [Conv] inputs: [105_convolutional_mish -> (1, 1024, 13, 13)[FLOAT]], [106_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 106_convolutional for ONNX node: 106_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 106_convolutional for ONNX tensor: 106_convolutional
[05/21/2022-03:01:55] [V] [TRT] 106_convolutional [Conv] outputs: [106_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 106_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 106_convolutional_bn [BatchNormalization] inputs: [106_convolutional -> (1, 512, 13, 13)[FLOAT]], [106_convolutional_bn_scale -> (512)[FLOAT]], [106_convolutional_bn_bias -> (512)[FLOAT]], [106_convolutional_bn_mean -> (512)[FLOAT]], [106_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 106_convolutional_bn for ONNX node: 106_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 106_convolutional_bn for ONNX tensor: 106_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 106_convolutional_bn [BatchNormalization] outputs: [106_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 106_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 106_convolutional_lrelu [LeakyRelu] inputs: [106_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 106_convolutional_lrelu for ONNX node: 106_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 106_convolutional_lrelu for ONNX tensor: 106_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 106_convolutional_lrelu [LeakyRelu] outputs: [106_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 107_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 106_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 107_convolutional [Conv] inputs: [106_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], [107_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 107_convolutional for ONNX node: 107_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 107_convolutional for ONNX tensor: 107_convolutional
[05/21/2022-03:01:55] [V] [TRT] 107_convolutional [Conv] outputs: [107_convolutional -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 107_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 107_convolutional_bn [BatchNormalization] inputs: [107_convolutional -> (1, 1024, 13, 13)[FLOAT]], [107_convolutional_bn_scale -> (1024)[FLOAT]], [107_convolutional_bn_bias -> (1024)[FLOAT]], [107_convolutional_bn_mean -> (1024)[FLOAT]], [107_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 107_convolutional_bn for ONNX node: 107_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 107_convolutional_bn for ONNX tensor: 107_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 107_convolutional_bn [BatchNormalization] outputs: [107_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 107_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 107_convolutional_lrelu [LeakyRelu] inputs: [107_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 107_convolutional_lrelu for ONNX node: 107_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 107_convolutional_lrelu for ONNX tensor: 107_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 107_convolutional_lrelu [LeakyRelu] outputs: [107_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 108_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 107_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 108_convolutional [Conv] inputs: [107_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], [108_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 108_convolutional for ONNX node: 108_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 108_convolutional for ONNX tensor: 108_convolutional
[05/21/2022-03:01:55] [V] [TRT] 108_convolutional [Conv] outputs: [108_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 108_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 108_convolutional_bn [BatchNormalization] inputs: [108_convolutional -> (1, 512, 13, 13)[FLOAT]], [108_convolutional_bn_scale -> (512)[FLOAT]], [108_convolutional_bn_bias -> (512)[FLOAT]], [108_convolutional_bn_mean -> (512)[FLOAT]], [108_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 108_convolutional_bn for ONNX node: 108_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 108_convolutional_bn for ONNX tensor: 108_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 108_convolutional_bn [BatchNormalization] outputs: [108_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 108_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 108_convolutional_lrelu [LeakyRelu] inputs: [108_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 108_convolutional_lrelu for ONNX node: 108_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 108_convolutional_lrelu for ONNX tensor: 108_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 108_convolutional_lrelu [LeakyRelu] outputs: [108_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 109_maxpool [MaxPool]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 109_maxpool [MaxPool] inputs: [108_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 109_maxpool for ONNX node: 109_maxpool
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 109_maxpool for ONNX tensor: 109_maxpool
[05/21/2022-03:01:55] [V] [TRT] 109_maxpool [MaxPool] outputs: [109_maxpool -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 111_maxpool [MaxPool]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 111_maxpool [MaxPool] inputs: [108_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 111_maxpool for ONNX node: 111_maxpool
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 111_maxpool for ONNX tensor: 111_maxpool
[05/21/2022-03:01:55] [V] [TRT] 111_maxpool [MaxPool] outputs: [111_maxpool -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 113_maxpool [MaxPool]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 113_maxpool [MaxPool] inputs: [108_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 113_maxpool for ONNX node: 113_maxpool
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 113_maxpool for ONNX tensor: 113_maxpool
[05/21/2022-03:01:55] [V] [TRT] 113_maxpool [MaxPool] outputs: [113_maxpool -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 114_route [Concat]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 113_maxpool
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 111_maxpool
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 109_maxpool
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 108_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 114_route [Concat] inputs: [113_maxpool -> (1, 512, 13, 13)[FLOAT]], [111_maxpool -> (1, 512, 13, 13)[FLOAT]], [109_maxpool -> (1, 512, 13, 13)[FLOAT]], [108_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 114_route for ONNX node: 114_route
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 114_route for ONNX tensor: 114_route
[05/21/2022-03:01:55] [V] [TRT] 114_route [Concat] outputs: [114_route -> (1, 2048, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 115_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 114_route
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 115_convolutional [Conv] inputs: [114_route -> (1, 2048, 13, 13)[FLOAT]], [115_convolutional_conv_weights -> (512, 2048, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 2048, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 115_convolutional for ONNX node: 115_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 115_convolutional for ONNX tensor: 115_convolutional
[05/21/2022-03:01:55] [V] [TRT] 115_convolutional [Conv] outputs: [115_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 115_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 115_convolutional_bn [BatchNormalization] inputs: [115_convolutional -> (1, 512, 13, 13)[FLOAT]], [115_convolutional_bn_scale -> (512)[FLOAT]], [115_convolutional_bn_bias -> (512)[FLOAT]], [115_convolutional_bn_mean -> (512)[FLOAT]], [115_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 115_convolutional_bn for ONNX node: 115_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 115_convolutional_bn for ONNX tensor: 115_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 115_convolutional_bn [BatchNormalization] outputs: [115_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 115_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 115_convolutional_lrelu [LeakyRelu] inputs: [115_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 115_convolutional_lrelu for ONNX node: 115_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 115_convolutional_lrelu for ONNX tensor: 115_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 115_convolutional_lrelu [LeakyRelu] outputs: [115_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 116_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 115_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 116_convolutional [Conv] inputs: [115_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], [116_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 116_convolutional for ONNX node: 116_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 116_convolutional for ONNX tensor: 116_convolutional
[05/21/2022-03:01:55] [V] [TRT] 116_convolutional [Conv] outputs: [116_convolutional -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 116_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 116_convolutional_bn [BatchNormalization] inputs: [116_convolutional -> (1, 1024, 13, 13)[FLOAT]], [116_convolutional_bn_scale -> (1024)[FLOAT]], [116_convolutional_bn_bias -> (1024)[FLOAT]], [116_convolutional_bn_mean -> (1024)[FLOAT]], [116_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 116_convolutional_bn for ONNX node: 116_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 116_convolutional_bn for ONNX tensor: 116_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 116_convolutional_bn [BatchNormalization] outputs: [116_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 116_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 116_convolutional_lrelu [LeakyRelu] inputs: [116_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 116_convolutional_lrelu for ONNX node: 116_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 116_convolutional_lrelu for ONNX tensor: 116_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 116_convolutional_lrelu [LeakyRelu] outputs: [116_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 117_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 116_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 117_convolutional [Conv] inputs: [116_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], [117_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 117_convolutional for ONNX node: 117_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 117_convolutional for ONNX tensor: 117_convolutional
[05/21/2022-03:01:55] [V] [TRT] 117_convolutional [Conv] outputs: [117_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 117_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 117_convolutional_bn [BatchNormalization] inputs: [117_convolutional -> (1, 512, 13, 13)[FLOAT]], [117_convolutional_bn_scale -> (512)[FLOAT]], [117_convolutional_bn_bias -> (512)[FLOAT]], [117_convolutional_bn_mean -> (512)[FLOAT]], [117_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 117_convolutional_bn for ONNX node: 117_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 117_convolutional_bn for ONNX tensor: 117_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 117_convolutional_bn [BatchNormalization] outputs: [117_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 117_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 117_convolutional_lrelu [LeakyRelu] inputs: [117_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 117_convolutional_lrelu for ONNX node: 117_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 117_convolutional_lrelu for ONNX tensor: 117_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 117_convolutional_lrelu [LeakyRelu] outputs: [117_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 118_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 118_convolutional [Conv] inputs: [117_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], [118_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 118_convolutional for ONNX node: 118_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 118_convolutional for ONNX tensor: 118_convolutional
[05/21/2022-03:01:55] [V] [TRT] 118_convolutional [Conv] outputs: [118_convolutional -> (1, 256, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 118_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 118_convolutional_bn [BatchNormalization] inputs: [118_convolutional -> (1, 256, 13, 13)[FLOAT]], [118_convolutional_bn_scale -> (256)[FLOAT]], [118_convolutional_bn_bias -> (256)[FLOAT]], [118_convolutional_bn_mean -> (256)[FLOAT]], [118_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 118_convolutional_bn for ONNX node: 118_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 118_convolutional_bn for ONNX tensor: 118_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 118_convolutional_bn [BatchNormalization] outputs: [118_convolutional_bn -> (1, 256, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 118_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 118_convolutional_lrelu [LeakyRelu] inputs: [118_convolutional_bn -> (1, 256, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 118_convolutional_lrelu for ONNX node: 118_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 118_convolutional_lrelu for ONNX tensor: 118_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 118_convolutional_lrelu [LeakyRelu] outputs: [118_convolutional_lrelu -> (1, 256, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 119_upsample [Upsample]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 118_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 119_upsample_scale
[05/21/2022-03:01:55] [V] [TRT] 119_upsample [Upsample] inputs: [118_convolutional_lrelu -> (1, 256, 13, 13)[FLOAT]], [119_upsample_scale -> (4)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 119_upsample for ONNX node: 119_upsample
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 119_upsample for ONNX tensor: 119_upsample
[05/21/2022-03:01:55] [V] [TRT] 119_upsample [Upsample] outputs: [119_upsample -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 121_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 086_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 121_convolutional [Conv] inputs: [086_convolutional_mish -> (1, 512, 26, 26)[FLOAT]], [121_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 121_convolutional for ONNX node: 121_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 121_convolutional for ONNX tensor: 121_convolutional
[05/21/2022-03:01:55] [V] [TRT] 121_convolutional [Conv] outputs: [121_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 121_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 121_convolutional_bn [BatchNormalization] inputs: [121_convolutional -> (1, 256, 26, 26)[FLOAT]], [121_convolutional_bn_scale -> (256)[FLOAT]], [121_convolutional_bn_bias -> (256)[FLOAT]], [121_convolutional_bn_mean -> (256)[FLOAT]], [121_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 121_convolutional_bn for ONNX node: 121_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 121_convolutional_bn for ONNX tensor: 121_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 121_convolutional_bn [BatchNormalization] outputs: [121_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 121_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 121_convolutional_lrelu [LeakyRelu] inputs: [121_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 121_convolutional_lrelu for ONNX node: 121_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 121_convolutional_lrelu for ONNX tensor: 121_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 121_convolutional_lrelu [LeakyRelu] outputs: [121_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 122_route [Concat]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 121_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 119_upsample
[05/21/2022-03:01:55] [V] [TRT] 122_route [Concat] inputs: [121_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [119_upsample -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 122_route for ONNX node: 122_route
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 122_route for ONNX tensor: 122_route
[05/21/2022-03:01:55] [V] [TRT] 122_route [Concat] outputs: [122_route -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 123_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 122_route
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 123_convolutional [Conv] inputs: [122_route -> (1, 512, 26, 26)[FLOAT]], [123_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 123_convolutional for ONNX node: 123_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 123_convolutional for ONNX tensor: 123_convolutional
[05/21/2022-03:01:55] [V] [TRT] 123_convolutional [Conv] outputs: [123_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 123_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 123_convolutional_bn [BatchNormalization] inputs: [123_convolutional -> (1, 256, 26, 26)[FLOAT]], [123_convolutional_bn_scale -> (256)[FLOAT]], [123_convolutional_bn_bias -> (256)[FLOAT]], [123_convolutional_bn_mean -> (256)[FLOAT]], [123_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 123_convolutional_bn for ONNX node: 123_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 123_convolutional_bn for ONNX tensor: 123_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 123_convolutional_bn [BatchNormalization] outputs: [123_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 123_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 123_convolutional_lrelu [LeakyRelu] inputs: [123_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 123_convolutional_lrelu for ONNX node: 123_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 123_convolutional_lrelu for ONNX tensor: 123_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 123_convolutional_lrelu [LeakyRelu] outputs: [123_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 124_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 123_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 124_convolutional [Conv] inputs: [123_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [124_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 124_convolutional for ONNX node: 124_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 124_convolutional for ONNX tensor: 124_convolutional
[05/21/2022-03:01:55] [V] [TRT] 124_convolutional [Conv] outputs: [124_convolutional -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 124_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 124_convolutional_bn [BatchNormalization] inputs: [124_convolutional -> (1, 512, 26, 26)[FLOAT]], [124_convolutional_bn_scale -> (512)[FLOAT]], [124_convolutional_bn_bias -> (512)[FLOAT]], [124_convolutional_bn_mean -> (512)[FLOAT]], [124_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 124_convolutional_bn for ONNX node: 124_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 124_convolutional_bn for ONNX tensor: 124_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 124_convolutional_bn [BatchNormalization] outputs: [124_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 124_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 124_convolutional_lrelu [LeakyRelu] inputs: [124_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 124_convolutional_lrelu for ONNX node: 124_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 124_convolutional_lrelu for ONNX tensor: 124_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 124_convolutional_lrelu [LeakyRelu] outputs: [124_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 125_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 124_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 125_convolutional [Conv] inputs: [124_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], [125_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 125_convolutional for ONNX node: 125_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 125_convolutional for ONNX tensor: 125_convolutional
[05/21/2022-03:01:55] [V] [TRT] 125_convolutional [Conv] outputs: [125_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 125_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 125_convolutional_bn [BatchNormalization] inputs: [125_convolutional -> (1, 256, 26, 26)[FLOAT]], [125_convolutional_bn_scale -> (256)[FLOAT]], [125_convolutional_bn_bias -> (256)[FLOAT]], [125_convolutional_bn_mean -> (256)[FLOAT]], [125_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 125_convolutional_bn for ONNX node: 125_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 125_convolutional_bn for ONNX tensor: 125_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 125_convolutional_bn [BatchNormalization] outputs: [125_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 125_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 125_convolutional_lrelu [LeakyRelu] inputs: [125_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 125_convolutional_lrelu for ONNX node: 125_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 125_convolutional_lrelu for ONNX tensor: 125_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 125_convolutional_lrelu [LeakyRelu] outputs: [125_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 126_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 125_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 126_convolutional [Conv] inputs: [125_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [126_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 126_convolutional for ONNX node: 126_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 126_convolutional for ONNX tensor: 126_convolutional
[05/21/2022-03:01:55] [V] [TRT] 126_convolutional [Conv] outputs: [126_convolutional -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 126_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 126_convolutional_bn [BatchNormalization] inputs: [126_convolutional -> (1, 512, 26, 26)[FLOAT]], [126_convolutional_bn_scale -> (512)[FLOAT]], [126_convolutional_bn_bias -> (512)[FLOAT]], [126_convolutional_bn_mean -> (512)[FLOAT]], [126_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 126_convolutional_bn for ONNX node: 126_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 126_convolutional_bn for ONNX tensor: 126_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 126_convolutional_bn [BatchNormalization] outputs: [126_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 126_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 126_convolutional_lrelu [LeakyRelu] inputs: [126_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 126_convolutional_lrelu for ONNX node: 126_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 126_convolutional_lrelu for ONNX tensor: 126_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 126_convolutional_lrelu [LeakyRelu] outputs: [126_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 127_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 126_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 127_convolutional [Conv] inputs: [126_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], [127_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 127_convolutional for ONNX node: 127_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 127_convolutional for ONNX tensor: 127_convolutional
[05/21/2022-03:01:55] [V] [TRT] 127_convolutional [Conv] outputs: [127_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 127_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 127_convolutional_bn [BatchNormalization] inputs: [127_convolutional -> (1, 256, 26, 26)[FLOAT]], [127_convolutional_bn_scale -> (256)[FLOAT]], [127_convolutional_bn_bias -> (256)[FLOAT]], [127_convolutional_bn_mean -> (256)[FLOAT]], [127_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 127_convolutional_bn for ONNX node: 127_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 127_convolutional_bn for ONNX tensor: 127_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 127_convolutional_bn [BatchNormalization] outputs: [127_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 127_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 127_convolutional_lrelu [LeakyRelu] inputs: [127_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 127_convolutional_lrelu for ONNX node: 127_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 127_convolutional_lrelu for ONNX tensor: 127_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 127_convolutional_lrelu [LeakyRelu] outputs: [127_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 128_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 128_convolutional [Conv] inputs: [127_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [128_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 128_convolutional for ONNX node: 128_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 128, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 128_convolutional for ONNX tensor: 128_convolutional
[05/21/2022-03:01:55] [V] [TRT] 128_convolutional [Conv] outputs: [128_convolutional -> (1, 128, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 128_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 128_convolutional_bn [BatchNormalization] inputs: [128_convolutional -> (1, 128, 26, 26)[FLOAT]], [128_convolutional_bn_scale -> (128)[FLOAT]], [128_convolutional_bn_bias -> (128)[FLOAT]], [128_convolutional_bn_mean -> (128)[FLOAT]], [128_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 128_convolutional_bn for ONNX node: 128_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 128_convolutional_bn for ONNX tensor: 128_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 128_convolutional_bn [BatchNormalization] outputs: [128_convolutional_bn -> (1, 128, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 128_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 128_convolutional_lrelu [LeakyRelu] inputs: [128_convolutional_bn -> (1, 128, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 128_convolutional_lrelu for ONNX node: 128_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 128_convolutional_lrelu for ONNX tensor: 128_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 128_convolutional_lrelu [LeakyRelu] outputs: [128_convolutional_lrelu -> (1, 128, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 129_upsample [Upsample]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 128_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 129_upsample_scale
[05/21/2022-03:01:55] [V] [TRT] 129_upsample [Upsample] inputs: [128_convolutional_lrelu -> (1, 128, 26, 26)[FLOAT]], [129_upsample_scale -> (4)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 129_upsample for ONNX node: 129_upsample
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 129_upsample for ONNX tensor: 129_upsample
[05/21/2022-03:01:55] [V] [TRT] 129_upsample [Upsample] outputs: [129_upsample -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 131_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 055_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 131_convolutional [Conv] inputs: [055_convolutional_mish -> (1, 256, 52, 52)[FLOAT]], [131_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 131_convolutional for ONNX node: 131_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 131_convolutional for ONNX tensor: 131_convolutional
[05/21/2022-03:01:55] [V] [TRT] 131_convolutional [Conv] outputs: [131_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 131_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 131_convolutional_bn [BatchNormalization] inputs: [131_convolutional -> (1, 128, 52, 52)[FLOAT]], [131_convolutional_bn_scale -> (128)[FLOAT]], [131_convolutional_bn_bias -> (128)[FLOAT]], [131_convolutional_bn_mean -> (128)[FLOAT]], [131_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 131_convolutional_bn for ONNX node: 131_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 131_convolutional_bn for ONNX tensor: 131_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 131_convolutional_bn [BatchNormalization] outputs: [131_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 131_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 131_convolutional_lrelu [LeakyRelu] inputs: [131_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 131_convolutional_lrelu for ONNX node: 131_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 131_convolutional_lrelu for ONNX tensor: 131_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 131_convolutional_lrelu [LeakyRelu] outputs: [131_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 132_route [Concat]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 131_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 129_upsample
[05/21/2022-03:01:55] [V] [TRT] 132_route [Concat] inputs: [131_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], [129_upsample -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 132_route for ONNX node: 132_route
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 132_route for ONNX tensor: 132_route
[05/21/2022-03:01:55] [V] [TRT] 132_route [Concat] outputs: [132_route -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 133_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 132_route
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 133_convolutional [Conv] inputs: [132_route -> (1, 256, 52, 52)[FLOAT]], [133_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 133_convolutional for ONNX node: 133_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 133_convolutional for ONNX tensor: 133_convolutional
[05/21/2022-03:01:55] [V] [TRT] 133_convolutional [Conv] outputs: [133_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 133_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 133_convolutional_bn [BatchNormalization] inputs: [133_convolutional -> (1, 128, 52, 52)[FLOAT]], [133_convolutional_bn_scale -> (128)[FLOAT]], [133_convolutional_bn_bias -> (128)[FLOAT]], [133_convolutional_bn_mean -> (128)[FLOAT]], [133_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 133_convolutional_bn for ONNX node: 133_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 133_convolutional_bn for ONNX tensor: 133_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 133_convolutional_bn [BatchNormalization] outputs: [133_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 133_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 133_convolutional_lrelu [LeakyRelu] inputs: [133_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 133_convolutional_lrelu for ONNX node: 133_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 133_convolutional_lrelu for ONNX tensor: 133_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 133_convolutional_lrelu [LeakyRelu] outputs: [133_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 134_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 133_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 134_convolutional [Conv] inputs: [133_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], [134_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 134_convolutional for ONNX node: 134_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 134_convolutional for ONNX tensor: 134_convolutional
[05/21/2022-03:01:55] [V] [TRT] 134_convolutional [Conv] outputs: [134_convolutional -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 134_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 134_convolutional_bn [BatchNormalization] inputs: [134_convolutional -> (1, 256, 52, 52)[FLOAT]], [134_convolutional_bn_scale -> (256)[FLOAT]], [134_convolutional_bn_bias -> (256)[FLOAT]], [134_convolutional_bn_mean -> (256)[FLOAT]], [134_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 134_convolutional_bn for ONNX node: 134_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 134_convolutional_bn for ONNX tensor: 134_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 134_convolutional_bn [BatchNormalization] outputs: [134_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 134_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 134_convolutional_lrelu [LeakyRelu] inputs: [134_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 134_convolutional_lrelu for ONNX node: 134_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 134_convolutional_lrelu for ONNX tensor: 134_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 134_convolutional_lrelu [LeakyRelu] outputs: [134_convolutional_lrelu -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 135_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 134_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 135_convolutional [Conv] inputs: [134_convolutional_lrelu -> (1, 256, 52, 52)[FLOAT]], [135_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 135_convolutional for ONNX node: 135_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 135_convolutional for ONNX tensor: 135_convolutional
[05/21/2022-03:01:55] [V] [TRT] 135_convolutional [Conv] outputs: [135_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 135_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 135_convolutional_bn [BatchNormalization] inputs: [135_convolutional -> (1, 128, 52, 52)[FLOAT]], [135_convolutional_bn_scale -> (128)[FLOAT]], [135_convolutional_bn_bias -> (128)[FLOAT]], [135_convolutional_bn_mean -> (128)[FLOAT]], [135_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 135_convolutional_bn for ONNX node: 135_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 135_convolutional_bn for ONNX tensor: 135_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 135_convolutional_bn [BatchNormalization] outputs: [135_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 135_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 135_convolutional_lrelu [LeakyRelu] inputs: [135_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 135_convolutional_lrelu for ONNX node: 135_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 135_convolutional_lrelu for ONNX tensor: 135_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 135_convolutional_lrelu [LeakyRelu] outputs: [135_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 136_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 135_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 136_convolutional [Conv] inputs: [135_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], [136_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 136_convolutional for ONNX node: 136_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 136_convolutional for ONNX tensor: 136_convolutional
[05/21/2022-03:01:55] [V] [TRT] 136_convolutional [Conv] outputs: [136_convolutional -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 136_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 136_convolutional_bn [BatchNormalization] inputs: [136_convolutional -> (1, 256, 52, 52)[FLOAT]], [136_convolutional_bn_scale -> (256)[FLOAT]], [136_convolutional_bn_bias -> (256)[FLOAT]], [136_convolutional_bn_mean -> (256)[FLOAT]], [136_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 136_convolutional_bn for ONNX node: 136_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 136_convolutional_bn for ONNX tensor: 136_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 136_convolutional_bn [BatchNormalization] outputs: [136_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 136_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 136_convolutional_lrelu [LeakyRelu] inputs: [136_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 136_convolutional_lrelu for ONNX node: 136_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 136_convolutional_lrelu for ONNX tensor: 136_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 136_convolutional_lrelu [LeakyRelu] outputs: [136_convolutional_lrelu -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 137_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 136_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 137_convolutional [Conv] inputs: [136_convolutional_lrelu -> (1, 256, 52, 52)[FLOAT]], [137_convolutional_conv_weights -> (128, 256, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 137_convolutional for ONNX node: 137_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 128
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 137_convolutional for ONNX tensor: 137_convolutional
[05/21/2022-03:01:55] [V] [TRT] 137_convolutional [Conv] outputs: [137_convolutional -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 137_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 137_convolutional_bn [BatchNormalization] inputs: [137_convolutional -> (1, 128, 52, 52)[FLOAT]], [137_convolutional_bn_scale -> (128)[FLOAT]], [137_convolutional_bn_bias -> (128)[FLOAT]], [137_convolutional_bn_mean -> (128)[FLOAT]], [137_convolutional_bn_var -> (128)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 137_convolutional_bn for ONNX node: 137_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 137_convolutional_bn for ONNX tensor: 137_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 137_convolutional_bn [BatchNormalization] outputs: [137_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 137_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 137_convolutional_lrelu [LeakyRelu] inputs: [137_convolutional_bn -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 137_convolutional_lrelu for ONNX node: 137_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 137_convolutional_lrelu for ONNX tensor: 137_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 137_convolutional_lrelu [LeakyRelu] outputs: [137_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 138_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 138_convolutional [Conv] inputs: [137_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], [138_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 138_convolutional for ONNX node: 138_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 138_convolutional for ONNX tensor: 138_convolutional
[05/21/2022-03:01:55] [V] [TRT] 138_convolutional [Conv] outputs: [138_convolutional -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 138_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 138_convolutional_bn [BatchNormalization] inputs: [138_convolutional -> (1, 256, 52, 52)[FLOAT]], [138_convolutional_bn_scale -> (256)[FLOAT]], [138_convolutional_bn_bias -> (256)[FLOAT]], [138_convolutional_bn_mean -> (256)[FLOAT]], [138_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 138_convolutional_bn for ONNX node: 138_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 138_convolutional_bn for ONNX tensor: 138_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 138_convolutional_bn [BatchNormalization] outputs: [138_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 138_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 138_convolutional_lrelu [LeakyRelu] inputs: [138_convolutional_bn -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 138_convolutional_lrelu for ONNX node: 138_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 138_convolutional_lrelu for ONNX tensor: 138_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 138_convolutional_lrelu [LeakyRelu] outputs: [138_convolutional_lrelu -> (1, 256, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 139_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 138_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 139_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 139_convolutional_conv_bias
[05/21/2022-03:01:55] [V] [TRT] 139_convolutional [Conv] inputs: [138_convolutional_lrelu -> (1, 256, 52, 52)[FLOAT]], [139_convolutional_conv_weights -> (255, 256, 1, 1)[FLOAT]], [139_convolutional_conv_bias -> (255)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 139_convolutional for ONNX node: 139_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 255
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 255, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 139_convolutional_543 for ONNX tensor: 139_convolutional
[05/21/2022-03:01:55] [V] [TRT] 139_convolutional [Conv] outputs: [139_convolutional -> (1, 255, 52, 52)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 142_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 137_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 142_convolutional [Conv] inputs: [137_convolutional_lrelu -> (1, 128, 52, 52)[FLOAT]], [142_convolutional_conv_weights -> (256, 128, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 128, 52, 52)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 142_convolutional for ONNX node: 142_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 142_convolutional for ONNX tensor: 142_convolutional
[05/21/2022-03:01:55] [V] [TRT] 142_convolutional [Conv] outputs: [142_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 142_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 142_convolutional_bn [BatchNormalization] inputs: [142_convolutional -> (1, 256, 26, 26)[FLOAT]], [142_convolutional_bn_scale -> (256)[FLOAT]], [142_convolutional_bn_bias -> (256)[FLOAT]], [142_convolutional_bn_mean -> (256)[FLOAT]], [142_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 142_convolutional_bn for ONNX node: 142_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 142_convolutional_bn for ONNX tensor: 142_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 142_convolutional_bn [BatchNormalization] outputs: [142_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 142_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 142_convolutional_lrelu [LeakyRelu] inputs: [142_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 142_convolutional_lrelu for ONNX node: 142_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 142_convolutional_lrelu for ONNX tensor: 142_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 142_convolutional_lrelu [LeakyRelu] outputs: [142_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 143_route [Concat]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 142_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 127_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 143_route [Concat] inputs: [142_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [127_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 143_route for ONNX node: 143_route
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 143_route for ONNX tensor: 143_route
[05/21/2022-03:01:55] [V] [TRT] 143_route [Concat] outputs: [143_route -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 144_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 143_route
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 144_convolutional [Conv] inputs: [143_route -> (1, 512, 26, 26)[FLOAT]], [144_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 144_convolutional for ONNX node: 144_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 144_convolutional for ONNX tensor: 144_convolutional
[05/21/2022-03:01:55] [V] [TRT] 144_convolutional [Conv] outputs: [144_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 144_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 144_convolutional_bn [BatchNormalization] inputs: [144_convolutional -> (1, 256, 26, 26)[FLOAT]], [144_convolutional_bn_scale -> (256)[FLOAT]], [144_convolutional_bn_bias -> (256)[FLOAT]], [144_convolutional_bn_mean -> (256)[FLOAT]], [144_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 144_convolutional_bn for ONNX node: 144_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 144_convolutional_bn for ONNX tensor: 144_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 144_convolutional_bn [BatchNormalization] outputs: [144_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 144_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 144_convolutional_lrelu [LeakyRelu] inputs: [144_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 144_convolutional_lrelu for ONNX node: 144_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 144_convolutional_lrelu for ONNX tensor: 144_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 144_convolutional_lrelu [LeakyRelu] outputs: [144_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 145_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 144_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 145_convolutional [Conv] inputs: [144_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [145_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 145_convolutional for ONNX node: 145_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 145_convolutional for ONNX tensor: 145_convolutional
[05/21/2022-03:01:55] [V] [TRT] 145_convolutional [Conv] outputs: [145_convolutional -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 145_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 145_convolutional_bn [BatchNormalization] inputs: [145_convolutional -> (1, 512, 26, 26)[FLOAT]], [145_convolutional_bn_scale -> (512)[FLOAT]], [145_convolutional_bn_bias -> (512)[FLOAT]], [145_convolutional_bn_mean -> (512)[FLOAT]], [145_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 145_convolutional_bn for ONNX node: 145_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 145_convolutional_bn for ONNX tensor: 145_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 145_convolutional_bn [BatchNormalization] outputs: [145_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 145_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 145_convolutional_lrelu [LeakyRelu] inputs: [145_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 145_convolutional_lrelu for ONNX node: 145_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 145_convolutional_lrelu for ONNX tensor: 145_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 145_convolutional_lrelu [LeakyRelu] outputs: [145_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 146_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 145_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 146_convolutional [Conv] inputs: [145_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], [146_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 146_convolutional for ONNX node: 146_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 146_convolutional for ONNX tensor: 146_convolutional
[05/21/2022-03:01:55] [V] [TRT] 146_convolutional [Conv] outputs: [146_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 146_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 146_convolutional_bn [BatchNormalization] inputs: [146_convolutional -> (1, 256, 26, 26)[FLOAT]], [146_convolutional_bn_scale -> (256)[FLOAT]], [146_convolutional_bn_bias -> (256)[FLOAT]], [146_convolutional_bn_mean -> (256)[FLOAT]], [146_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 146_convolutional_bn for ONNX node: 146_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 146_convolutional_bn for ONNX tensor: 146_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 146_convolutional_bn [BatchNormalization] outputs: [146_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 146_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 146_convolutional_lrelu [LeakyRelu] inputs: [146_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 146_convolutional_lrelu for ONNX node: 146_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 146_convolutional_lrelu for ONNX tensor: 146_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 146_convolutional_lrelu [LeakyRelu] outputs: [146_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 147_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 146_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 147_convolutional [Conv] inputs: [146_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [147_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 147_convolutional for ONNX node: 147_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 147_convolutional for ONNX tensor: 147_convolutional
[05/21/2022-03:01:55] [V] [TRT] 147_convolutional [Conv] outputs: [147_convolutional -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 147_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 147_convolutional_bn [BatchNormalization] inputs: [147_convolutional -> (1, 512, 26, 26)[FLOAT]], [147_convolutional_bn_scale -> (512)[FLOAT]], [147_convolutional_bn_bias -> (512)[FLOAT]], [147_convolutional_bn_mean -> (512)[FLOAT]], [147_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 147_convolutional_bn for ONNX node: 147_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 147_convolutional_bn for ONNX tensor: 147_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 147_convolutional_bn [BatchNormalization] outputs: [147_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 147_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 147_convolutional_lrelu [LeakyRelu] inputs: [147_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 147_convolutional_lrelu for ONNX node: 147_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 147_convolutional_lrelu for ONNX tensor: 147_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 147_convolutional_lrelu [LeakyRelu] outputs: [147_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 148_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 147_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 148_convolutional [Conv] inputs: [147_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], [148_convolutional_conv_weights -> (256, 512, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 148_convolutional for ONNX node: 148_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 256
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 148_convolutional for ONNX tensor: 148_convolutional
[05/21/2022-03:01:55] [V] [TRT] 148_convolutional [Conv] outputs: [148_convolutional -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 148_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 148_convolutional_bn [BatchNormalization] inputs: [148_convolutional -> (1, 256, 26, 26)[FLOAT]], [148_convolutional_bn_scale -> (256)[FLOAT]], [148_convolutional_bn_bias -> (256)[FLOAT]], [148_convolutional_bn_mean -> (256)[FLOAT]], [148_convolutional_bn_var -> (256)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 148_convolutional_bn for ONNX node: 148_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 148_convolutional_bn for ONNX tensor: 148_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 148_convolutional_bn [BatchNormalization] outputs: [148_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 148_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 148_convolutional_lrelu [LeakyRelu] inputs: [148_convolutional_bn -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 148_convolutional_lrelu for ONNX node: 148_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 148_convolutional_lrelu for ONNX tensor: 148_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 148_convolutional_lrelu [LeakyRelu] outputs: [148_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 149_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 149_convolutional [Conv] inputs: [148_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [149_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 149_convolutional for ONNX node: 149_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 149_convolutional for ONNX tensor: 149_convolutional
[05/21/2022-03:01:55] [V] [TRT] 149_convolutional [Conv] outputs: [149_convolutional -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 149_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 149_convolutional_bn [BatchNormalization] inputs: [149_convolutional -> (1, 512, 26, 26)[FLOAT]], [149_convolutional_bn_scale -> (512)[FLOAT]], [149_convolutional_bn_bias -> (512)[FLOAT]], [149_convolutional_bn_mean -> (512)[FLOAT]], [149_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 149_convolutional_bn for ONNX node: 149_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 149_convolutional_bn for ONNX tensor: 149_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 149_convolutional_bn [BatchNormalization] outputs: [149_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 149_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 149_convolutional_lrelu [LeakyRelu] inputs: [149_convolutional_bn -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 149_convolutional_lrelu for ONNX node: 149_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 149_convolutional_lrelu for ONNX tensor: 149_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 149_convolutional_lrelu [LeakyRelu] outputs: [149_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 150_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 149_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 150_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 150_convolutional_conv_bias
[05/21/2022-03:01:55] [V] [TRT] 150_convolutional [Conv] inputs: [149_convolutional_lrelu -> (1, 512, 26, 26)[FLOAT]], [150_convolutional_conv_weights -> (255, 512, 1, 1)[FLOAT]], [150_convolutional_conv_bias -> (255)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 150_convolutional for ONNX node: 150_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 255
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 255, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 150_convolutional_544 for ONNX tensor: 150_convolutional
[05/21/2022-03:01:55] [V] [TRT] 150_convolutional [Conv] outputs: [150_convolutional -> (1, 255, 26, 26)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 153_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 148_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 153_convolutional [Conv] inputs: [148_convolutional_lrelu -> (1, 256, 26, 26)[FLOAT]], [153_convolutional_conv_weights -> (512, 256, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 256, 26, 26)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 153_convolutional for ONNX node: 153_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (2, 2), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 153_convolutional for ONNX tensor: 153_convolutional
[05/21/2022-03:01:55] [V] [TRT] 153_convolutional [Conv] outputs: [153_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 153_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 153_convolutional_bn [BatchNormalization] inputs: [153_convolutional -> (1, 512, 13, 13)[FLOAT]], [153_convolutional_bn_scale -> (512)[FLOAT]], [153_convolutional_bn_bias -> (512)[FLOAT]], [153_convolutional_bn_mean -> (512)[FLOAT]], [153_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 153_convolutional_bn for ONNX node: 153_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 153_convolutional_bn for ONNX tensor: 153_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 153_convolutional_bn [BatchNormalization] outputs: [153_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 153_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 153_convolutional_lrelu [LeakyRelu] inputs: [153_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 153_convolutional_lrelu for ONNX node: 153_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 153_convolutional_lrelu for ONNX tensor: 153_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 153_convolutional_lrelu [LeakyRelu] outputs: [153_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 154_route [Concat]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 153_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 117_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 154_route [Concat] inputs: [153_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], [117_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 154_route for ONNX node: 154_route
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 154_route for ONNX tensor: 154_route
[05/21/2022-03:01:55] [V] [TRT] 154_route [Concat] outputs: [154_route -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 155_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 154_route
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 155_convolutional [Conv] inputs: [154_route -> (1, 1024, 13, 13)[FLOAT]], [155_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 155_convolutional for ONNX node: 155_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 155_convolutional for ONNX tensor: 155_convolutional
[05/21/2022-03:01:55] [V] [TRT] 155_convolutional [Conv] outputs: [155_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 155_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 155_convolutional_bn [BatchNormalization] inputs: [155_convolutional -> (1, 512, 13, 13)[FLOAT]], [155_convolutional_bn_scale -> (512)[FLOAT]], [155_convolutional_bn_bias -> (512)[FLOAT]], [155_convolutional_bn_mean -> (512)[FLOAT]], [155_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 155_convolutional_bn for ONNX node: 155_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 155_convolutional_bn for ONNX tensor: 155_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 155_convolutional_bn [BatchNormalization] outputs: [155_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 155_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 155_convolutional_lrelu [LeakyRelu] inputs: [155_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 155_convolutional_lrelu for ONNX node: 155_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 155_convolutional_lrelu for ONNX tensor: 155_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 155_convolutional_lrelu [LeakyRelu] outputs: [155_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 156_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 155_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 156_convolutional [Conv] inputs: [155_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], [156_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 156_convolutional for ONNX node: 156_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 156_convolutional for ONNX tensor: 156_convolutional
[05/21/2022-03:01:55] [V] [TRT] 156_convolutional [Conv] outputs: [156_convolutional -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 156_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 156_convolutional_bn [BatchNormalization] inputs: [156_convolutional -> (1, 1024, 13, 13)[FLOAT]], [156_convolutional_bn_scale -> (1024)[FLOAT]], [156_convolutional_bn_bias -> (1024)[FLOAT]], [156_convolutional_bn_mean -> (1024)[FLOAT]], [156_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 156_convolutional_bn for ONNX node: 156_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 156_convolutional_bn for ONNX tensor: 156_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 156_convolutional_bn [BatchNormalization] outputs: [156_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 156_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 156_convolutional_lrelu [LeakyRelu] inputs: [156_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 156_convolutional_lrelu for ONNX node: 156_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 156_convolutional_lrelu for ONNX tensor: 156_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 156_convolutional_lrelu [LeakyRelu] outputs: [156_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 157_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 156_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 157_convolutional [Conv] inputs: [156_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], [157_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 157_convolutional for ONNX node: 157_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 157_convolutional for ONNX tensor: 157_convolutional
[05/21/2022-03:01:55] [V] [TRT] 157_convolutional [Conv] outputs: [157_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 157_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 157_convolutional_bn [BatchNormalization] inputs: [157_convolutional -> (1, 512, 13, 13)[FLOAT]], [157_convolutional_bn_scale -> (512)[FLOAT]], [157_convolutional_bn_bias -> (512)[FLOAT]], [157_convolutional_bn_mean -> (512)[FLOAT]], [157_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 157_convolutional_bn for ONNX node: 157_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 157_convolutional_bn for ONNX tensor: 157_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 157_convolutional_bn [BatchNormalization] outputs: [157_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 157_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 157_convolutional_lrelu [LeakyRelu] inputs: [157_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 157_convolutional_lrelu for ONNX node: 157_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 157_convolutional_lrelu for ONNX tensor: 157_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 157_convolutional_lrelu [LeakyRelu] outputs: [157_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 158_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 157_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 158_convolutional [Conv] inputs: [157_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], [158_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 158_convolutional for ONNX node: 158_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 158_convolutional for ONNX tensor: 158_convolutional
[05/21/2022-03:01:55] [V] [TRT] 158_convolutional [Conv] outputs: [158_convolutional -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 158_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 158_convolutional_bn [BatchNormalization] inputs: [158_convolutional -> (1, 1024, 13, 13)[FLOAT]], [158_convolutional_bn_scale -> (1024)[FLOAT]], [158_convolutional_bn_bias -> (1024)[FLOAT]], [158_convolutional_bn_mean -> (1024)[FLOAT]], [158_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 158_convolutional_bn for ONNX node: 158_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 158_convolutional_bn for ONNX tensor: 158_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 158_convolutional_bn [BatchNormalization] outputs: [158_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 158_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 158_convolutional_lrelu [LeakyRelu] inputs: [158_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 158_convolutional_lrelu for ONNX node: 158_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 158_convolutional_lrelu for ONNX tensor: 158_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 158_convolutional_lrelu [LeakyRelu] outputs: [158_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 159_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 158_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 159_convolutional [Conv] inputs: [158_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], [159_convolutional_conv_weights -> (512, 1024, 1, 1)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 159_convolutional for ONNX node: 159_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 512
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 159_convolutional for ONNX tensor: 159_convolutional
[05/21/2022-03:01:55] [V] [TRT] 159_convolutional [Conv] outputs: [159_convolutional -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 159_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 159_convolutional_bn [BatchNormalization] inputs: [159_convolutional -> (1, 512, 13, 13)[FLOAT]], [159_convolutional_bn_scale -> (512)[FLOAT]], [159_convolutional_bn_bias -> (512)[FLOAT]], [159_convolutional_bn_mean -> (512)[FLOAT]], [159_convolutional_bn_var -> (512)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 159_convolutional_bn for ONNX node: 159_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 159_convolutional_bn for ONNX tensor: 159_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 159_convolutional_bn [BatchNormalization] outputs: [159_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 159_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 159_convolutional_lrelu [LeakyRelu] inputs: [159_convolutional_bn -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 159_convolutional_lrelu for ONNX node: 159_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 159_convolutional_lrelu for ONNX tensor: 159_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 159_convolutional_lrelu [LeakyRelu] outputs: [159_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 160_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 159_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] 160_convolutional [Conv] inputs: [159_convolutional_lrelu -> (1, 512, 13, 13)[FLOAT]], [160_convolutional_conv_weights -> (1024, 512, 3, 3)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 512, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 160_convolutional for ONNX node: 160_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (3, 3), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 1024
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 160_convolutional for ONNX tensor: 160_convolutional
[05/21/2022-03:01:55] [V] [TRT] 160_convolutional [Conv] outputs: [160_convolutional -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 160_convolutional_bn [BatchNormalization]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional_bn_scale
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional_bn_bias
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional_bn_mean
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional_bn_var
[05/21/2022-03:01:55] [V] [TRT] 160_convolutional_bn [BatchNormalization] inputs: [160_convolutional -> (1, 1024, 13, 13)[FLOAT]], [160_convolutional_bn_scale -> (1024)[FLOAT]], [160_convolutional_bn_bias -> (1024)[FLOAT]], [160_convolutional_bn_mean -> (1024)[FLOAT]], [160_convolutional_bn_var -> (1024)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 160_convolutional_bn for ONNX node: 160_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 160_convolutional_bn for ONNX tensor: 160_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 160_convolutional_bn [BatchNormalization] outputs: [160_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 160_convolutional_lrelu [LeakyRelu]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] 160_convolutional_lrelu [LeakyRelu] inputs: [160_convolutional_bn -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 160_convolutional_lrelu for ONNX node: 160_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 160_convolutional_lrelu for ONNX tensor: 160_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] 160_convolutional_lrelu [LeakyRelu] outputs: [160_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Parsing node: 161_convolutional [Conv]
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 160_convolutional_lrelu
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 161_convolutional_conv_weights
[05/21/2022-03:01:55] [V] [TRT] Searching for input: 161_convolutional_conv_bias
[05/21/2022-03:01:55] [V] [TRT] 161_convolutional [Conv] inputs: [160_convolutional_lrelu -> (1, 1024, 13, 13)[FLOAT]], [161_convolutional_conv_weights -> (255, 1024, 1, 1)[FLOAT]], [161_convolutional_conv_bias -> (255)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Convolution input dimensions: (1, 1024, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering layer: 161_convolutional for ONNX node: 161_convolutional
[05/21/2022-03:01:55] [V] [TRT] Using kernel: (1, 1), strides: (1, 1), prepadding: (0, 0), postpadding: (0, 0), dilations: (1, 1), numOutputs: 255
[05/21/2022-03:01:55] [V] [TRT] Convolution output dimensions: (1, 255, 13, 13)
[05/21/2022-03:01:55] [V] [TRT] Registering tensor: 161_convolutional_545 for ONNX tensor: 161_convolutional
[05/21/2022-03:01:55] [V] [TRT] 161_convolutional [Conv] outputs: [161_convolutional -> (1, 255, 13, 13)[FLOAT]], 
[05/21/2022-03:01:55] [V] [TRT] Marking 139_convolutional_543 as output: 139_convolutional
[05/21/2022-03:01:55] [V] [TRT] Marking 150_convolutional_544 as output: 150_convolutional
[05/21/2022-03:01:55] [V] [TRT] Marking 161_convolutional_545 as output: 161_convolutional
[05/21/2022-03:01:55] [I] Finish parsing network model
[05/21/2022-03:01:55] [V] [TRT] Applying generic optimizations to the graph for inference.
[05/21/2022-03:01:55] [V] [TRT] Original: 506 layers
[05/21/2022-03:01:55] [V] [TRT] After dead-layer removal: 506 layers
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 001_convolutional with 001_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 002_convolutional with 002_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 003_convolutional with 003_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 005_convolutional with 005_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 006_convolutional with 006_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 007_convolutional with 007_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 009_convolutional with 009_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 011_convolutional with 011_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 012_convolutional with 012_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 013_convolutional with 013_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 015_convolutional with 015_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 016_convolutional with 016_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 017_convolutional with 017_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 019_convolutional with 019_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 020_convolutional with 020_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 022_convolutional with 022_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 024_convolutional with 024_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 025_convolutional with 025_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 026_convolutional with 026_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 028_convolutional with 028_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 029_convolutional with 029_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 030_convolutional with 030_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 032_convolutional with 032_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 033_convolutional with 033_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 035_convolutional with 035_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 036_convolutional with 036_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 038_convolutional with 038_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 039_convolutional with 039_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 041_convolutional with 041_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 042_convolutional with 042_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 044_convolutional with 044_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 045_convolutional with 045_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 047_convolutional with 047_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 048_convolutional with 048_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 050_convolutional with 050_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 051_convolutional with 051_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 053_convolutional with 053_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 055_convolutional with 055_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 056_convolutional with 056_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 057_convolutional with 057_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 059_convolutional with 059_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 060_convolutional with 060_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 061_convolutional with 061_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 063_convolutional with 063_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 064_convolutional with 064_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 066_convolutional with 066_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 067_convolutional with 067_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 069_convolutional with 069_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 070_convolutional with 070_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 072_convolutional with 072_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 073_convolutional with 073_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 075_convolutional with 075_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 076_convolutional with 076_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 078_convolutional with 078_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 079_convolutional with 079_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 081_convolutional with 081_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 082_convolutional with 082_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 084_convolutional with 084_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 086_convolutional with 086_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 087_convolutional with 087_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 088_convolutional with 088_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 090_convolutional with 090_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 091_convolutional with 091_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 092_convolutional with 092_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 094_convolutional with 094_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 095_convolutional with 095_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 097_convolutional with 097_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 098_convolutional with 098_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 100_convolutional with 100_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 101_convolutional with 101_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 103_convolutional with 103_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 105_convolutional with 105_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 106_convolutional with 106_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 107_convolutional with 107_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 108_convolutional with 108_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 115_convolutional with 115_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 116_convolutional with 116_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 117_convolutional with 117_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 118_convolutional with 118_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 121_convolutional with 121_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 123_convolutional with 123_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 124_convolutional with 124_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 125_convolutional with 125_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 126_convolutional with 126_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 127_convolutional with 127_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 128_convolutional with 128_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 131_convolutional with 131_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 133_convolutional with 133_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 134_convolutional with 134_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 135_convolutional with 135_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 136_convolutional with 136_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 137_convolutional with 137_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 138_convolutional with 138_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 142_convolutional with 142_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 144_convolutional with 144_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 145_convolutional with 145_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 146_convolutional with 146_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 147_convolutional with 147_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 148_convolutional with 148_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 149_convolutional with 149_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 153_convolutional with 153_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 155_convolutional with 155_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 156_convolutional with 156_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 157_convolutional with 157_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 158_convolutional with 158_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 159_convolutional with 159_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] Running: ConvScaleFusion
[05/21/2022-03:01:55] [V] [TRT] ConvScaleFusion: Fusing 160_convolutional with 160_convolutional_bn
[05/21/2022-03:01:55] [V] [TRT] After Myelin optimization: 399 layers
[05/21/2022-03:01:55] [V] [TRT] Applying ScaleNodes fusions.
[05/21/2022-03:01:55] [V] [TRT] After scale fusion: 399 layers
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 001_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 001_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 002_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 002_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 003_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 003_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 005_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 005_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 006_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 006_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 007_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 007_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 009_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 009_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 011_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 011_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 012_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 012_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 013_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 013_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 015_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 015_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 016_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 016_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 017_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 017_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 019_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 019_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 020_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 020_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 022_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 022_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 024_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 024_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 025_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 025_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 026_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 026_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 028_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 028_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 029_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 029_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 030_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 030_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 032_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 032_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 033_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 033_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 035_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 035_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 036_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 036_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 038_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 038_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 039_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 039_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 041_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 041_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 042_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 042_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 044_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 044_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 045_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 045_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 047_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 047_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 048_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 048_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 050_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 050_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 051_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 051_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 053_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 053_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 055_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 055_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 056_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 056_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 057_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 057_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 059_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 059_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 060_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 060_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 061_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 061_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 063_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 063_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 064_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 064_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 066_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 066_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 067_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 067_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 069_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 069_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 070_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 070_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 072_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 072_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 073_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 073_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 075_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 075_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 076_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 076_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 078_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 078_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 079_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 079_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 081_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 081_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 082_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 082_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 084_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 084_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 086_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 086_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 087_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 087_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 088_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 088_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 090_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 090_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 091_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 091_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 092_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 092_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 094_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 094_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 095_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 095_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 097_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 097_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 098_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 098_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 100_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 100_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 101_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 101_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 103_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 103_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 105_convolutional_softplus from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 105_convolutional_tanh from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 106_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 107_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 108_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 115_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 116_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 117_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 118_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 121_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 123_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 124_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 125_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 126_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 127_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 128_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 131_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 133_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 134_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 135_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 136_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 137_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 138_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 142_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 144_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 145_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 146_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 147_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 148_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 149_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 153_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 155_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 156_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 157_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 158_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 159_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: ActivationToPointwiseConversion
[05/21/2022-03:01:55] [V] [TRT] Swap the layer type of 160_convolutional_lrelu from ACTIVATION to POINTWISE
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(001_convolutional_softplus) with PWN(001_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)) with 001_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(002_convolutional_softplus) with PWN(002_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)) with 002_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(003_convolutional_softplus) with PWN(003_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)) with 003_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(005_convolutional_softplus) with PWN(005_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)) with 005_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(006_convolutional_softplus) with PWN(006_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)) with 006_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(007_convolutional_softplus) with PWN(007_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)) with 007_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish) with 008_shortcut
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(009_convolutional_softplus) with PWN(009_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)) with 009_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(011_convolutional_softplus) with PWN(011_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)) with 011_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(012_convolutional_softplus) with PWN(012_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)) with 012_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(013_convolutional_softplus) with PWN(013_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)) with 013_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(015_convolutional_softplus) with PWN(015_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)) with 015_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(016_convolutional_softplus) with PWN(016_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)) with 016_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(017_convolutional_softplus) with PWN(017_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)) with 017_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish) with 018_shortcut
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(019_convolutional_softplus) with PWN(019_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)) with 019_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(020_convolutional_softplus) with PWN(020_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)) with 020_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish) with 021_shortcut
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(022_convolutional_softplus) with PWN(022_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)) with 022_convolutional_mish
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(024_convolutional_softplus) with PWN(024_convolutional_tanh)
[05/21/2022-03:01:55] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:55] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)) with 024_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(025_convolutional_softplus) with PWN(025_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)) with 025_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(026_convolutional_softplus) with PWN(026_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)) with 026_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(028_convolutional_softplus) with PWN(028_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)) with 028_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(029_convolutional_softplus) with PWN(029_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)) with 029_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(030_convolutional_softplus) with PWN(030_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)) with 030_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish) with 031_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(032_convolutional_softplus) with PWN(032_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)) with 032_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(033_convolutional_softplus) with PWN(033_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)) with 033_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish) with 034_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(035_convolutional_softplus) with PWN(035_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)) with 035_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(036_convolutional_softplus) with PWN(036_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)) with 036_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish) with 037_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(038_convolutional_softplus) with PWN(038_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)) with 038_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(039_convolutional_softplus) with PWN(039_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)) with 039_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish) with 040_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(041_convolutional_softplus) with PWN(041_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)) with 041_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(042_convolutional_softplus) with PWN(042_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)) with 042_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish) with 043_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(044_convolutional_softplus) with PWN(044_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)) with 044_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(045_convolutional_softplus) with PWN(045_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)) with 045_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish) with 046_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(047_convolutional_softplus) with PWN(047_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)) with 047_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(048_convolutional_softplus) with PWN(048_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)) with 048_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish) with 049_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(050_convolutional_softplus) with PWN(050_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)) with 050_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(051_convolutional_softplus) with PWN(051_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)) with 051_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish) with 052_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(053_convolutional_softplus) with PWN(053_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)) with 053_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(055_convolutional_softplus) with PWN(055_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)) with 055_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(056_convolutional_softplus) with PWN(056_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)) with 056_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(057_convolutional_softplus) with PWN(057_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)) with 057_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(059_convolutional_softplus) with PWN(059_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)) with 059_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(060_convolutional_softplus) with PWN(060_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)) with 060_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(061_convolutional_softplus) with PWN(061_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)) with 061_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish) with 062_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(063_convolutional_softplus) with PWN(063_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)) with 063_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(064_convolutional_softplus) with PWN(064_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)) with 064_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish) with 065_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(066_convolutional_softplus) with PWN(066_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)) with 066_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(067_convolutional_softplus) with PWN(067_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)) with 067_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish) with 068_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(069_convolutional_softplus) with PWN(069_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)) with 069_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(070_convolutional_softplus) with PWN(070_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)) with 070_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish) with 071_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(072_convolutional_softplus) with PWN(072_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)) with 072_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(073_convolutional_softplus) with PWN(073_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)) with 073_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish) with 074_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(075_convolutional_softplus) with PWN(075_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)) with 075_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(076_convolutional_softplus) with PWN(076_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)) with 076_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish) with 077_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(078_convolutional_softplus) with PWN(078_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)) with 078_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(079_convolutional_softplus) with PWN(079_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)) with 079_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish) with 080_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(081_convolutional_softplus) with PWN(081_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)) with 081_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(082_convolutional_softplus) with PWN(082_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)) with 082_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish) with 083_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(084_convolutional_softplus) with PWN(084_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)) with 084_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(086_convolutional_softplus) with PWN(086_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)) with 086_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(087_convolutional_softplus) with PWN(087_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)) with 087_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(088_convolutional_softplus) with PWN(088_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)) with 088_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(090_convolutional_softplus) with PWN(090_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)) with 090_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(091_convolutional_softplus) with PWN(091_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)) with 091_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(092_convolutional_softplus) with PWN(092_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)) with 092_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish) with 093_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(094_convolutional_softplus) with PWN(094_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)) with 094_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(095_convolutional_softplus) with PWN(095_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)) with 095_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish) with 096_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(097_convolutional_softplus) with PWN(097_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)) with 097_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(098_convolutional_softplus) with PWN(098_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)) with 098_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish) with 099_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(100_convolutional_softplus) with PWN(100_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)) with 100_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(101_convolutional_softplus) with PWN(101_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)) with 101_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish) with 102_shortcut
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(103_convolutional_softplus) with PWN(103_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)) with 103_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(105_convolutional_softplus) with PWN(105_convolutional_tanh)
[05/21/2022-03:01:56] [V] [TRT] Running: PointWiseFusion
[05/21/2022-03:01:56] [V] [TRT] PointWiseFusion: Fusing PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)) with 105_convolutional_mish
[05/21/2022-03:01:56] [V] [TRT] After vertical fusions: 232 layers
[05/21/2022-03:01:56] [V] [TRT] After dupe layer removal: 232 layers
[05/21/2022-03:01:56] [V] [TRT] After final dead-layer removal: 232 layers
[05/21/2022-03:01:56] [V] [TRT] Merging layers: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn
[05/21/2022-03:01:56] [V] [TRT] Merging layers: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn
[05/21/2022-03:01:56] [V] [TRT] Merging layers: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn
[05/21/2022-03:01:56] [V] [TRT] Merging layers: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn
[05/21/2022-03:01:56] [V] [TRT] Merging layers: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn
[05/21/2022-03:01:56] [V] [TRT] After tensor merging: 227 layers
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 154_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 153_convolutional_lrelu to 154_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 117_convolutional_lrelu to 154_route
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 143_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 142_convolutional_lrelu to 143_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 127_convolutional_lrelu to 143_route
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 132_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 131_convolutional_lrelu to 132_route
[05/21/2022-03:01:56] [V] [TRT] Generating copy for 129_upsample to 132_route because input does not support striding.
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 122_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 121_convolutional_lrelu to 122_route
[05/21/2022-03:01:56] [V] [TRT] Generating copy for 119_upsample to 122_route because input does not support striding.
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 114_route
[05/21/2022-03:01:56] [V] [TRT] Generating copy for 113_maxpool to 114_route because input does not support striding.
[05/21/2022-03:01:56] [V] [TRT] Generating copy for 111_maxpool to 114_route because input does not support striding.
[05/21/2022-03:01:56] [V] [TRT] Generating copy for 109_maxpool to 114_route because input does not support striding.
[05/21/2022-03:01:56] [V] [TRT] Generating copy for 108_convolutional_lrelu to 114_route because input does not support striding.
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 104_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 103_convolutional_mish to 104_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 088_convolutional_mish to 104_route
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 085_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 084_convolutional_mish to 085_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 057_convolutional_mish to 085_route
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 054_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 053_convolutional_mish to 054_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 026_convolutional_mish to 054_route
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 023_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 022_convolutional_mish to 023_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 013_convolutional_mish to 023_route
[05/21/2022-03:01:56] [V] [TRT] Eliminating concatenation 010_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 009_convolutional_mish to 010_route
[05/21/2022-03:01:56] [V] [TRT] Retargeting 003_convolutional_mish to 010_route
[05/21/2022-03:01:56] [V] [TRT] After concat removal: 223 layers
[05/21/2022-03:01:56] [V] [TRT] Graph construction and optimization completed in 1.3382 seconds.
[05/21/2022-03:01:56] [I] [TRT] ---------- Layers Running on DLA ----------
[05/21/2022-03:01:56] [I] [TRT] ---------- Layers Running on GPU ----------
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 001_convolutional + 001_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 002_convolutional + 002_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 006_convolutional + 006_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 007_convolutional + 007_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 009_convolutional + 009_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 011_convolutional + 011_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 012_convolutional + 012_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 016_convolutional + 016_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 017_convolutional + 017_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 019_convolutional + 019_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 020_convolutional + 020_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 022_convolutional + 022_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 024_convolutional + 024_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 025_convolutional + 025_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 029_convolutional + 029_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 030_convolutional + 030_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 032_convolutional + 032_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 033_convolutional + 033_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 035_convolutional + 035_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 036_convolutional + 036_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 038_convolutional + 038_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 039_convolutional + 039_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 041_convolutional + 041_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 042_convolutional + 042_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 044_convolutional + 044_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 045_convolutional + 045_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 047_convolutional + 047_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 048_convolutional + 048_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 050_convolutional + 050_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 051_convolutional + 051_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 053_convolutional + 053_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 055_convolutional + 055_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 056_convolutional + 056_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 060_convolutional + 060_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 061_convolutional + 061_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 063_convolutional + 063_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 064_convolutional + 064_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 066_convolutional + 066_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 067_convolutional + 067_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 069_convolutional + 069_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 070_convolutional + 070_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 072_convolutional + 072_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 073_convolutional + 073_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 075_convolutional + 075_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 076_convolutional + 076_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 078_convolutional + 078_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 079_convolutional + 079_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 081_convolutional + 081_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 082_convolutional + 082_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 084_convolutional + 084_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 086_convolutional + 086_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 087_convolutional + 087_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 091_convolutional + 091_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 092_convolutional + 092_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 094_convolutional + 094_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 095_convolutional + 095_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 097_convolutional + 097_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 098_convolutional + 098_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 100_convolutional + 100_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 101_convolutional + 101_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 103_convolutional + 103_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 105_convolutional + 105_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 106_convolutional + 106_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(106_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 107_convolutional + 107_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(107_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 108_convolutional + 108_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(108_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 109_maxpool
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 111_maxpool
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 113_maxpool
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 113_maxpool copy
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 111_maxpool copy
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 109_maxpool copy
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 108_convolutional_lrelu copy
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 115_convolutional + 115_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(115_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 116_convolutional + 116_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(116_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 117_convolutional + 117_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(117_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 118_convolutional + 118_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(118_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 119_upsample
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 121_convolutional + 121_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(121_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 119_upsample copy
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 123_convolutional + 123_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(123_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 124_convolutional + 124_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(124_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 125_convolutional + 125_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(125_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 126_convolutional + 126_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(126_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 127_convolutional + 127_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(127_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 128_convolutional + 128_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(128_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 129_upsample
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 131_convolutional + 131_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(131_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 129_upsample copy
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 133_convolutional + 133_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(133_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 134_convolutional + 134_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(134_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 135_convolutional + 135_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(135_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 136_convolutional + 136_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(136_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 137_convolutional + 137_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(137_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 138_convolutional + 138_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(138_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 139_convolutional
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 142_convolutional + 142_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(142_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 144_convolutional + 144_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(144_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 145_convolutional + 145_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(145_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 146_convolutional + 146_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(146_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 147_convolutional + 147_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(147_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 148_convolutional + 148_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(148_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 149_convolutional + 149_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(149_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 150_convolutional
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 153_convolutional + 153_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(153_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 155_convolutional + 155_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(155_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 156_convolutional + 156_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(156_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 157_convolutional + 157_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(157_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 158_convolutional + 158_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(158_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 159_convolutional + 159_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(159_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 160_convolutional + 160_convolutional_bn
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] PWN(160_convolutional_lrelu)
[05/21/2022-03:01:56] [I] [TRT] [GpuLayer] 161_convolutional
[05/21/2022-03:01:58] [V] [TRT] Using cublas as a tactic source
[05/21/2022-03:01:58] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +158, GPU +232, now: CPU 928, GPU 3639 (MiB)
[05/21/2022-03:01:58] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-03:02:02] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +241, GPU +252, now: CPU 1169, GPU 3891 (MiB)
[05/21/2022-03:02:02] [I] [TRT] Local timing cache in use. Profiling results in this builder pass will not be stored.
[05/21/2022-03:02:02] [V] [TRT] Constructing optimization profile number 0 [1/1].
[05/21/2022-03:02:02] [V] [TRT] Reserving memory for activation tensors. Host: 0 bytes Device: 5696652 bytes
[05/21/2022-03:02:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:02] [V] [TRT] *************** Autotuning Reformat: Float(519168,173056,416,1) -> Float(519168,1,1248,3) ***************
[05/21/2022-03:02:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(000_net -> <out>) (Reformat)
[05/21/2022-03:02:02] [V] [TRT] Tactic: 1002 Time: 2.35882
[05/21/2022-03:02:02] [V] [TRT] Tactic: 0 Time: 1.51298
[05/21/2022-03:02:02] [V] [TRT] Fastest Tactic: 0 Time: 1.51298
[05/21/2022-03:02:02] [V] [TRT] *************** Autotuning Reformat: Float(519168,173056,416,1) -> Half(519168,173056,416,1) ***************
[05/21/2022-03:02:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(000_net -> <out>) (Reformat)
[05/21/2022-03:02:02] [V] [TRT] Tactic: 1002 Time: 1.2904
[05/21/2022-03:02:02] [V] [TRT] Tactic: 0 Time: 1.04868
[05/21/2022-03:02:02] [V] [TRT] Fastest Tactic: 0 Time: 1.04868
[05/21/2022-03:02:02] [V] [TRT] *************** Autotuning Reformat: Float(519168,173056,416,1) -> Half(346112,173056:2,416,1) ***************
[05/21/2022-03:02:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(000_net -> <out>) (Reformat)
[05/21/2022-03:02:02] [V] [TRT] Tactic: 1002 Time: 2.89755
[05/21/2022-03:02:02] [V] [TRT] Tactic: 0 Time: 1.11542
[05/21/2022-03:02:02] [V] [TRT] Fastest Tactic: 0 Time: 1.11542
[05/21/2022-03:02:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:02] [V] [TRT] *************** Autotuning Reformat: Float(5537792,173056,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:02] [V] [TRT] Tactic: 1002 Time: 13.0301
[05/21/2022-03:02:03] [V] [TRT] Tactic: 0 Time: 10.0512
[05/21/2022-03:02:03] [V] [TRT] Fastest Tactic: 0 Time: 10.0512
[05/21/2022-03:02:03] [V] [TRT] *************** Autotuning Reformat: Float(5537792,173056,416,1) -> Float(173056,173056:32,416,1) ***************
[05/21/2022-03:02:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:03] [V] [TRT] Tactic: 1002 Time: 12.7748
[05/21/2022-03:02:03] [V] [TRT] Tactic: 0 Time: 17.9898
[05/21/2022-03:02:03] [V] [TRT] Fastest Tactic: 1002 Time: 12.7748
[05/21/2022-03:02:03] [V] [TRT] *************** Autotuning Reformat: Float(5537792,173056,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:03] [V] [TRT] Tactic: 1002 Time: 6.89577
[05/21/2022-03:02:03] [V] [TRT] Tactic: 0 Time: 5.60357
[05/21/2022-03:02:03] [V] [TRT] Fastest Tactic: 0 Time: 5.60357
[05/21/2022-03:02:03] [V] [TRT] *************** Autotuning Reformat: Float(5537792,173056,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:04] [V] [TRT] Tactic: 1002 Time: 8.18947
[05/21/2022-03:02:04] [V] [TRT] Tactic: 0 Time: 4.48434
[05/21/2022-03:02:04] [V] [TRT] Fastest Tactic: 0 Time: 4.48434
[05/21/2022-03:02:04] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,13312,32) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:04] [V] [TRT] Tactic: 1002 Time: 12.7388
[05/21/2022-03:02:04] [V] [TRT] Tactic: 0 Time: 18.5863
[05/21/2022-03:02:04] [V] [TRT] Fastest Tactic: 1002 Time: 12.7388
[05/21/2022-03:02:04] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,13312,32) -> Float(173056,173056:32,416,1) ***************
[05/21/2022-03:02:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:05] [V] [TRT] Tactic: 1002 Time: 12.3656
[05/21/2022-03:02:05] [V] [TRT] Tactic: 0 Time: 37.4926
[05/21/2022-03:02:05] [V] [TRT] Fastest Tactic: 1002 Time: 12.3656
[05/21/2022-03:02:05] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,13312,32) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:05] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:05] [V] [TRT] Tactic: 1002 Time: 5.19555
[05/21/2022-03:02:06] [V] [TRT] Tactic: 0 Time: 18.2365
[05/21/2022-03:02:06] [V] [TRT] Fastest Tactic: 1002 Time: 5.19555
[05/21/2022-03:02:06] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,13312,32) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:06] [V] [TRT] Tactic: 1002 Time: 6.94089
[05/21/2022-03:02:06] [V] [TRT] Tactic: 0 Time: 19.656
[05/21/2022-03:02:06] [V] [TRT] Fastest Tactic: 1002 Time: 6.94089
[05/21/2022-03:02:06] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:06] [V] [TRT] Tactic: 1002 Time: 12.6968
[05/21/2022-03:02:07] [V] [TRT] Tactic: 0 Time: 18.7131
[05/21/2022-03:02:07] [V] [TRT] Fastest Tactic: 1002 Time: 12.6968
[05/21/2022-03:02:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:07] [V] [TRT] Tactic: 1002 Time: 12.446
[05/21/2022-03:02:07] [V] [TRT] Tactic: 0 Time: 9.4796
[05/21/2022-03:02:07] [V] [TRT] Fastest Tactic: 0 Time: 9.4796
[05/21/2022-03:02:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:07] [V] [TRT] Tactic: 1002 Time: 5.46492
[05/21/2022-03:02:08] [V] [TRT] Tactic: 0 Time: 18.1967
[05/21/2022-03:02:08] [V] [TRT] Fastest Tactic: 1002 Time: 5.46492
[05/21/2022-03:02:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:08] [V] [TRT] Tactic: 1002 Time: 6.93801
[05/21/2022-03:02:08] [V] [TRT] Tactic: 0 Time: 19.6265
[05/21/2022-03:02:08] [V] [TRT] Fastest Tactic: 1002 Time: 6.93801
[05/21/2022-03:02:08] [V] [TRT] *************** Autotuning Reformat: Half(5537792,173056,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:08] [V] [TRT] Tactic: 1002 Time: 6.96257
[05/21/2022-03:02:09] [V] [TRT] Tactic: 0 Time: 4.78286
[05/21/2022-03:02:09] [V] [TRT] Fastest Tactic: 0 Time: 4.78286
[05/21/2022-03:02:09] [V] [TRT] *************** Autotuning Reformat: Half(5537792,173056,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:09] [V] [TRT] Tactic: 1002 Time: 5.05241
[05/21/2022-03:02:09] [V] [TRT] Tactic: 0 Time: 8.64272
[05/21/2022-03:02:09] [V] [TRT] Fastest Tactic: 1002 Time: 5.05241
[05/21/2022-03:02:09] [V] [TRT] *************** Autotuning Reformat: Half(5537792,173056,416,1) -> Float(173056,173056:32,416,1) ***************
[05/21/2022-03:02:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:09] [V] [TRT] Tactic: 1002 Time: 5.05278
[05/21/2022-03:02:09] [V] [TRT] Tactic: 0 Time: 18.3907
[05/21/2022-03:02:09] [V] [TRT] Fastest Tactic: 1002 Time: 5.05278
[05/21/2022-03:02:09] [V] [TRT] *************** Autotuning Reformat: Half(5537792,173056,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:09] [V] [TRT] Tactic: 1002 Time: 5.06282
[05/21/2022-03:02:09] [V] [TRT] Tactic: 0 Time: 4.43796
[05/21/2022-03:02:09] [V] [TRT] Fastest Tactic: 0 Time: 4.43796
[05/21/2022-03:02:09] [V] [TRT] *************** Autotuning Reformat: Half(2768896,173056:2,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:10] [V] [TRT] Tactic: 1002 Time: 6.57731
[05/21/2022-03:02:10] [V] [TRT] Tactic: 0 Time: 3.90416
[05/21/2022-03:02:10] [V] [TRT] Fastest Tactic: 0 Time: 3.90416
[05/21/2022-03:02:10] [V] [TRT] *************** Autotuning Reformat: Half(2768896,173056:2,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:10] [V] [TRT] Tactic: 1002 Time: 5.12047
[05/21/2022-03:02:10] [V] [TRT] Tactic: 0 Time: 9.65548
[05/21/2022-03:02:10] [V] [TRT] Fastest Tactic: 1002 Time: 5.12047
[05/21/2022-03:02:10] [V] [TRT] *************** Autotuning Reformat: Half(2768896,173056:2,416,1) -> Float(173056,173056:32,416,1) ***************
[05/21/2022-03:02:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:10] [V] [TRT] Tactic: 1002 Time: 5.11731
[05/21/2022-03:02:10] [V] [TRT] Tactic: 0 Time: 18.8028
[05/21/2022-03:02:10] [V] [TRT] Fastest Tactic: 1002 Time: 5.11731
[05/21/2022-03:02:10] [V] [TRT] *************** Autotuning Reformat: Half(2768896,173056:2,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:10] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(001_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:11] [V] [TRT] Tactic: 1002 Time: 17.6009
[05/21/2022-03:02:11] [V] [TRT] Tactic: 0 Time: 3.79087
[05/21/2022-03:02:11] [V] [TRT] Fastest Tactic: 0 Time: 3.79087
[05/21/2022-03:02:11] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(5537792,173056,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(5537792,173056,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(5537792,173056,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,13312,32) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,13312,32) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,13312,32) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(173056,173056:32,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Half(5537792,173056,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Half(5537792,173056,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Half(5537792,173056,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Half(2768896,173056:2,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Half(2768896,173056:2,416,1) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Half(2768896,173056:2,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:02:11] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:11] [V] [TRT] Tactic: 1002 Time: 2.89192
[05/21/2022-03:02:11] [V] [TRT] Tactic: 0 Time: 5.18133
[05/21/2022-03:02:11] [V] [TRT] Fastest Tactic: 1002 Time: 2.89192
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:11] [V] [TRT] Tactic: 1002 Time: 2.90753
[05/21/2022-03:02:11] [V] [TRT] Tactic: 0 Time: 8.80113
[05/21/2022-03:02:11] [V] [TRT] Fastest Tactic: 1002 Time: 2.90753
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:11] [V] [TRT] Tactic: 1002 Time: 3.47579
[05/21/2022-03:02:11] [V] [TRT] Tactic: 0 Time: 2.80952
[05/21/2022-03:02:11] [V] [TRT] Fastest Tactic: 0 Time: 2.80952
[05/21/2022-03:02:11] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:11] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:12] [V] [TRT] Tactic: 1002 Time: 4.12007
[05/21/2022-03:02:12] [V] [TRT] Tactic: 0 Time: 2.24662
[05/21/2022-03:02:12] [V] [TRT] Fastest Tactic: 0 Time: 2.24662
[05/21/2022-03:02:12] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:12] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:12] [V] [TRT] Tactic: 1002 Time: 3.26142
[05/21/2022-03:02:12] [V] [TRT] Tactic: 0 Time: 9.39334
[05/21/2022-03:02:12] [V] [TRT] Fastest Tactic: 1002 Time: 3.26142
[05/21/2022-03:02:12] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:12] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:12] [V] [TRT] Tactic: 1002 Time: 2.34573
[05/21/2022-03:02:12] [V] [TRT] Tactic: 0 Time: 18.5775
[05/21/2022-03:02:12] [V] [TRT] Fastest Tactic: 1002 Time: 2.34573
[05/21/2022-03:02:12] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:12] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:12] [V] [TRT] Tactic: 1002 Time: 2.60373
[05/21/2022-03:02:13] [V] [TRT] Tactic: 0 Time: 9.20506
[05/21/2022-03:02:13] [V] [TRT] Fastest Tactic: 1002 Time: 2.60373
[05/21/2022-03:02:13] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:13] [V] [TRT] Tactic: 1002 Time: 3.52784
[05/21/2022-03:02:13] [V] [TRT] Tactic: 0 Time: 9.8449
[05/21/2022-03:02:13] [V] [TRT] Fastest Tactic: 1002 Time: 3.52784
[05/21/2022-03:02:13] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:13] [V] [TRT] Tactic: 1002 Time: 3.28209
[05/21/2022-03:02:13] [V] [TRT] Tactic: 0 Time: 9.26419
[05/21/2022-03:02:13] [V] [TRT] Fastest Tactic: 1002 Time: 3.28209
[05/21/2022-03:02:13] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:13] [V] [TRT] Tactic: 1002 Time: 2.37449
[05/21/2022-03:02:13] [V] [TRT] Tactic: 0 Time: 4.74807
[05/21/2022-03:02:13] [V] [TRT] Fastest Tactic: 1002 Time: 2.37449
[05/21/2022-03:02:13] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:13] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:13] [V] [TRT] Tactic: 1002 Time: 2.74054
[05/21/2022-03:02:14] [V] [TRT] Tactic: 0 Time: 9.07349
[05/21/2022-03:02:14] [V] [TRT] Fastest Tactic: 1002 Time: 2.74054
[05/21/2022-03:02:14] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:14] [V] [TRT] Tactic: 1002 Time: 3.54019
[05/21/2022-03:02:14] [V] [TRT] Tactic: 0 Time: 9.78045
[05/21/2022-03:02:14] [V] [TRT] Fastest Tactic: 1002 Time: 3.54019
[05/21/2022-03:02:14] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:14] [V] [TRT] Tactic: 1002 Time: 3.50721
[05/21/2022-03:02:14] [V] [TRT] Tactic: 0 Time: 2.39931
[05/21/2022-03:02:14] [V] [TRT] Fastest Tactic: 0 Time: 2.39931
[05/21/2022-03:02:14] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:14] [V] [TRT] Tactic: 1002 Time: 2.5318
[05/21/2022-03:02:14] [V] [TRT] Tactic: 0 Time: 4.42077
[05/21/2022-03:02:14] [V] [TRT] Fastest Tactic: 1002 Time: 2.5318
[05/21/2022-03:02:14] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:14] [V] [TRT] Tactic: 1002 Time: 2.53242
[05/21/2022-03:02:14] [V] [TRT] Tactic: 0 Time: 8.74277
[05/21/2022-03:02:14] [V] [TRT] Fastest Tactic: 1002 Time: 2.53242
[05/21/2022-03:02:14] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:14] [V] [TRT] Tactic: 1002 Time: 2.57339
[05/21/2022-03:02:14] [V] [TRT] Tactic: 0 Time: 2.22514
[05/21/2022-03:02:14] [V] [TRT] Fastest Tactic: 0 Time: 2.22514
[05/21/2022-03:02:14] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:14] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:15] [V] [TRT] Tactic: 1002 Time: 3.29934
[05/21/2022-03:02:15] [V] [TRT] Tactic: 0 Time: 1.95404
[05/21/2022-03:02:15] [V] [TRT] Fastest Tactic: 0 Time: 1.95404
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:15] [V] [TRT] Tactic: 1002 Time: 2.56451
[05/21/2022-03:02:15] [V] [TRT] Tactic: 0 Time: 4.82049
[05/21/2022-03:02:15] [V] [TRT] Fastest Tactic: 1002 Time: 2.56451
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:15] [V] [TRT] Tactic: 1002 Time: 2.56898
[05/21/2022-03:02:15] [V] [TRT] Tactic: 0 Time: 9.03148
[05/21/2022-03:02:15] [V] [TRT] Fastest Tactic: 1002 Time: 2.56898
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(002_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:15] [V] [TRT] Tactic: 1002 Time: 5.579
[05/21/2022-03:02:15] [V] [TRT] Tactic: 0 Time: 1.89644
[05/21/2022-03:02:15] [V] [TRT] Fastest Tactic: 0 Time: 1.89644
[05/21/2022-03:02:15] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:15] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:15] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:15] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:15] [V] [TRT] Tactic: 1002 Time: 5.94412
[05/21/2022-03:02:16] [V] [TRT] Tactic: 0 Time: 10.7221
[05/21/2022-03:02:16] [V] [TRT] Fastest Tactic: 1002 Time: 5.94412
[05/21/2022-03:02:16] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:16] [V] [TRT] Tactic: 1002 Time: 5.91202
[05/21/2022-03:02:16] [V] [TRT] Tactic: 0 Time: 17.5601
[05/21/2022-03:02:16] [V] [TRT] Fastest Tactic: 1002 Time: 5.91202
[05/21/2022-03:02:16] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:16] [V] [TRT] Tactic: 1002 Time: 6.93507
[05/21/2022-03:02:16] [V] [TRT] Tactic: 0 Time: 5.60707
[05/21/2022-03:02:16] [V] [TRT] Fastest Tactic: 0 Time: 5.60707
[05/21/2022-03:02:16] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:16] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:16] [V] [TRT] Tactic: 1002 Time: 8.22843
[05/21/2022-03:02:17] [V] [TRT] Tactic: 0 Time: 4.4832
[05/21/2022-03:02:17] [V] [TRT] Fastest Tactic: 0 Time: 4.4832
[05/21/2022-03:02:17] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:17] [V] [TRT] Tactic: 1002 Time: 6.57163
[05/21/2022-03:02:17] [V] [TRT] Tactic: 0 Time: 20.0768
[05/21/2022-03:02:17] [V] [TRT] Fastest Tactic: 1002 Time: 6.57163
[05/21/2022-03:02:17] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:17] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:17] [V] [TRT] Tactic: 1002 Time: 4.69983
[05/21/2022-03:02:18] [V] [TRT] Tactic: 0 Time: 36.5593
[05/21/2022-03:02:18] [V] [TRT] Fastest Tactic: 1002 Time: 4.69983
[05/21/2022-03:02:18] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:18] [V] [TRT] Tactic: 1002 Time: 5.2161
[05/21/2022-03:02:18] [V] [TRT] Tactic: 0 Time: 20.0645
[05/21/2022-03:02:18] [V] [TRT] Fastest Tactic: 1002 Time: 5.2161
[05/21/2022-03:02:18] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:18] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:18] [V] [TRT] Tactic: 1002 Time: 7.0793
[05/21/2022-03:02:19] [V] [TRT] Tactic: 0 Time: 21.1321
[05/21/2022-03:02:19] [V] [TRT] Fastest Tactic: 1002 Time: 7.0793
[05/21/2022-03:02:19] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:19] [V] [TRT] Tactic: 1002 Time: 7.02653
[05/21/2022-03:02:19] [V] [TRT] Tactic: 0 Time: 4.78695
[05/21/2022-03:02:19] [V] [TRT] Fastest Tactic: 0 Time: 4.78695
[05/21/2022-03:02:19] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:19] [V] [TRT] Tactic: 1002 Time: 5.05077
[05/21/2022-03:02:19] [V] [TRT] Tactic: 0 Time: 9.33879
[05/21/2022-03:02:19] [V] [TRT] Fastest Tactic: 1002 Time: 5.05077
[05/21/2022-03:02:19] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:19] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:20] [V] [TRT] Tactic: 1002 Time: 5.04903
[05/21/2022-03:02:20] [V] [TRT] Tactic: 0 Time: 17.4602
[05/21/2022-03:02:20] [V] [TRT] Fastest Tactic: 1002 Time: 5.04903
[05/21/2022-03:02:20] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:20] [V] [TRT] Tactic: 1002 Time: 5.17501
[05/21/2022-03:02:20] [V] [TRT] Tactic: 0 Time: 4.44075
[05/21/2022-03:02:20] [V] [TRT] Fastest Tactic: 0 Time: 4.44075
[05/21/2022-03:02:20] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:20] [V] [TRT] Tactic: 1002 Time: 6.58233
[05/21/2022-03:02:20] [V] [TRT] Tactic: 0 Time: 3.90336
[05/21/2022-03:02:20] [V] [TRT] Fastest Tactic: 0 Time: 3.90336
[05/21/2022-03:02:20] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:20] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:20] [V] [TRT] Tactic: 1002 Time: 5.11329
[05/21/2022-03:02:21] [V] [TRT] Tactic: 0 Time: 9.63379
[05/21/2022-03:02:21] [V] [TRT] Fastest Tactic: 1002 Time: 5.11329
[05/21/2022-03:02:21] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:21] [V] [TRT] Tactic: 1002 Time: 5.11363
[05/21/2022-03:02:21] [V] [TRT] Tactic: 0 Time: 17.8689
[05/21/2022-03:02:21] [V] [TRT] Fastest Tactic: 1002 Time: 5.11363
[05/21/2022-03:02:21] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn) (Reformat)
[05/21/2022-03:02:21] [V] [TRT] Tactic: 1002 Time: 10.5562
[05/21/2022-03:02:21] [V] [TRT] Tactic: 0 Time: 3.78734
[05/21/2022-03:02:21] [V] [TRT] Fastest Tactic: 0 Time: 3.78734
[05/21/2022-03:02:21] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:21] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:21] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:21] [V] [TRT] Tactic: 1002 Time: 2.9045
[05/21/2022-03:02:22] [V] [TRT] Tactic: 0 Time: 5.2301
[05/21/2022-03:02:22] [V] [TRT] Fastest Tactic: 1002 Time: 2.9045
[05/21/2022-03:02:22] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:22] [V] [TRT] Tactic: 1002 Time: 2.90783
[05/21/2022-03:02:22] [V] [TRT] Tactic: 0 Time: 8.76973
[05/21/2022-03:02:22] [V] [TRT] Fastest Tactic: 1002 Time: 2.90783
[05/21/2022-03:02:22] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:22] [V] [TRT] Tactic: 1002 Time: 4.11916
[05/21/2022-03:02:22] [V] [TRT] Tactic: 0 Time: 3.78991
[05/21/2022-03:02:22] [V] [TRT] Fastest Tactic: 0 Time: 3.78991
[05/21/2022-03:02:22] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:22] [V] [TRT] Tactic: 1002 Time: 4.11938
[05/21/2022-03:02:22] [V] [TRT] Tactic: 0 Time: 4.53692
[05/21/2022-03:02:22] [V] [TRT] Fastest Tactic: 1002 Time: 4.11938
[05/21/2022-03:02:22] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:22] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:22] [V] [TRT] Tactic: 1002 Time: 3.27985
[05/21/2022-03:02:23] [V] [TRT] Tactic: 0 Time: 10.169
[05/21/2022-03:02:23] [V] [TRT] Fastest Tactic: 1002 Time: 3.27985
[05/21/2022-03:02:23] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:23] [V] [TRT] Tactic: 1002 Time: 2.39168
[05/21/2022-03:02:23] [V] [TRT] Tactic: 0 Time: 18.3487
[05/21/2022-03:02:23] [V] [TRT] Fastest Tactic: 1002 Time: 2.39168
[05/21/2022-03:02:23] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:23] [V] [TRT] Tactic: 1002 Time: 2.60536
[05/21/2022-03:02:23] [V] [TRT] Tactic: 0 Time: 9.90403
[05/21/2022-03:02:23] [V] [TRT] Fastest Tactic: 1002 Time: 2.60536
[05/21/2022-03:02:23] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:23] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:23] [V] [TRT] Tactic: 1002 Time: 3.52917
[05/21/2022-03:02:24] [V] [TRT] Tactic: 0 Time: 10.5613
[05/21/2022-03:02:24] [V] [TRT] Fastest Tactic: 1002 Time: 3.52917
[05/21/2022-03:02:24] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:24] [V] [TRT] Tactic: 1002 Time: 3.28817
[05/21/2022-03:02:24] [V] [TRT] Tactic: 0 Time: 9.23323
[05/21/2022-03:02:24] [V] [TRT] Fastest Tactic: 1002 Time: 3.28817
[05/21/2022-03:02:24] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:24] [V] [TRT] Tactic: 1002 Time: 2.37501
[05/21/2022-03:02:24] [V] [TRT] Tactic: 0 Time: 4.7488
[05/21/2022-03:02:24] [V] [TRT] Fastest Tactic: 1002 Time: 2.37501
[05/21/2022-03:02:24] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:24] [V] [TRT] Tactic: 1002 Time: 2.74044
[05/21/2022-03:02:24] [V] [TRT] Tactic: 0 Time: 9.07794
[05/21/2022-03:02:24] [V] [TRT] Fastest Tactic: 1002 Time: 2.74044
[05/21/2022-03:02:24] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:24] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:24] [V] [TRT] Tactic: 1002 Time: 3.52997
[05/21/2022-03:02:25] [V] [TRT] Tactic: 0 Time: 9.76422
[05/21/2022-03:02:25] [V] [TRT] Fastest Tactic: 1002 Time: 3.52997
[05/21/2022-03:02:25] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:25] [V] [TRT] Tactic: 1002 Time: 4.15104
[05/21/2022-03:02:25] [V] [TRT] Tactic: 0 Time: 3.81342
[05/21/2022-03:02:25] [V] [TRT] Fastest Tactic: 0 Time: 3.81342
[05/21/2022-03:02:25] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:25] [V] [TRT] Tactic: 1002 Time: 2.53158
[05/21/2022-03:02:25] [V] [TRT] Tactic: 0 Time: 4.40522
[05/21/2022-03:02:25] [V] [TRT] Fastest Tactic: 1002 Time: 2.53158
[05/21/2022-03:02:25] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:25] [V] [TRT] Tactic: 1002 Time: 2.53294
[05/21/2022-03:02:25] [V] [TRT] Tactic: 0 Time: 8.74376
[05/21/2022-03:02:25] [V] [TRT] Fastest Tactic: 1002 Time: 2.53294
[05/21/2022-03:02:25] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:25] [V] [TRT] Tactic: 1002 Time: 2.58201
[05/21/2022-03:02:25] [V] [TRT] Tactic: 0 Time: 4.04523
[05/21/2022-03:02:25] [V] [TRT] Fastest Tactic: 1002 Time: 2.58201
[05/21/2022-03:02:25] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:25] [V] [TRT] Tactic: 1002 Time: 3.29908
[05/21/2022-03:02:25] [V] [TRT] Tactic: 0 Time: 1.95471
[05/21/2022-03:02:25] [V] [TRT] Fastest Tactic: 0 Time: 1.95471
[05/21/2022-03:02:25] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:25] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:25] [V] [TRT] Tactic: 1002 Time: 2.56273
[05/21/2022-03:02:26] [V] [TRT] Tactic: 0 Time: 4.82017
[05/21/2022-03:02:26] [V] [TRT] Fastest Tactic: 1002 Time: 2.56273
[05/21/2022-03:02:26] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:26] [V] [TRT] Tactic: 1002 Time: 2.56599
[05/21/2022-03:02:26] [V] [TRT] Tactic: 0 Time: 8.94423
[05/21/2022-03:02:26] [V] [TRT] Fastest Tactic: 1002 Time: 2.56599
[05/21/2022-03:02:26] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(003_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:26] [V] [TRT] Tactic: 1002 Time: 5.52458
[05/21/2022-03:02:26] [V] [TRT] Tactic: 0 Time: 1.8987
[05/21/2022-03:02:26] [V] [TRT] Fastest Tactic: 0 Time: 1.8987
[05/21/2022-03:02:26] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:26] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:26] [V] [TRT] Tactic: 1002 Time: 2.92359
[05/21/2022-03:02:26] [V] [TRT] Tactic: 0 Time: 5.20434
[05/21/2022-03:02:26] [V] [TRT] Fastest Tactic: 1002 Time: 2.92359
[05/21/2022-03:02:26] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:26] [V] [TRT] Tactic: 1002 Time: 2.91214
[05/21/2022-03:02:26] [V] [TRT] Tactic: 0 Time: 8.78818
[05/21/2022-03:02:26] [V] [TRT] Fastest Tactic: 1002 Time: 2.91214
[05/21/2022-03:02:26] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:26] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:27] [V] [TRT] Tactic: 1002 Time: 4.11945
[05/21/2022-03:02:27] [V] [TRT] Tactic: 0 Time: 3.78971
[05/21/2022-03:02:27] [V] [TRT] Fastest Tactic: 0 Time: 3.78971
[05/21/2022-03:02:27] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:27] [V] [TRT] Tactic: 1002 Time: 4.11919
[05/21/2022-03:02:27] [V] [TRT] Tactic: 0 Time: 2.24757
[05/21/2022-03:02:27] [V] [TRT] Fastest Tactic: 0 Time: 2.24757
[05/21/2022-03:02:27] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:27] [V] [TRT] Tactic: 1002 Time: 3.25096
[05/21/2022-03:02:27] [V] [TRT] Tactic: 0 Time: 9.3915
[05/21/2022-03:02:27] [V] [TRT] Fastest Tactic: 1002 Time: 3.25096
[05/21/2022-03:02:27] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:27] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:27] [V] [TRT] Tactic: 1002 Time: 2.34079
[05/21/2022-03:02:28] [V] [TRT] Tactic: 0 Time: 18.6292
[05/21/2022-03:02:28] [V] [TRT] Fastest Tactic: 1002 Time: 2.34079
[05/21/2022-03:02:28] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:28] [V] [TRT] Tactic: 1002 Time: 2.60443
[05/21/2022-03:02:28] [V] [TRT] Tactic: 0 Time: 9.22188
[05/21/2022-03:02:28] [V] [TRT] Fastest Tactic: 1002 Time: 2.60443
[05/21/2022-03:02:28] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:28] [V] [TRT] Tactic: 1002 Time: 3.52942
[05/21/2022-03:02:28] [V] [TRT] Tactic: 0 Time: 9.87043
[05/21/2022-03:02:28] [V] [TRT] Fastest Tactic: 1002 Time: 3.52942
[05/21/2022-03:02:28] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:28] [V] [TRT] Tactic: 1002 Time: 3.29373
[05/21/2022-03:02:28] [V] [TRT] Tactic: 0 Time: 9.26194
[05/21/2022-03:02:28] [V] [TRT] Fastest Tactic: 1002 Time: 3.29373
[05/21/2022-03:02:28] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:28] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:28] [V] [TRT] Tactic: 1002 Time: 2.3849
[05/21/2022-03:02:29] [V] [TRT] Tactic: 0 Time: 4.74692
[05/21/2022-03:02:29] [V] [TRT] Fastest Tactic: 1002 Time: 2.3849
[05/21/2022-03:02:29] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:29] [V] [TRT] Tactic: 1002 Time: 2.74098
[05/21/2022-03:02:29] [V] [TRT] Tactic: 0 Time: 9.06746
[05/21/2022-03:02:29] [V] [TRT] Fastest Tactic: 1002 Time: 2.74098
[05/21/2022-03:02:29] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:29] [V] [TRT] Tactic: 1002 Time: 3.52997
[05/21/2022-03:02:29] [V] [TRT] Tactic: 0 Time: 9.77301
[05/21/2022-03:02:29] [V] [TRT] Fastest Tactic: 1002 Time: 3.52997
[05/21/2022-03:02:29] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:29] [V] [TRT] Tactic: 1002 Time: 4.15286
[05/21/2022-03:02:29] [V] [TRT] Tactic: 0 Time: 3.81402
[05/21/2022-03:02:29] [V] [TRT] Fastest Tactic: 0 Time: 3.81402
[05/21/2022-03:02:29] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:29] [V] [TRT] Tactic: 1002 Time: 2.53104
[05/21/2022-03:02:29] [V] [TRT] Tactic: 0 Time: 4.45141
[05/21/2022-03:02:29] [V] [TRT] Fastest Tactic: 1002 Time: 2.53104
[05/21/2022-03:02:29] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:29] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:29] [V] [TRT] Tactic: 1002 Time: 2.53158
[05/21/2022-03:02:30] [V] [TRT] Tactic: 0 Time: 8.72148
[05/21/2022-03:02:30] [V] [TRT] Fastest Tactic: 1002 Time: 2.53158
[05/21/2022-03:02:30] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:30] [V] [TRT] Tactic: 1002 Time: 2.55318
[05/21/2022-03:02:30] [V] [TRT] Tactic: 0 Time: 2.2246
[05/21/2022-03:02:30] [V] [TRT] Fastest Tactic: 0 Time: 2.2246
[05/21/2022-03:02:30] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:30] [V] [TRT] Tactic: 1002 Time: 3.30081
[05/21/2022-03:02:30] [V] [TRT] Tactic: 0 Time: 4.47577
[05/21/2022-03:02:30] [V] [TRT] Fastest Tactic: 1002 Time: 3.30081
[05/21/2022-03:02:30] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:30] [V] [TRT] Tactic: 1002 Time: 2.56274
[05/21/2022-03:02:30] [V] [TRT] Tactic: 0 Time: 4.82201
[05/21/2022-03:02:30] [V] [TRT] Fastest Tactic: 1002 Time: 2.56274
[05/21/2022-03:02:30] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:30] [V] [TRT] Tactic: 1002 Time: 2.56389
[05/21/2022-03:02:30] [V] [TRT] Tactic: 0 Time: 8.93689
[05/21/2022-03:02:30] [V] [TRT] Fastest Tactic: 1002 Time: 2.56389
[05/21/2022-03:02:30] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:30] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 003_convolutional_mish) (Reformat)
[05/21/2022-03:02:31] [V] [TRT] Tactic: 1002 Time: 5.52755
[05/21/2022-03:02:31] [V] [TRT] Tactic: 0 Time: 4.03932
[05/21/2022-03:02:31] [V] [TRT] Fastest Tactic: 0 Time: 4.03932
[05/21/2022-03:02:31] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:31] [V] [TRT] Tactic: 1002 Time: 2.9043
[05/21/2022-03:02:31] [V] [TRT] Tactic: 0 Time: 5.19426
[05/21/2022-03:02:31] [V] [TRT] Fastest Tactic: 1002 Time: 2.9043
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:31] [V] [TRT] Tactic: 1002 Time: 2.90702
[05/21/2022-03:02:31] [V] [TRT] Tactic: 0 Time: 8.76781
[05/21/2022-03:02:31] [V] [TRT] Fastest Tactic: 1002 Time: 2.90702
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:31] [V] [TRT] Tactic: 1002 Time: 3.49381
[05/21/2022-03:02:31] [V] [TRT] Tactic: 0 Time: 2.81691
[05/21/2022-03:02:31] [V] [TRT] Fastest Tactic: 0 Time: 2.81691
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:31] [V] [TRT] Tactic: 1002 Time: 4.11846
[05/21/2022-03:02:31] [V] [TRT] Tactic: 0 Time: 2.24712
[05/21/2022-03:02:31] [V] [TRT] Fastest Tactic: 0 Time: 2.24712
[05/21/2022-03:02:31] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:31] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:31] [V] [TRT] Tactic: 1002 Time: 3.25331
[05/21/2022-03:02:32] [V] [TRT] Tactic: 0 Time: 9.39969
[05/21/2022-03:02:32] [V] [TRT] Fastest Tactic: 1002 Time: 3.25331
[05/21/2022-03:02:32] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:32] [V] [TRT] Tactic: 1002 Time: 2.33874
[05/21/2022-03:02:32] [V] [TRT] Tactic: 0 Time: 18.6142
[05/21/2022-03:02:32] [V] [TRT] Fastest Tactic: 1002 Time: 2.33874
[05/21/2022-03:02:32] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:32] [V] [TRT] Tactic: 1002 Time: 2.60639
[05/21/2022-03:02:32] [V] [TRT] Tactic: 0 Time: 9.18279
[05/21/2022-03:02:32] [V] [TRT] Fastest Tactic: 1002 Time: 2.60639
[05/21/2022-03:02:32] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:32] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:32] [V] [TRT] Tactic: 1002 Time: 3.54447
[05/21/2022-03:02:33] [V] [TRT] Tactic: 0 Time: 9.82721
[05/21/2022-03:02:33] [V] [TRT] Fastest Tactic: 1002 Time: 3.54447
[05/21/2022-03:02:33] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:33] [V] [TRT] Tactic: 1002 Time: 3.26618
[05/21/2022-03:02:33] [V] [TRT] Tactic: 0 Time: 9.27191
[05/21/2022-03:02:33] [V] [TRT] Fastest Tactic: 1002 Time: 3.26618
[05/21/2022-03:02:33] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:33] [V] [TRT] Tactic: 1002 Time: 2.38339
[05/21/2022-03:02:33] [V] [TRT] Tactic: 0 Time: 4.76048
[05/21/2022-03:02:33] [V] [TRT] Fastest Tactic: 1002 Time: 2.38339
[05/21/2022-03:02:33] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:33] [V] [TRT] Tactic: 1002 Time: 2.74055
[05/21/2022-03:02:33] [V] [TRT] Tactic: 0 Time: 9.07242
[05/21/2022-03:02:33] [V] [TRT] Fastest Tactic: 1002 Time: 2.74055
[05/21/2022-03:02:33] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:33] [V] [TRT] Tactic: 1002 Time: 3.53202
[05/21/2022-03:02:33] [V] [TRT] Tactic: 0 Time: 9.87568
[05/21/2022-03:02:33] [V] [TRT] Fastest Tactic: 1002 Time: 3.53202
[05/21/2022-03:02:33] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:33] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:34] [V] [TRT] Tactic: 1002 Time: 3.50769
[05/21/2022-03:02:34] [V] [TRT] Tactic: 0 Time: 2.39775
[05/21/2022-03:02:34] [V] [TRT] Fastest Tactic: 0 Time: 2.39775
[05/21/2022-03:02:34] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:34] [V] [TRT] Tactic: 1002 Time: 2.5331
[05/21/2022-03:02:34] [V] [TRT] Tactic: 0 Time: 4.42565
[05/21/2022-03:02:34] [V] [TRT] Fastest Tactic: 1002 Time: 2.5331
[05/21/2022-03:02:34] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:34] [V] [TRT] Tactic: 1002 Time: 2.53341
[05/21/2022-03:02:34] [V] [TRT] Tactic: 0 Time: 8.70836
[05/21/2022-03:02:34] [V] [TRT] Fastest Tactic: 1002 Time: 2.53341
[05/21/2022-03:02:34] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:34] [V] [TRT] Tactic: 1002 Time: 2.56135
[05/21/2022-03:02:34] [V] [TRT] Tactic: 0 Time: 2.2252
[05/21/2022-03:02:34] [V] [TRT] Fastest Tactic: 0 Time: 2.2252
[05/21/2022-03:02:34] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:34] [V] [TRT] Tactic: 1002 Time: 3.29759
[05/21/2022-03:02:34] [V] [TRT] Tactic: 0 Time: 1.9546
[05/21/2022-03:02:34] [V] [TRT] Fastest Tactic: 0 Time: 1.9546
[05/21/2022-03:02:34] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:34] [V] [TRT] Tactic: 1002 Time: 2.56406
[05/21/2022-03:02:34] [V] [TRT] Tactic: 0 Time: 4.85012
[05/21/2022-03:02:34] [V] [TRT] Fastest Tactic: 1002 Time: 2.56406
[05/21/2022-03:02:34] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:34] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:34] [V] [TRT] Tactic: 1002 Time: 2.56423
[05/21/2022-03:02:35] [V] [TRT] Tactic: 0 Time: 8.94219
[05/21/2022-03:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 2.56423
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 005_convolutional_mish) (Reformat)
[05/21/2022-03:02:35] [V] [TRT] Tactic: 1002 Time: 5.52332
[05/21/2022-03:02:35] [V] [TRT] Tactic: 0 Time: 1.89766
[05/21/2022-03:02:35] [V] [TRT] Fastest Tactic: 0 Time: 1.89766
[05/21/2022-03:02:35] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(1384448,43264,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:35] [V] [TRT] Tactic: 1002 Time: 3.1987
[05/21/2022-03:02:35] [V] [TRT] Tactic: 0 Time: 2.53379
[05/21/2022-03:02:35] [V] [TRT] Fastest Tactic: 0 Time: 2.53379
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(1384448,43264,208,1) -> Float(43264,43264:32,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:35] [V] [TRT] Tactic: 1002 Time: 3.20044
[05/21/2022-03:02:35] [V] [TRT] Tactic: 0 Time: 4.37254
[05/21/2022-03:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 3.20044
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(1384448,43264,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:35] [V] [TRT] Tactic: 1002 Time: 1.74371
[05/21/2022-03:02:35] [V] [TRT] Tactic: 0 Time: 1.41051
[05/21/2022-03:02:35] [V] [TRT] Fastest Tactic: 0 Time: 1.41051
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(1384448,43264,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:35] [V] [TRT] Tactic: 1002 Time: 2.06912
[05/21/2022-03:02:35] [V] [TRT] Tactic: 0 Time: 1.12827
[05/21/2022-03:02:35] [V] [TRT] Fastest Tactic: 0 Time: 1.12827
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,6656,32) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:35] [V] [TRT] Tactic: 1002 Time: 3.18161
[05/21/2022-03:02:35] [V] [TRT] Tactic: 0 Time: 4.63105
[05/21/2022-03:02:35] [V] [TRT] Fastest Tactic: 1002 Time: 3.18161
[05/21/2022-03:02:35] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,6656,32) -> Float(43264,43264:32,208,1) ***************
[05/21/2022-03:02:35] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:36] [V] [TRT] Tactic: 1002 Time: 3.09864
[05/21/2022-03:02:36] [V] [TRT] Tactic: 0 Time: 9.2242
[05/21/2022-03:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 3.09864
[05/21/2022-03:02:36] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,6656,32) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:36] [V] [TRT] Tactic: 1002 Time: 1.30898
[05/21/2022-03:02:36] [V] [TRT] Tactic: 0 Time: 4.53704
[05/21/2022-03:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.30898
[05/21/2022-03:02:36] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,6656,32) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:36] [V] [TRT] Tactic: 1002 Time: 1.77739
[05/21/2022-03:02:36] [V] [TRT] Tactic: 0 Time: 4.88528
[05/21/2022-03:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.77739
[05/21/2022-03:02:36] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:36] [V] [TRT] Tactic: 1002 Time: 3.18223
[05/21/2022-03:02:36] [V] [TRT] Tactic: 0 Time: 4.63757
[05/21/2022-03:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 3.18223
[05/21/2022-03:02:36] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:36] [V] [TRT] Tactic: 1002 Time: 3.12196
[05/21/2022-03:02:36] [V] [TRT] Tactic: 0 Time: 2.37959
[05/21/2022-03:02:36] [V] [TRT] Fastest Tactic: 0 Time: 2.37959
[05/21/2022-03:02:36] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:36] [V] [TRT] Tactic: 1002 Time: 1.3765
[05/21/2022-03:02:36] [V] [TRT] Tactic: 0 Time: 4.5274
[05/21/2022-03:02:36] [V] [TRT] Fastest Tactic: 1002 Time: 1.3765
[05/21/2022-03:02:36] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:36] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:36] [V] [TRT] Tactic: 1002 Time: 1.75001
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 4.87559
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.75001
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 1.77707
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 1.20533
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 0 Time: 1.20533
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 1.27357
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 2.16125
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.27357
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264,208,1) -> Float(43264,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 1.27376
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 4.34068
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.27376
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 1.28093
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 1.11777
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 0 Time: 1.11777
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(692224,43264:2,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 1.65778
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 0.982572
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.982572
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(692224,43264:2,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 1.28897
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 2.41716
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.28897
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(692224,43264:2,208,1) -> Float(43264,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 1.28794
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 4.4544
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 1002 Time: 1.28794
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(692224,43264:2,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(006_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:37] [V] [TRT] Tactic: 1002 Time: 4.36892
[05/21/2022-03:02:37] [V] [TRT] Tactic: 0 Time: 0.954199
[05/21/2022-03:02:37] [V] [TRT] Fastest Tactic: 0 Time: 0.954199
[05/21/2022-03:02:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(1384448,43264,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(1384448,43264,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(1384448,43264,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,6656,32) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,6656,32) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,6656,32) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(43264,43264:32,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(692224,43264:2,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(692224,43264:2,208,1) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(692224,43264:2,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:37] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:37] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:37] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:38] [V] [TRT] Tactic: 1002 Time: 5.86078
[05/21/2022-03:02:38] [V] [TRT] Tactic: 0 Time: 10.5494
[05/21/2022-03:02:38] [V] [TRT] Fastest Tactic: 1002 Time: 5.86078
[05/21/2022-03:02:38] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:38] [V] [TRT] Tactic: 1002 Time: 6.94104
[05/21/2022-03:02:38] [V] [TRT] Tactic: 0 Time: 5.60754
[05/21/2022-03:02:38] [V] [TRT] Fastest Tactic: 0 Time: 5.60754
[05/21/2022-03:02:38] [V] [TRT] *************** Autotuning Reformat: Float(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:38] [V] [TRT] Tactic: 1002 Time: 8.26823
[05/21/2022-03:02:38] [V] [TRT] Tactic: 0 Time: 4.48604
[05/21/2022-03:02:38] [V] [TRT] Fastest Tactic: 0 Time: 4.48604
[05/21/2022-03:02:38] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:38] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:38] [V] [TRT] Tactic: 1002 Time: 6.58185
[05/21/2022-03:02:39] [V] [TRT] Tactic: 0 Time: 20.1332
[05/21/2022-03:02:39] [V] [TRT] Fastest Tactic: 1002 Time: 6.58185
[05/21/2022-03:02:39] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:39] [V] [TRT] Tactic: 1002 Time: 5.20571
[05/21/2022-03:02:39] [V] [TRT] Tactic: 0 Time: 19.9385
[05/21/2022-03:02:39] [V] [TRT] Fastest Tactic: 1002 Time: 5.20571
[05/21/2022-03:02:39] [V] [TRT] *************** Autotuning Reformat: Float(5537792,1,26624,128) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:39] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:39] [V] [TRT] Tactic: 1002 Time: 7.07903
[05/21/2022-03:02:40] [V] [TRT] Tactic: 0 Time: 21.2447
[05/21/2022-03:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 7.07903
[05/21/2022-03:02:40] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:40] [V] [TRT] Tactic: 1002 Time: 6.53139
[05/21/2022-03:02:40] [V] [TRT] Tactic: 0 Time: 18.4881
[05/21/2022-03:02:40] [V] [TRT] Fastest Tactic: 1002 Time: 6.53139
[05/21/2022-03:02:40] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:40] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:40] [V] [TRT] Tactic: 1002 Time: 4.76224
[05/21/2022-03:02:41] [V] [TRT] Tactic: 0 Time: 9.49042
[05/21/2022-03:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 4.76224
[05/21/2022-03:02:41] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:41] [V] [TRT] Tactic: 1002 Time: 5.46637
[05/21/2022-03:02:41] [V] [TRT] Tactic: 0 Time: 18.1802
[05/21/2022-03:02:41] [V] [TRT] Fastest Tactic: 1002 Time: 5.46637
[05/21/2022-03:02:41] [V] [TRT] *************** Autotuning Reformat: Float(173056,43264:32,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:41] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:41] [V] [TRT] Tactic: 1002 Time: 7.08131
[05/21/2022-03:02:42] [V] [TRT] Tactic: 0 Time: 19.4568
[05/21/2022-03:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 7.08131
[05/21/2022-03:02:42] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:42] [V] [TRT] Tactic: 1002 Time: 7.00958
[05/21/2022-03:02:42] [V] [TRT] Tactic: 0 Time: 4.82161
[05/21/2022-03:02:42] [V] [TRT] Fastest Tactic: 0 Time: 4.82161
[05/21/2022-03:02:42] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:42] [V] [TRT] Tactic: 1002 Time: 5.05215
[05/21/2022-03:02:42] [V] [TRT] Tactic: 0 Time: 9.38373
[05/21/2022-03:02:42] [V] [TRT] Fastest Tactic: 1002 Time: 5.05215
[05/21/2022-03:02:42] [V] [TRT] *************** Autotuning Reformat: Half(5537792,43264,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:42] [V] [TRT] Tactic: 1002 Time: 5.27521
[05/21/2022-03:02:42] [V] [TRT] Tactic: 0 Time: 4.44146
[05/21/2022-03:02:42] [V] [TRT] Fastest Tactic: 0 Time: 4.44146
[05/21/2022-03:02:42] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:02:42] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:43] [V] [TRT] Tactic: 1002 Time: 6.58425
[05/21/2022-03:02:43] [V] [TRT] Tactic: 0 Time: 3.90342
[05/21/2022-03:02:43] [V] [TRT] Fastest Tactic: 0 Time: 3.90342
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:43] [V] [TRT] Tactic: 1002 Time: 5.11271
[05/21/2022-03:02:43] [V] [TRT] Tactic: 0 Time: 9.63203
[05/21/2022-03:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 5.11271
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264:2,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(010_route -> <out>) (Reformat)
[05/21/2022-03:02:43] [V] [TRT] Tactic: 1002 Time: 10.2263
[05/21/2022-03:02:43] [V] [TRT] Tactic: 0 Time: 3.78806
[05/21/2022-03:02:43] [V] [TRT] Fastest Tactic: 0 Time: 3.78806
[05/21/2022-03:02:43] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(2768896,1,13312,64) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(86528,43264:32,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(2768896,43264,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:02:43] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:43] [V] [TRT] Tactic: 1002 Time: 1.4655
[05/21/2022-03:02:43] [V] [TRT] Tactic: 0 Time: 2.64566
[05/21/2022-03:02:43] [V] [TRT] Fastest Tactic: 1002 Time: 1.4655
[05/21/2022-03:02:43] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:43] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:43] [V] [TRT] Tactic: 1002 Time: 1.46579
[05/21/2022-03:02:44] [V] [TRT] Tactic: 0 Time: 4.38038
[05/21/2022-03:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 1.46579
[05/21/2022-03:02:44] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:44] [V] [TRT] Tactic: 1002 Time: 1.8175
[05/21/2022-03:02:44] [V] [TRT] Tactic: 0 Time: 1.41062
[05/21/2022-03:02:44] [V] [TRT] Fastest Tactic: 0 Time: 1.41062
[05/21/2022-03:02:44] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:44] [V] [TRT] Tactic: 1002 Time: 2.07011
[05/21/2022-03:02:44] [V] [TRT] Tactic: 0 Time: 1.12923
[05/21/2022-03:02:44] [V] [TRT] Fastest Tactic: 0 Time: 1.12923
[05/21/2022-03:02:44] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:44] [V] [TRT] Tactic: 1002 Time: 1.65161
[05/21/2022-03:02:44] [V] [TRT] Tactic: 0 Time: 4.97901
[05/21/2022-03:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 1.65161
[05/21/2022-03:02:44] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:44] [V] [TRT] Tactic: 1002 Time: 1.1881
[05/21/2022-03:02:44] [V] [TRT] Tactic: 0 Time: 8.99214
[05/21/2022-03:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 1.1881
[05/21/2022-03:02:44] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:44] [V] [TRT] Tactic: 1002 Time: 1.31954
[05/21/2022-03:02:44] [V] [TRT] Tactic: 0 Time: 4.9558
[05/21/2022-03:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 1.31954
[05/21/2022-03:02:44] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:44] [V] [TRT] Tactic: 1002 Time: 1.78857
[05/21/2022-03:02:44] [V] [TRT] Tactic: 0 Time: 5.28905
[05/21/2022-03:02:44] [V] [TRT] Fastest Tactic: 1002 Time: 1.78857
[05/21/2022-03:02:44] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:44] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:44] [V] [TRT] Tactic: 1002 Time: 1.65692
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 4.78951
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 1.65692
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.20215
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 2.38018
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 1.20215
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.37635
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 4.53656
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 1.37635
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.77783
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 4.86475
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 1.77783
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.82715
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 1.20462
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 0 Time: 1.20462
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.27301
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 2.27745
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 1.27301
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.28023
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 4.33199
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 1.28023
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.29637
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 1.11739
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 0 Time: 1.11739
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.65695
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 0.976126
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 0 Time: 0.976126
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.2882
[05/21/2022-03:02:45] [V] [TRT] Tactic: 0 Time: 2.41701
[05/21/2022-03:02:45] [V] [TRT] Fastest Tactic: 1002 Time: 1.2882
[05/21/2022-03:02:45] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:45] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:45] [V] [TRT] Tactic: 1002 Time: 1.28915
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 4.3326
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 1.28915
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(012_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 2.59245
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 0.952324
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 0 Time: 0.952324
[05/21/2022-03:02:46] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 1.46675
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 2.6166
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 1.46675
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 1.46199
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 4.38199
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 1.46199
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 1.80438
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 1.41094
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 0 Time: 1.41094
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 2.06945
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 1.12868
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 0 Time: 1.12868
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 1.64111
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 4.9807
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 1.64111
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 1.17773
[05/21/2022-03:02:46] [V] [TRT] Tactic: 0 Time: 8.93726
[05/21/2022-03:02:46] [V] [TRT] Fastest Tactic: 1002 Time: 1.17773
[05/21/2022-03:02:46] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:46] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:46] [V] [TRT] Tactic: 1002 Time: 1.31111
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 4.98419
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.31111
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.77677
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 5.19973
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.77677
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.8457
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 1.20415
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 0 Time: 1.20415
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.27205
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 2.26738
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.27205
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.27216
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 4.35252
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.27216
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.28882
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 1.11784
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 0 Time: 1.11784
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.65538
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 0.974922
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.974922
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.2882
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 2.41535
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.2882
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 1.28868
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 4.32373
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 1002 Time: 1.28868
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 2.54702
[05/21/2022-03:02:47] [V] [TRT] Tactic: 0 Time: 0.952233
[05/21/2022-03:02:47] [V] [TRT] Fastest Tactic: 0 Time: 0.952233
[05/21/2022-03:02:47] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:47] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:47] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:47] [V] [TRT] Tactic: 1002 Time: 0.737285
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 1.29583
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.737285
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.736712
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 2.18399
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.736712
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 1.0737
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 0.955332
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.955332
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 1.0399
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 1.14218
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 1.0399
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.830059
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 2.49997
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.830059
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.598659
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 4.43682
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.598659
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.660313
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 2.48172
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.660313
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.900872
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 2.61165
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.900872
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.834915
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 2.31452
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.834915
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.599981
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 1.19577
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.599981
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.69461
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 2.26619
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.69461
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.891908
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 2.43639
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 1002 Time: 0.891908
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 1.08284
[05/21/2022-03:02:48] [V] [TRT] Tactic: 0 Time: 0.961361
[05/21/2022-03:02:48] [V] [TRT] Fastest Tactic: 0 Time: 0.961361
[05/21/2022-03:02:48] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:48] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:48] [V] [TRT] Tactic: 1002 Time: 0.643334
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 1.08424
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.643334
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.643464
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 2.17468
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.643464
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.653418
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 1.01921
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.653418
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.835625
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 0.492819
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.492819
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.651074
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 1.21389
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.651074
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.650912
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 2.16329
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.650912
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(013_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 1.38324
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 0.481725
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.481725
[05/21/2022-03:02:49] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.741693
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 1.29074
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.741693
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.737311
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 2.19384
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.737311
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 1.07517
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 0.95554
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.95554
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 1.0398
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 0.568991
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 0 Time: 0.568991
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.827265
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 2.34757
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.827265
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.59345
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 4.63372
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.59345
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.662559
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 2.2979
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.662559
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.890827
[05/21/2022-03:02:49] [V] [TRT] Tactic: 0 Time: 2.50462
[05/21/2022-03:02:49] [V] [TRT] Fastest Tactic: 1002 Time: 0.890827
[05/21/2022-03:02:49] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:49] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:49] [V] [TRT] Tactic: 1002 Time: 0.829499
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 2.31874
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.829499
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.604024
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 1.19565
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.604024
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.694785
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 2.26506
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.694785
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.890495
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 2.44221
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.890495
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 1.08226
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 0.96125
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 0 Time: 0.96125
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.643223
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 1.07926
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.643223
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.642728
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 2.16923
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.642728
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.654583
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 0.563809
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 0 Time: 0.563809
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.835976
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 1.1266
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.835976
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.650768
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 1.21337
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.650768
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.650664
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 2.16786
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.650664
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 013_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 1.3812
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 1.01824
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 0 Time: 1.01824
[05/21/2022-03:02:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.736126
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 1.29413
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.736126
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.736185
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 2.18873
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 1002 Time: 0.736185
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.906933
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 0.711777
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 0 Time: 0.711777
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 1.04049
[05/21/2022-03:02:50] [V] [TRT] Tactic: 0 Time: 0.569701
[05/21/2022-03:02:50] [V] [TRT] Fastest Tactic: 0 Time: 0.569701
[05/21/2022-03:02:50] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:50] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:50] [V] [TRT] Tactic: 1002 Time: 0.825911
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.34889
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.825911
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.592604
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 4.63106
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.592604
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.660931
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.30471
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.660931
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.891042
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.46449
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.891042
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.824713
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.31906
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.824713
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.600443
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 1.19532
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.600443
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.695163
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.26361
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.695163
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.892265
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.42998
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.892265
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.91582
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 0.606712
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 0 Time: 0.606712
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.642917
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 1.06402
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.642917
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.643412
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.16902
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.643412
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.656159
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 0.564356
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 0 Time: 0.564356
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.83623
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 0.491992
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 0 Time: 0.491992
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.650358
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 1.21363
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.650358
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:51] [V] [TRT] Tactic: 1002 Time: 0.651387
[05/21/2022-03:02:51] [V] [TRT] Tactic: 0 Time: 2.15828
[05/21/2022-03:02:51] [V] [TRT] Fastest Tactic: 1002 Time: 0.651387
[05/21/2022-03:02:51] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:51] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 015_convolutional_mish) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 1.39356
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 0.481315
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 0 Time: 0.481315
[05/21/2022-03:02:52] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.735794
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 1.30055
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.735794
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.908385
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 0.711537
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 0 Time: 0.711537
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 1.04014
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 0.56974
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 0 Time: 0.56974
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.826999
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 2.34626
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.826999
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.661621
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 2.29544
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.661621
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.889759
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 2.46387
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.889759
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.84
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 2.31376
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.84
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.600944
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 1.19579
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.600944
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.694935
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 2.26197
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.694935
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.890241
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 2.43998
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.890241
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.91655
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 0.607363
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 0 Time: 0.607363
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.642858
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 1.08083
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.642858
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.654036
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 0.564596
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 0 Time: 0.564596
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.838138
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 0.492539
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 0 Time: 0.492539
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:52] [V] [TRT] Tactic: 1002 Time: 0.650202
[05/21/2022-03:02:52] [V] [TRT] Tactic: 0 Time: 1.21372
[05/21/2022-03:02:52] [V] [TRT] Fastest Tactic: 1002 Time: 0.650202
[05/21/2022-03:02:52] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:52] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(015_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 1.39314
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 0.481367
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 0 Time: 0.481367
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.737285
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 2.19322
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.737285
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.590476
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 4.6407
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.590476
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.643802
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 2.16934
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.643802
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(016_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.650241
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 2.15757
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.650241
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,6656,64) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,10816:32,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(1384448,1,13312,128) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(43264,10816:32,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(1384448,10816,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:02:53] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.759616
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 1.31099
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.759616
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.759967
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 2.21465
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.759967
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.98778
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 0.711231
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 0 Time: 0.711231
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 1.03423
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 0.569108
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 0 Time: 0.569108
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.843001
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 2.60594
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.843001
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.613737
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 4.66546
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.613737
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.666172
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 2.51531
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.666172
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:53] [V] [TRT] Tactic: 1002 Time: 0.8725
[05/21/2022-03:02:53] [V] [TRT] Tactic: 0 Time: 2.69973
[05/21/2022-03:02:53] [V] [TRT] Fastest Tactic: 1002 Time: 0.8725
[05/21/2022-03:02:53] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:53] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.831999
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 2.30011
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.831999
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.615547
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 1.19505
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.615547
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.698919
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 2.25956
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.698919
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.876523
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 2.41574
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.876523
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.998437
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 0.606562
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 0 Time: 0.606562
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.647116
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 1.07266
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.647116
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.647891
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 2.22413
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.647891
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.668652
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 0.563587
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 0 Time: 0.563587
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.818613
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 0.493861
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 0 Time: 0.493861
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.653483
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 1.21296
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.653483
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.653425
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 2.16266
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.653425
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(025_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 1.25758
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 0.480781
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 0 Time: 0.480781
[05/21/2022-03:02:54] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.759049
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 1.30988
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.759049
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.75692
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 2.20905
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 1002 Time: 0.75692
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.988274
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 0.711732
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 0 Time: 0.711732
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 1.03376
[05/21/2022-03:02:54] [V] [TRT] Tactic: 0 Time: 0.569499
[05/21/2022-03:02:54] [V] [TRT] Fastest Tactic: 0 Time: 0.569499
[05/21/2022-03:02:54] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:54] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:54] [V] [TRT] Tactic: 1002 Time: 0.844876
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 2.60037
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.844876
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.612389
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 4.65771
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.612389
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.665911
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 2.51178
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.665911
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.871465
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 2.68985
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.871465
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.996816
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 0.606895
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 0 Time: 0.606895
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.647682
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 1.06345
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.647682
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.647116
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 2.17095
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.647116
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.669831
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 0.563828
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 0 Time: 0.563828
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.819798
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 0.494831
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 0 Time: 0.494831
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.654466
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 1.21372
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.654466
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.654115
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 2.16427
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.654115
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 1.25794
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 0.481842
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 0 Time: 0.481842
[05/21/2022-03:02:55] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.384662
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 0.653027
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.384662
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.384381
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 1.10658
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.384381
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.590983
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 0.483197
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 0 Time: 0.483197
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.52388
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 0.576641
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.52388
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.434317
[05/21/2022-03:02:55] [V] [TRT] Tactic: 0 Time: 1.3313
[05/21/2022-03:02:55] [V] [TRT] Fastest Tactic: 1002 Time: 0.434317
[05/21/2022-03:02:55] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:55] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:55] [V] [TRT] Tactic: 1002 Time: 0.312435
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 2.3336
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.312435
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.338437
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.25698
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.338437
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.440384
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.3478
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.440384
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.425762
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.15621
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.425762
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.31043
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.602819
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.31043
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.3553
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.13391
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.3553
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.43946
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.21348
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.43946
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.59502
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.486042
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 0 Time: 0.486042
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.32974
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.531458
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.32974
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.329694
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.09991
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.329694
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.337246
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.51528
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.337246
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.416797
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.251322
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 0 Time: 0.251322
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.332839
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.612096
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.332839
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.332429
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.09505
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.332429
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(026_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.638053
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.245638
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 0 Time: 0.245638
[05/21/2022-03:02:56] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.383275
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.637077
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.383275
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.384668
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.12657
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.384668
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.590234
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.482663
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 0 Time: 0.482663
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.52332
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.290742
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 0 Time: 0.290742
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.430619
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.25095
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.430619
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.308574
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 2.2396
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.308574
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.337689
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.23566
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.337689
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.440644
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.30171
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.440644
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.427376
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 1.15952
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.427376
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.313516
[05/21/2022-03:02:56] [V] [TRT] Tactic: 0 Time: 0.603034
[05/21/2022-03:02:56] [V] [TRT] Fastest Tactic: 1002 Time: 0.313516
[05/21/2022-03:02:56] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:56] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:56] [V] [TRT] Tactic: 1002 Time: 0.355996
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.13992
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.355996
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.439525
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.22217
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.439525
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.59515
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.48541
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.48541
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.329219
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.529538
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.329219
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.329512
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.09212
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.329512
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.341621
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.286543
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.286543
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.417129
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.567923
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.417129
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.332604
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.611361
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.332604
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.332187
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.11986
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.332187
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 026_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.635944
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.513952
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.513952
[05/21/2022-03:02:57] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.383893
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.643737
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.383893
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.386016
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.12996
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.386016
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.498932
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.361777
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.361777
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.522897
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.289173
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.289173
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.430716
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.24057
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.430716
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.308379
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 2.21018
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.308379
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.338151
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.23477
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.338151
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.438574
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.29728
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.438574
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.426699
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.15718
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.426699
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.308711
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.60222
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.308711
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.354713
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.14615
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.354713
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.438568
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.21224
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.438568
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.504076
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.307728
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.307728
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.329082
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.529811
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.329082
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.329277
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 1.09266
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 1002 Time: 0.329277
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.340248
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.287071
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.287071
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.416608
[05/21/2022-03:02:57] [V] [TRT] Tactic: 0 Time: 0.25084
[05/21/2022-03:02:57] [V] [TRT] Fastest Tactic: 0 Time: 0.25084
[05/21/2022-03:02:57] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:57] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:57] [V] [TRT] Tactic: 1002 Time: 0.332174
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.611647
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.332174
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.332253
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.08591
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.332253
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 028_convolutional_mish) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.632702
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.245169
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 0 Time: 0.245169
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.381485
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.635586
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.381485
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.499024
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.361563
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 0 Time: 0.361563
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.523431
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.28946
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 0 Time: 0.28946
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.432904
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.24339
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.432904
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.337695
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.22983
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.337695
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.439245
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.29799
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.439245
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.426627
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.15299
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.426627
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.309987
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.602728
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.309987
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.355338
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.13228
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.355338
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.439662
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.21115
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.439662
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.506087
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.307858
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 0 Time: 0.307858
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.329779
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.530176
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.329779
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.340234
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.286725
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 0 Time: 0.286725
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.416992
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.251022
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 0 Time: 0.251022
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.331973
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.611946
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.331973
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(028_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.643867
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 0.245006
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 0 Time: 0.245006
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.382389
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.10719
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.382389
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.308847
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 2.20209
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.308847
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.329844
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.0875
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.329844
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(029_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.332591
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 1.08395
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.332591
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.828561
[05/21/2022-03:02:58] [V] [TRT] Tactic: 0 Time: 2.30317
[05/21/2022-03:02:58] [V] [TRT] Fastest Tactic: 1002 Time: 0.828561
[05/21/2022-03:02:58] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:58] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-03:02:58] [V] [TRT] Tactic: 1002 Time: 0.613236
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 1.19503
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.613236
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.69791
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 2.25869
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.69791
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 055_convolutional_mish) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.877545
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 2.40671
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.877545
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:02:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.391908
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.547715
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.391908
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.39377
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.799505
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.39377
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.660085
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.361549
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.361549
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.536927
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.289394
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.289394
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.508711
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.542637
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.508711
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.320267
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 1.18061
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.320267
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.355521
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.546426
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.355521
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.449473
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.616745
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.449473
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.493223
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.593353
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.493223
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.326335
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.603281
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.326335
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.370423
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.602187
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.370423
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.450892
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.683444
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.450892
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.665755
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.306888
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.306888
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.342565
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.525873
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.342565
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.342702
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.802982
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.342702
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.373509
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.286263
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.286263
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.503503
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.250827
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.250827
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.345957
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.611882
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.345957
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.345892
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.80709
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.345892
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(056_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.740788
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.244863
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.244863
[05/21/2022-03:02:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.392656
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.554935
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.392656
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.394434
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.7997
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.394434
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.659551
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.36179
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.36179
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.537096
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.289518
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 0 Time: 0.289518
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.500254
[05/21/2022-03:02:59] [V] [TRT] Tactic: 0 Time: 0.543268
[05/21/2022-03:02:59] [V] [TRT] Fastest Tactic: 1002 Time: 0.500254
[05/21/2022-03:02:59] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:02:59] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:02:59] [V] [TRT] Tactic: 1002 Time: 0.319818
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 1.18152
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.319818
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.355814
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.545807
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.355814
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.45082
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.615846
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.45082
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.665644
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.307858
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.307858
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.342057
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.525534
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.342057
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.342474
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.80582
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.342474
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.374603
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.287129
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.287129
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.502852
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.251055
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.251055
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.34541
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.611354
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.34541
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.345358
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.808281
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.345358
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.739544
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.245085
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.245085
[05/21/2022-03:03:00] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.196797
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.28054
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.196797
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.198164
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.404427
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.198164
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.395951
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.246576
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.246576
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.274166
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.293574
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.274166
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.259473
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.276855
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.259473
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.16349
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.596628
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.16349
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.183828
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.278828
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.183828
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.230645
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.313105
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.230645
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.256302
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.303321
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.256302
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.166139
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.306699
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.166139
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.191055
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.305853
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.191055
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.230371
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.34707
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.230371
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.398919
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.247604
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.247604
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.176758
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.268327
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.176758
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.176387
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.407304
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.176387
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.194251
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.262429
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.194251
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.259381
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.128659
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.128659
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.177669
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.311074
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.177669
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.177838
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.40929
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.177838
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(057_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.377897
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.126556
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.126556
[05/21/2022-03:03:00] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.196068
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.278477
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.196068
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.198041
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.405378
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.198041
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.395423
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.246322
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.246322
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.273092
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.149101
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 0 Time: 0.149101
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.258939
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.276947
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.258939
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.165918
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.563757
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.165918
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.18373
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.278555
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.18373
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.230312
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.311823
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.230312
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.263496
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.302363
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.263496
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.168164
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.30612
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.168164
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:00] [V] [TRT] Tactic: 1002 Time: 0.191374
[05/21/2022-03:03:00] [V] [TRT] Tactic: 0 Time: 0.305937
[05/21/2022-03:03:00] [V] [TRT] Fastest Tactic: 1002 Time: 0.191374
[05/21/2022-03:03:00] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:00] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.232246
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.34722
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.232246
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.398848
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.248815
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.248815
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.176139
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.268424
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.176139
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.176296
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.406875
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.176296
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.19459
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.1475
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.1475
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.259466
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.289375
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.259466
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.177793
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.310873
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.177793
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.177448
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.409772
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.177448
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 057_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.37683
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.262142
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.262142
[05/21/2022-03:03:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.197787
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.284251
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.197787
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.19752
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.403776
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.19752
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.334668
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.186165
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.186165
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.272683
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.148913
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.148913
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.255814
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.276641
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.255814
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.165065
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.565104
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.165065
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.183607
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.277044
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.183607
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.230469
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.314154
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.230469
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.256432
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.302904
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.256432
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.166855
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.306478
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.166855
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.190834
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.3072
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.190834
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.230612
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.346855
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.230612
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.338672
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.157943
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.157943
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.176602
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.267949
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.176602
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.176628
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.408835
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.176628
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.192721
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.147415
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.147415
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.259082
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.129154
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.129154
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.17776
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.31071
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.17776
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.177754
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.408789
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.177754
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 059_convolutional_mish) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.376523
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.126419
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.126419
[05/21/2022-03:03:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.198021
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.277526
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.198021
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.334824
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.185873
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.185873
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.272285
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.149023
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.149023
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.25347
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.277031
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.25347
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.183555
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.277663
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.183555
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.230352
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.312891
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.230352
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.256256
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.301803
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.256256
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.167415
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.305879
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.167415
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.191361
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.306159
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.191361
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.230286
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.347441
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.230286
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.338991
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.157546
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.157546
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.17627
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.267461
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.17627
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.19416
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.147103
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.147103
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.258952
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.129193
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.129193
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.177832
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.310443
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.177832
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(059_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.375892
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.126295
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 0 Time: 0.126295
[05/21/2022-03:03:01] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.197441
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.404655
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.197441
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.164968
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.563359
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.164968
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.176999
[05/21/2022-03:03:01] [V] [TRT] Tactic: 0 Time: 0.409271
[05/21/2022-03:03:01] [V] [TRT] Fastest Tactic: 1002 Time: 0.176999
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:01] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:01] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(060_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:01] [V] [TRT] Tactic: 1002 Time: 0.178268
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.408815
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.178268
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.497233
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.594707
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.497233
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.325287
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.603222
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.325287
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.369779
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.602246
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.369779
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 086_convolutional_mish) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.451777
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.683763
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.451777
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.215221
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.263763
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.215221
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.215853
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.395795
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.215853
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 5.44911
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.185847
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.185847
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.296289
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.149329
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.149329
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.260163
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.253099
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.253099
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.1811
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.533848
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.1811
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.200768
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.250189
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.200768
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.260631
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.293737
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.260631
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.264486
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.285931
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.264486
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.181146
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.306374
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.181146
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.208483
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.288998
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.208483
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.257734
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.337018
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.257734
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 5.65735
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.157708
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.157708
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.194492
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.267604
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.194492
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.194687
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.398476
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.194687
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.241283
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.147135
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.147135
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.267891
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.129401
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.129401
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.195794
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.31071
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.195794
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.196061
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.400462
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.196061
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(087_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.385853
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.126556
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.126556
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.21528
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.263542
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.21528
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.214967
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.395866
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 1002 Time: 0.214967
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 5.44995
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.185833
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.185833
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.295606
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.14914
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.14914
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:02] [V] [TRT] Tactic: 1002 Time: 0.258262
[05/21/2022-03:03:02] [V] [TRT] Tactic: 0 Time: 0.25239
[05/21/2022-03:03:02] [V] [TRT] Fastest Tactic: 0 Time: 0.25239
[05/21/2022-03:03:02] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:02] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.181204
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.533978
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.181204
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.201107
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.250078
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.201107
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.260736
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.294076
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.260736
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 5.65747
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.157318
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.157318
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.194714
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.267767
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.194714
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.194765
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.39808
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.194765
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.241107
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.147285
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.147285
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.267741
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.129382
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.129382
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.195397
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.311185
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.195397
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.19612
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.400208
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.19612
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.384707
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.126341
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.126341
[05/21/2022-03:03:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.11071
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.136771
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.11071
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.111074
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.202891
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.111074
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 3.18516
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.127136
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.127136
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.152461
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.150977
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.150977
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.135592
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.129421
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.129421
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.0939777
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.271211
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.0939777
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.105742
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.129238
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.105742
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.134186
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.151842
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.134186
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.135508
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.147819
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.135508
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.0939972
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.15776
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.0939972
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.109251
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.149284
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.109251
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.133574
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.172969
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.133574
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 3.29376
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.127741
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.127741
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.101745
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.138288
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.101745
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.102096
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.203971
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.102096
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.124857
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.1353
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.124857
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.140423
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.0678974
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0678974
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.102201
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.160306
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.102201
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.102012
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.205488
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.102012
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(088_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.198125
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.0662239
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0662239
[05/21/2022-03:03:03] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.111966
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.136673
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.111966
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.110371
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.203131
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.110371
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 3.18529
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.126999
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.126999
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.152663
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.0777344
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.0777344
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.138919
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.128945
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 0 Time: 0.128945
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.092689
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.269935
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.092689
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.10556
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.128743
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.10556
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.13403
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.151094
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.13403
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.14028
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.148294
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.14028
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.094362
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.157728
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.094362
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.109329
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.148366
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.109329
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:03] [V] [TRT] Tactic: 1002 Time: 0.133223
[05/21/2022-03:03:03] [V] [TRT] Tactic: 0 Time: 0.173047
[05/21/2022-03:03:03] [V] [TRT] Fastest Tactic: 1002 Time: 0.133223
[05/21/2022-03:03:03] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:03] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 3.29344
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.127865
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.127865
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.101758
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.13834
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.101758
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.102207
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.204375
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.102207
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.12595
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0770054
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0770054
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.140449
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.148867
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.140449
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.102351
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.159935
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.102351
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.101868
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.205312
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.101868
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 088_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.199141
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.134961
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.134961
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.110501
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.1361
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.110501
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.110794
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.203099
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.110794
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 2.72965
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0978385
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0978385
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.152279
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0779297
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0779297
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.140267
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.129622
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.129622
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.0936459
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.268809
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.0936459
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.105866
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.128353
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.105866
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.133991
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.151224
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.133991
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.13946
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.147793
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.13946
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.0942644
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.157825
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.0942644
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.108991
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.148392
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.108991
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.133939
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.173333
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.133939
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 2.83447
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0819139
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0819139
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.101979
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.138405
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.101979
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.101829
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.204095
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.101829
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.125039
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0770963
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0770963
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.140254
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0677018
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0677018
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.102025
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.160319
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.102025
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.101907
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.206133
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.101907
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 090_convolutional_mish) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.198535
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0666016
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0666016
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.111498
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.136471
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.111498
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 2.72997
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0980535
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0980535
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.152233
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0776042
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0776042
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.139427
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.129421
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.129421
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.105729
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.128828
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.105729
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.134342
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.150996
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.134342
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.138932
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.147331
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.138932
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.0941211
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.157884
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.0941211
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.109115
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.148366
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.109115
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.133327
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.172851
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.133327
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 2.83505
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0820964
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0820964
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.102025
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.13875
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.102025
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.125547
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.07694
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.07694
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.139876
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.067741
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.067741
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.102435
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.160221
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.102435
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(090_convolutional_mish -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.197481
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.0660807
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 0 Time: 0.0660807
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.110527
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.202904
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.110527
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.0941341
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.26834
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.0941341
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.101732
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.204095
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.101732
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(091_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:04] [V] [TRT] Tactic: 1002 Time: 0.102136
[05/21/2022-03:03:04] [V] [TRT] Tactic: 0 Time: 0.205632
[05/21/2022-03:03:04] [V] [TRT] Fastest Tactic: 1002 Time: 0.102136
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:04] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:04] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 6.19546
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0479689
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0479689
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.110697
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.136732
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.110697
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 3.18367
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.127337
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.127337
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.151979
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.077728
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.077728
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 3.29333
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.127656
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.127656
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.102057
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.138757
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.102057
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 3.24136
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0259637
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0259637
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.124649
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0763931
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0763931
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.140365
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.14873
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.140365
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.102057
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.160436
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.102057
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.198985
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.135371
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.135371
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 113_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.150879
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0257683
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0257683
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 6.19568
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0481187
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0481187
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.111055
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.136615
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.111055
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 3.18471
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.127428
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.127428
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.152422
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0777605
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0777605
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 3.29482
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.128151
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.128151
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.102044
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.138477
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.102044
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 3.24199
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0259896
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0259896
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.124765
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0770833
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0770833
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.140814
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.149036
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.140814
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.102311
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.160072
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 1002 Time: 0.102311
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.198717
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.134941
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.134941
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 111_maxpool copy (Reformat)
[05/21/2022-03:03:05] [V] [TRT] Tactic: 1002 Time: 0.15138
[05/21/2022-03:03:05] [V] [TRT] Tactic: 0 Time: 0.0261525
[05/21/2022-03:03:05] [V] [TRT] Fastest Tactic: 0 Time: 0.0261525
[05/21/2022-03:03:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:05] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:05] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:05] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 6.19351
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0478971
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0478971
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.111484
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.136302
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.111484
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 3.18438
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.126927
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.126927
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.151576
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.077975
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.077975
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 3.29373
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.12804
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.12804
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.102168
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.138614
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.102168
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 3.2412
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0257356
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0257356
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.12625
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0769533
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0769533
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.140775
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.148959
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.140775
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.101921
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.159837
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.101921
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.198223
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.134928
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.134928
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 109_maxpool copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.150899
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0255924
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0255924
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 6.19676
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0476822
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0476822
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.111406
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.136816
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.111406
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 3.185
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.127031
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.127031
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.152272
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0778321
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0778321
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.141204
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.12821
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.12821
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.116029
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.13558
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.116029
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.105814
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.12899
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.105814
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.133516
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.151452
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.133516
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.137728
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.147194
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.137728
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.0947464
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.157474
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.0947464
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.109505
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.149277
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.109505
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.133164
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.173242
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.133164
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 3.29371
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.128268
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.128268
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.102018
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.138965
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.102018
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 3.24144
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0257682
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0257682
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.126022
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0763803
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0763803
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.140241
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.148822
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.140241
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.101992
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.16015
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 1002 Time: 0.101992
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.197741
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.134733
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.134733
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: 108_convolutional_lrelu copy (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.151133
[05/21/2022-03:03:06] [V] [TRT] Tactic: 0 Time: 0.0260937
[05/21/2022-03:03:06] [V] [TRT] Fastest Tactic: 0 Time: 0.0260937
[05/21/2022-03:03:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:06] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:06] [V] [TRT] *************** Autotuning Reformat: Float(346112,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:06] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:06] [V] [TRT] Tactic: 1002 Time: 0.422487
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.973405
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.422487
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(346112,169,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 10.8865
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.361647
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.361647
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(346112,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.581602
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.28959
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.28959
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,26624,2048) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.510417
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.524603
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.510417
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,26624,2048) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.389473
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.501445
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.389473
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,26624,2048) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.510527
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.579297
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.510527
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(346112,169,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 11.3066
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.30791
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.30791
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(346112,169,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.379206
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.899147
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.379206
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(346112,169,13,1) -> Half(173056,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.461029
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.286445
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.286445
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169:2,13,1) -> Float(346112,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.520592
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.250729
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.250729
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169:2,13,1) -> Float(346112,1,26624,2048) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.381732
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.611888
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.381732
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169:2,13,1) -> Half(346112,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(114_route -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.756589
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.245508
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.245508
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,169,13,1) -> Float(43264,1,3328,256) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.056504
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.071803
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.056504
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,169,13,1) -> Float(1352,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0567383
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.105469
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.0567383
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,169,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 1.37031
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0495117
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.0495117
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,169,13,1) -> Half(21632,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0790887
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0407617
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.0407617
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,1,3328,256) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0763669
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0676366
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.0676366
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,1,3328,256) -> Float(1352,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.049987
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.134622
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.049987
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,1,3328,256) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.056517
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0667382
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.056517
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(43264,1,3328,256) -> Half(21632,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0702411
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0789386
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.0702411
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(1352,169:32,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.077168
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0774676
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.077168
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(1352,169:32,13,1) -> Float(43264,1,3328,256) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0508136
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0821811
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.0508136
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(1352,169:32,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0588931
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0776564
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.0588931
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Float(1352,169:32,13,1) -> Half(21632,169:2,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0699934
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.090124
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.0699934
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 1.42339
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0424937
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 0 Time: 0.0424937
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169,13,1) -> Float(43264,1,3328,256) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0539845
[05/21/2022-03:03:07] [V] [TRT] Tactic: 0 Time: 0.0722983
[05/21/2022-03:03:07] [V] [TRT] Fastest Tactic: 1002 Time: 0.0539845
[05/21/2022-03:03:07] [V] [TRT] *************** Autotuning Reformat: Half(43264,169,13,1) -> Float(1352,169:32,13,1) ***************
[05/21/2022-03:03:07] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:07] [V] [TRT] Tactic: 1002 Time: 0.0540234
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.10489
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0540234
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,169,13,1) -> Half(21632,169:2,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0635484
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0401171
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0401171
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(21632,169:2,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0750455
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0358461
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0358461
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(21632,169:2,13,1) -> Float(43264,1,3328,256) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0536654
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0833661
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0536654
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(21632,169:2,13,1) -> Float(1352,169:32,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0541863
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.106361
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0541863
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(21632,169:2,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(118_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.101627
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.034147
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.034147
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(43264,169,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(43264,1,3328,256) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(43264,1,3328,256) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(1352,169:32,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(1352,169:32,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,169,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(21632,169:2,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(21632,169:2,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.303197
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0917771
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0917771
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.197012
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.279499
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.197012
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.198646
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.404297
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.198646
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.396003
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.246061
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.246061
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.273796
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.149232
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.149232
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.39946
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.247819
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.247819
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.176634
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.267799
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.176634
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.176816
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.40778
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.176816
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.274563
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0480664
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0480664
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 119_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.194518
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.147773
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.147773
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,676,26,1) -> Float(86528,1,3328,128) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.10485
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.137513
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.10485
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,676,26,1) -> Float(2704,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.104798
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.208333
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.104798
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,676,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.172422
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0977344
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0977344
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,676,26,1) -> Half(43264,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.14237
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0774675
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0774675
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,3328,128) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.135189
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.142637
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.135189
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,3328,128) -> Float(2704,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0889714
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.29138
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0889714
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,3328,128) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0978842
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.14377
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0978842
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,3328,128) -> Half(43264,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.120501
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.160924
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.120501
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(2704,676:32,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.136634
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.156992
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.136634
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(2704,676:32,26,1) -> Float(86528,1,3328,128) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0906836
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.157598
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0906836
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(2704,676:32,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.10097
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.157962
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.10097
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(2704,676:32,26,1) -> Half(43264,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.120189
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.178424
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.120189
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.174778
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0815366
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0815366
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676,26,1) -> Float(86528,1,3328,128) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0921356
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.139069
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0921356
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676,26,1) -> Float(2704,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0928581
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.20916
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0928581
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676,26,1) -> Half(43264,676:2,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.106107
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0772397
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0772397
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,676:2,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.136361
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.067103
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.067103
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,676:2,26,1) -> Float(86528,1,3328,128) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.0925065
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.160215
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.0925065
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,676:2,26,1) -> Float(2704,676:32,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.092344
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.211022
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.092344
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,676:2,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(128_convolutional_bn -> <out>) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.194896
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0663154
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0663154
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,676,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,3328,128) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,3328,128) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(2704,676:32,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(2704,676:32,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(86528,676,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,676:2,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(43264,676:2,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.545338
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.168626
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.168626
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.383678
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.645397
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.383678
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.383815
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 1.12242
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.383815
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.58974
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.48265
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.48265
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.523431
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.290123
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.290123
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.595514
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.486562
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.486562
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.329994
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.538262
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.329994
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.329713
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 1.11041
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 1002 Time: 0.329713
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 1002
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.406894
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.0921028
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.0921028
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: 129_upsample copy (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.342826
[05/21/2022-03:03:08] [V] [TRT] Tactic: 0 Time: 0.286569
[05/21/2022-03:03:08] [V] [TRT] Fastest Tactic: 0 Time: 0.286569
[05/21/2022-03:03:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Reformat Tactic: 0
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(692224,1,13312,256) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(21632,2704:32,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(692224,2704,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:08] [V] [TRT] *************** Autotuning Reformat: Float(689520,1,13260,255) -> Float(689520,2704,52,1) ***************
[05/21/2022-03:03:08] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 139_convolutional) (Reformat)
[05/21/2022-03:03:08] [V] [TRT] Tactic: 1002 Time: 0.939948
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 2.59556
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 1002 Time: 0.939948
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(689520,2704,52,1) -> Float(689520,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 139_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 0.993216
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.604792
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.604792
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704:2,52,1) -> Float(689520,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 139_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 0.815866
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.491895
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.491895
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,6656,128) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,2704:32,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,2704,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(346112,1,13312,512) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(10816,676:32,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(346112,676,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(172380,1,6630,255) -> Float(172380,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 150_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 0.281139
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.251126
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.251126
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(172380,676,26,1) -> Float(172380,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 150_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 0.337337
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.156999
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.156999
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(172380,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 150_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 0.257695
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.128822
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.128822
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,6656,256) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,676:32,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,676,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(86528,1,6656,512) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(2704,169:32,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(173056,1,13312,1024) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(5408,169:32,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(173056,169,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] =============== Computing reformatting costs
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Float(43095,1,3315,255) -> Float(43095,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 161_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 0.0810219
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.0664126
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.0664126
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(43095,169,13,1) -> Float(43095,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 161_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 1.41715
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.0420702
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.0420702
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning Reformat: Half(21632,169:2,13,1) -> Float(43095,169,13,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: Optimizer Reformat(<in> -> 161_convolutional) (Reformat)
[05/21/2022-03:03:09] [V] [TRT] Tactic: 1002 Time: 0.0750456
[05/21/2022-03:03:09] [V] [TRT] Tactic: 0 Time: 0.0350781
[05/21/2022-03:03:09] [V] [TRT] Fastest Tactic: 0 Time: 0.0350781
[05/21/2022-03:03:09] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:03:09] [V] [TRT] *************** Autotuning format combination: Float(519168,173056,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:03:09] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:03:09] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:03:09] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-03:03:13] [V] [TRT] Tactic: 0 Time: 9.51493
[05/21/2022-03:03:13] [V] [TRT] Tactic: 1 Time: 7.1132
[05/21/2022-03:03:13] [V] [TRT] Tactic: 2 Time: 18.4513
[05/21/2022-03:03:15] [V] [TRT] Tactic: 5 Time: 130.042
[05/21/2022-03:03:16] [V] [TRT] Tactic: 6 Time: 9.73268
[05/21/2022-03:03:16] [V] [TRT] Fastest Tactic: 1 Time: 7.1132
[05/21/2022-03:03:16] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-03:03:16] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:03:16] [V] [TRT] Tactic: 1062367460111450758 Time: 4.66628
[05/21/2022-03:03:16] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:03:16] [V] [TRT] Tactic: 1754984623894446479 Time: 4.48438
[05/21/2022-03:03:16] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:03:16] [V] [TRT] Tactic: 3611739942397549984 Time: 15.2568
[05/21/2022-03:03:16] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:03:16] [V] [TRT] Tactic: 3827454225649558724 Time: 11.1244
[05/21/2022-03:03:16] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:03:16] [V] [TRT] Tactic: 4337000649858996379 Time: 7.21191
[05/21/2022-03:03:16] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:03:17] [V] [TRT] Tactic: 4501471010995462441 Time: 13.9283
[05/21/2022-03:03:17] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:03:17] [V] [TRT] Tactic: 5137655947464784826 Time: 6.73486
[05/21/2022-03:03:17] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:03:17] [V] [TRT] Tactic: 5288347012147084929 Time: 14.6789
[05/21/2022-03:03:17] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:03:17] [V] [TRT] Tactic: 5921334924264294896 Time: 7.39732
[05/21/2022-03:03:17] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:03:17] [V] [TRT] Tactic: 6645123197870846056 Time: 6.92839
[05/21/2022-03:03:17] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:03:18] [V] [TRT] Tactic: 7144526460361122478 Time: 4.33807
[05/21/2022-03:03:18] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:03:18] [V] [TRT] Tactic: 7852627285308570038 Time: 11.3383
[05/21/2022-03:03:18] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:03:18] [V] [TRT] Tactic: -9137461792520977713 Time: 14.0887
[05/21/2022-03:03:18] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:03:18] [V] [TRT] Tactic: -8776506421218919509 Time: 10.8432
[05/21/2022-03:03:18] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:03:19] [V] [TRT] Tactic: -8262349710178828730 Time: 14.9663
[05/21/2022-03:03:19] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:03:19] [V] [TRT] Tactic: -8133971918129952780 Time: 7.022
[05/21/2022-03:03:19] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:03:19] [V] [TRT] Tactic: -6092040395344634144 Time: 4.77399
[05/21/2022-03:03:19] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:03:19] [V] [TRT] Tactic: -4787320710726427159 Time: 4.47438
[05/21/2022-03:03:19] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:03:19] [V] [TRT] Tactic: -3456450830548107839 Time: 4.36488
[05/21/2022-03:03:19] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:03:19] [V] [TRT] Tactic: -2318106587342035239 Time: 10.8404
[05/21/2022-03:03:19] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:03:19] [V] [TRT] Tactic: -1343271414618805657 Time: 7.16938
[05/21/2022-03:03:19] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:03:20] [V] [TRT] Tactic: -1218658103698133241 Time: 7.34205
[05/21/2022-03:03:20] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:03:20] [V] [TRT] Tactic: -836875257600482091 Time: 6.86855
[05/21/2022-03:03:20] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:03:20] [V] [TRT] Tactic: -410470605513481746 Time: 13.7612
[05/21/2022-03:03:20] [V] [TRT] Fastest Tactic: 7144526460361122478 Time: 4.33807
[05/21/2022-03:03:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 7144526460361122478
[05/21/2022-03:03:20] [V] [TRT] *************** Autotuning format combination: Float(519168,1,1248,3) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:03:20] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-03:03:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:03:20] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-03:03:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:03:20] [V] [TRT] *************** Autotuning format combination: Half(519168,173056,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:03:20] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-03:03:20] [V] [TRT] Tactic: 0 Time: 8.27926
[05/21/2022-03:03:20] [V] [TRT] Tactic: 1 Time: 8.84046
[05/21/2022-03:03:21] [V] [TRT] Tactic: 2 Time: 18.8217
[05/21/2022-03:03:23] [V] [TRT] Tactic: 5 Time: 128.693
[05/21/2022-03:03:23] [V] [TRT] Tactic: 6 Time: 12.5939
[05/21/2022-03:03:23] [V] [TRT] Fastest Tactic: 0 Time: 8.27926
[05/21/2022-03:03:23] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-03:03:23] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:03:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 0
[05/21/2022-03:03:23] [V] [TRT] *************** Autotuning format combination: Half(346112,173056:2,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:03:23] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:03:23] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:03:23] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CudnnConvolution)
[05/21/2022-03:03:23] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:03:23] [V] [TRT] --------------- Timing Runner: 001_convolutional + 001_convolutional_bn (CaskConvolution)
[05/21/2022-03:03:23] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:03:23] [V] [TRT] Tactic: 3564772625446233998 Time: 3.44223
[05/21/2022-03:03:23] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:03:23] [V] [TRT] Tactic: 3650389455493082349 Time: 3.52372
[05/21/2022-03:03:23] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:03:23] [V] [TRT] Tactic: 4772821744921268633 Time: 6.04449
[05/21/2022-03:03:23] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:03:23] [V] [TRT] Tactic: 5319956359050645452 Time: 3.25152
[05/21/2022-03:03:23] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:03:23] [V] [TRT] Tactic: 7205456024582378848 Time: 5.11831
[05/21/2022-03:03:23] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:03:24] [V] [TRT] Tactic: -6490690591794140522 Time: 5.20693
[05/21/2022-03:03:24] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:03:24] [V] [TRT] Tactic: -4686027666808657977 Time: 10.2762
[05/21/2022-03:03:24] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:03:24] [V] [TRT] Tactic: -4212163711445252890 Time: 9.93867
[05/21/2022-03:03:24] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:03:24] [V] [TRT] Tactic: -3898373634979201110 Time: 10.1806
[05/21/2022-03:03:24] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:03:24] [V] [TRT] Tactic: -2409163523992614473 Time: 4.97322
[05/21/2022-03:03:24] [V] [TRT] Fastest Tactic: 5319956359050645452 Time: 3.25152
[05/21/2022-03:03:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5319956359050645452
[05/21/2022-03:03:24] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:03:24] [V] [TRT] *************** Autotuning format combination: Float(5537792,173056,416,1) -> Float(5537792,173056,416,1) ***************
[05/21/2022-03:03:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-03:03:25] [V] [TRT] Tactic: 0 Time: 8.17501
[05/21/2022-03:03:27] [V] [TRT] Tactic: 1 Time: 5.8041
[05/21/2022-03:03:27] [V] [TRT] Tactic: 2 Time: 4.16945
[05/21/2022-03:03:29] [V] [TRT] Tactic: 3 Time: 8.04143
[05/21/2022-03:03:30] [V] [TRT] Tactic: 4 Time: 4.94588
[05/21/2022-03:03:31] [V] [TRT] Tactic: 5 Time: 5.71202
[05/21/2022-03:03:32] [V] [TRT] Tactic: 6 Time: 8.03435
[05/21/2022-03:03:33] [V] [TRT] Tactic: 7 Time: 4.15627
[05/21/2022-03:03:34] [V] [TRT] Tactic: 8 Time: 3.26587
[05/21/2022-03:03:35] [V] [TRT] Tactic: 9 Time: 3.75653
[05/21/2022-03:03:36] [V] [TRT] Tactic: 28 Time: 7.08585
[05/21/2022-03:03:36] [V] [TRT] Fastest Tactic: 8 Time: 3.26587
[05/21/2022-03:03:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-03:03:36] [V] [TRT] Tactic: 128 Time: 22.2018
[05/21/2022-03:03:37] [V] [TRT] Tactic: 256 Time: 22.285
[05/21/2022-03:03:37] [V] [TRT] Tactic: 512 Time: 22.2875
[05/21/2022-03:03:38] [V] [TRT] Tactic: -32 Time: 22.9474
[05/21/2022-03:03:38] [V] [TRT] Tactic: -64 Time: 22.8995
[05/21/2022-03:03:39] [V] [TRT] Tactic: -128 Time: 23.0567
[05/21/2022-03:03:39] [V] [TRT] Fastest Tactic: 128 Time: 22.2018
[05/21/2022-03:03:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:03:39] [V] [TRT] *************** Autotuning format combination: Float(5537792,1,13312,32) -> Float(5537792,1,13312,32) ***************
[05/21/2022-03:03:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-03:03:39] [V] [TRT] Tactic: 0 Time: 5.97637
[05/21/2022-03:03:39] [V] [TRT] Tactic: 1 Time: 4.41062
[05/21/2022-03:03:39] [V] [TRT] Tactic: 2 Time: 4.18902
[05/21/2022-03:03:39] [V] [TRT] Tactic: 3 Time: 3.65964
[05/21/2022-03:03:39] [V] [TRT] Tactic: 4 Time: 3.11577
[05/21/2022-03:03:39] [V] [TRT] Tactic: 5 Time: 3.21836
[05/21/2022-03:03:39] [V] [TRT] Tactic: 6 Time: 3.36475
[05/21/2022-03:03:39] [V] [TRT] Tactic: 7 Time: 2.6868
[05/21/2022-03:03:39] [V] [TRT] Tactic: 8 Time: 2.55152
[05/21/2022-03:03:40] [V] [TRT] Tactic: 9 Time: 2.73228
[05/21/2022-03:03:40] [V] [TRT] Tactic: 28 Time: 5.87611
[05/21/2022-03:03:40] [V] [TRT] Fastest Tactic: 8 Time: 2.55152
[05/21/2022-03:03:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-03:03:40] [V] [TRT] Tactic: 128 Time: 22.2456
[05/21/2022-03:03:41] [V] [TRT] Tactic: 256 Time: 22.2588
[05/21/2022-03:03:41] [V] [TRT] Tactic: 512 Time: 22.3595
[05/21/2022-03:03:41] [V] [TRT] Tactic: -32 Time: 22.8732
[05/21/2022-03:03:42] [V] [TRT] Tactic: -64 Time: 22.9008
[05/21/2022-03:03:42] [V] [TRT] Tactic: -128 Time: 23.0596
[05/21/2022-03:03:42] [V] [TRT] Fastest Tactic: 128 Time: 22.2456
[05/21/2022-03:03:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:03:42] [V] [TRT] *************** Autotuning format combination: Float(173056,173056:32,416,1) -> Float(173056,173056:32,416,1) ***************
[05/21/2022-03:03:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-03:03:43] [V] [TRT] Tactic: 24 Time: 4.92674
[05/21/2022-03:03:44] [V] [TRT] Tactic: 25 Time: 4.89143
[05/21/2022-03:03:45] [V] [TRT] Tactic: 26 Time: 4.83708
[05/21/2022-03:03:47] [V] [TRT] Tactic: 27 Time: 5.68335
[05/21/2022-03:03:48] [V] [TRT] Tactic: 31 Time: 4.9386
[05/21/2022-03:03:48] [V] [TRT] Fastest Tactic: 26 Time: 4.83708
[05/21/2022-03:03:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-03:03:48] [V] [TRT] Tactic: 128 Time: 22.3865
[05/21/2022-03:03:48] [V] [TRT] Tactic: 256 Time: 22.2385
[05/21/2022-03:03:49] [V] [TRT] Tactic: 512 Time: 22.2866
[05/21/2022-03:03:49] [V] [TRT] Tactic: -32 Time: 22.8665
[05/21/2022-03:03:50] [V] [TRT] Tactic: -64 Time: 22.932
[05/21/2022-03:03:50] [V] [TRT] Tactic: -128 Time: 23.0852
[05/21/2022-03:03:50] [V] [TRT] Fastest Tactic: 256 Time: 22.2385
[05/21/2022-03:03:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:03:50] [V] [TRT] *************** Autotuning format combination: Half(5537792,173056,416,1) -> Half(5537792,173056,416,1) ***************
[05/21/2022-03:03:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-03:03:51] [V] [TRT] Tactic: 0 Time: 6.09007
[05/21/2022-03:03:52] [V] [TRT] Tactic: 1 Time: 6.13064
[05/21/2022-03:03:53] [V] [TRT] Tactic: 2 Time: 7.15742
[05/21/2022-03:03:54] [V] [TRT] Tactic: 3 Time: 4.82303
[05/21/2022-03:03:55] [V] [TRT] Tactic: 4 Time: 9.57389
[05/21/2022-03:03:57] [V] [TRT] Tactic: 5 Time: 5.86234
[05/21/2022-03:03:57] [V] [TRT] Tactic: 6 Time: 3.92333
[05/21/2022-03:03:59] [V] [TRT] Tactic: 7 Time: 5.59355
[05/21/2022-03:04:00] [V] [TRT] Tactic: 8 Time: 4.94602
[05/21/2022-03:04:01] [V] [TRT] Tactic: 9 Time: 4.50734
[05/21/2022-03:04:02] [V] [TRT] Tactic: 28 Time: 7.32176
[05/21/2022-03:04:02] [V] [TRT] Fastest Tactic: 6 Time: 3.92333
[05/21/2022-03:04:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-03:04:02] [V] [TRT] Tactic: 128 Time: 22.8444
[05/21/2022-03:04:03] [V] [TRT] Tactic: 256 Time: 22.554
[05/21/2022-03:04:03] [V] [TRT] Tactic: 512 Time: 21.2209
[05/21/2022-03:04:03] [V] [TRT] Tactic: -32 Time: 22.8988
[05/21/2022-03:04:04] [V] [TRT] Tactic: -64 Time: 22.7946
[05/21/2022-03:04:04] [V] [TRT] Tactic: -128 Time: 22.9378
[05/21/2022-03:04:04] [V] [TRT] Fastest Tactic: 512 Time: 21.2209
[05/21/2022-03:04:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 6
[05/21/2022-03:04:04] [V] [TRT] *************** Autotuning format combination: Half(2768896,173056:2,416,1) -> Half(2768896,173056:2,416,1) ***************
[05/21/2022-03:04:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWiseV2)
[05/21/2022-03:04:05] [V] [TRT] Tactic: 0 Time: 4.65857
[05/21/2022-03:04:06] [V] [TRT] Tactic: 1 Time: 5.78811
[05/21/2022-03:04:07] [V] [TRT] Tactic: 2 Time: 5.32842
[05/21/2022-03:04:08] [V] [TRT] Tactic: 3 Time: 4.99714
[05/21/2022-03:04:09] [V] [TRT] Tactic: 4 Time: 5.17237
[05/21/2022-03:04:11] [V] [TRT] Tactic: 5 Time: 5.09241
[05/21/2022-03:04:12] [V] [TRT] Tactic: 6 Time: 7.89028
[05/21/2022-03:04:13] [V] [TRT] Tactic: 7 Time: 4.33997
[05/21/2022-03:04:14] [V] [TRT] Tactic: 8 Time: 4.96097
[05/21/2022-03:04:15] [V] [TRT] Tactic: 9 Time: 4.74576
[05/21/2022-03:04:16] [V] [TRT] Tactic: 10 Time: 6.73785
[05/21/2022-03:04:17] [V] [TRT] Tactic: 11 Time: 6.381
[05/21/2022-03:04:18] [V] [TRT] Tactic: 12 Time: 6.01564
[05/21/2022-03:04:19] [V] [TRT] Tactic: 13 Time: 5.60298
[05/21/2022-03:04:20] [V] [TRT] Tactic: 14 Time: 3.44435
[05/21/2022-03:04:21] [V] [TRT] Tactic: 15 Time: 3.55216
[05/21/2022-03:04:22] [V] [TRT] Tactic: 16 Time: 3.27775
[05/21/2022-03:04:23] [V] [TRT] Tactic: 17 Time: 4.56164
[05/21/2022-03:04:24] [V] [TRT] Tactic: 18 Time: 5.14217
[05/21/2022-03:04:25] [V] [TRT] Tactic: 19 Time: 5.63389
[05/21/2022-03:04:26] [V] [TRT] Tactic: 28 Time: 5.84846
[05/21/2022-03:04:27] [V] [TRT] Tactic: 29 Time: 8.46583
[05/21/2022-03:04:27] [V] [TRT] Fastest Tactic: 16 Time: 3.27775
[05/21/2022-03:04:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) (PointWise)
[05/21/2022-03:04:28] [V] [TRT] Tactic: 128 Time: 22.8705
[05/21/2022-03:04:28] [V] [TRT] Tactic: 256 Time: 22.5688
[05/21/2022-03:04:29] [V] [TRT] Tactic: 512 Time: 21.2102
[05/21/2022-03:04:29] [V] [TRT] Tactic: -32 Time: 22.9225
[05/21/2022-03:04:29] [V] [TRT] Tactic: -64 Time: 22.8252
[05/21/2022-03:04:30] [V] [TRT] Tactic: -128 Time: 22.9092
[05/21/2022-03:04:30] [V] [TRT] Fastest Tactic: 512 Time: 21.2102
[05/21/2022-03:04:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 16
[05/21/2022-03:04:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:04:30] [V] [TRT] *************** Autotuning format combination: Float(5537792,173056,416,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:04:30] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:04:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:04:30] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:04:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:04:30] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-03:04:30] [V] [TRT] Tactic: 0 Time: 34.4129
[05/21/2022-03:04:31] [V] [TRT] Tactic: 1 Time: 14.8663
[05/21/2022-03:04:31] [V] [TRT] Tactic: 2 Time: 34.9339
[05/21/2022-03:04:37] [V] [TRT] Tactic: 5 Time: 362.568
[05/21/2022-03:04:37] [V] [TRT] Fastest Tactic: 1 Time: 14.8663
[05/21/2022-03:04:37] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-03:04:37] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:04:37] [V] [TRT] Tactic: 1062367460111450758 Time: 11.1812
[05/21/2022-03:04:38] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:04:38] [V] [TRT] Tactic: 1754984623894446479 Time: 12.4025
[05/21/2022-03:04:38] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:04:38] [V] [TRT] Tactic: 3611739942397549984 Time: 17.7677
[05/21/2022-03:04:38] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:04:38] [V] [TRT] Tactic: 4337000649858996379 Time: 8.91543
[05/21/2022-03:04:38] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:04:39] [V] [TRT] Tactic: 4501471010995462441 Time: 17.7062
[05/21/2022-03:04:39] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:04:39] [V] [TRT] Tactic: 5137655947464784826 Time: 8.61607
[05/21/2022-03:04:39] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:04:39] [V] [TRT] Tactic: 5288347012147084929 Time: 17.4933
[05/21/2022-03:04:39] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:04:39] [V] [TRT] Tactic: 6645123197870846056 Time: 8.90981
[05/21/2022-03:04:39] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:04:39] [V] [TRT] Tactic: 7144526460361122478 Time: 11.8562
[05/21/2022-03:04:39] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:04:40] [V] [TRT] Tactic: -9137461792520977713 Time: 17.9354
[05/21/2022-03:04:40] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:04:40] [V] [TRT] Tactic: -8262349710178828730 Time: 17.7641
[05/21/2022-03:04:40] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:04:40] [V] [TRT] Tactic: -8133971918129952780 Time: 9.87742
[05/21/2022-03:04:40] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:04:41] [V] [TRT] Tactic: -6092040395344634144 Time: 11.6169
[05/21/2022-03:04:41] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:04:41] [V] [TRT] Tactic: -4787320710726427159 Time: 12.3244
[05/21/2022-03:04:41] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:04:41] [V] [TRT] Tactic: -3456450830548107839 Time: 10.3921
[05/21/2022-03:04:41] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:04:41] [V] [TRT] Tactic: -1218658103698133241 Time: 9.78253
[05/21/2022-03:04:41] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:04:41] [V] [TRT] Tactic: -836875257600482091 Time: 9.6747
[05/21/2022-03:04:41] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:04:42] [V] [TRT] Tactic: -410470605513481746 Time: 17.1842
[05/21/2022-03:04:42] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 8.61607
[05/21/2022-03:04:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-03:04:42] [V] [TRT] *************** Autotuning format combination: Float(5537792,1,13312,32) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:04:42] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-03:04:42] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:04:42] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-03:04:42] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:04:42] [V] [TRT] Tactic: -9153228964338181824 Time: 15.7169
[05/21/2022-03:04:42] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:04:42] [V] [TRT] Tactic: -7394439838318485025 Time: 8.97921
[05/21/2022-03:04:42] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 8.97921
[05/21/2022-03:04:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:04:42] [V] [TRT] *************** Autotuning format combination: Half(5537792,173056,416,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:04:42] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-03:04:43] [V] [TRT] Tactic: 0 Time: 35.3575
[05/21/2022-03:04:43] [V] [TRT] Tactic: 1 Time: 16.9194
[05/21/2022-03:04:44] [V] [TRT] Tactic: 2 Time: 33.9524
[05/21/2022-03:04:50] [V] [TRT] Tactic: 5 Time: 355.751
[05/21/2022-03:04:50] [V] [TRT] Fastest Tactic: 1 Time: 16.9194
[05/21/2022-03:04:50] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-03:04:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:04:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:04:50] [V] [TRT] *************** Autotuning format combination: Half(2768896,173056:2,416,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:04:50] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:04:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:04:50] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CudnnConvolution)
[05/21/2022-03:04:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:04:50] [V] [TRT] --------------- Timing Runner: 002_convolutional + 002_convolutional_bn (CaskConvolution)
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:04:50] [V] [TRT] Tactic: 3564772625446233998 Time: 5.82639
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:04:50] [V] [TRT] Tactic: 3650389455493082349 Time: 6.04753
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:04:50] [V] [TRT] Tactic: 5319956359050645452 Time: 5.42553
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:04:50] [V] [TRT] Tactic: 7205456024582378848 Time: 4.57967
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:04:50] [V] [TRT] Tactic: -6490690591794140522 Time: 4.62885
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:04:50] [V] [TRT] Tactic: -4686027666808657977 Time: 9.1957
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:04:50] [V] [TRT] Tactic: -4212163711445252890 Time: 8.87471
[05/21/2022-03:04:50] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:04:51] [V] [TRT] Tactic: -3898373634979201110 Time: 9.10765
[05/21/2022-03:04:51] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:04:51] [V] [TRT] Tactic: -2409163523992614473 Time: 4.47798
[05/21/2022-03:04:51] [V] [TRT] Fastest Tactic: -2409163523992614473 Time: 4.47798
[05/21/2022-03:04:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -2409163523992614473
[05/21/2022-03:04:51] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:04:51] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:04:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-03:04:51] [V] [TRT] Tactic: 0 Time: 2.99085
[05/21/2022-03:04:51] [V] [TRT] Tactic: 1 Time: 2.21212
[05/21/2022-03:04:51] [V] [TRT] Tactic: 2 Time: 2.09378
[05/21/2022-03:04:51] [V] [TRT] Tactic: 3 Time: 1.88515
[05/21/2022-03:04:51] [V] [TRT] Tactic: 4 Time: 1.56351
[05/21/2022-03:04:51] [V] [TRT] Tactic: 5 Time: 1.61401
[05/21/2022-03:04:51] [V] [TRT] Tactic: 6 Time: 1.696
[05/21/2022-03:04:51] [V] [TRT] Tactic: 7 Time: 1.3484
[05/21/2022-03:04:51] [V] [TRT] Tactic: 8 Time: 1.27803
[05/21/2022-03:04:51] [V] [TRT] Tactic: 9 Time: 1.3715
[05/21/2022-03:04:51] [V] [TRT] Tactic: 28 Time: 2.94451
[05/21/2022-03:04:51] [V] [TRT] Fastest Tactic: 8 Time: 1.27803
[05/21/2022-03:04:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-03:04:52] [V] [TRT] Tactic: 128 Time: 11.1037
[05/21/2022-03:04:52] [V] [TRT] Tactic: 256 Time: 11.1306
[05/21/2022-03:04:52] [V] [TRT] Tactic: 512 Time: 11.1485
[05/21/2022-03:04:52] [V] [TRT] Tactic: -32 Time: 11.4495
[05/21/2022-03:04:52] [V] [TRT] Tactic: -64 Time: 11.463
[05/21/2022-03:04:53] [V] [TRT] Tactic: -128 Time: 11.5484
[05/21/2022-03:04:53] [V] [TRT] Fastest Tactic: 128 Time: 11.1037
[05/21/2022-03:04:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:04:53] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:04:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-03:04:53] [V] [TRT] Tactic: 0 Time: 2.99135
[05/21/2022-03:04:53] [V] [TRT] Tactic: 1 Time: 2.20625
[05/21/2022-03:04:53] [V] [TRT] Tactic: 2 Time: 2.08945
[05/21/2022-03:04:53] [V] [TRT] Tactic: 3 Time: 1.83205
[05/21/2022-03:04:53] [V] [TRT] Tactic: 4 Time: 1.56233
[05/21/2022-03:04:53] [V] [TRT] Tactic: 5 Time: 1.6134
[05/21/2022-03:04:53] [V] [TRT] Tactic: 6 Time: 1.66924
[05/21/2022-03:04:53] [V] [TRT] Tactic: 7 Time: 1.3479
[05/21/2022-03:04:53] [V] [TRT] Tactic: 8 Time: 1.27799
[05/21/2022-03:04:53] [V] [TRT] Tactic: 9 Time: 1.37145
[05/21/2022-03:04:53] [V] [TRT] Tactic: 28 Time: 2.9406
[05/21/2022-03:04:53] [V] [TRT] Fastest Tactic: 8 Time: 1.27799
[05/21/2022-03:04:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-03:04:54] [V] [TRT] Tactic: 128 Time: 11.1039
[05/21/2022-03:04:54] [V] [TRT] Tactic: 256 Time: 11.1391
[05/21/2022-03:04:54] [V] [TRT] Tactic: 512 Time: 11.1449
[05/21/2022-03:04:54] [V] [TRT] Tactic: -32 Time: 11.4902
[05/21/2022-03:04:54] [V] [TRT] Tactic: -64 Time: 11.4645
[05/21/2022-03:04:55] [V] [TRT] Tactic: -128 Time: 11.5355
[05/21/2022-03:04:55] [V] [TRT] Fastest Tactic: 128 Time: 11.1039
[05/21/2022-03:04:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:04:55] [V] [TRT] *************** Autotuning format combination: Float(86528,43264:32,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:04:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-03:04:55] [V] [TRT] Tactic: 24 Time: 2.05415
[05/21/2022-03:04:55] [V] [TRT] Tactic: 25 Time: 1.8738
[05/21/2022-03:04:55] [V] [TRT] Tactic: 26 Time: 1.8479
[05/21/2022-03:04:55] [V] [TRT] Tactic: 27 Time: 1.77056
[05/21/2022-03:04:55] [V] [TRT] Tactic: 31 Time: 2.05252
[05/21/2022-03:04:55] [V] [TRT] Fastest Tactic: 27 Time: 1.77056
[05/21/2022-03:04:55] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-03:04:55] [V] [TRT] Tactic: 128 Time: 11.1194
[05/21/2022-03:04:55] [V] [TRT] Tactic: 256 Time: 11.1258
[05/21/2022-03:04:56] [V] [TRT] Tactic: 512 Time: 11.158
[05/21/2022-03:04:56] [V] [TRT] Tactic: -32 Time: 11.485
[05/21/2022-03:04:56] [V] [TRT] Tactic: -64 Time: 11.5289
[05/21/2022-03:04:56] [V] [TRT] Tactic: -128 Time: 11.5337
[05/21/2022-03:04:56] [V] [TRT] Fastest Tactic: 128 Time: 11.1194
[05/21/2022-03:04:56] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:04:56] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:04:56] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-03:04:56] [V] [TRT] Tactic: 0 Time: 3.04998
[05/21/2022-03:04:56] [V] [TRT] Tactic: 1 Time: 2.30334
[05/21/2022-03:04:56] [V] [TRT] Tactic: 2 Time: 2.14576
[05/21/2022-03:04:56] [V] [TRT] Tactic: 3 Time: 1.82631
[05/21/2022-03:04:57] [V] [TRT] Tactic: 4 Time: 1.66108
[05/21/2022-03:04:57] [V] [TRT] Tactic: 5 Time: 1.70074
[05/21/2022-03:04:57] [V] [TRT] Tactic: 6 Time: 1.62359
[05/21/2022-03:04:57] [V] [TRT] Tactic: 7 Time: 1.40999
[05/21/2022-03:04:57] [V] [TRT] Tactic: 8 Time: 1.41493
[05/21/2022-03:04:57] [V] [TRT] Tactic: 9 Time: 1.46234
[05/21/2022-03:04:57] [V] [TRT] Tactic: 28 Time: 3.05943
[05/21/2022-03:04:57] [V] [TRT] Fastest Tactic: 7 Time: 1.40999
[05/21/2022-03:04:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-03:04:57] [V] [TRT] Tactic: 128 Time: 11.4202
[05/21/2022-03:04:57] [V] [TRT] Tactic: 256 Time: 11.2642
[05/21/2022-03:04:57] [V] [TRT] Tactic: 512 Time: 10.5592
[05/21/2022-03:04:58] [V] [TRT] Tactic: -32 Time: 11.463
[05/21/2022-03:04:58] [V] [TRT] Tactic: -64 Time: 11.4096
[05/21/2022-03:04:58] [V] [TRT] Tactic: -128 Time: 11.5527
[05/21/2022-03:04:58] [V] [TRT] Fastest Tactic: 512 Time: 10.5592
[05/21/2022-03:04:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:04:58] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:04:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWiseV2)
[05/21/2022-03:04:58] [V] [TRT] Tactic: 0 Time: 2.33255
[05/21/2022-03:04:58] [V] [TRT] Tactic: 1 Time: 1.88344
[05/21/2022-03:04:58] [V] [TRT] Tactic: 2 Time: 1.89195
[05/21/2022-03:04:58] [V] [TRT] Tactic: 3 Time: 1.72436
[05/21/2022-03:04:58] [V] [TRT] Tactic: 4 Time: 1.67497
[05/21/2022-03:04:58] [V] [TRT] Tactic: 5 Time: 1.70329
[05/21/2022-03:04:58] [V] [TRT] Tactic: 6 Time: 1.63841
[05/21/2022-03:04:58] [V] [TRT] Tactic: 7 Time: 1.59733
[05/21/2022-03:04:58] [V] [TRT] Tactic: 8 Time: 1.55792
[05/21/2022-03:04:59] [V] [TRT] Tactic: 9 Time: 1.65614
[05/21/2022-03:04:59] [V] [TRT] Tactic: 10 Time: 3.21364
[05/21/2022-03:04:59] [V] [TRT] Tactic: 11 Time: 2.38161
[05/21/2022-03:04:59] [V] [TRT] Tactic: 12 Time: 2.2622
[05/21/2022-03:04:59] [V] [TRT] Tactic: 13 Time: 1.8651
[05/21/2022-03:04:59] [V] [TRT] Tactic: 14 Time: 1.72736
[05/21/2022-03:04:59] [V] [TRT] Tactic: 15 Time: 1.77473
[05/21/2022-03:04:59] [V] [TRT] Tactic: 16 Time: 1.64212
[05/21/2022-03:04:59] [V] [TRT] Tactic: 17 Time: 1.44243
[05/21/2022-03:04:59] [V] [TRT] Tactic: 18 Time: 1.43699
[05/21/2022-03:04:59] [V] [TRT] Tactic: 19 Time: 1.55622
[05/21/2022-03:04:59] [V] [TRT] Tactic: 28 Time: 2.29296
[05/21/2022-03:04:59] [V] [TRT] Tactic: 29 Time: 3.15848
[05/21/2022-03:04:59] [V] [TRT] Fastest Tactic: 18 Time: 1.43699
[05/21/2022-03:04:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) (PointWise)
[05/21/2022-03:04:59] [V] [TRT] Tactic: 128 Time: 11.4183
[05/21/2022-03:05:00] [V] [TRT] Tactic: 256 Time: 11.2758
[05/21/2022-03:05:00] [V] [TRT] Tactic: 512 Time: 10.5723
[05/21/2022-03:05:00] [V] [TRT] Tactic: -32 Time: 11.5362
[05/21/2022-03:05:00] [V] [TRT] Tactic: -64 Time: 11.5102
[05/21/2022-03:05:00] [V] [TRT] Tactic: -128 Time: 11.467
[05/21/2022-03:05:00] [V] [TRT] Fastest Tactic: 512 Time: 10.5723
[05/21/2022-03:05:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:05:00] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:05:00] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:05:00] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:05:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:00] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:05:00] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:00] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-03:05:01] [V] [TRT] Tactic: 0 Time: 11.7775
[05/21/2022-03:05:01] [V] [TRT] Tactic: 1 Time: 8.1343
[05/21/2022-03:05:01] [V] [TRT] Tactic: 2 Time: 12.4844
[05/21/2022-03:05:02] [V] [TRT] Tactic: 5 Time: 21.1068
[05/21/2022-03:05:02] [V] [TRT] Fastest Tactic: 1 Time: 8.1343
[05/21/2022-03:05:02] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-03:05:02] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:02] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:05:02] [V] [TRT] Tactic: 1062367460111450758 Time: 7.35013
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:05:02] [V] [TRT] Tactic: 1698681053543049347 Time: 6.60809
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:05:02] [V] [TRT] Tactic: 4501471010995462441 Time: 5.6784
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:05:02] [V] [TRT] Tactic: 5137655947464784826 Time: 5.31256
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:05:02] [V] [TRT] Tactic: 5288347012147084929 Time: 5.69221
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:05:02] [V] [TRT] Tactic: 5326823351883942011 Time: 5.39393
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:05:02] [V] [TRT] Tactic: 5500448035057547314 Time: 6.1938
[05/21/2022-03:05:02] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:05:03] [V] [TRT] Tactic: 6645123197870846056 Time: 5.36998
[05/21/2022-03:05:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:05:03] [V] [TRT] Tactic: 7144526460361122478 Time: 7.54079
[05/21/2022-03:05:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:05:03] [V] [TRT] Tactic: -8262349710178828730 Time: 5.80368
[05/21/2022-03:05:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:05:03] [V] [TRT] Tactic: -6576203419454146580 Time: 6.99949
[05/21/2022-03:05:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:05:03] [V] [TRT] Tactic: -4787320710726427159 Time: 7.7782
[05/21/2022-03:05:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:05:03] [V] [TRT] Tactic: -3456450830548107839 Time: 7.12863
[05/21/2022-03:05:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:05:03] [V] [TRT] Tactic: -1218658103698133241 Time: 6.44001
[05/21/2022-03:05:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:05:04] [V] [TRT] Tactic: -836875257600482091 Time: 6.00037
[05/21/2022-03:05:04] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:05:04] [V] [TRT] Tactic: -410470605513481746 Time: 5.52607
[05/21/2022-03:05:04] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:05:04] [V] [TRT] Tactic: -377491875521947884 Time: 5.70519
[05/21/2022-03:05:04] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:05:04] [V] [TRT] Tactic: -37215280111360163 Time: 5.27406
[05/21/2022-03:05:04] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 5.27406
[05/21/2022-03:05:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:05:04] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:05:04] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-03:05:04] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:04] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-03:05:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:04] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-03:05:04] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:05:04] [V] [TRT] Tactic: 3886731678879822788 Time: 6.40905
[05/21/2022-03:05:04] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:05:04] [V] [TRT] Tactic: 6629944304117643200 Time: 16.6195
[05/21/2022-03:05:04] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:05:05] [V] [TRT] Tactic: -9153228964338181824 Time: 16.8777
[05/21/2022-03:05:05] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:05:05] [V] [TRT] Tactic: -7394439838318485025 Time: 6.39788
[05/21/2022-03:05:05] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 6.39788
[05/21/2022-03:05:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:05:05] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:05:05] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-03:05:05] [V] [TRT] Tactic: 0 Time: 10.6927
[05/21/2022-03:05:05] [V] [TRT] Tactic: 1 Time: 7.86431
[05/21/2022-03:05:06] [V] [TRT] Tactic: 2 Time: 10.6245
[05/21/2022-03:05:06] [V] [TRT] Tactic: 5 Time: 20.3041
[05/21/2022-03:05:06] [V] [TRT] Fastest Tactic: 1 Time: 7.86431
[05/21/2022-03:05:06] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-03:05:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:06] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-03:05:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:05:06] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:05:06] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-03:05:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:06] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:05:06] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:05:06] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:06] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CudnnConvolution)
[05/21/2022-03:05:06] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:06] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CublasConvolution)
[05/21/2022-03:05:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:05:06] [V] [TRT] --------------- Timing Runner: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn (CaskConvolution)
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:05:06] [V] [TRT] Tactic: 3066127711859985668 Time: 3.91733
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:05:06] [V] [TRT] Tactic: 3564772625446233998 Time: 4.18681
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:05:06] [V] [TRT] Tactic: 5319956359050645452 Time: 3.99405
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:05:06] [V] [TRT] Tactic: 7205456024582378848 Time: 3.06452
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:05:06] [V] [TRT] Tactic: 8163473458334948789 Time: 2.97696
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:05:06] [V] [TRT] Tactic: -4212163711445252890 Time: 3.14173
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:05:06] [V] [TRT] Tactic: -3898373634979201110 Time: 3.1256
[05/21/2022-03:05:06] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:05:07] [V] [TRT] Tactic: -2409163523992614473 Time: 2.99843
[05/21/2022-03:05:07] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:05:07] [V] [TRT] Tactic: -1716393687483585322 Time: 3.03968
[05/21/2022-03:05:07] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 2.97696
[05/21/2022-03:05:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:05:07] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:05:07] [V] [TRT] *************** Autotuning format combination: Float(5537792,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:05:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-03:05:08] [V] [TRT] Tactic: 0 Time: 5.44208
[05/21/2022-03:05:09] [V] [TRT] Tactic: 1 Time: 4.27964
[05/21/2022-03:05:10] [V] [TRT] Tactic: 2 Time: 3.06417
[05/21/2022-03:05:11] [V] [TRT] Tactic: 3 Time: 4.5143
[05/21/2022-03:05:12] [V] [TRT] Tactic: 4 Time: 5.40613
[05/21/2022-03:05:13] [V] [TRT] Tactic: 5 Time: 5.51794
[05/21/2022-03:05:14] [V] [TRT] Tactic: 6 Time: 4.72138
[05/21/2022-03:05:15] [V] [TRT] Tactic: 7 Time: 3.40624
[05/21/2022-03:05:16] [V] [TRT] Tactic: 8 Time: 2.43895
[05/21/2022-03:05:17] [V] [TRT] Tactic: 9 Time: 5.23342
[05/21/2022-03:05:18] [V] [TRT] Tactic: 28 Time: 5.12032
[05/21/2022-03:05:18] [V] [TRT] Fastest Tactic: 8 Time: 2.43895
[05/21/2022-03:05:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-03:05:18] [V] [TRT] Tactic: 128 Time: 12.5905
[05/21/2022-03:05:19] [V] [TRT] Tactic: 256 Time: 12.5235
[05/21/2022-03:05:19] [V] [TRT] Tactic: 512 Time: 12.5398
[05/21/2022-03:05:19] [V] [TRT] Tactic: -32 Time: 11.4941
[05/21/2022-03:05:19] [V] [TRT] Tactic: -64 Time: 11.5414
[05/21/2022-03:05:19] [V] [TRT] Tactic: -128 Time: 11.7048
[05/21/2022-03:05:20] [V] [TRT] Fastest Tactic: -32 Time: 11.4941
[05/21/2022-03:05:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:05:20] [V] [TRT] *************** Autotuning format combination: Float(5537792,1,26624,128) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:05:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-03:05:20] [V] [TRT] Tactic: 0 Time: 3.80143
[05/21/2022-03:05:20] [V] [TRT] Tactic: 1 Time: 2.63771
[05/21/2022-03:05:20] [V] [TRT] Tactic: 2 Time: 2.49307
[05/21/2022-03:05:20] [V] [TRT] Tactic: 3 Time: 3.16294
[05/21/2022-03:05:20] [V] [TRT] Tactic: 4 Time: 2.93855
[05/21/2022-03:05:20] [V] [TRT] Tactic: 5 Time: 2.65848
[05/21/2022-03:05:20] [V] [TRT] Tactic: 6 Time: 4.33574
[05/21/2022-03:05:20] [V] [TRT] Tactic: 7 Time: 3.59994
[05/21/2022-03:05:20] [V] [TRT] Tactic: 8 Time: 3.51573
[05/21/2022-03:05:20] [V] [TRT] Tactic: 9 Time: 3.0804
[05/21/2022-03:05:21] [V] [TRT] Tactic: 28 Time: 3.7605
[05/21/2022-03:05:21] [V] [TRT] Fastest Tactic: 2 Time: 2.49307
[05/21/2022-03:05:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-03:05:21] [V] [TRT] Tactic: 128 Time: 12.5159
[05/21/2022-03:05:21] [V] [TRT] Tactic: 256 Time: 12.5211
[05/21/2022-03:05:21] [V] [TRT] Tactic: 512 Time: 12.539
[05/21/2022-03:05:22] [V] [TRT] Tactic: -32 Time: 12.6696
[05/21/2022-03:05:22] [V] [TRT] Tactic: -64 Time: 13.8377
[05/21/2022-03:05:22] [V] [TRT] Tactic: -128 Time: 13.8574
[05/21/2022-03:05:22] [V] [TRT] Fastest Tactic: 128 Time: 12.5159
[05/21/2022-03:05:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-03:05:22] [V] [TRT] *************** Autotuning format combination: Float(173056,43264:32,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:05:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-03:05:23] [V] [TRT] Tactic: 24 Time: 2.07549
[05/21/2022-03:05:24] [V] [TRT] Tactic: 25 Time: 3.39527
[05/21/2022-03:05:25] [V] [TRT] Tactic: 26 Time: 3.41729
[05/21/2022-03:05:26] [V] [TRT] Tactic: 27 Time: 2.98019
[05/21/2022-03:05:27] [V] [TRT] Tactic: 31 Time: 4.18158
[05/21/2022-03:05:27] [V] [TRT] Fastest Tactic: 24 Time: 2.07549
[05/21/2022-03:05:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-03:05:27] [V] [TRT] Tactic: 128 Time: 12.5512
[05/21/2022-03:05:28] [V] [TRT] Tactic: 256 Time: 12.521
[05/21/2022-03:05:28] [V] [TRT] Tactic: 512 Time: 12.5396
[05/21/2022-03:05:28] [V] [TRT] Tactic: -32 Time: 11.4922
[05/21/2022-03:05:28] [V] [TRT] Tactic: -64 Time: 11.5442
[05/21/2022-03:05:29] [V] [TRT] Tactic: -128 Time: 11.7612
[05/21/2022-03:05:29] [V] [TRT] Fastest Tactic: -32 Time: 11.4922
[05/21/2022-03:05:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 24
[05/21/2022-03:05:29] [V] [TRT] *************** Autotuning format combination: Half(5537792,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:05:29] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-03:05:30] [V] [TRT] Tactic: 0 Time: 5.59717
[05/21/2022-03:05:31] [V] [TRT] Tactic: 1 Time: 6.80911
[05/21/2022-03:05:32] [V] [TRT] Tactic: 2 Time: 6.2684
[05/21/2022-03:05:33] [V] [TRT] Tactic: 3 Time: 4.21249
[05/21/2022-03:05:34] [V] [TRT] Tactic: 4 Time: 2.85624
[05/21/2022-03:05:35] [V] [TRT] Tactic: 5 Time: 4.58477
[05/21/2022-03:05:36] [V] [TRT] Tactic: 6 Time: 4.93732
[05/21/2022-03:05:37] [V] [TRT] Tactic: 7 Time: 4.40513
[05/21/2022-03:05:38] [V] [TRT] Tactic: 8 Time: 3.90944
[05/21/2022-03:05:39] [V] [TRT] Tactic: 9 Time: 3.64116
[05/21/2022-03:05:40] [V] [TRT] Tactic: 28 Time: 5.66356
[05/21/2022-03:05:40] [V] [TRT] Fastest Tactic: 4 Time: 2.85624
[05/21/2022-03:05:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-03:05:40] [V] [TRT] Tactic: 128 Time: 12.1903
[05/21/2022-03:05:41] [V] [TRT] Tactic: 256 Time: 11.8266
[05/21/2022-03:05:41] [V] [TRT] Tactic: 512 Time: 11.1485
[05/21/2022-03:05:41] [V] [TRT] Tactic: -32 Time: 11.5654
[05/21/2022-03:05:41] [V] [TRT] Tactic: -64 Time: 11.5366
[05/21/2022-03:05:41] [V] [TRT] Tactic: -128 Time: 11.6705
[05/21/2022-03:05:41] [V] [TRT] Fastest Tactic: 512 Time: 11.1485
[05/21/2022-03:05:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 4
[05/21/2022-03:05:41] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264:2,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:05:41] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWiseV2)
[05/21/2022-03:05:43] [V] [TRT] Tactic: 0 Time: 4.53181
[05/21/2022-03:05:44] [V] [TRT] Tactic: 1 Time: 5.11591
[05/21/2022-03:05:45] [V] [TRT] Tactic: 2 Time: 4.5762
[05/21/2022-03:05:46] [V] [TRT] Tactic: 3 Time: 2.52458
[05/21/2022-03:05:47] [V] [TRT] Tactic: 4 Time: 3.77318
[05/21/2022-03:05:48] [V] [TRT] Tactic: 5 Time: 3.88678
[05/21/2022-03:05:49] [V] [TRT] Tactic: 6 Time: 2.60479
[05/21/2022-03:05:50] [V] [TRT] Tactic: 7 Time: 3.61277
[05/21/2022-03:05:51] [V] [TRT] Tactic: 8 Time: 3.16667
[05/21/2022-03:05:52] [V] [TRT] Tactic: 9 Time: 3.1023
[05/21/2022-03:05:53] [V] [TRT] Tactic: 10 Time: 5.39612
[05/21/2022-03:05:54] [V] [TRT] Tactic: 11 Time: 7.06046
[05/21/2022-03:05:55] [V] [TRT] Tactic: 12 Time: 6.64463
[05/21/2022-03:05:56] [V] [TRT] Tactic: 13 Time: 5.4284
[05/21/2022-03:05:57] [V] [TRT] Tactic: 14 Time: 3.39212
[05/21/2022-03:05:58] [V] [TRT] Tactic: 15 Time: 2.70452
[05/21/2022-03:05:59] [V] [TRT] Tactic: 16 Time: 4.6894
[05/21/2022-03:06:00] [V] [TRT] Tactic: 17 Time: 4.03361
[05/21/2022-03:06:01] [V] [TRT] Tactic: 18 Time: 2.90225
[05/21/2022-03:06:02] [V] [TRT] Tactic: 19 Time: 4.29296
[05/21/2022-03:06:03] [V] [TRT] Tactic: 28 Time: 3.11471
[05/21/2022-03:06:04] [V] [TRT] Tactic: 29 Time: 4.05584
[05/21/2022-03:06:04] [V] [TRT] Fastest Tactic: 3 Time: 2.52458
[05/21/2022-03:06:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) (PointWise)
[05/21/2022-03:06:04] [V] [TRT] Tactic: 128 Time: 12.0694
[05/21/2022-03:06:04] [V] [TRT] Tactic: 256 Time: 11.8528
[05/21/2022-03:06:05] [V] [TRT] Tactic: 512 Time: 11.1469
[05/21/2022-03:06:05] [V] [TRT] Tactic: -32 Time: 11.5481
[05/21/2022-03:06:05] [V] [TRT] Tactic: -64 Time: 11.5398
[05/21/2022-03:06:05] [V] [TRT] Tactic: -128 Time: 11.6727
[05/21/2022-03:06:05] [V] [TRT] Fastest Tactic: 512 Time: 11.1469
[05/21/2022-03:06:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 3
[05/21/2022-03:06:05] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:06:05] [V] [TRT] *************** Autotuning format combination: Float(5537792,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:06:05] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:05] [V] [TRT] Tactic: 0 Time: 3.80364
[05/21/2022-03:06:06] [V] [TRT] Tactic: 1 Time: 2.63734
[05/21/2022-03:06:06] [V] [TRT] Tactic: 2 Time: 2.49035
[05/21/2022-03:06:06] [V] [TRT] Tactic: 3 Time: 1.98402
[05/21/2022-03:06:06] [V] [TRT] Tactic: 4 Time: 1.83681
[05/21/2022-03:06:06] [V] [TRT] Tactic: 5 Time: 1.81563
[05/21/2022-03:06:06] [V] [TRT] Tactic: 6 Time: 1.72264
[05/21/2022-03:06:06] [V] [TRT] Tactic: 7 Time: 1.46239
[05/21/2022-03:06:06] [V] [TRT] Tactic: 8 Time: 1.44556
[05/21/2022-03:06:06] [V] [TRT] Tactic: 9 Time: 1.49254
[05/21/2022-03:06:06] [V] [TRT] Tactic: 28 Time: 3.76314
[05/21/2022-03:06:06] [V] [TRT] Fastest Tactic: 8 Time: 1.44556
[05/21/2022-03:06:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-03:06:06] [V] [TRT] Tactic: 128 Time: 12.5228
[05/21/2022-03:06:07] [V] [TRT] Tactic: 256 Time: 12.5285
[05/21/2022-03:06:07] [V] [TRT] Tactic: 512 Time: 12.5386
[05/21/2022-03:06:07] [V] [TRT] Tactic: -32 Time: 11.5133
[05/21/2022-03:06:07] [V] [TRT] Tactic: -64 Time: 11.5951
[05/21/2022-03:06:08] [V] [TRT] Tactic: -128 Time: 11.7118
[05/21/2022-03:06:08] [V] [TRT] Fastest Tactic: -32 Time: 11.5133
[05/21/2022-03:06:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:06:08] [V] [TRT] *************** Autotuning format combination: Float(5537792,1,26624,128) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:06:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:08] [V] [TRT] Tactic: 0 Time: 3.80243
[05/21/2022-03:06:08] [V] [TRT] Tactic: 1 Time: 2.63779
[05/21/2022-03:06:08] [V] [TRT] Tactic: 2 Time: 2.4918
[05/21/2022-03:06:08] [V] [TRT] Tactic: 3 Time: 3.16326
[05/21/2022-03:06:08] [V] [TRT] Tactic: 4 Time: 2.93885
[05/21/2022-03:06:08] [V] [TRT] Tactic: 5 Time: 2.65892
[05/21/2022-03:06:08] [V] [TRT] Tactic: 6 Time: 4.33818
[05/21/2022-03:06:08] [V] [TRT] Tactic: 7 Time: 3.60219
[05/21/2022-03:06:08] [V] [TRT] Tactic: 8 Time: 3.5157
[05/21/2022-03:06:08] [V] [TRT] Tactic: 9 Time: 3.08071
[05/21/2022-03:06:09] [V] [TRT] Tactic: 28 Time: 3.76298
[05/21/2022-03:06:09] [V] [TRT] Fastest Tactic: 2 Time: 2.4918
[05/21/2022-03:06:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-03:06:09] [V] [TRT] Tactic: 128 Time: 12.525
[05/21/2022-03:06:09] [V] [TRT] Tactic: 256 Time: 12.557
[05/21/2022-03:06:09] [V] [TRT] Tactic: 512 Time: 12.5864
[05/21/2022-03:06:10] [V] [TRT] Tactic: -32 Time: 12.6786
[05/21/2022-03:06:10] [V] [TRT] Tactic: -64 Time: 13.8951
[05/21/2022-03:06:10] [V] [TRT] Tactic: -128 Time: 13.8748
[05/21/2022-03:06:10] [V] [TRT] Fastest Tactic: 128 Time: 12.525
[05/21/2022-03:06:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-03:06:10] [V] [TRT] *************** Autotuning format combination: Float(173056,43264:32,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:06:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:10] [V] [TRT] Tactic: 24 Time: 2.0891
[05/21/2022-03:06:10] [V] [TRT] Tactic: 25 Time: 1.87014
[05/21/2022-03:06:10] [V] [TRT] Tactic: 26 Time: 1.84217
[05/21/2022-03:06:10] [V] [TRT] Tactic: 27 Time: 1.77523
[05/21/2022-03:06:10] [V] [TRT] Tactic: 31 Time: 2.07602
[05/21/2022-03:06:10] [V] [TRT] Fastest Tactic: 27 Time: 1.77523
[05/21/2022-03:06:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-03:06:11] [V] [TRT] Tactic: 128 Time: 12.5642
[05/21/2022-03:06:11] [V] [TRT] Tactic: 256 Time: 12.5571
[05/21/2022-03:06:11] [V] [TRT] Tactic: 512 Time: 12.5422
[05/21/2022-03:06:11] [V] [TRT] Tactic: -32 Time: 11.499
[05/21/2022-03:06:12] [V] [TRT] Tactic: -64 Time: 11.5497
[05/21/2022-03:06:12] [V] [TRT] Tactic: -128 Time: 11.7178
[05/21/2022-03:06:12] [V] [TRT] Fastest Tactic: -32 Time: 11.499
[05/21/2022-03:06:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:06:12] [V] [TRT] *************** Autotuning format combination: Half(5537792,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:06:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:12] [V] [TRT] Tactic: 0 Time: 3.91519
[05/21/2022-03:06:12] [V] [TRT] Tactic: 1 Time: 2.75652
[05/21/2022-03:06:12] [V] [TRT] Tactic: 2 Time: 2.57104
[05/21/2022-03:06:12] [V] [TRT] Tactic: 3 Time: 2.02989
[05/21/2022-03:06:12] [V] [TRT] Tactic: 4 Time: 1.92137
[05/21/2022-03:06:12] [V] [TRT] Tactic: 5 Time: 1.8834
[05/21/2022-03:06:12] [V] [TRT] Tactic: 6 Time: 1.6985
[05/21/2022-03:06:12] [V] [TRT] Tactic: 7 Time: 1.52602
[05/21/2022-03:06:12] [V] [TRT] Tactic: 8 Time: 1.55118
[05/21/2022-03:06:12] [V] [TRT] Tactic: 9 Time: 1.53915
[05/21/2022-03:06:13] [V] [TRT] Tactic: 28 Time: 3.89665
[05/21/2022-03:06:13] [V] [TRT] Fastest Tactic: 7 Time: 1.52602
[05/21/2022-03:06:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-03:06:13] [V] [TRT] Tactic: 128 Time: 12.0805
[05/21/2022-03:06:13] [V] [TRT] Tactic: 256 Time: 11.8686
[05/21/2022-03:06:13] [V] [TRT] Tactic: 512 Time: 11.1665
[05/21/2022-03:06:13] [V] [TRT] Tactic: -32 Time: 11.5618
[05/21/2022-03:06:14] [V] [TRT] Tactic: -64 Time: 11.5685
[05/21/2022-03:06:14] [V] [TRT] Tactic: -128 Time: 11.6736
[05/21/2022-03:06:14] [V] [TRT] Fastest Tactic: 512 Time: 11.1665
[05/21/2022-03:06:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:06:14] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264:2,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:06:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:14] [V] [TRT] Tactic: 0 Time: 2.65128
[05/21/2022-03:06:14] [V] [TRT] Tactic: 1 Time: 2.02843
[05/21/2022-03:06:14] [V] [TRT] Tactic: 2 Time: 2.03198
[05/21/2022-03:06:14] [V] [TRT] Tactic: 3 Time: 1.7818
[05/21/2022-03:06:14] [V] [TRT] Tactic: 4 Time: 1.729
[05/21/2022-03:06:14] [V] [TRT] Tactic: 5 Time: 1.76926
[05/21/2022-03:06:14] [V] [TRT] Tactic: 6 Time: 1.66574
[05/21/2022-03:06:14] [V] [TRT] Tactic: 7 Time: 1.61197
[05/21/2022-03:06:14] [V] [TRT] Tactic: 8 Time: 1.57934
[05/21/2022-03:06:14] [V] [TRT] Tactic: 9 Time: 1.68785
[05/21/2022-03:06:15] [V] [TRT] Tactic: 10 Time: 4.03702
[05/21/2022-03:06:15] [V] [TRT] Tactic: 11 Time: 2.88172
[05/21/2022-03:06:15] [V] [TRT] Tactic: 12 Time: 2.69546
[05/21/2022-03:06:15] [V] [TRT] Tactic: 13 Time: 2.10883
[05/21/2022-03:06:15] [V] [TRT] Tactic: 14 Time: 2.00152
[05/21/2022-03:06:15] [V] [TRT] Tactic: 15 Time: 2.02587
[05/21/2022-03:06:15] [V] [TRT] Tactic: 16 Time: 1.75269
[05/21/2022-03:06:15] [V] [TRT] Tactic: 17 Time: 1.56771
[05/21/2022-03:06:15] [V] [TRT] Tactic: 18 Time: 1.599
[05/21/2022-03:06:15] [V] [TRT] Tactic: 19 Time: 1.673
[05/21/2022-03:06:15] [V] [TRT] Tactic: 28 Time: 2.60969
[05/21/2022-03:06:15] [V] [TRT] Tactic: 29 Time: 4.05607
[05/21/2022-03:06:15] [V] [TRT] Fastest Tactic: 17 Time: 1.56771
[05/21/2022-03:06:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) (PointWise)
[05/21/2022-03:06:15] [V] [TRT] Tactic: 128 Time: 12.0707
[05/21/2022-03:06:16] [V] [TRT] Tactic: 256 Time: 11.8735
[05/21/2022-03:06:16] [V] [TRT] Tactic: 512 Time: 11.1309
[05/21/2022-03:06:16] [V] [TRT] Tactic: -32 Time: 11.6141
[05/21/2022-03:06:16] [V] [TRT] Tactic: -64 Time: 11.5352
[05/21/2022-03:06:17] [V] [TRT] Tactic: -128 Time: 11.6752
[05/21/2022-03:06:17] [V] [TRT] Fastest Tactic: 512 Time: 11.1309
[05/21/2022-03:06:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:06:17] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:06:17] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:06:17] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:06:17] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:17] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:06:17] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:17] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:17] [V] [TRT] Tactic: 0 Time: 3.14473
[05/21/2022-03:06:17] [V] [TRT] Tactic: 1 Time: 2.47694
[05/21/2022-03:06:17] [V] [TRT] Tactic: 2 Time: 8.64443
[05/21/2022-03:06:17] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1115955200, available: 536870912
[05/21/2022-03:06:17] [V] [TRT] Tactic: 5 Time: 17.3378
[05/21/2022-03:06:17] [I] [TRT] Some tactics do not have sufficient workspace memory to run. Increasing workspace size may increase performance, please check verbose output.
[05/21/2022-03:06:17] [V] [TRT] Fastest Tactic: 1 Time: 2.47694
[05/21/2022-03:06:17] [V] [TRT] Setting workspace to 1115955200enables more tactics for profiling
[05/21/2022-03:06:17] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-03:06:17] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:17] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:17] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:06:17] [V] [TRT] Tactic: 1062367460111450758 Time: 1.83585
[05/21/2022-03:06:17] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:06:17] [V] [TRT] Tactic: 1698681053543049347 Time: 1.69466
[05/21/2022-03:06:17] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:06:17] [V] [TRT] Tactic: 4501471010995462441 Time: 5.26574
[05/21/2022-03:06:17] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:06:17] [V] [TRT] Tactic: 5137655947464784826 Time: 2.58434
[05/21/2022-03:06:17] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:06:18] [V] [TRT] Tactic: 5288347012147084929 Time: 5.41628
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:06:18] [V] [TRT] Tactic: 5326823351883942011 Time: 5.22154
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:06:18] [V] [TRT] Tactic: 5500448035057547314 Time: 2.83945
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:06:18] [V] [TRT] Tactic: 6645123197870846056 Time: 2.71997
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:06:18] [V] [TRT] Tactic: 7144526460361122478 Time: 1.90105
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:06:18] [V] [TRT] Tactic: -8262349710178828730 Time: 5.5513
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:06:18] [V] [TRT] Tactic: -6576203419454146580 Time: 1.73565
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:06:18] [V] [TRT] Tactic: -4787320710726427159 Time: 1.95523
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:06:18] [V] [TRT] Tactic: -3456450830548107839 Time: 1.76728
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:06:18] [V] [TRT] Tactic: -1218658103698133241 Time: 2.98463
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:06:18] [V] [TRT] Tactic: -836875257600482091 Time: 2.91767
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:06:18] [V] [TRT] Tactic: -410470605513481746 Time: 5.30691
[05/21/2022-03:06:18] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:06:19] [V] [TRT] Tactic: -377491875521947884 Time: 5.4039
[05/21/2022-03:06:19] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:06:19] [V] [TRT] Tactic: -37215280111360163 Time: 2.60786
[05/21/2022-03:06:19] [V] [TRT] Fastest Tactic: 1698681053543049347 Time: 1.69466
[05/21/2022-03:06:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 1698681053543049347
[05/21/2022-03:06:19] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:06:19] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:19] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:19] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-03:06:19] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:19] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:19] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:06:19] [V] [TRT] Tactic: 3886731678879822788 Time: 3.21048
[05/21/2022-03:06:19] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:06:19] [V] [TRT] Tactic: 6629944304117643200 Time: 4.15014
[05/21/2022-03:06:19] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:06:19] [V] [TRT] Tactic: -9153228964338181824 Time: 4.17551
[05/21/2022-03:06:19] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:06:19] [V] [TRT] Tactic: -7394439838318485025 Time: 3.23473
[05/21/2022-03:06:19] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 3.21048
[05/21/2022-03:06:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-03:06:19] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:06:19] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:19] [V] [TRT] Tactic: 0 Time: 3.09567
[05/21/2022-03:06:19] [V] [TRT] Tactic: 1 Time: 2.78766
[05/21/2022-03:06:19] [V] [TRT] Tactic: 2 Time: 8.50665
[05/21/2022-03:06:19] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1115955200, available: 536870912
[05/21/2022-03:06:20] [V] [TRT] Tactic: 5 Time: 17.2334
[05/21/2022-03:06:20] [V] [TRT] Fastest Tactic: 1 Time: 2.78766
[05/21/2022-03:06:20] [V] [TRT] Setting workspace to 1115955200enables more tactics for profiling
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-03:06:20] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:06:20] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:20] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:06:20] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CublasConvolution)
[05/21/2022-03:06:20] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: 006_convolutional + 006_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:06:20] [V] [TRT] Tactic: 3066127711859985668 Time: 0.990976
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:06:20] [V] [TRT] Tactic: 3564772625446233998 Time: 1.05581
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:06:20] [V] [TRT] Tactic: 5319956359050645452 Time: 1.00968
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:06:20] [V] [TRT] Tactic: 7205456024582378848 Time: 1.5254
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:06:20] [V] [TRT] Tactic: 8163473458334948789 Time: 1.48127
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:06:20] [V] [TRT] Tactic: -4212163711445252890 Time: 3.01524
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:06:20] [V] [TRT] Tactic: -3898373634979201110 Time: 3.01914
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:06:20] [V] [TRT] Tactic: -2409163523992614473 Time: 1.51216
[05/21/2022-03:06:20] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:06:20] [V] [TRT] Tactic: -1716393687483585322 Time: 2.93813
[05/21/2022-03:06:20] [V] [TRT] Fastest Tactic: 3066127711859985668 Time: 0.990976
[05/21/2022-03:06:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3066127711859985668
[05/21/2022-03:06:20] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:06:20] [V] [TRT] *************** Autotuning format combination: Float(1384448,43264,208,1) -> Float(1384448,43264,208,1) ***************
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:20] [V] [TRT] Tactic: 0 Time: 1.5014
[05/21/2022-03:06:20] [V] [TRT] Tactic: 1 Time: 1.1082
[05/21/2022-03:06:20] [V] [TRT] Tactic: 2 Time: 1.04936
[05/21/2022-03:06:20] [V] [TRT] Tactic: 3 Time: 0.921699
[05/21/2022-03:06:20] [V] [TRT] Tactic: 4 Time: 0.786432
[05/21/2022-03:06:20] [V] [TRT] Tactic: 5 Time: 0.812643
[05/21/2022-03:06:20] [V] [TRT] Tactic: 6 Time: 0.839277
[05/21/2022-03:06:20] [V] [TRT] Tactic: 7 Time: 0.679642
[05/21/2022-03:06:20] [V] [TRT] Tactic: 8 Time: 0.645215
[05/21/2022-03:06:20] [V] [TRT] Tactic: 9 Time: 0.691732
[05/21/2022-03:06:20] [V] [TRT] Tactic: 28 Time: 1.47681
[05/21/2022-03:06:20] [V] [TRT] Fastest Tactic: 8 Time: 0.645215
[05/21/2022-03:06:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-03:06:20] [V] [TRT] Tactic: 128 Time: 5.55773
[05/21/2022-03:06:21] [V] [TRT] Tactic: 256 Time: 5.56947
[05/21/2022-03:06:21] [V] [TRT] Tactic: 512 Time: 5.58216
[05/21/2022-03:06:21] [V] [TRT] Tactic: -32 Time: 5.75312
[05/21/2022-03:06:21] [V] [TRT] Tactic: -64 Time: 5.74799
[05/21/2022-03:06:21] [V] [TRT] Tactic: -128 Time: 5.84566
[05/21/2022-03:06:21] [V] [TRT] Fastest Tactic: 128 Time: 5.55773
[05/21/2022-03:06:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:06:21] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,6656,32) -> Float(1384448,1,6656,32) ***************
[05/21/2022-03:06:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:21] [V] [TRT] Tactic: 0 Time: 1.50107
[05/21/2022-03:06:21] [V] [TRT] Tactic: 1 Time: 1.1085
[05/21/2022-03:06:21] [V] [TRT] Tactic: 2 Time: 1.05023
[05/21/2022-03:06:21] [V] [TRT] Tactic: 3 Time: 0.921927
[05/21/2022-03:06:21] [V] [TRT] Tactic: 4 Time: 0.786784
[05/21/2022-03:06:21] [V] [TRT] Tactic: 5 Time: 0.812233
[05/21/2022-03:06:21] [V] [TRT] Tactic: 6 Time: 0.837663
[05/21/2022-03:06:21] [V] [TRT] Tactic: 7 Time: 0.679987
[05/21/2022-03:06:21] [V] [TRT] Tactic: 8 Time: 0.644896
[05/21/2022-03:06:21] [V] [TRT] Tactic: 9 Time: 0.69194
[05/21/2022-03:06:21] [V] [TRT] Tactic: 28 Time: 1.47536
[05/21/2022-03:06:21] [V] [TRT] Fastest Tactic: 8 Time: 0.644896
[05/21/2022-03:06:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-03:06:22] [V] [TRT] Tactic: 128 Time: 5.55767
[05/21/2022-03:06:22] [V] [TRT] Tactic: 256 Time: 5.5729
[05/21/2022-03:06:22] [V] [TRT] Tactic: 512 Time: 5.5827
[05/21/2022-03:06:22] [V] [TRT] Tactic: -32 Time: 5.75128
[05/21/2022-03:06:22] [V] [TRT] Tactic: -64 Time: 5.74779
[05/21/2022-03:06:22] [V] [TRT] Tactic: -128 Time: 5.7804
[05/21/2022-03:06:22] [V] [TRT] Fastest Tactic: 128 Time: 5.55767
[05/21/2022-03:06:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:06:22] [V] [TRT] *************** Autotuning format combination: Float(43264,43264:32,208,1) -> Float(43264,43264:32,208,1) ***************
[05/21/2022-03:06:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:22] [V] [TRT] Tactic: 24 Time: 1.02727
[05/21/2022-03:06:22] [V] [TRT] Tactic: 25 Time: 0.936452
[05/21/2022-03:06:22] [V] [TRT] Tactic: 26 Time: 0.925189
[05/21/2022-03:06:22] [V] [TRT] Tactic: 27 Time: 0.889915
[05/21/2022-03:06:22] [V] [TRT] Tactic: 31 Time: 1.02748
[05/21/2022-03:06:22] [V] [TRT] Fastest Tactic: 27 Time: 0.889915
[05/21/2022-03:06:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-03:06:22] [V] [TRT] Tactic: 128 Time: 5.55488
[05/21/2022-03:06:23] [V] [TRT] Tactic: 256 Time: 5.58081
[05/21/2022-03:06:23] [V] [TRT] Tactic: 512 Time: 5.61973
[05/21/2022-03:06:23] [V] [TRT] Tactic: -32 Time: 5.76085
[05/21/2022-03:06:23] [V] [TRT] Tactic: -64 Time: 5.74792
[05/21/2022-03:06:23] [V] [TRT] Tactic: -128 Time: 5.82821
[05/21/2022-03:06:23] [V] [TRT] Fastest Tactic: 128 Time: 5.55488
[05/21/2022-03:06:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:06:23] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264,208,1) -> Half(1384448,43264,208,1) ***************
[05/21/2022-03:06:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:23] [V] [TRT] Tactic: 0 Time: 1.53065
[05/21/2022-03:06:23] [V] [TRT] Tactic: 1 Time: 1.1564
[05/21/2022-03:06:23] [V] [TRT] Tactic: 2 Time: 1.07576
[05/21/2022-03:06:23] [V] [TRT] Tactic: 3 Time: 0.918457
[05/21/2022-03:06:23] [V] [TRT] Tactic: 4 Time: 0.836244
[05/21/2022-03:06:23] [V] [TRT] Tactic: 5 Time: 0.855026
[05/21/2022-03:06:23] [V] [TRT] Tactic: 6 Time: 0.81474
[05/21/2022-03:06:23] [V] [TRT] Tactic: 7 Time: 0.711374
[05/21/2022-03:06:23] [V] [TRT] Tactic: 8 Time: 0.713366
[05/21/2022-03:06:23] [V] [TRT] Tactic: 9 Time: 0.736257
[05/21/2022-03:06:23] [V] [TRT] Tactic: 28 Time: 1.53472
[05/21/2022-03:06:23] [V] [TRT] Fastest Tactic: 7 Time: 0.711374
[05/21/2022-03:06:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-03:06:24] [V] [TRT] Tactic: 128 Time: 5.71441
[05/21/2022-03:06:24] [V] [TRT] Tactic: 256 Time: 5.64795
[05/21/2022-03:06:24] [V] [TRT] Tactic: 512 Time: 5.2742
[05/21/2022-03:06:24] [V] [TRT] Tactic: -32 Time: 5.75576
[05/21/2022-03:06:24] [V] [TRT] Tactic: -64 Time: 5.71503
[05/21/2022-03:06:24] [V] [TRT] Tactic: -128 Time: 5.75988
[05/21/2022-03:06:24] [V] [TRT] Fastest Tactic: 512 Time: 5.2742
[05/21/2022-03:06:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:06:24] [V] [TRT] *************** Autotuning format combination: Half(692224,43264:2,208,1) -> Half(692224,43264:2,208,1) ***************
[05/21/2022-03:06:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWiseV2)
[05/21/2022-03:06:24] [V] [TRT] Tactic: 0 Time: 1.17095
[05/21/2022-03:06:24] [V] [TRT] Tactic: 1 Time: 0.945039
[05/21/2022-03:06:24] [V] [TRT] Tactic: 2 Time: 0.95071
[05/21/2022-03:06:24] [V] [TRT] Tactic: 3 Time: 0.865163
[05/21/2022-03:06:24] [V] [TRT] Tactic: 4 Time: 0.843848
[05/21/2022-03:06:24] [V] [TRT] Tactic: 5 Time: 0.858366
[05/21/2022-03:06:24] [V] [TRT] Tactic: 6 Time: 0.825736
[05/21/2022-03:06:24] [V] [TRT] Tactic: 7 Time: 0.803587
[05/21/2022-03:06:24] [V] [TRT] Tactic: 8 Time: 0.786029
[05/21/2022-03:06:24] [V] [TRT] Tactic: 9 Time: 0.834382
[05/21/2022-03:06:24] [V] [TRT] Tactic: 10 Time: 1.61225
[05/21/2022-03:06:24] [V] [TRT] Tactic: 11 Time: 1.19572
[05/21/2022-03:06:25] [V] [TRT] Tactic: 12 Time: 1.13762
[05/21/2022-03:06:25] [V] [TRT] Tactic: 13 Time: 0.939239
[05/21/2022-03:06:25] [V] [TRT] Tactic: 14 Time: 0.869395
[05/21/2022-03:06:25] [V] [TRT] Tactic: 15 Time: 0.893092
[05/21/2022-03:06:25] [V] [TRT] Tactic: 16 Time: 0.828424
[05/21/2022-03:06:25] [V] [TRT] Tactic: 17 Time: 0.727741
[05/21/2022-03:06:25] [V] [TRT] Tactic: 18 Time: 0.725228
[05/21/2022-03:06:25] [V] [TRT] Tactic: 19 Time: 0.784603
[05/21/2022-03:06:25] [V] [TRT] Tactic: 28 Time: 1.15242
[05/21/2022-03:06:25] [V] [TRT] Tactic: 29 Time: 1.58507
[05/21/2022-03:06:25] [V] [TRT] Fastest Tactic: 18 Time: 0.725228
[05/21/2022-03:06:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) (PointWise)
[05/21/2022-03:06:25] [V] [TRT] Tactic: 128 Time: 5.71587
[05/21/2022-03:06:25] [V] [TRT] Tactic: 256 Time: 5.64987
[05/21/2022-03:06:25] [V] [TRT] Tactic: 512 Time: 5.29176
[05/21/2022-03:06:25] [V] [TRT] Tactic: -32 Time: 5.76005
[05/21/2022-03:06:25] [V] [TRT] Tactic: -64 Time: 5.74406
[05/21/2022-03:06:25] [V] [TRT] Tactic: -128 Time: 5.74149
[05/21/2022-03:06:25] [V] [TRT] Fastest Tactic: 512 Time: 5.29176
[05/21/2022-03:06:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:06:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:06:25] [V] [TRT] *************** Autotuning format combination: Float(1384448,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:06:25] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:06:25] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:25] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:06:25] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:25] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:26] [V] [TRT] Tactic: 0 Time: 29.7048
[05/21/2022-03:06:26] [V] [TRT] Tactic: 1 Time: 12.0125
[05/21/2022-03:06:27] [V] [TRT] Tactic: 2 Time: 29.9617
[05/21/2022-03:06:27] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1099112448, available: 536870912
[05/21/2022-03:06:28] [V] [TRT] Tactic: 5 Time: 91.0402
[05/21/2022-03:06:28] [V] [TRT] Tactic: 6 Time: 8.17425
[05/21/2022-03:06:28] [V] [TRT] Fastest Tactic: 6 Time: 8.17425
[05/21/2022-03:06:28] [V] [TRT] Setting workspace to 1099112448enables more tactics for profiling
[05/21/2022-03:06:28] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:28] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:06:29] [V] [TRT] Tactic: 1062367460111450758 Time: 11.0699
[05/21/2022-03:06:29] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:06:29] [V] [TRT] Tactic: 1754984623894446479 Time: 11.8852
[05/21/2022-03:06:29] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:06:29] [V] [TRT] Tactic: 3611739942397549984 Time: 17.6652
[05/21/2022-03:06:29] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:06:29] [V] [TRT] Tactic: 3827454225649558724 Time: 10.3771
[05/21/2022-03:06:29] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:06:30] [V] [TRT] Tactic: 4337000649858996379 Time: 8.88537
[05/21/2022-03:06:30] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:06:30] [V] [TRT] Tactic: 4501471010995462441 Time: 17.6022
[05/21/2022-03:06:30] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:06:30] [V] [TRT] Tactic: 5137655947464784826 Time: 8.68829
[05/21/2022-03:06:30] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:06:30] [V] [TRT] Tactic: 5288347012147084929 Time: 17.5022
[05/21/2022-03:06:30] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:06:31] [V] [TRT] Tactic: 5921334924264294896 Time: 7.2499
[05/21/2022-03:06:31] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:06:31] [V] [TRT] Tactic: 6645123197870846056 Time: 8.86871
[05/21/2022-03:06:31] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:06:31] [V] [TRT] Tactic: 7144526460361122478 Time: 11.121
[05/21/2022-03:06:31] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:06:31] [V] [TRT] Tactic: 7852627285308570038 Time: 10.6605
[05/21/2022-03:06:31] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:06:31] [V] [TRT] Tactic: -9137461792520977713 Time: 17.6885
[05/21/2022-03:06:31] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:06:32] [V] [TRT] Tactic: -8776506421218919509 Time: 10.351
[05/21/2022-03:06:32] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:06:32] [V] [TRT] Tactic: -8262349710178828730 Time: 17.7507
[05/21/2022-03:06:32] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:06:32] [V] [TRT] Tactic: -8133971918129952780 Time: 9.91174
[05/21/2022-03:06:32] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:06:32] [V] [TRT] Tactic: -6092040395344634144 Time: 11.3882
[05/21/2022-03:06:32] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:06:33] [V] [TRT] Tactic: -4787320710726427159 Time: 11.8413
[05/21/2022-03:06:33] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:06:33] [V] [TRT] Tactic: -3456450830548107839 Time: 10.1778
[05/21/2022-03:06:33] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:06:33] [V] [TRT] Tactic: -2318106587342035239 Time: 10.4487
[05/21/2022-03:06:33] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:06:33] [V] [TRT] Tactic: -1343271414618805657 Time: 6.65199
[05/21/2022-03:06:33] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:06:33] [V] [TRT] Tactic: -1218658103698133241 Time: 9.51784
[05/21/2022-03:06:33] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:06:34] [V] [TRT] Tactic: -836875257600482091 Time: 9.26558
[05/21/2022-03:06:34] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:06:34] [V] [TRT] Tactic: -410470605513481746 Time: 17.4095
[05/21/2022-03:06:34] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 6.65199
[05/21/2022-03:06:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:06:34] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,6656,32) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:06:34] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:34] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:34] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:06:34] [V] [TRT] Tactic: -9153228964338181824 Time: 14.5242
[05/21/2022-03:06:34] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:06:34] [V] [TRT] Tactic: -7394439838318485025 Time: 9.12951
[05/21/2022-03:06:34] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 9.12951
[05/21/2022-03:06:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:06:34] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:06:34] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:35] [V] [TRT] Tactic: 0 Time: 30.6943
[05/21/2022-03:06:35] [V] [TRT] Tactic: 1 Time: 11.2147
[05/21/2022-03:06:36] [V] [TRT] Tactic: 2 Time: 29.1718
[05/21/2022-03:06:36] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1099112448, available: 536870912
[05/21/2022-03:06:37] [V] [TRT] Tactic: 5 Time: 90.4128
[05/21/2022-03:06:37] [V] [TRT] Tactic: 6 Time: 10.2577
[05/21/2022-03:06:37] [V] [TRT] Fastest Tactic: 6 Time: 10.2577
[05/21/2022-03:06:37] [V] [TRT] Setting workspace to 1099112448enables more tactics for profiling
[05/21/2022-03:06:37] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:37] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-03:06:37] [V] [TRT] *************** Autotuning format combination: Half(692224,43264:2,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:06:37] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:06:37] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:37] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CudnnConvolution)
[05/21/2022-03:06:37] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:06:37] [V] [TRT] --------------- Timing Runner: 007_convolutional + 007_convolutional_bn (CaskConvolution)
[05/21/2022-03:06:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:06:37] [V] [TRT] Tactic: 3564772625446233998 Time: 5.77291
[05/21/2022-03:06:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:06:37] [V] [TRT] Tactic: 3650389455493082349 Time: 5.97942
[05/21/2022-03:06:37] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:06:38] [V] [TRT] Tactic: 4772821744921268633 Time: 4.01296
[05/21/2022-03:06:38] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:06:38] [V] [TRT] Tactic: 5319956359050645452 Time: 5.34978
[05/21/2022-03:06:38] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:06:38] [V] [TRT] Tactic: 7205456024582378848 Time: 4.57475
[05/21/2022-03:06:38] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:06:38] [V] [TRT] Tactic: -6490690591794140522 Time: 4.6243
[05/21/2022-03:06:38] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:06:38] [V] [TRT] Tactic: -4686027666808657977 Time: 9.20769
[05/21/2022-03:06:38] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:06:38] [V] [TRT] Tactic: -4212163711445252890 Time: 8.87366
[05/21/2022-03:06:38] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:06:38] [V] [TRT] Tactic: -3898373634979201110 Time: 9.13157
[05/21/2022-03:06:38] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:06:38] [V] [TRT] Tactic: -2409163523992614473 Time: 4.46732
[05/21/2022-03:06:38] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 4.01296
[05/21/2022-03:06:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:06:38] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:06:38] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1), Float(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:06:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-03:06:39] [V] [TRT] Tactic: 0 Time: 4.30395
[05/21/2022-03:06:41] [V] [TRT] Tactic: 1 Time: 5.4609
[05/21/2022-03:06:42] [V] [TRT] Tactic: 2 Time: 5.25401
[05/21/2022-03:06:42] [V] [TRT] Tactic: 3 Time: 3.15834
[05/21/2022-03:06:43] [V] [TRT] Tactic: 4 Time: 2.27768
[05/21/2022-03:06:44] [V] [TRT] Tactic: 5 Time: 1.89313
[05/21/2022-03:06:45] [V] [TRT] Tactic: 6 Time: 4.64398
[05/21/2022-03:06:46] [V] [TRT] Tactic: 7 Time: 4.12272
[05/21/2022-03:06:48] [V] [TRT] Tactic: 8 Time: 3.4152
[05/21/2022-03:06:49] [V] [TRT] Tactic: 9 Time: 5.62127
[05/21/2022-03:06:50] [V] [TRT] Tactic: 28 Time: 3.49187
[05/21/2022-03:06:50] [V] [TRT] Fastest Tactic: 5 Time: 1.89313
[05/21/2022-03:06:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-03:06:50] [V] [TRT] Tactic: 128 Time: 12.851
[05/21/2022-03:06:50] [V] [TRT] Tactic: 256 Time: 12.873
[05/21/2022-03:06:50] [V] [TRT] Tactic: 512 Time: 12.9007
[05/21/2022-03:06:51] [V] [TRT] Tactic: -32 Time: 13.4094
[05/21/2022-03:06:51] [V] [TRT] Tactic: -64 Time: 13.358
[05/21/2022-03:06:51] [V] [TRT] Tactic: -128 Time: 13.4384
[05/21/2022-03:06:51] [V] [TRT] Fastest Tactic: 128 Time: 12.851
[05/21/2022-03:06:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:06:51] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64), Float(2768896,1,13312,64) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:06:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-03:06:51] [V] [TRT] Tactic: 0 Time: 3.16609
[05/21/2022-03:06:51] [V] [TRT] Tactic: 1 Time: 2.37785
[05/21/2022-03:06:51] [V] [TRT] Tactic: 2 Time: 2.36381
[05/21/2022-03:06:51] [V] [TRT] Tactic: 3 Time: 2.05531
[05/21/2022-03:06:51] [V] [TRT] Tactic: 4 Time: 1.8277
[05/21/2022-03:06:52] [V] [TRT] Tactic: 5 Time: 1.76088
[05/21/2022-03:06:52] [V] [TRT] Tactic: 6 Time: 1.99527
[05/21/2022-03:06:52] [V] [TRT] Tactic: 7 Time: 1.68735
[05/21/2022-03:06:52] [V] [TRT] Tactic: 8 Time: 1.65257
[05/21/2022-03:06:52] [V] [TRT] Tactic: 9 Time: 1.75512
[05/21/2022-03:06:52] [V] [TRT] Tactic: 28 Time: 3.14309
[05/21/2022-03:06:52] [V] [TRT] Fastest Tactic: 8 Time: 1.65257
[05/21/2022-03:06:52] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-03:06:52] [V] [TRT] Tactic: 128 Time: 12.8545
[05/21/2022-03:06:52] [V] [TRT] Tactic: 256 Time: 12.8772
[05/21/2022-03:06:53] [V] [TRT] Tactic: 512 Time: 12.9221
[05/21/2022-03:06:53] [V] [TRT] Tactic: -32 Time: 13.402
[05/21/2022-03:06:53] [V] [TRT] Tactic: -64 Time: 13.3613
[05/21/2022-03:06:53] [V] [TRT] Tactic: -128 Time: 13.4936
[05/21/2022-03:06:53] [V] [TRT] Fastest Tactic: 128 Time: 12.8545
[05/21/2022-03:06:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:06:53] [V] [TRT] *************** Autotuning format combination: Float(86528,43264:32,208,1), Float(86528,43264:32,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:06:53] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-03:06:54] [V] [TRT] Tactic: 24 Time: 5.47293
[05/21/2022-03:06:56] [V] [TRT] Tactic: 25 Time: 4.67977
[05/21/2022-03:06:57] [V] [TRT] Tactic: 26 Time: 3.22079
[05/21/2022-03:06:58] [V] [TRT] Tactic: 27 Time: 4.59344
[05/21/2022-03:06:59] [V] [TRT] Tactic: 31 Time: 5.5065
[05/21/2022-03:06:59] [V] [TRT] Fastest Tactic: 26 Time: 3.22079
[05/21/2022-03:06:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-03:06:59] [V] [TRT] Tactic: 128 Time: 12.9383
[05/21/2022-03:06:59] [V] [TRT] Tactic: 256 Time: 12.8793
[05/21/2022-03:06:59] [V] [TRT] Tactic: 512 Time: 12.903
[05/21/2022-03:07:00] [V] [TRT] Tactic: -32 Time: 13.4029
[05/21/2022-03:07:00] [V] [TRT] Tactic: -64 Time: 13.3836
[05/21/2022-03:07:00] [V] [TRT] Tactic: -128 Time: 13.4849
[05/21/2022-03:07:00] [V] [TRT] Fastest Tactic: 256 Time: 12.8793
[05/21/2022-03:07:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:07:00] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1), Half(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:07:00] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-03:07:01] [V] [TRT] Tactic: 0 Time: 3.22922
[05/21/2022-03:07:02] [V] [TRT] Tactic: 1 Time: 2.42211
[05/21/2022-03:07:03] [V] [TRT] Tactic: 2 Time: 4.37982
[05/21/2022-03:07:04] [V] [TRT] Tactic: 3 Time: 5.02173
[05/21/2022-03:07:05] [V] [TRT] Tactic: 4 Time: 3.39045
[05/21/2022-03:07:06] [V] [TRT] Tactic: 5 Time: 4.50195
[05/21/2022-03:07:07] [V] [TRT] Tactic: 6 Time: 3.7462
[05/21/2022-03:07:08] [V] [TRT] Tactic: 7 Time: 2.63024
[05/21/2022-03:07:09] [V] [TRT] Tactic: 8 Time: 3.70146
[05/21/2022-03:07:10] [V] [TRT] Tactic: 9 Time: 4.62498
[05/21/2022-03:07:11] [V] [TRT] Tactic: 28 Time: 4.14135
[05/21/2022-03:07:11] [V] [TRT] Fastest Tactic: 1 Time: 2.42211
[05/21/2022-03:07:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-03:07:11] [V] [TRT] Tactic: 128 Time: 13.395
[05/21/2022-03:07:12] [V] [TRT] Tactic: 256 Time: 13.1506
[05/21/2022-03:07:12] [V] [TRT] Tactic: 512 Time: 12.4422
[05/21/2022-03:07:12] [V] [TRT] Tactic: -32 Time: 13.7416
[05/21/2022-03:07:12] [V] [TRT] Tactic: -64 Time: 13.5513
[05/21/2022-03:07:13] [V] [TRT] Tactic: -128 Time: 13.648
[05/21/2022-03:07:13] [V] [TRT] Fastest Tactic: 512 Time: 12.4422
[05/21/2022-03:07:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 1
[05/21/2022-03:07:13] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1), Half(1384448,43264:2,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:07:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWiseV2)
[05/21/2022-03:07:14] [V] [TRT] Tactic: 0 Time: 2.73936
[05/21/2022-03:07:15] [V] [TRT] Tactic: 1 Time: 4.49876
[05/21/2022-03:07:16] [V] [TRT] Tactic: 2 Time: 5.25612
[05/21/2022-03:07:17] [V] [TRT] Tactic: 3 Time: 5.44388
[05/21/2022-03:07:18] [V] [TRT] Tactic: 4 Time: 5.35064
[05/21/2022-03:07:19] [V] [TRT] Tactic: 5 Time: 4.43253
[05/21/2022-03:07:20] [V] [TRT] Tactic: 6 Time: 4.20987
[05/21/2022-03:07:21] [V] [TRT] Tactic: 7 Time: 4.10317
[05/21/2022-03:07:22] [V] [TRT] Tactic: 8 Time: 6.42114
[05/21/2022-03:07:24] [V] [TRT] Tactic: 9 Time: 5.42249
[05/21/2022-03:07:25] [V] [TRT] Tactic: 10 Time: 6.68418
[05/21/2022-03:07:26] [V] [TRT] Tactic: 11 Time: 3.04386
[05/21/2022-03:07:27] [V] [TRT] Tactic: 12 Time: 2.57814
[05/21/2022-03:07:28] [V] [TRT] Tactic: 13 Time: 6.47306
[05/21/2022-03:07:29] [V] [TRT] Tactic: 14 Time: 4.44743
[05/21/2022-03:07:30] [V] [TRT] Tactic: 15 Time: 5.34569
[05/21/2022-03:07:31] [V] [TRT] Tactic: 16 Time: 3.69238
[05/21/2022-03:07:32] [V] [TRT] Tactic: 17 Time: 4.20864
[05/21/2022-03:07:33] [V] [TRT] Tactic: 18 Time: 4.90623
[05/21/2022-03:07:34] [V] [TRT] Tactic: 19 Time: 5.16783
[05/21/2022-03:07:35] [V] [TRT] Tactic: 28 Time: 6.77124
[05/21/2022-03:07:36] [V] [TRT] Tactic: 29 Time: 8.10174
[05/21/2022-03:07:36] [V] [TRT] Fastest Tactic: 12 Time: 2.57814
[05/21/2022-03:07:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) (PointWise)
[05/21/2022-03:07:36] [V] [TRT] Tactic: 128 Time: 13.3818
[05/21/2022-03:07:37] [V] [TRT] Tactic: 256 Time: 13.1553
[05/21/2022-03:07:37] [V] [TRT] Tactic: 512 Time: 12.4201
[05/21/2022-03:07:37] [V] [TRT] Tactic: -32 Time: 13.6871
[05/21/2022-03:07:37] [V] [TRT] Tactic: -64 Time: 13.5382
[05/21/2022-03:07:38] [V] [TRT] Tactic: -128 Time: 13.5968
[05/21/2022-03:07:38] [V] [TRT] Fastest Tactic: 512 Time: 12.4201
[05/21/2022-03:07:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 12
[05/21/2022-03:07:38] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:07:38] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:07:38] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:07:38] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:38] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:07:38] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:38] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:38] [V] [TRT] Tactic: 0 Time: 8.86736
[05/21/2022-03:07:38] [V] [TRT] Tactic: 1 Time: 4.88213
[05/21/2022-03:07:38] [V] [TRT] Tactic: 2 Time: 9.30701
[05/21/2022-03:07:38] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198093824, available: 536870912
[05/21/2022-03:07:38] [V] [TRT] Tactic: 5 Time: 12.7751
[05/21/2022-03:07:38] [V] [TRT] Fastest Tactic: 1 Time: 4.88213
[05/21/2022-03:07:38] [V] [TRT] Setting workspace to 2198093824enables more tactics for profiling
[05/21/2022-03:07:38] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:38] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:38] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:38] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:07:38] [V] [TRT] Tactic: 1062367460111450758 Time: 3.66357
[05/21/2022-03:07:38] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:07:38] [V] [TRT] Tactic: 1698681053543049347 Time: 3.32218
[05/21/2022-03:07:38] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:07:39] [V] [TRT] Tactic: 4501471010995462441 Time: 5.46894
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:07:39] [V] [TRT] Tactic: 5137655947464784826 Time: 2.64964
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:07:39] [V] [TRT] Tactic: 5288347012147084929 Time: 5.50308
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:07:39] [V] [TRT] Tactic: 5326823351883942011 Time: 5.22408
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:07:39] [V] [TRT] Tactic: 5500448035057547314 Time: 2.94079
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:07:39] [V] [TRT] Tactic: 6645123197870846056 Time: 2.7052
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:07:39] [V] [TRT] Tactic: 7144526460361122478 Time: 3.80128
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:07:39] [V] [TRT] Tactic: -8262349710178828730 Time: 5.58242
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:07:39] [V] [TRT] Tactic: -6576203419454146580 Time: 3.43363
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:07:39] [V] [TRT] Tactic: -4787320710726427159 Time: 3.87291
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:07:39] [V] [TRT] Tactic: -3456450830548107839 Time: 3.53989
[05/21/2022-03:07:39] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:07:40] [V] [TRT] Tactic: -1218658103698133241 Time: 3.06118
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:07:40] [V] [TRT] Tactic: -836875257600482091 Time: 3.00584
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:07:40] [V] [TRT] Tactic: -410470605513481746 Time: 5.25751
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:07:40] [V] [TRT] Tactic: -377491875521947884 Time: 5.4385
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:07:40] [V] [TRT] Tactic: -37215280111360163 Time: 2.6296
[05/21/2022-03:07:40] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 2.6296
[05/21/2022-03:07:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:07:40] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:07:40] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:40] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:40] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:40] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:40] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:07:40] [V] [TRT] Tactic: 3886731678879822788 Time: 3.25444
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:07:40] [V] [TRT] Tactic: 6629944304117643200 Time: 8.23169
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:07:40] [V] [TRT] Tactic: -9153228964338181824 Time: 8.28486
[05/21/2022-03:07:40] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:07:40] [V] [TRT] Tactic: -7394439838318485025 Time: 3.19068
[05/21/2022-03:07:40] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 3.19068
[05/21/2022-03:07:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:07:40] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:07:40] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:41] [V] [TRT] Tactic: 0 Time: 9.13157
[05/21/2022-03:07:41] [V] [TRT] Tactic: 1 Time: 4.26943
[05/21/2022-03:07:41] [V] [TRT] Tactic: 2 Time: 9.15915
[05/21/2022-03:07:41] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198093824, available: 536870912
[05/21/2022-03:07:41] [V] [TRT] Tactic: 5 Time: 12.2747
[05/21/2022-03:07:41] [V] [TRT] Fastest Tactic: 1 Time: 4.26943
[05/21/2022-03:07:41] [V] [TRT] Setting workspace to 2198093824enables more tactics for profiling
[05/21/2022-03:07:41] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:41] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:41] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:07:41] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:07:41] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:41] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:41] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:07:41] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:07:41] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:41] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:41] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:41] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:41] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:41] [V] [TRT] --------------- Timing Runner: 009_convolutional + 009_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:41] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:07:41] [V] [TRT] Tactic: 3066127711859985668 Time: 1.96515
[05/21/2022-03:07:41] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:07:41] [V] [TRT] Tactic: 3564772625446233998 Time: 2.1026
[05/21/2022-03:07:41] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:07:41] [V] [TRT] Tactic: 5319956359050645452 Time: 2.01266
[05/21/2022-03:07:41] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:07:41] [V] [TRT] Tactic: 7205456024582378848 Time: 1.539
[05/21/2022-03:07:41] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:07:41] [V] [TRT] Tactic: 8163473458334948789 Time: 1.49477
[05/21/2022-03:07:41] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:07:41] [V] [TRT] Tactic: -4212163711445252890 Time: 3.0295
[05/21/2022-03:07:41] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:07:42] [V] [TRT] Tactic: -3898373634979201110 Time: 3.05645
[05/21/2022-03:07:42] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:07:42] [V] [TRT] Tactic: -2409163523992614473 Time: 1.50497
[05/21/2022-03:07:42] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:07:42] [V] [TRT] Tactic: -1716393687483585322 Time: 2.98702
[05/21/2022-03:07:42] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 1.49477
[05/21/2022-03:07:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:07:42] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:07:42] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1) -> Float(5537792,43264,208,1) ***************
[05/21/2022-03:07:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-03:07:42] [V] [TRT] Tactic: 0 Time: 3.80361
[05/21/2022-03:07:42] [V] [TRT] Tactic: 1 Time: 2.63944
[05/21/2022-03:07:42] [V] [TRT] Tactic: 2 Time: 2.49257
[05/21/2022-03:07:42] [V] [TRT] Tactic: 3 Time: 2.01723
[05/21/2022-03:07:42] [V] [TRT] Tactic: 4 Time: 1.87345
[05/21/2022-03:07:42] [V] [TRT] Tactic: 5 Time: 1.81488
[05/21/2022-03:07:42] [V] [TRT] Tactic: 6 Time: 1.71617
[05/21/2022-03:07:42] [V] [TRT] Tactic: 7 Time: 1.46208
[05/21/2022-03:07:42] [V] [TRT] Tactic: 8 Time: 1.44526
[05/21/2022-03:07:42] [V] [TRT] Tactic: 9 Time: 1.49188
[05/21/2022-03:07:42] [V] [TRT] Tactic: 28 Time: 3.76116
[05/21/2022-03:07:42] [V] [TRT] Fastest Tactic: 8 Time: 1.44526
[05/21/2022-03:07:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-03:07:43] [V] [TRT] Tactic: 128 Time: 12.5186
[05/21/2022-03:07:43] [V] [TRT] Tactic: 256 Time: 12.52
[05/21/2022-03:07:43] [V] [TRT] Tactic: 512 Time: 12.5371
[05/21/2022-03:07:43] [V] [TRT] Tactic: -32 Time: 11.495
[05/21/2022-03:07:44] [V] [TRT] Tactic: -64 Time: 11.5472
[05/21/2022-03:07:44] [V] [TRT] Tactic: -128 Time: 11.712
[05/21/2022-03:07:44] [V] [TRT] Fastest Tactic: -32 Time: 11.495
[05/21/2022-03:07:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:07:44] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64) -> Float(5537792,1,26624,128) ***************
[05/21/2022-03:07:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-03:07:44] [V] [TRT] Tactic: 0 Time: 3.80301
[05/21/2022-03:07:44] [V] [TRT] Tactic: 1 Time: 2.64089
[05/21/2022-03:07:44] [V] [TRT] Tactic: 2 Time: 2.49271
[05/21/2022-03:07:44] [V] [TRT] Tactic: 3 Time: 3.1614
[05/21/2022-03:07:44] [V] [TRT] Tactic: 4 Time: 2.93771
[05/21/2022-03:07:44] [V] [TRT] Tactic: 5 Time: 2.65777
[05/21/2022-03:07:44] [V] [TRT] Tactic: 6 Time: 4.33841
[05/21/2022-03:07:45] [V] [TRT] Tactic: 7 Time: 3.60305
[05/21/2022-03:07:45] [V] [TRT] Tactic: 8 Time: 3.51633
[05/21/2022-03:07:45] [V] [TRT] Tactic: 9 Time: 3.08381
[05/21/2022-03:07:45] [V] [TRT] Tactic: 28 Time: 3.76348
[05/21/2022-03:07:45] [V] [TRT] Fastest Tactic: 2 Time: 2.49271
[05/21/2022-03:07:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-03:07:45] [V] [TRT] Tactic: 128 Time: 12.5212
[05/21/2022-03:07:45] [V] [TRT] Tactic: 256 Time: 12.5259
[05/21/2022-03:07:46] [V] [TRT] Tactic: 512 Time: 12.5529
[05/21/2022-03:07:46] [V] [TRT] Tactic: -32 Time: 12.6692
[05/21/2022-03:07:46] [V] [TRT] Tactic: -64 Time: 13.8614
[05/21/2022-03:07:46] [V] [TRT] Tactic: -128 Time: 13.8594
[05/21/2022-03:07:46] [V] [TRT] Fastest Tactic: 128 Time: 12.5212
[05/21/2022-03:07:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-03:07:46] [V] [TRT] *************** Autotuning format combination: Float(86528,43264:32,208,1) -> Float(173056,43264:32,208,1) ***************
[05/21/2022-03:07:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-03:07:46] [V] [TRT] Tactic: 24 Time: 2.08314
[05/21/2022-03:07:47] [V] [TRT] Tactic: 25 Time: 1.86871
[05/21/2022-03:07:47] [V] [TRT] Tactic: 26 Time: 1.84085
[05/21/2022-03:07:47] [V] [TRT] Tactic: 27 Time: 1.77804
[05/21/2022-03:07:47] [V] [TRT] Tactic: 31 Time: 2.07898
[05/21/2022-03:07:47] [V] [TRT] Fastest Tactic: 27 Time: 1.77804
[05/21/2022-03:07:47] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-03:07:47] [V] [TRT] Tactic: 128 Time: 12.5217
[05/21/2022-03:07:47] [V] [TRT] Tactic: 256 Time: 12.526
[05/21/2022-03:07:47] [V] [TRT] Tactic: 512 Time: 12.5386
[05/21/2022-03:07:48] [V] [TRT] Tactic: -32 Time: 11.5137
[05/21/2022-03:07:48] [V] [TRT] Tactic: -64 Time: 11.5516
[05/21/2022-03:07:48] [V] [TRT] Tactic: -128 Time: 11.7125
[05/21/2022-03:07:48] [V] [TRT] Fastest Tactic: -32 Time: 11.5137
[05/21/2022-03:07:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:07:48] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1) -> Half(5537792,43264,208,1) ***************
[05/21/2022-03:07:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-03:07:48] [V] [TRT] Tactic: 0 Time: 3.91395
[05/21/2022-03:07:48] [V] [TRT] Tactic: 1 Time: 2.75559
[05/21/2022-03:07:48] [V] [TRT] Tactic: 2 Time: 2.56877
[05/21/2022-03:07:48] [V] [TRT] Tactic: 3 Time: 2.02923
[05/21/2022-03:07:48] [V] [TRT] Tactic: 4 Time: 1.91977
[05/21/2022-03:07:49] [V] [TRT] Tactic: 5 Time: 1.88149
[05/21/2022-03:07:49] [V] [TRT] Tactic: 6 Time: 1.69757
[05/21/2022-03:07:49] [V] [TRT] Tactic: 7 Time: 1.52454
[05/21/2022-03:07:49] [V] [TRT] Tactic: 8 Time: 1.55005
[05/21/2022-03:07:49] [V] [TRT] Tactic: 9 Time: 1.53866
[05/21/2022-03:07:49] [V] [TRT] Tactic: 28 Time: 3.8942
[05/21/2022-03:07:49] [V] [TRT] Fastest Tactic: 7 Time: 1.52454
[05/21/2022-03:07:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-03:07:49] [V] [TRT] Tactic: 128 Time: 12.0587
[05/21/2022-03:07:49] [V] [TRT] Tactic: 256 Time: 11.817
[05/21/2022-03:07:49] [V] [TRT] Tactic: 512 Time: 11.1292
[05/21/2022-03:07:50] [V] [TRT] Tactic: -32 Time: 11.5791
[05/21/2022-03:07:50] [V] [TRT] Tactic: -64 Time: 11.5339
[05/21/2022-03:07:50] [V] [TRT] Tactic: -128 Time: 11.6679
[05/21/2022-03:07:50] [V] [TRT] Fastest Tactic: 512 Time: 11.1292
[05/21/2022-03:07:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:07:50] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(2768896,43264:2,208,1) ***************
[05/21/2022-03:07:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWiseV2)
[05/21/2022-03:07:50] [V] [TRT] Tactic: 0 Time: 2.65111
[05/21/2022-03:07:50] [V] [TRT] Tactic: 1 Time: 2.02756
[05/21/2022-03:07:50] [V] [TRT] Tactic: 2 Time: 2.0341
[05/21/2022-03:07:50] [V] [TRT] Tactic: 3 Time: 1.77971
[05/21/2022-03:07:50] [V] [TRT] Tactic: 4 Time: 1.72812
[05/21/2022-03:07:50] [V] [TRT] Tactic: 5 Time: 1.76771
[05/21/2022-03:07:51] [V] [TRT] Tactic: 6 Time: 1.66392
[05/21/2022-03:07:51] [V] [TRT] Tactic: 7 Time: 1.61413
[05/21/2022-03:07:51] [V] [TRT] Tactic: 8 Time: 1.58023
[05/21/2022-03:07:51] [V] [TRT] Tactic: 9 Time: 1.68926
[05/21/2022-03:07:51] [V] [TRT] Tactic: 10 Time: 4.03333
[05/21/2022-03:07:51] [V] [TRT] Tactic: 11 Time: 2.88091
[05/21/2022-03:07:51] [V] [TRT] Tactic: 12 Time: 2.69374
[05/21/2022-03:07:51] [V] [TRT] Tactic: 13 Time: 2.10908
[05/21/2022-03:07:51] [V] [TRT] Tactic: 14 Time: 2.00057
[05/21/2022-03:07:51] [V] [TRT] Tactic: 15 Time: 2.02418
[05/21/2022-03:07:51] [V] [TRT] Tactic: 16 Time: 1.75409
[05/21/2022-03:07:51] [V] [TRT] Tactic: 17 Time: 1.56615
[05/21/2022-03:07:51] [V] [TRT] Tactic: 18 Time: 1.5987
[05/21/2022-03:07:51] [V] [TRT] Tactic: 19 Time: 1.67152
[05/21/2022-03:07:51] [V] [TRT] Tactic: 28 Time: 2.60885
[05/21/2022-03:07:51] [V] [TRT] Tactic: 29 Time: 4.05354
[05/21/2022-03:07:51] [V] [TRT] Fastest Tactic: 17 Time: 1.56615
[05/21/2022-03:07:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) (PointWise)
[05/21/2022-03:07:52] [V] [TRT] Tactic: 128 Time: 12.0603
[05/21/2022-03:07:52] [V] [TRT] Tactic: 256 Time: 11.8577
[05/21/2022-03:07:52] [V] [TRT] Tactic: 512 Time: 11.157
[05/21/2022-03:07:52] [V] [TRT] Tactic: -32 Time: 11.5836
[05/21/2022-03:07:53] [V] [TRT] Tactic: -64 Time: 11.5434
[05/21/2022-03:07:53] [V] [TRT] Tactic: -128 Time: 11.6717
[05/21/2022-03:07:53] [V] [TRT] Fastest Tactic: 512 Time: 11.157
[05/21/2022-03:07:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:07:53] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:07:53] [V] [TRT] *************** Autotuning format combination: Float(5537792,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:07:53] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:07:53] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:53] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:07:53] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:53] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:53] [V] [TRT] Tactic: 0 Time: 15.1615
[05/21/2022-03:07:53] [V] [TRT] Tactic: 1 Time: 7.25582
[05/21/2022-03:07:54] [V] [TRT] Tactic: 2 Time: 16.4126
[05/21/2022-03:07:54] [V] [TRT] Tactic: 5 Time: 21.161
[05/21/2022-03:07:54] [V] [TRT] Fastest Tactic: 1 Time: 7.25582
[05/21/2022-03:07:54] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:54] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:54] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:54] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:07:54] [V] [TRT] Tactic: 1062367460111450758 Time: 6.09532
[05/21/2022-03:07:54] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:07:54] [V] [TRT] Tactic: 1698681053543049347 Time: 5.54072
[05/21/2022-03:07:54] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:07:54] [V] [TRT] Tactic: 4501471010995462441 Time: 8.98157
[05/21/2022-03:07:54] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:07:55] [V] [TRT] Tactic: 5137655947464784826 Time: 4.37855
[05/21/2022-03:07:55] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:07:55] [V] [TRT] Tactic: 5288347012147084929 Time: 9.074
[05/21/2022-03:07:55] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:07:55] [V] [TRT] Tactic: 5326823351883942011 Time: 8.64344
[05/21/2022-03:07:55] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:07:55] [V] [TRT] Tactic: 5500448035057547314 Time: 5.09269
[05/21/2022-03:07:55] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:07:55] [V] [TRT] Tactic: 6645123197870846056 Time: 4.47465
[05/21/2022-03:07:55] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:07:55] [V] [TRT] Tactic: 7144526460361122478 Time: 6.36119
[05/21/2022-03:07:55] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:07:55] [V] [TRT] Tactic: -8262349710178828730 Time: 9.23603
[05/21/2022-03:07:55] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:07:56] [V] [TRT] Tactic: -6576203419454146580 Time: 5.59734
[05/21/2022-03:07:56] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:07:56] [V] [TRT] Tactic: -4787320710726427159 Time: 6.76492
[05/21/2022-03:07:56] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:07:56] [V] [TRT] Tactic: -3456450830548107839 Time: 5.80096
[05/21/2022-03:07:56] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:07:56] [V] [TRT] Tactic: -1218658103698133241 Time: 5.17287
[05/21/2022-03:07:56] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:07:56] [V] [TRT] Tactic: -836875257600482091 Time: 5.19741
[05/21/2022-03:07:56] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:07:56] [V] [TRT] Tactic: -410470605513481746 Time: 8.83508
[05/21/2022-03:07:56] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:07:56] [V] [TRT] Tactic: -377491875521947884 Time: 8.90565
[05/21/2022-03:07:56] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:07:57] [V] [TRT] Tactic: -37215280111360163 Time: 4.42425
[05/21/2022-03:07:57] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 4.37855
[05/21/2022-03:07:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-03:07:57] [V] [TRT] *************** Autotuning format combination: Float(5537792,1,26624,128) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:07:57] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:57] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:57] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:57] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:07:57] [V] [TRT] Tactic: 3886731678879822788 Time: 4.86499
[05/21/2022-03:07:57] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:07:57] [V] [TRT] Tactic: 6629944304117643200 Time: 10.6381
[05/21/2022-03:07:57] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:07:57] [V] [TRT] Tactic: -9153228964338181824 Time: 10.9643
[05/21/2022-03:07:57] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:07:57] [V] [TRT] Tactic: -7394439838318485025 Time: 4.86724
[05/21/2022-03:07:57] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 4.86499
[05/21/2022-03:07:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-03:07:57] [V] [TRT] *************** Autotuning format combination: Half(5537792,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:07:57] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:58] [V] [TRT] Tactic: 0 Time: 15.7201
[05/21/2022-03:07:58] [V] [TRT] Tactic: 1 Time: 6.23336
[05/21/2022-03:07:58] [V] [TRT] Tactic: 2 Time: 15.7468
[05/21/2022-03:07:58] [V] [TRT] Tactic: 5 Time: 20.7672
[05/21/2022-03:07:58] [V] [TRT] Fastest Tactic: 1 Time: 6.23336
[05/21/2022-03:07:58] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:58] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:58] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:07:58] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264:2,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:07:58] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:58] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:58] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264:2,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:07:58] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:07:58] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:58] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:58] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:58] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CublasConvolution)
[05/21/2022-03:07:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:58] [V] [TRT] --------------- Timing Runner: 011_convolutional + 011_convolutional_bn (CaskConvolution)
[05/21/2022-03:07:58] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:07:58] [V] [TRT] Tactic: 3066127711859985668 Time: 3.0774
[05/21/2022-03:07:58] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:07:59] [V] [TRT] Tactic: 3564772625446233998 Time: 3.30825
[05/21/2022-03:07:59] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:07:59] [V] [TRT] Tactic: 5319956359050645452 Time: 3.15645
[05/21/2022-03:07:59] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:07:59] [V] [TRT] Tactic: 7205456024582378848 Time: 2.41551
[05/21/2022-03:07:59] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:07:59] [V] [TRT] Tactic: 8163473458334948789 Time: 2.35111
[05/21/2022-03:07:59] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:07:59] [V] [TRT] Tactic: -4212163711445252890 Time: 4.73557
[05/21/2022-03:07:59] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:07:59] [V] [TRT] Tactic: -3898373634979201110 Time: 4.86649
[05/21/2022-03:07:59] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:07:59] [V] [TRT] Tactic: -2409163523992614473 Time: 2.37383
[05/21/2022-03:07:59] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:07:59] [V] [TRT] Tactic: -1716393687483585322 Time: 4.64962
[05/21/2022-03:07:59] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 2.35111
[05/21/2022-03:07:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:07:59] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:07:59] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1) -> Float(2768896,43264,208,1) ***************
[05/21/2022-03:07:59] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64) -> Float(2768896,1,13312,64) ***************
[05/21/2022-03:07:59] [V] [TRT] *************** Autotuning format combination: Float(86528,43264:32,208,1) -> Float(86528,43264:32,208,1) ***************
[05/21/2022-03:07:59] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1) -> Half(2768896,43264,208,1) ***************
[05/21/2022-03:07:59] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(1384448,43264:2,208,1) ***************
[05/21/2022-03:07:59] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:07:59] [V] [TRT] *************** Autotuning format combination: Float(2768896,43264,208,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:07:59] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:07:59] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:59] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:07:59] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:07:59] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-03:07:59] [V] [TRT] Tactic: 0 Time: 17.8973
[05/21/2022-03:08:00] [V] [TRT] Tactic: 1 Time: 11.5917
[05/21/2022-03:08:00] [V] [TRT] Tactic: 2 Time: 18.2695
[05/21/2022-03:08:04] [V] [TRT] Tactic: 5 Time: 242.601
[05/21/2022-03:08:04] [V] [TRT] Fastest Tactic: 1 Time: 11.5917
[05/21/2022-03:08:04] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:04] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:08:04] [V] [TRT] Tactic: 1062367460111450758 Time: 10.4013
[05/21/2022-03:08:04] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:08:04] [V] [TRT] Tactic: 1754984623894446479 Time: 12.223
[05/21/2022-03:08:04] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:08:05] [V] [TRT] Tactic: 3611739942397549984 Time: 8.65118
[05/21/2022-03:08:05] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:08:05] [V] [TRT] Tactic: 4337000649858996379 Time: 8.679
[05/21/2022-03:08:05] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:08:05] [V] [TRT] Tactic: 4501471010995462441 Time: 8.53972
[05/21/2022-03:08:05] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:08:05] [V] [TRT] Tactic: 5137655947464784826 Time: 8.31934
[05/21/2022-03:08:05] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:08:05] [V] [TRT] Tactic: 5288347012147084929 Time: 8.54645
[05/21/2022-03:08:05] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:08:05] [V] [TRT] Tactic: 6645123197870846056 Time: 8.48462
[05/21/2022-03:08:05] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:08:06] [V] [TRT] Tactic: 7144526460361122478 Time: 11.379
[05/21/2022-03:08:06] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:08:06] [V] [TRT] Tactic: -9137461792520977713 Time: 8.73253
[05/21/2022-03:08:06] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:08:06] [V] [TRT] Tactic: -8262349710178828730 Time: 8.65137
[05/21/2022-03:08:06] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:08:06] [V] [TRT] Tactic: -8133971918129952780 Time: 9.82529
[05/21/2022-03:08:06] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:08:06] [V] [TRT] Tactic: -6092040395344634144 Time: 10.8314
[05/21/2022-03:08:06] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:08:07] [V] [TRT] Tactic: -4787320710726427159 Time: 12.0907
[05/21/2022-03:08:07] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:08:07] [V] [TRT] Tactic: -3456450830548107839 Time: 9.79936
[05/21/2022-03:08:07] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:08:07] [V] [TRT] Tactic: -1218658103698133241 Time: 9.59029
[05/21/2022-03:08:07] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:08:07] [V] [TRT] Tactic: -836875257600482091 Time: 9.16488
[05/21/2022-03:08:07] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:08:07] [V] [TRT] Tactic: -410470605513481746 Time: 8.37551
[05/21/2022-03:08:07] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 8.31934
[05/21/2022-03:08:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-03:08:07] [V] [TRT] *************** Autotuning format combination: Float(2768896,1,13312,64) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:08:07] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:07] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:07] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:07] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:08:08] [V] [TRT] Tactic: -9153228964338181824 Time: 13.7378
[05/21/2022-03:08:08] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:08:08] [V] [TRT] Tactic: -7394439838318485025 Time: 8.59715
[05/21/2022-03:08:08] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 8.59715
[05/21/2022-03:08:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:08:08] [V] [TRT] *************** Autotuning format combination: Half(2768896,43264,208,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:08] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:08] [V] [TRT] Tactic: 0 Time: 17.8288
[05/21/2022-03:08:08] [V] [TRT] Tactic: 1 Time: 12.2574
[05/21/2022-03:08:09] [V] [TRT] Tactic: 2 Time: 17.1131
[05/21/2022-03:08:13] [V] [TRT] Tactic: 5 Time: 238.541
[05/21/2022-03:08:13] [V] [TRT] Fastest Tactic: 1 Time: 12.2574
[05/21/2022-03:08:13] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:13] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:08:13] [V] [TRT] *************** Autotuning format combination: Half(1384448,43264:2,208,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:08:13] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:13] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:13] [V] [TRT] --------------- Timing Runner: 012_convolutional + 012_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:08:13] [V] [TRT] Tactic: 3564772625446233998 Time: 5.39842
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:08:13] [V] [TRT] Tactic: 3650389455493082349 Time: 5.62983
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:08:13] [V] [TRT] Tactic: 5319956359050645452 Time: 4.98833
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:08:13] [V] [TRT] Tactic: 7205456024582378848 Time: 4.31583
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:08:13] [V] [TRT] Tactic: -6490690591794140522 Time: 4.46014
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:08:13] [V] [TRT] Tactic: -4686027666808657977 Time: 4.37903
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:08:13] [V] [TRT] Tactic: -4212163711445252890 Time: 4.23003
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:08:13] [V] [TRT] Tactic: -3898373634979201110 Time: 4.34895
[05/21/2022-03:08:13] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:08:13] [V] [TRT] Tactic: -2409163523992614473 Time: 4.25211
[05/21/2022-03:08:13] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 4.23003
[05/21/2022-03:08:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-03:08:13] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:13] [V] [TRT] *************** Autotuning format combination: Float(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:08:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:13] [V] [TRT] Tactic: 0 Time: 1.50104
[05/21/2022-03:08:13] [V] [TRT] Tactic: 1 Time: 1.10869
[05/21/2022-03:08:14] [V] [TRT] Tactic: 2 Time: 1.05051
[05/21/2022-03:08:14] [V] [TRT] Tactic: 3 Time: 0.9211
[05/21/2022-03:08:14] [V] [TRT] Tactic: 4 Time: 0.788926
[05/21/2022-03:08:14] [V] [TRT] Tactic: 5 Time: 0.81265
[05/21/2022-03:08:14] [V] [TRT] Tactic: 6 Time: 0.852825
[05/21/2022-03:08:14] [V] [TRT] Tactic: 7 Time: 0.681009
[05/21/2022-03:08:14] [V] [TRT] Tactic: 8 Time: 0.64485
[05/21/2022-03:08:14] [V] [TRT] Tactic: 9 Time: 0.691517
[05/21/2022-03:08:14] [V] [TRT] Tactic: 28 Time: 1.47619
[05/21/2022-03:08:14] [V] [TRT] Fastest Tactic: 8 Time: 0.64485
[05/21/2022-03:08:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-03:08:14] [V] [TRT] Tactic: 128 Time: 5.55567
[05/21/2022-03:08:14] [V] [TRT] Tactic: 256 Time: 5.56867
[05/21/2022-03:08:14] [V] [TRT] Tactic: 512 Time: 5.57989
[05/21/2022-03:08:14] [V] [TRT] Tactic: -32 Time: 5.74876
[05/21/2022-03:08:14] [V] [TRT] Tactic: -64 Time: 5.74846
[05/21/2022-03:08:14] [V] [TRT] Tactic: -128 Time: 5.7793
[05/21/2022-03:08:14] [V] [TRT] Fastest Tactic: 128 Time: 5.55567
[05/21/2022-03:08:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:14] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,13312,128) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:08:14] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:15] [V] [TRT] Tactic: 0 Time: 1.50094
[05/21/2022-03:08:15] [V] [TRT] Tactic: 1 Time: 1.10887
[05/21/2022-03:08:15] [V] [TRT] Tactic: 2 Time: 1.04952
[05/21/2022-03:08:15] [V] [TRT] Tactic: 3 Time: 0.92209
[05/21/2022-03:08:15] [V] [TRT] Tactic: 4 Time: 0.786595
[05/21/2022-03:08:15] [V] [TRT] Tactic: 5 Time: 0.812292
[05/21/2022-03:08:15] [V] [TRT] Tactic: 6 Time: 0.838379
[05/21/2022-03:08:15] [V] [TRT] Tactic: 7 Time: 0.678001
[05/21/2022-03:08:15] [V] [TRT] Tactic: 8 Time: 0.645078
[05/21/2022-03:08:15] [V] [TRT] Tactic: 9 Time: 0.691562
[05/21/2022-03:08:15] [V] [TRT] Tactic: 28 Time: 1.4762
[05/21/2022-03:08:15] [V] [TRT] Fastest Tactic: 8 Time: 0.645078
[05/21/2022-03:08:15] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-03:08:15] [V] [TRT] Tactic: 128 Time: 5.5555
[05/21/2022-03:08:15] [V] [TRT] Tactic: 256 Time: 5.56958
[05/21/2022-03:08:15] [V] [TRT] Tactic: 512 Time: 5.57917
[05/21/2022-03:08:15] [V] [TRT] Tactic: -32 Time: 5.76825
[05/21/2022-03:08:15] [V] [TRT] Tactic: -64 Time: 5.77669
[05/21/2022-03:08:16] [V] [TRT] Tactic: -128 Time: 5.7752
[05/21/2022-03:08:16] [V] [TRT] Fastest Tactic: 128 Time: 5.5555
[05/21/2022-03:08:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:16] [V] [TRT] *************** Autotuning format combination: Float(43264,10816:32,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:08:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:16] [V] [TRT] Tactic: 24 Time: 1.02988
[05/21/2022-03:08:16] [V] [TRT] Tactic: 25 Time: 0.935853
[05/21/2022-03:08:16] [V] [TRT] Tactic: 26 Time: 0.922839
[05/21/2022-03:08:16] [V] [TRT] Tactic: 27 Time: 0.891543
[05/21/2022-03:08:16] [V] [TRT] Tactic: 31 Time: 1.02671
[05/21/2022-03:08:16] [V] [TRT] Fastest Tactic: 27 Time: 0.891543
[05/21/2022-03:08:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-03:08:16] [V] [TRT] Tactic: 128 Time: 5.55563
[05/21/2022-03:08:16] [V] [TRT] Tactic: 256 Time: 5.56875
[05/21/2022-03:08:16] [V] [TRT] Tactic: 512 Time: 5.57985
[05/21/2022-03:08:16] [V] [TRT] Tactic: -32 Time: 5.75005
[05/21/2022-03:08:16] [V] [TRT] Tactic: -64 Time: 5.74536
[05/21/2022-03:08:16] [V] [TRT] Tactic: -128 Time: 5.79356
[05/21/2022-03:08:16] [V] [TRT] Fastest Tactic: 128 Time: 5.55563
[05/21/2022-03:08:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:08:16] [V] [TRT] *************** Autotuning format combination: Half(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:16] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:16] [V] [TRT] Tactic: 0 Time: 1.5305
[05/21/2022-03:08:17] [V] [TRT] Tactic: 1 Time: 1.15658
[05/21/2022-03:08:17] [V] [TRT] Tactic: 2 Time: 1.07614
[05/21/2022-03:08:17] [V] [TRT] Tactic: 3 Time: 0.918177
[05/21/2022-03:08:17] [V] [TRT] Tactic: 4 Time: 0.836166
[05/21/2022-03:08:17] [V] [TRT] Tactic: 5 Time: 0.855866
[05/21/2022-03:08:17] [V] [TRT] Tactic: 6 Time: 0.816211
[05/21/2022-03:08:17] [V] [TRT] Tactic: 7 Time: 0.711133
[05/21/2022-03:08:17] [V] [TRT] Tactic: 8 Time: 0.713737
[05/21/2022-03:08:17] [V] [TRT] Tactic: 9 Time: 0.736055
[05/21/2022-03:08:17] [V] [TRT] Tactic: 28 Time: 1.53507
[05/21/2022-03:08:17] [V] [TRT] Fastest Tactic: 7 Time: 0.711133
[05/21/2022-03:08:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-03:08:17] [V] [TRT] Tactic: 128 Time: 5.71803
[05/21/2022-03:08:17] [V] [TRT] Tactic: 256 Time: 5.65352
[05/21/2022-03:08:17] [V] [TRT] Tactic: 512 Time: 5.28667
[05/21/2022-03:08:17] [V] [TRT] Tactic: -32 Time: 5.75624
[05/21/2022-03:08:17] [V] [TRT] Tactic: -64 Time: 5.71612
[05/21/2022-03:08:17] [V] [TRT] Tactic: -128 Time: 5.74074
[05/21/2022-03:08:17] [V] [TRT] Fastest Tactic: 512 Time: 5.28667
[05/21/2022-03:08:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:08:17] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:08:17] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:18] [V] [TRT] Tactic: 0 Time: 1.17064
[05/21/2022-03:08:18] [V] [TRT] Tactic: 1 Time: 0.94802
[05/21/2022-03:08:18] [V] [TRT] Tactic: 2 Time: 0.951016
[05/21/2022-03:08:18] [V] [TRT] Tactic: 3 Time: 0.865462
[05/21/2022-03:08:18] [V] [TRT] Tactic: 4 Time: 0.84265
[05/21/2022-03:08:18] [V] [TRT] Tactic: 5 Time: 0.859199
[05/21/2022-03:08:18] [V] [TRT] Tactic: 6 Time: 0.826139
[05/21/2022-03:08:18] [V] [TRT] Tactic: 7 Time: 0.800977
[05/21/2022-03:08:18] [V] [TRT] Tactic: 8 Time: 0.788053
[05/21/2022-03:08:18] [V] [TRT] Tactic: 9 Time: 0.835944
[05/21/2022-03:08:18] [V] [TRT] Tactic: 10 Time: 1.61274
[05/21/2022-03:08:18] [V] [TRT] Tactic: 11 Time: 1.1962
[05/21/2022-03:08:18] [V] [TRT] Tactic: 12 Time: 1.13748
[05/21/2022-03:08:18] [V] [TRT] Tactic: 13 Time: 0.939694
[05/21/2022-03:08:18] [V] [TRT] Tactic: 14 Time: 0.869368
[05/21/2022-03:08:18] [V] [TRT] Tactic: 15 Time: 0.892272
[05/21/2022-03:08:18] [V] [TRT] Tactic: 16 Time: 0.826999
[05/21/2022-03:08:18] [V] [TRT] Tactic: 17 Time: 0.726784
[05/21/2022-03:08:18] [V] [TRT] Tactic: 18 Time: 0.724245
[05/21/2022-03:08:18] [V] [TRT] Tactic: 19 Time: 0.784075
[05/21/2022-03:08:18] [V] [TRT] Tactic: 28 Time: 1.15123
[05/21/2022-03:08:18] [V] [TRT] Tactic: 29 Time: 1.58443
[05/21/2022-03:08:18] [V] [TRT] Fastest Tactic: 18 Time: 0.724245
[05/21/2022-03:08:18] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) (PointWise)
[05/21/2022-03:08:18] [V] [TRT] Tactic: 128 Time: 5.71204
[05/21/2022-03:08:18] [V] [TRT] Tactic: 256 Time: 5.64363
[05/21/2022-03:08:19] [V] [TRT] Tactic: 512 Time: 5.28476
[05/21/2022-03:08:19] [V] [TRT] Tactic: -32 Time: 5.75558
[05/21/2022-03:08:19] [V] [TRT] Tactic: -64 Time: 5.71617
[05/21/2022-03:08:19] [V] [TRT] Tactic: -128 Time: 5.73836
[05/21/2022-03:08:19] [V] [TRT] Fastest Tactic: 512 Time: 5.28476
[05/21/2022-03:08:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:08:19] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:19] [V] [TRT] *************** Autotuning format combination: Float(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:08:19] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:19] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:19] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:08:19] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:19] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:19] [V] [TRT] Tactic: 0 Time: 4.38479
[05/21/2022-03:08:19] [V] [TRT] Tactic: 1 Time: 3.01717
[05/21/2022-03:08:19] [V] [TRT] Tactic: 2 Time: 4.78608
[05/21/2022-03:08:19] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198142976, available: 536870912
[05/21/2022-03:08:19] [V] [TRT] Tactic: 5 Time: 9.91409
[05/21/2022-03:08:19] [V] [TRT] Fastest Tactic: 1 Time: 3.01717
[05/21/2022-03:08:19] [V] [TRT] Setting workspace to 2198142976enables more tactics for profiling
[05/21/2022-03:08:19] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:19] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:19] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:19] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:08:19] [V] [TRT] Tactic: 1062367460111450758 Time: 3.04149
[05/21/2022-03:08:19] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:08:19] [V] [TRT] Tactic: 1698681053543049347 Time: 2.78708
[05/21/2022-03:08:19] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:08:19] [V] [TRT] Tactic: 4501471010995462441 Time: 2.28428
[05/21/2022-03:08:19] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:08:20] [V] [TRT] Tactic: 5137655947464784826 Time: 2.20219
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:08:20] [V] [TRT] Tactic: 5288347012147084929 Time: 2.31517
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:08:20] [V] [TRT] Tactic: 5326823351883942011 Time: 2.2596
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:08:20] [V] [TRT] Tactic: 5500448035057547314 Time: 2.48039
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:08:20] [V] [TRT] Tactic: 6645123197870846056 Time: 2.24433
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:08:20] [V] [TRT] Tactic: 7144526460361122478 Time: 3.15007
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:08:20] [V] [TRT] Tactic: -8262349710178828730 Time: 2.35586
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:08:20] [V] [TRT] Tactic: -6576203419454146580 Time: 2.78436
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:08:20] [V] [TRT] Tactic: -4787320710726427159 Time: 3.28311
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:08:20] [V] [TRT] Tactic: -3456450830548107839 Time: 2.91906
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:08:20] [V] [TRT] Tactic: -1218658103698133241 Time: 2.53656
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:08:20] [V] [TRT] Tactic: -836875257600482091 Time: 2.48094
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:08:20] [V] [TRT] Tactic: -410470605513481746 Time: 2.30609
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:08:20] [V] [TRT] Tactic: -377491875521947884 Time: 2.28411
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:08:20] [V] [TRT] Tactic: -37215280111360163 Time: 2.17193
[05/21/2022-03:08:20] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 2.17193
[05/21/2022-03:08:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:08:20] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,13312,128) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:08:20] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:20] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:20] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:20] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:20] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:08:20] [V] [TRT] Tactic: 3886731678879822788 Time: 2.4961
[05/21/2022-03:08:20] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:08:21] [V] [TRT] Tactic: 6629944304117643200 Time: 5.44854
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:08:21] [V] [TRT] Tactic: -9153228964338181824 Time: 5.53191
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:08:21] [V] [TRT] Tactic: -7394439838318485025 Time: 2.44131
[05/21/2022-03:08:21] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.44131
[05/21/2022-03:08:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:08:21] [V] [TRT] *************** Autotuning format combination: Half(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:21] [V] [TRT] Tactic: 0 Time: 4.27673
[05/21/2022-03:08:21] [V] [TRT] Tactic: 1 Time: 2.98888
[05/21/2022-03:08:21] [V] [TRT] Tactic: 2 Time: 4.36579
[05/21/2022-03:08:21] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2198142976, available: 536870912
[05/21/2022-03:08:21] [V] [TRT] Tactic: 5 Time: 9.81637
[05/21/2022-03:08:21] [V] [TRT] Fastest Tactic: 1 Time: 2.98888
[05/21/2022-03:08:21] [V] [TRT] Setting workspace to 2198142976enables more tactics for profiling
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:21] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:08:21] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:21] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:21] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:21] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:21] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:21] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:21] [V] [TRT] --------------- Timing Runner: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:08:21] [V] [TRT] Tactic: 3066127711859985668 Time: 1.55462
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:08:21] [V] [TRT] Tactic: 3564772625446233998 Time: 1.66954
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:08:21] [V] [TRT] Tactic: 5319956359050645452 Time: 1.59769
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:08:21] [V] [TRT] Tactic: 7205456024582378848 Time: 1.23204
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:08:21] [V] [TRT] Tactic: 8163473458334948789 Time: 1.18768
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:08:21] [V] [TRT] Tactic: -4212163711445252890 Time: 1.22135
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:08:21] [V] [TRT] Tactic: -3898373634979201110 Time: 1.23415
[05/21/2022-03:08:21] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:08:22] [V] [TRT] Tactic: -2409163523992614473 Time: 1.21141
[05/21/2022-03:08:22] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:08:22] [V] [TRT] Tactic: -1716393687483585322 Time: 1.20682
[05/21/2022-03:08:22] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 1.18768
[05/21/2022-03:08:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:08:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:22] [V] [TRT] *************** Autotuning format combination: Float(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:08:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:22] [V] [TRT] Tactic: 0 Time: 0.958379
[05/21/2022-03:08:22] [V] [TRT] Tactic: 1 Time: 0.667077
[05/21/2022-03:08:22] [V] [TRT] Tactic: 2 Time: 0.630547
[05/21/2022-03:08:22] [V] [TRT] Tactic: 3 Time: 0.504264
[05/21/2022-03:08:22] [V] [TRT] Tactic: 4 Time: 0.467513
[05/21/2022-03:08:22] [V] [TRT] Tactic: 5 Time: 0.462038
[05/21/2022-03:08:22] [V] [TRT] Tactic: 6 Time: 0.437097
[05/21/2022-03:08:22] [V] [TRT] Tactic: 7 Time: 0.37433
[05/21/2022-03:08:22] [V] [TRT] Tactic: 8 Time: 0.369303
[05/21/2022-03:08:22] [V] [TRT] Tactic: 9 Time: 0.381289
[05/21/2022-03:08:22] [V] [TRT] Tactic: 28 Time: 0.948809
[05/21/2022-03:08:22] [V] [TRT] Fastest Tactic: 8 Time: 0.369303
[05/21/2022-03:08:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-03:08:22] [V] [TRT] Tactic: 128 Time: 3.13848
[05/21/2022-03:08:22] [V] [TRT] Tactic: 256 Time: 3.13908
[05/21/2022-03:08:22] [V] [TRT] Tactic: 512 Time: 3.14214
[05/21/2022-03:08:22] [V] [TRT] Tactic: -32 Time: 2.91204
[05/21/2022-03:08:22] [V] [TRT] Tactic: -64 Time: 2.90666
[05/21/2022-03:08:22] [V] [TRT] Tactic: -128 Time: 2.94197
[05/21/2022-03:08:22] [V] [TRT] Fastest Tactic: -64 Time: 2.90666
[05/21/2022-03:08:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:22] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,13312,128) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:08:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:22] [V] [TRT] Tactic: 0 Time: 0.958731
[05/21/2022-03:08:22] [V] [TRT] Tactic: 1 Time: 0.667721
[05/21/2022-03:08:22] [V] [TRT] Tactic: 2 Time: 0.630619
[05/21/2022-03:08:22] [V] [TRT] Tactic: 3 Time: 0.798809
[05/21/2022-03:08:22] [V] [TRT] Tactic: 4 Time: 0.742292
[05/21/2022-03:08:22] [V] [TRT] Tactic: 5 Time: 0.672689
[05/21/2022-03:08:23] [V] [TRT] Tactic: 6 Time: 1.09163
[05/21/2022-03:08:23] [V] [TRT] Tactic: 7 Time: 0.908861
[05/21/2022-03:08:23] [V] [TRT] Tactic: 8 Time: 0.887038
[05/21/2022-03:08:23] [V] [TRT] Tactic: 9 Time: 0.778522
[05/21/2022-03:08:23] [V] [TRT] Tactic: 28 Time: 0.949531
[05/21/2022-03:08:23] [V] [TRT] Fastest Tactic: 2 Time: 0.630619
[05/21/2022-03:08:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-03:08:23] [V] [TRT] Tactic: 128 Time: 3.13788
[05/21/2022-03:08:23] [V] [TRT] Tactic: 256 Time: 3.13846
[05/21/2022-03:08:23] [V] [TRT] Tactic: 512 Time: 3.14124
[05/21/2022-03:08:23] [V] [TRT] Tactic: -32 Time: 3.17585
[05/21/2022-03:08:23] [V] [TRT] Tactic: -64 Time: 3.46803
[05/21/2022-03:08:23] [V] [TRT] Tactic: -128 Time: 3.4736
[05/21/2022-03:08:23] [V] [TRT] Fastest Tactic: 128 Time: 3.13788
[05/21/2022-03:08:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-03:08:23] [V] [TRT] *************** Autotuning format combination: Float(43264,10816:32,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:08:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:23] [V] [TRT] Tactic: 24 Time: 0.523581
[05/21/2022-03:08:23] [V] [TRT] Tactic: 25 Time: 0.471549
[05/21/2022-03:08:23] [V] [TRT] Tactic: 26 Time: 0.466504
[05/21/2022-03:08:23] [V] [TRT] Tactic: 27 Time: 0.451094
[05/21/2022-03:08:23] [V] [TRT] Tactic: 31 Time: 0.525488
[05/21/2022-03:08:23] [V] [TRT] Fastest Tactic: 27 Time: 0.451094
[05/21/2022-03:08:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-03:08:23] [V] [TRT] Tactic: 128 Time: 3.13816
[05/21/2022-03:08:23] [V] [TRT] Tactic: 256 Time: 3.13956
[05/21/2022-03:08:23] [V] [TRT] Tactic: 512 Time: 3.14192
[05/21/2022-03:08:23] [V] [TRT] Tactic: -32 Time: 2.91301
[05/21/2022-03:08:24] [V] [TRT] Tactic: -64 Time: 2.90465
[05/21/2022-03:08:24] [V] [TRT] Tactic: -128 Time: 2.94085
[05/21/2022-03:08:24] [V] [TRT] Fastest Tactic: -64 Time: 2.90465
[05/21/2022-03:08:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:08:24] [V] [TRT] *************** Autotuning format combination: Half(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:24] [V] [TRT] Tactic: 0 Time: 0.985658
[05/21/2022-03:08:24] [V] [TRT] Tactic: 1 Time: 0.697272
[05/21/2022-03:08:24] [V] [TRT] Tactic: 2 Time: 0.65
[05/21/2022-03:08:24] [V] [TRT] Tactic: 3 Time: 0.516068
[05/21/2022-03:08:24] [V] [TRT] Tactic: 4 Time: 0.488535
[05/21/2022-03:08:24] [V] [TRT] Tactic: 5 Time: 0.478314
[05/21/2022-03:08:24] [V] [TRT] Tactic: 6 Time: 0.433229
[05/21/2022-03:08:24] [V] [TRT] Tactic: 7 Time: 0.389433
[05/21/2022-03:08:24] [V] [TRT] Tactic: 8 Time: 0.395677
[05/21/2022-03:08:24] [V] [TRT] Tactic: 9 Time: 0.393223
[05/21/2022-03:08:24] [V] [TRT] Tactic: 28 Time: 0.981673
[05/21/2022-03:08:24] [V] [TRT] Fastest Tactic: 7 Time: 0.389433
[05/21/2022-03:08:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-03:08:24] [V] [TRT] Tactic: 128 Time: 3.0211
[05/21/2022-03:08:24] [V] [TRT] Tactic: 256 Time: 2.97574
[05/21/2022-03:08:24] [V] [TRT] Tactic: 512 Time: 2.75891
[05/21/2022-03:08:24] [V] [TRT] Tactic: -32 Time: 2.92253
[05/21/2022-03:08:24] [V] [TRT] Tactic: -64 Time: 2.89413
[05/21/2022-03:08:24] [V] [TRT] Tactic: -128 Time: 2.92993
[05/21/2022-03:08:24] [V] [TRT] Fastest Tactic: 512 Time: 2.75891
[05/21/2022-03:08:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:08:24] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:08:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:24] [V] [TRT] Tactic: 0 Time: 0.669727
[05/21/2022-03:08:24] [V] [TRT] Tactic: 1 Time: 0.51513
[05/21/2022-03:08:24] [V] [TRT] Tactic: 2 Time: 0.514987
[05/21/2022-03:08:24] [V] [TRT] Tactic: 3 Time: 0.454381
[05/21/2022-03:08:24] [V] [TRT] Tactic: 4 Time: 0.439271
[05/21/2022-03:08:24] [V] [TRT] Tactic: 5 Time: 0.450371
[05/21/2022-03:08:24] [V] [TRT] Tactic: 6 Time: 0.427175
[05/21/2022-03:08:24] [V] [TRT] Tactic: 7 Time: 0.412168
[05/21/2022-03:08:24] [V] [TRT] Tactic: 8 Time: 0.405645
[05/21/2022-03:08:25] [V] [TRT] Tactic: 9 Time: 0.428965
[05/21/2022-03:08:25] [V] [TRT] Tactic: 10 Time: 1.01604
[05/21/2022-03:08:25] [V] [TRT] Tactic: 11 Time: 0.728073
[05/21/2022-03:08:25] [V] [TRT] Tactic: 12 Time: 0.681015
[05/21/2022-03:08:25] [V] [TRT] Tactic: 13 Time: 0.535612
[05/21/2022-03:08:25] [V] [TRT] Tactic: 14 Time: 0.508001
[05/21/2022-03:08:25] [V] [TRT] Tactic: 15 Time: 0.513066
[05/21/2022-03:08:25] [V] [TRT] Tactic: 16 Time: 0.446582
[05/21/2022-03:08:25] [V] [TRT] Tactic: 17 Time: 0.400065
[05/21/2022-03:08:25] [V] [TRT] Tactic: 18 Time: 0.408099
[05/21/2022-03:08:25] [V] [TRT] Tactic: 19 Time: 0.425716
[05/21/2022-03:08:25] [V] [TRT] Tactic: 28 Time: 0.658906
[05/21/2022-03:08:25] [V] [TRT] Tactic: 29 Time: 1.0213
[05/21/2022-03:08:25] [V] [TRT] Fastest Tactic: 17 Time: 0.400065
[05/21/2022-03:08:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) (PointWise)
[05/21/2022-03:08:25] [V] [TRT] Tactic: 128 Time: 3.02018
[05/21/2022-03:08:25] [V] [TRT] Tactic: 256 Time: 2.98458
[05/21/2022-03:08:25] [V] [TRT] Tactic: 512 Time: 2.75578
[05/21/2022-03:08:25] [V] [TRT] Tactic: -32 Time: 2.92398
[05/21/2022-03:08:25] [V] [TRT] Tactic: -64 Time: 2.94558
[05/21/2022-03:08:25] [V] [TRT] Tactic: -128 Time: 2.93138
[05/21/2022-03:08:25] [V] [TRT] Fastest Tactic: 512 Time: 2.75578
[05/21/2022-03:08:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:08:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:25] [V] [TRT] *************** Autotuning format combination: Float(1384448,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:25] [V] [TRT] Tactic: 0 Time: 0.958639
[05/21/2022-03:08:25] [V] [TRT] Tactic: 1 Time: 0.667246
[05/21/2022-03:08:25] [V] [TRT] Tactic: 2 Time: 0.630417
[05/21/2022-03:08:25] [V] [TRT] Tactic: 3 Time: 0.503757
[05/21/2022-03:08:25] [V] [TRT] Tactic: 4 Time: 0.467246
[05/21/2022-03:08:25] [V] [TRT] Tactic: 5 Time: 0.461908
[05/21/2022-03:08:25] [V] [TRT] Tactic: 6 Time: 0.443164
[05/21/2022-03:08:25] [V] [TRT] Tactic: 7 Time: 0.373802
[05/21/2022-03:08:25] [V] [TRT] Tactic: 8 Time: 0.36959
[05/21/2022-03:08:25] [V] [TRT] Tactic: 9 Time: 0.381289
[05/21/2022-03:08:25] [V] [TRT] Tactic: 28 Time: 0.948515
[05/21/2022-03:08:25] [V] [TRT] Fastest Tactic: 8 Time: 0.36959
[05/21/2022-03:08:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-03:08:26] [V] [TRT] Tactic: 128 Time: 3.13827
[05/21/2022-03:08:26] [V] [TRT] Tactic: 256 Time: 3.1397
[05/21/2022-03:08:26] [V] [TRT] Tactic: 512 Time: 3.16927
[05/21/2022-03:08:26] [V] [TRT] Tactic: -32 Time: 2.91245
[05/21/2022-03:08:26] [V] [TRT] Tactic: -64 Time: 2.90481
[05/21/2022-03:08:26] [V] [TRT] Tactic: -128 Time: 2.94048
[05/21/2022-03:08:26] [V] [TRT] Fastest Tactic: -64 Time: 2.90481
[05/21/2022-03:08:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:26] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,13312,128) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:26] [V] [TRT] Tactic: 0 Time: 0.958229
[05/21/2022-03:08:26] [V] [TRT] Tactic: 1 Time: 0.667598
[05/21/2022-03:08:26] [V] [TRT] Tactic: 2 Time: 0.630619
[05/21/2022-03:08:26] [V] [TRT] Tactic: 3 Time: 0.798216
[05/21/2022-03:08:26] [V] [TRT] Tactic: 4 Time: 0.742337
[05/21/2022-03:08:26] [V] [TRT] Tactic: 5 Time: 0.672539
[05/21/2022-03:08:26] [V] [TRT] Tactic: 6 Time: 1.09124
[05/21/2022-03:08:26] [V] [TRT] Tactic: 7 Time: 0.907845
[05/21/2022-03:08:26] [V] [TRT] Tactic: 8 Time: 0.886797
[05/21/2022-03:08:26] [V] [TRT] Tactic: 9 Time: 0.778073
[05/21/2022-03:08:26] [V] [TRT] Tactic: 28 Time: 0.948822
[05/21/2022-03:08:26] [V] [TRT] Fastest Tactic: 2 Time: 0.630619
[05/21/2022-03:08:26] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-03:08:26] [V] [TRT] Tactic: 128 Time: 3.13626
[05/21/2022-03:08:26] [V] [TRT] Tactic: 256 Time: 3.13872
[05/21/2022-03:08:26] [V] [TRT] Tactic: 512 Time: 3.14133
[05/21/2022-03:08:26] [V] [TRT] Tactic: -32 Time: 3.17592
[05/21/2022-03:08:27] [V] [TRT] Tactic: -64 Time: 3.46794
[05/21/2022-03:08:27] [V] [TRT] Tactic: -128 Time: 3.47377
[05/21/2022-03:08:27] [V] [TRT] Fastest Tactic: 128 Time: 3.13626
[05/21/2022-03:08:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-03:08:27] [V] [TRT] *************** Autotuning format combination: Float(43264,10816:32,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:08:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:27] [V] [TRT] Tactic: 24 Time: 0.524271
[05/21/2022-03:08:27] [V] [TRT] Tactic: 25 Time: 0.471601
[05/21/2022-03:08:27] [V] [TRT] Tactic: 26 Time: 0.468464
[05/21/2022-03:08:27] [V] [TRT] Tactic: 27 Time: 0.452148
[05/21/2022-03:08:27] [V] [TRT] Tactic: 31 Time: 0.524922
[05/21/2022-03:08:27] [V] [TRT] Fastest Tactic: 27 Time: 0.452148
[05/21/2022-03:08:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-03:08:27] [V] [TRT] Tactic: 128 Time: 3.13687
[05/21/2022-03:08:27] [V] [TRT] Tactic: 256 Time: 3.13777
[05/21/2022-03:08:27] [V] [TRT] Tactic: 512 Time: 3.13944
[05/21/2022-03:08:27] [V] [TRT] Tactic: -32 Time: 2.9116
[05/21/2022-03:08:27] [V] [TRT] Tactic: -64 Time: 2.90421
[05/21/2022-03:08:27] [V] [TRT] Tactic: -128 Time: 2.94015
[05/21/2022-03:08:27] [V] [TRT] Fastest Tactic: -64 Time: 2.90421
[05/21/2022-03:08:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:08:27] [V] [TRT] *************** Autotuning format combination: Half(1384448,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:27] [V] [TRT] Tactic: 0 Time: 0.986133
[05/21/2022-03:08:27] [V] [TRT] Tactic: 1 Time: 0.697181
[05/21/2022-03:08:27] [V] [TRT] Tactic: 2 Time: 0.649583
[05/21/2022-03:08:27] [V] [TRT] Tactic: 3 Time: 0.516439
[05/21/2022-03:08:27] [V] [TRT] Tactic: 4 Time: 0.488125
[05/21/2022-03:08:27] [V] [TRT] Tactic: 5 Time: 0.478242
[05/21/2022-03:08:27] [V] [TRT] Tactic: 6 Time: 0.43304
[05/21/2022-03:08:27] [V] [TRT] Tactic: 7 Time: 0.389518
[05/21/2022-03:08:27] [V] [TRT] Tactic: 8 Time: 0.395755
[05/21/2022-03:08:27] [V] [TRT] Tactic: 9 Time: 0.392747
[05/21/2022-03:08:27] [V] [TRT] Tactic: 28 Time: 0.981484
[05/21/2022-03:08:27] [V] [TRT] Fastest Tactic: 7 Time: 0.389518
[05/21/2022-03:08:27] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-03:08:27] [V] [TRT] Tactic: 128 Time: 3.02055
[05/21/2022-03:08:28] [V] [TRT] Tactic: 256 Time: 2.98148
[05/21/2022-03:08:28] [V] [TRT] Tactic: 512 Time: 2.75863
[05/21/2022-03:08:28] [V] [TRT] Tactic: -32 Time: 2.91816
[05/21/2022-03:08:28] [V] [TRT] Tactic: -64 Time: 2.89318
[05/21/2022-03:08:28] [V] [TRT] Tactic: -128 Time: 2.92823
[05/21/2022-03:08:28] [V] [TRT] Fastest Tactic: 512 Time: 2.75863
[05/21/2022-03:08:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:08:28] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:28] [V] [TRT] Tactic: 0 Time: 0.670417
[05/21/2022-03:08:28] [V] [TRT] Tactic: 1 Time: 0.514023
[05/21/2022-03:08:28] [V] [TRT] Tactic: 2 Time: 0.515605
[05/21/2022-03:08:28] [V] [TRT] Tactic: 3 Time: 0.452956
[05/21/2022-03:08:28] [V] [TRT] Tactic: 4 Time: 0.439486
[05/21/2022-03:08:28] [V] [TRT] Tactic: 5 Time: 0.4503
[05/21/2022-03:08:28] [V] [TRT] Tactic: 6 Time: 0.426244
[05/21/2022-03:08:28] [V] [TRT] Tactic: 7 Time: 0.410514
[05/21/2022-03:08:28] [V] [TRT] Tactic: 8 Time: 0.405208
[05/21/2022-03:08:28] [V] [TRT] Tactic: 9 Time: 0.430592
[05/21/2022-03:08:28] [V] [TRT] Tactic: 10 Time: 1.0161
[05/21/2022-03:08:28] [V] [TRT] Tactic: 11 Time: 0.727663
[05/21/2022-03:08:28] [V] [TRT] Tactic: 12 Time: 0.680449
[05/21/2022-03:08:28] [V] [TRT] Tactic: 13 Time: 0.534922
[05/21/2022-03:08:28] [V] [TRT] Tactic: 14 Time: 0.508412
[05/21/2022-03:08:28] [V] [TRT] Tactic: 15 Time: 0.513496
[05/21/2022-03:08:28] [V] [TRT] Tactic: 16 Time: 0.447181
[05/21/2022-03:08:28] [V] [TRT] Tactic: 17 Time: 0.399883
[05/21/2022-03:08:28] [V] [TRT] Tactic: 18 Time: 0.40735
[05/21/2022-03:08:28] [V] [TRT] Tactic: 19 Time: 0.425931
[05/21/2022-03:08:28] [V] [TRT] Tactic: 28 Time: 0.65819
[05/21/2022-03:08:28] [V] [TRT] Tactic: 29 Time: 1.02105
[05/21/2022-03:08:28] [V] [TRT] Fastest Tactic: 17 Time: 0.399883
[05/21/2022-03:08:28] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) (PointWise)
[05/21/2022-03:08:28] [V] [TRT] Tactic: 128 Time: 3.02076
[05/21/2022-03:08:28] [V] [TRT] Tactic: 256 Time: 2.97672
[05/21/2022-03:08:28] [V] [TRT] Tactic: 512 Time: 2.7721
[05/21/2022-03:08:29] [V] [TRT] Tactic: -32 Time: 2.91939
[05/21/2022-03:08:29] [V] [TRT] Tactic: -64 Time: 2.89438
[05/21/2022-03:08:29] [V] [TRT] Tactic: -128 Time: 2.93013
[05/21/2022-03:08:29] [V] [TRT] Fastest Tactic: 512 Time: 2.7721
[05/21/2022-03:08:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:08:29] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:29] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:29] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:08:29] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:29] [V] [TRT] Tactic: 0 Time: 1.56066
[05/21/2022-03:08:29] [V] [TRT] Tactic: 1 Time: 1.34145
[05/21/2022-03:08:29] [V] [TRT] Tactic: 2 Time: 2.37171
[05/21/2022-03:08:29] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553795584, available: 536870912
[05/21/2022-03:08:29] [V] [TRT] Tactic: 5 Time: 3.78249
[05/21/2022-03:08:29] [V] [TRT] Fastest Tactic: 1 Time: 1.34145
[05/21/2022-03:08:29] [V] [TRT] Setting workspace to 553795584enables more tactics for profiling
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:08:29] [V] [TRT] Tactic: 1062367460111450758 Time: 0.928223
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:08:29] [V] [TRT] Tactic: 1698681053543049347 Time: 0.847409
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:08:29] [V] [TRT] Tactic: 4501471010995462441 Time: 1.37453
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:08:29] [V] [TRT] Tactic: 5137655947464784826 Time: 0.676549
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:08:29] [V] [TRT] Tactic: 5288347012147084929 Time: 1.38656
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:08:29] [V] [TRT] Tactic: 5326823351883942011 Time: 1.30745
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:08:29] [V] [TRT] Tactic: 5500448035057547314 Time: 0.745417
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:08:29] [V] [TRT] Tactic: 6645123197870846056 Time: 0.689811
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:08:29] [V] [TRT] Tactic: 7144526460361122478 Time: 0.959479
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:08:29] [V] [TRT] Tactic: -8262349710178828730 Time: 1.41117
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:08:29] [V] [TRT] Tactic: -6576203419454146580 Time: 0.8725
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:08:29] [V] [TRT] Tactic: -4787320710726427159 Time: 0.990488
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:08:29] [V] [TRT] Tactic: -3456450830548107839 Time: 0.89959
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:08:29] [V] [TRT] Tactic: -1218658103698133241 Time: 0.794199
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:08:29] [V] [TRT] Tactic: -836875257600482091 Time: 0.779831
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:08:29] [V] [TRT] Tactic: -410470605513481746 Time: 1.3597
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:08:29] [V] [TRT] Tactic: -377491875521947884 Time: 1.38859
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:08:29] [V] [TRT] Tactic: -37215280111360163 Time: 0.671218
[05/21/2022-03:08:29] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.671218
[05/21/2022-03:08:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:08:29] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:29] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:29] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:29] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:08:29] [V] [TRT] Tactic: 3886731678879822788 Time: 0.810964
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:08:29] [V] [TRT] Tactic: 6629944304117643200 Time: 2.06768
[05/21/2022-03:08:29] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:08:30] [V] [TRT] Tactic: -9153228964338181824 Time: 2.0832
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:08:30] [V] [TRT] Tactic: -7394439838318485025 Time: 0.810417
[05/21/2022-03:08:30] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.810417
[05/21/2022-03:08:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:08:30] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:30] [V] [TRT] Tactic: 0 Time: 1.53699
[05/21/2022-03:08:30] [V] [TRT] Tactic: 1 Time: 1.09219
[05/21/2022-03:08:30] [V] [TRT] Tactic: 2 Time: 2.29781
[05/21/2022-03:08:30] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553795584, available: 536870912
[05/21/2022-03:08:30] [V] [TRT] Tactic: 5 Time: 3.65593
[05/21/2022-03:08:30] [V] [TRT] Fastest Tactic: 1 Time: 1.09219
[05/21/2022-03:08:30] [V] [TRT] Setting workspace to 553795584enables more tactics for profiling
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:08:30] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:30] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CublasConvolution)
[05/21/2022-03:08:30] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: 016_convolutional + 016_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:08:30] [V] [TRT] Tactic: 3066127711859985668 Time: 0.503808
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:08:30] [V] [TRT] Tactic: 3564772625446233998 Time: 0.538372
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:08:30] [V] [TRT] Tactic: 5319956359050645452 Time: 0.515963
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:08:30] [V] [TRT] Tactic: 7205456024582378848 Time: 0.397877
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:08:30] [V] [TRT] Tactic: 8163473458334948789 Time: 0.386283
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:08:30] [V] [TRT] Tactic: -4212163711445252890 Time: 0.776022
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:08:30] [V] [TRT] Tactic: -3898373634979201110 Time: 0.786172
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:08:30] [V] [TRT] Tactic: -2409163523992614473 Time: 0.389323
[05/21/2022-03:08:30] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:08:30] [V] [TRT] Tactic: -1716393687483585322 Time: 0.768802
[05/21/2022-03:08:30] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 0.386283
[05/21/2022-03:08:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:08:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:30] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:30] [V] [TRT] Tactic: 0 Time: 0.755045
[05/21/2022-03:08:30] [V] [TRT] Tactic: 1 Time: 0.558841
[05/21/2022-03:08:30] [V] [TRT] Tactic: 2 Time: 0.529088
[05/21/2022-03:08:30] [V] [TRT] Tactic: 3 Time: 0.465781
[05/21/2022-03:08:30] [V] [TRT] Tactic: 4 Time: 0.398477
[05/21/2022-03:08:30] [V] [TRT] Tactic: 5 Time: 0.410924
[05/21/2022-03:08:30] [V] [TRT] Tactic: 6 Time: 0.424199
[05/21/2022-03:08:30] [V] [TRT] Tactic: 7 Time: 0.345351
[05/21/2022-03:08:30] [V] [TRT] Tactic: 8 Time: 0.3275
[05/21/2022-03:08:30] [V] [TRT] Tactic: 9 Time: 0.35153
[05/21/2022-03:08:30] [V] [TRT] Tactic: 28 Time: 0.742305
[05/21/2022-03:08:30] [V] [TRT] Fastest Tactic: 8 Time: 0.3275
[05/21/2022-03:08:30] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-03:08:30] [V] [TRT] Tactic: 128 Time: 2.78052
[05/21/2022-03:08:30] [V] [TRT] Tactic: 256 Time: 2.78663
[05/21/2022-03:08:30] [V] [TRT] Tactic: 512 Time: 2.79135
[05/21/2022-03:08:30] [V] [TRT] Tactic: -32 Time: 2.90294
[05/21/2022-03:08:30] [V] [TRT] Tactic: -64 Time: 2.88355
[05/21/2022-03:08:31] [V] [TRT] Tactic: -128 Time: 2.89506
[05/21/2022-03:08:31] [V] [TRT] Fastest Tactic: 128 Time: 2.78052
[05/21/2022-03:08:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:31] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:31] [V] [TRT] Tactic: 0 Time: 0.754981
[05/21/2022-03:08:31] [V] [TRT] Tactic: 1 Time: 0.558834
[05/21/2022-03:08:31] [V] [TRT] Tactic: 2 Time: 0.529687
[05/21/2022-03:08:31] [V] [TRT] Tactic: 3 Time: 0.464922
[05/21/2022-03:08:31] [V] [TRT] Tactic: 4 Time: 0.397572
[05/21/2022-03:08:31] [V] [TRT] Tactic: 5 Time: 0.410488
[05/21/2022-03:08:31] [V] [TRT] Tactic: 6 Time: 0.424076
[05/21/2022-03:08:31] [V] [TRT] Tactic: 7 Time: 0.348164
[05/21/2022-03:08:31] [V] [TRT] Tactic: 8 Time: 0.327259
[05/21/2022-03:08:31] [V] [TRT] Tactic: 9 Time: 0.351107
[05/21/2022-03:08:31] [V] [TRT] Tactic: 28 Time: 0.742331
[05/21/2022-03:08:31] [V] [TRT] Fastest Tactic: 8 Time: 0.327259
[05/21/2022-03:08:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-03:08:31] [V] [TRT] Tactic: 128 Time: 2.78046
[05/21/2022-03:08:31] [V] [TRT] Tactic: 256 Time: 2.78635
[05/21/2022-03:08:31] [V] [TRT] Tactic: 512 Time: 2.7921
[05/21/2022-03:08:31] [V] [TRT] Tactic: -32 Time: 2.89778
[05/21/2022-03:08:31] [V] [TRT] Tactic: -64 Time: 2.95913
[05/21/2022-03:08:31] [V] [TRT] Tactic: -128 Time: 2.89472
[05/21/2022-03:08:31] [V] [TRT] Fastest Tactic: 128 Time: 2.78046
[05/21/2022-03:08:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:31] [V] [TRT] *************** Autotuning format combination: Float(21632,10816:32,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:08:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:31] [V] [TRT] Tactic: 24 Time: 0.5211
[05/21/2022-03:08:31] [V] [TRT] Tactic: 25 Time: 0.473958
[05/21/2022-03:08:31] [V] [TRT] Tactic: 26 Time: 0.469147
[05/21/2022-03:08:31] [V] [TRT] Tactic: 27 Time: 0.451934
[05/21/2022-03:08:31] [V] [TRT] Tactic: 31 Time: 0.517982
[05/21/2022-03:08:31] [V] [TRT] Fastest Tactic: 27 Time: 0.451934
[05/21/2022-03:08:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-03:08:31] [V] [TRT] Tactic: 128 Time: 2.78019
[05/21/2022-03:08:31] [V] [TRT] Tactic: 256 Time: 2.78763
[05/21/2022-03:08:31] [V] [TRT] Tactic: 512 Time: 2.79214
[05/21/2022-03:08:32] [V] [TRT] Tactic: -32 Time: 2.89881
[05/21/2022-03:08:32] [V] [TRT] Tactic: -64 Time: 2.88251
[05/21/2022-03:08:32] [V] [TRT] Tactic: -128 Time: 2.8947
[05/21/2022-03:08:32] [V] [TRT] Fastest Tactic: 128 Time: 2.78019
[05/21/2022-03:08:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:08:32] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:32] [V] [TRT] Tactic: 0 Time: 0.769726
[05/21/2022-03:08:32] [V] [TRT] Tactic: 1 Time: 0.583919
[05/21/2022-03:08:32] [V] [TRT] Tactic: 2 Time: 0.543522
[05/21/2022-03:08:32] [V] [TRT] Tactic: 3 Time: 0.467044
[05/21/2022-03:08:32] [V] [TRT] Tactic: 4 Time: 0.422702
[05/21/2022-03:08:32] [V] [TRT] Tactic: 5 Time: 0.43237
[05/21/2022-03:08:32] [V] [TRT] Tactic: 6 Time: 0.413392
[05/21/2022-03:08:32] [V] [TRT] Tactic: 7 Time: 0.361244
[05/21/2022-03:08:32] [V] [TRT] Tactic: 8 Time: 0.361302
[05/21/2022-03:08:32] [V] [TRT] Tactic: 9 Time: 0.372871
[05/21/2022-03:08:32] [V] [TRT] Tactic: 28 Time: 0.771868
[05/21/2022-03:08:32] [V] [TRT] Fastest Tactic: 7 Time: 0.361244
[05/21/2022-03:08:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-03:08:32] [V] [TRT] Tactic: 128 Time: 2.86289
[05/21/2022-03:08:32] [V] [TRT] Tactic: 256 Time: 2.83056
[05/21/2022-03:08:32] [V] [TRT] Tactic: 512 Time: 2.66166
[05/21/2022-03:08:32] [V] [TRT] Tactic: -32 Time: 2.90687
[05/21/2022-03:08:32] [V] [TRT] Tactic: -64 Time: 2.86561
[05/21/2022-03:08:32] [V] [TRT] Tactic: -128 Time: 2.87824
[05/21/2022-03:08:32] [V] [TRT] Fastest Tactic: 512 Time: 2.66166
[05/21/2022-03:08:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:08:32] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:32] [V] [TRT] Tactic: 0 Time: 0.592122
[05/21/2022-03:08:32] [V] [TRT] Tactic: 1 Time: 0.478359
[05/21/2022-03:08:32] [V] [TRT] Tactic: 2 Time: 0.479694
[05/21/2022-03:08:32] [V] [TRT] Tactic: 3 Time: 0.438776
[05/21/2022-03:08:32] [V] [TRT] Tactic: 4 Time: 0.426478
[05/21/2022-03:08:32] [V] [TRT] Tactic: 5 Time: 0.433548
[05/21/2022-03:08:32] [V] [TRT] Tactic: 6 Time: 0.419818
[05/21/2022-03:08:32] [V] [TRT] Tactic: 7 Time: 0.406953
[05/21/2022-03:08:32] [V] [TRT] Tactic: 8 Time: 0.398444
[05/21/2022-03:08:32] [V] [TRT] Tactic: 9 Time: 0.422663
[05/21/2022-03:08:32] [V] [TRT] Tactic: 10 Time: 0.810697
[05/21/2022-03:08:32] [V] [TRT] Tactic: 11 Time: 0.603262
[05/21/2022-03:08:32] [V] [TRT] Tactic: 12 Time: 0.572754
[05/21/2022-03:08:32] [V] [TRT] Tactic: 13 Time: 0.474649
[05/21/2022-03:08:33] [V] [TRT] Tactic: 14 Time: 0.43944
[05/21/2022-03:08:33] [V] [TRT] Tactic: 15 Time: 0.451172
[05/21/2022-03:08:33] [V] [TRT] Tactic: 16 Time: 0.41888
[05/21/2022-03:08:33] [V] [TRT] Tactic: 17 Time: 0.369356
[05/21/2022-03:08:33] [V] [TRT] Tactic: 18 Time: 0.367324
[05/21/2022-03:08:33] [V] [TRT] Tactic: 19 Time: 0.397064
[05/21/2022-03:08:33] [V] [TRT] Tactic: 28 Time: 0.580013
[05/21/2022-03:08:33] [V] [TRT] Tactic: 29 Time: 0.796868
[05/21/2022-03:08:33] [V] [TRT] Fastest Tactic: 18 Time: 0.367324
[05/21/2022-03:08:33] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) (PointWise)
[05/21/2022-03:08:33] [V] [TRT] Tactic: 128 Time: 2.86357
[05/21/2022-03:08:33] [V] [TRT] Tactic: 256 Time: 2.83802
[05/21/2022-03:08:33] [V] [TRT] Tactic: 512 Time: 2.64818
[05/21/2022-03:08:33] [V] [TRT] Tactic: -32 Time: 2.90542
[05/21/2022-03:08:33] [V] [TRT] Tactic: -64 Time: 2.86514
[05/21/2022-03:08:33] [V] [TRT] Tactic: -128 Time: 2.87804
[05/21/2022-03:08:33] [V] [TRT] Fastest Tactic: 512 Time: 2.64818
[05/21/2022-03:08:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:08:33] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:33] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:33] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:33] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:08:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:33] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:33] [V] [TRT] Tactic: 0 Time: 14.426
[05/21/2022-03:08:33] [V] [TRT] Tactic: 1 Time: 5.15132
[05/21/2022-03:08:34] [V] [TRT] Tactic: 2 Time: 14.7296
[05/21/2022-03:08:34] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553926656, available: 536870912
[05/21/2022-03:08:34] [V] [TRT] Tactic: 5 Time: 41.1899
[05/21/2022-03:08:34] [V] [TRT] Tactic: 6 Time: 3.73296
[05/21/2022-03:08:34] [V] [TRT] Fastest Tactic: 6 Time: 3.73296
[05/21/2022-03:08:34] [V] [TRT] Setting workspace to 553926656enables more tactics for profiling
[05/21/2022-03:08:34] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:34] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:08:35] [V] [TRT] Tactic: 1062367460111450758 Time: 5.2204
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:08:35] [V] [TRT] Tactic: 1754984623894446479 Time: 5.83456
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:08:35] [V] [TRT] Tactic: 3611739942397549984 Time: 8.48707
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:08:35] [V] [TRT] Tactic: 3827454225649558724 Time: 4.72115
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:08:35] [V] [TRT] Tactic: 4337000649858996379 Time: 4.29513
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:08:35] [V] [TRT] Tactic: 4501471010995462441 Time: 8.46381
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:08:35] [V] [TRT] Tactic: 5137655947464784826 Time: 4.14105
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:08:35] [V] [TRT] Tactic: 5288347012147084929 Time: 8.3141
[05/21/2022-03:08:35] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:08:36] [V] [TRT] Tactic: 5921334924264294896 Time: 3.28177
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:08:36] [V] [TRT] Tactic: 6645123197870846056 Time: 4.24416
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:08:36] [V] [TRT] Tactic: 7144526460361122478 Time: 5.33772
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:08:36] [V] [TRT] Tactic: 7852627285308570038 Time: 4.79187
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:08:36] [V] [TRT] Tactic: -9137461792520977713 Time: 8.48451
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:08:36] [V] [TRT] Tactic: -8776506421218919509 Time: 4.79131
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:08:36] [V] [TRT] Tactic: -8262349710178828730 Time: 8.44075
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:08:36] [V] [TRT] Tactic: -8133971918129952780 Time: 4.66416
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:08:36] [V] [TRT] Tactic: -6092040395344634144 Time: 5.48027
[05/21/2022-03:08:36] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:08:37] [V] [TRT] Tactic: -4787320710726427159 Time: 5.74591
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:08:37] [V] [TRT] Tactic: -3456450830548107839 Time: 4.86229
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:08:37] [V] [TRT] Tactic: -2318106587342035239 Time: 4.83885
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:08:37] [V] [TRT] Tactic: -1343271414618805657 Time: 3.0707
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:08:37] [V] [TRT] Tactic: -1218658103698133241 Time: 4.60413
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:08:37] [V] [TRT] Tactic: -836875257600482091 Time: 4.48622
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:08:37] [V] [TRT] Tactic: -410470605513481746 Time: 8.20714
[05/21/2022-03:08:37] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 3.0707
[05/21/2022-03:08:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:08:37] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:37] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:37] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:37] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:08:37] [V] [TRT] Tactic: -9153228964338181824 Time: 5.90855
[05/21/2022-03:08:37] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:08:37] [V] [TRT] Tactic: -7394439838318485025 Time: 4.15758
[05/21/2022-03:08:37] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.15758
[05/21/2022-03:08:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:08:37] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:37] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:38] [V] [TRT] Tactic: 0 Time: 14.3785
[05/21/2022-03:08:38] [V] [TRT] Tactic: 1 Time: 5.41418
[05/21/2022-03:08:38] [V] [TRT] Tactic: 2 Time: 13.8912
[05/21/2022-03:08:38] [V] [TRT] Tactic: 4 skipped. Scratch requested: 553926656, available: 536870912
[05/21/2022-03:08:39] [V] [TRT] Tactic: 5 Time: 41.5368
[05/21/2022-03:08:39] [V] [TRT] Tactic: 6 Time: 4.91296
[05/21/2022-03:08:39] [V] [TRT] Fastest Tactic: 6 Time: 4.91296
[05/21/2022-03:08:39] [V] [TRT] Setting workspace to 553926656enables more tactics for profiling
[05/21/2022-03:08:39] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:39] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-03:08:39] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:39] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:39] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:39] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:39] [V] [TRT] --------------- Timing Runner: 017_convolutional + 017_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:08:39] [V] [TRT] Tactic: 3564772625446233998 Time: 2.69807
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:08:39] [V] [TRT] Tactic: 3650389455493082349 Time: 2.79524
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:08:39] [V] [TRT] Tactic: 4772821744921268633 Time: 1.68086
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:08:39] [V] [TRT] Tactic: 5319956359050645452 Time: 2.47182
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:08:39] [V] [TRT] Tactic: 7205456024582378848 Time: 2.1685
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:08:39] [V] [TRT] Tactic: -6490690591794140522 Time: 2.21675
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:08:39] [V] [TRT] Tactic: -4686027666808657977 Time: 4.32714
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:08:39] [V] [TRT] Tactic: -4212163711445252890 Time: 4.17273
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:08:39] [V] [TRT] Tactic: -3898373634979201110 Time: 4.28966
[05/21/2022-03:08:39] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:08:39] [V] [TRT] Tactic: -2409163523992614473 Time: 2.11515
[05/21/2022-03:08:39] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 1.68086
[05/21/2022-03:08:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:08:39] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:39] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1), Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-03:08:40] [V] [TRT] Tactic: 0 Time: 0.798919
[05/21/2022-03:08:40] [V] [TRT] Tactic: 1 Time: 0.601992
[05/21/2022-03:08:40] [V] [TRT] Tactic: 2 Time: 0.597741
[05/21/2022-03:08:40] [V] [TRT] Tactic: 3 Time: 0.519453
[05/21/2022-03:08:40] [V] [TRT] Tactic: 4 Time: 0.464564
[05/21/2022-03:08:40] [V] [TRT] Tactic: 5 Time: 0.447337
[05/21/2022-03:08:40] [V] [TRT] Tactic: 6 Time: 0.506472
[05/21/2022-03:08:40] [V] [TRT] Tactic: 7 Time: 0.42776
[05/21/2022-03:08:40] [V] [TRT] Tactic: 8 Time: 0.417292
[05/21/2022-03:08:40] [V] [TRT] Tactic: 9 Time: 0.427441
[05/21/2022-03:08:40] [V] [TRT] Tactic: 28 Time: 0.792982
[05/21/2022-03:08:40] [V] [TRT] Fastest Tactic: 8 Time: 0.417292
[05/21/2022-03:08:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-03:08:40] [V] [TRT] Tactic: 128 Time: 3.21973
[05/21/2022-03:08:40] [V] [TRT] Tactic: 256 Time: 3.2234
[05/21/2022-03:08:40] [V] [TRT] Tactic: 512 Time: 3.23048
[05/21/2022-03:08:40] [V] [TRT] Tactic: -32 Time: 3.39128
[05/21/2022-03:08:40] [V] [TRT] Tactic: -64 Time: 3.35874
[05/21/2022-03:08:40] [V] [TRT] Tactic: -128 Time: 3.37132
[05/21/2022-03:08:40] [V] [TRT] Fastest Tactic: 128 Time: 3.21973
[05/21/2022-03:08:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:40] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64), Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-03:08:40] [V] [TRT] Tactic: 0 Time: 0.799193
[05/21/2022-03:08:40] [V] [TRT] Tactic: 1 Time: 0.600351
[05/21/2022-03:08:40] [V] [TRT] Tactic: 2 Time: 0.595403
[05/21/2022-03:08:40] [V] [TRT] Tactic: 3 Time: 0.519811
[05/21/2022-03:08:40] [V] [TRT] Tactic: 4 Time: 0.465059
[05/21/2022-03:08:40] [V] [TRT] Tactic: 5 Time: 0.447161
[05/21/2022-03:08:40] [V] [TRT] Tactic: 6 Time: 0.504993
[05/21/2022-03:08:40] [V] [TRT] Tactic: 7 Time: 0.426797
[05/21/2022-03:08:40] [V] [TRT] Tactic: 8 Time: 0.415065
[05/21/2022-03:08:40] [V] [TRT] Tactic: 9 Time: 0.434271
[05/21/2022-03:08:40] [V] [TRT] Tactic: 28 Time: 0.792923
[05/21/2022-03:08:40] [V] [TRT] Fastest Tactic: 8 Time: 0.415065
[05/21/2022-03:08:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-03:08:41] [V] [TRT] Tactic: 128 Time: 3.21865
[05/21/2022-03:08:41] [V] [TRT] Tactic: 256 Time: 3.22436
[05/21/2022-03:08:41] [V] [TRT] Tactic: 512 Time: 3.22951
[05/21/2022-03:08:41] [V] [TRT] Tactic: -32 Time: 3.39217
[05/21/2022-03:08:41] [V] [TRT] Tactic: -64 Time: 3.35933
[05/21/2022-03:08:41] [V] [TRT] Tactic: -128 Time: 3.37104
[05/21/2022-03:08:41] [V] [TRT] Fastest Tactic: 128 Time: 3.21865
[05/21/2022-03:08:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:41] [V] [TRT] *************** Autotuning format combination: Float(21632,10816:32,104,1), Float(21632,10816:32,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:08:41] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-03:08:41] [V] [TRT] Tactic: 24 Time: 0.740885
[05/21/2022-03:08:41] [V] [TRT] Tactic: 25 Time: 0.633665
[05/21/2022-03:08:41] [V] [TRT] Tactic: 26 Time: 0.631165
[05/21/2022-03:08:41] [V] [TRT] Tactic: 27 Time: 0.613633
[05/21/2022-03:08:41] [V] [TRT] Tactic: 31 Time: 0.74571
[05/21/2022-03:08:41] [V] [TRT] Fastest Tactic: 27 Time: 0.613633
[05/21/2022-03:08:41] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-03:08:41] [V] [TRT] Tactic: 128 Time: 3.21927
[05/21/2022-03:08:41] [V] [TRT] Tactic: 256 Time: 3.22459
[05/21/2022-03:08:41] [V] [TRT] Tactic: 512 Time: 3.23047
[05/21/2022-03:08:41] [V] [TRT] Tactic: -32 Time: 3.39109
[05/21/2022-03:08:41] [V] [TRT] Tactic: -64 Time: 3.36049
[05/21/2022-03:08:41] [V] [TRT] Tactic: -128 Time: 3.37223
[05/21/2022-03:08:41] [V] [TRT] Fastest Tactic: 128 Time: 3.21927
[05/21/2022-03:08:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:08:41] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1), Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:41] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-03:08:42] [V] [TRT] Tactic: 0 Time: 0.814915
[05/21/2022-03:08:42] [V] [TRT] Tactic: 1 Time: 0.613158
[05/21/2022-03:08:42] [V] [TRT] Tactic: 2 Time: 0.580104
[05/21/2022-03:08:42] [V] [TRT] Tactic: 3 Time: 0.489733
[05/21/2022-03:08:42] [V] [TRT] Tactic: 4 Time: 0.489915
[05/21/2022-03:08:42] [V] [TRT] Tactic: 5 Time: 0.46082
[05/21/2022-03:08:42] [V] [TRT] Tactic: 6 Time: 0.435287
[05/21/2022-03:08:42] [V] [TRT] Tactic: 7 Time: 0.422461
[05/21/2022-03:08:42] [V] [TRT] Tactic: 8 Time: 0.401244
[05/21/2022-03:08:42] [V] [TRT] Tactic: 9 Time: 0.410781
[05/21/2022-03:08:42] [V] [TRT] Tactic: 28 Time: 0.805091
[05/21/2022-03:08:42] [V] [TRT] Fastest Tactic: 8 Time: 0.401244
[05/21/2022-03:08:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-03:08:42] [V] [TRT] Tactic: 128 Time: 3.33538
[05/21/2022-03:08:42] [V] [TRT] Tactic: 256 Time: 3.30021
[05/21/2022-03:08:42] [V] [TRT] Tactic: 512 Time: 3.11238
[05/21/2022-03:08:42] [V] [TRT] Tactic: -32 Time: 3.45969
[05/21/2022-03:08:42] [V] [TRT] Tactic: -64 Time: 3.40379
[05/21/2022-03:08:42] [V] [TRT] Tactic: -128 Time: 3.41395
[05/21/2022-03:08:42] [V] [TRT] Fastest Tactic: 512 Time: 3.11238
[05/21/2022-03:08:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:42] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1), Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:42] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWiseV2)
[05/21/2022-03:08:42] [V] [TRT] Tactic: 0 Time: 0.685013
[05/21/2022-03:08:42] [V] [TRT] Tactic: 1 Time: 0.622279
[05/21/2022-03:08:42] [V] [TRT] Tactic: 2 Time: 0.589036
[05/21/2022-03:08:42] [V] [TRT] Tactic: 3 Time: 0.571895
[05/21/2022-03:08:42] [V] [TRT] Tactic: 4 Time: 0.5575
[05/21/2022-03:08:42] [V] [TRT] Tactic: 5 Time: 0.548125
[05/21/2022-03:08:42] [V] [TRT] Tactic: 6 Time: 0.546888
[05/21/2022-03:08:42] [V] [TRT] Tactic: 7 Time: 0.54179
[05/21/2022-03:08:42] [V] [TRT] Tactic: 8 Time: 0.618307
[05/21/2022-03:08:42] [V] [TRT] Tactic: 9 Time: 0.715807
[05/21/2022-03:08:42] [V] [TRT] Tactic: 10 Time: 0.872643
[05/21/2022-03:08:42] [V] [TRT] Tactic: 11 Time: 0.681627
[05/21/2022-03:08:42] [V] [TRT] Tactic: 12 Time: 0.652285
[05/21/2022-03:08:42] [V] [TRT] Tactic: 13 Time: 0.542246
[05/21/2022-03:08:43] [V] [TRT] Tactic: 14 Time: 0.567246
[05/21/2022-03:08:43] [V] [TRT] Tactic: 15 Time: 0.535996
[05/21/2022-03:08:43] [V] [TRT] Tactic: 16 Time: 0.479961
[05/21/2022-03:08:43] [V] [TRT] Tactic: 17 Time: 0.494948
[05/21/2022-03:08:43] [V] [TRT] Tactic: 18 Time: 0.479974
[05/21/2022-03:08:43] [V] [TRT] Tactic: 19 Time: 0.493464
[05/21/2022-03:08:43] [V] [TRT] Tactic: 28 Time: 0.680787
[05/21/2022-03:08:43] [V] [TRT] Tactic: 29 Time: 0.8561
[05/21/2022-03:08:43] [V] [TRT] Fastest Tactic: 16 Time: 0.479961
[05/21/2022-03:08:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) (PointWise)
[05/21/2022-03:08:43] [V] [TRT] Tactic: 128 Time: 3.33579
[05/21/2022-03:08:43] [V] [TRT] Tactic: 256 Time: 3.30251
[05/21/2022-03:08:43] [V] [TRT] Tactic: 512 Time: 3.1165
[05/21/2022-03:08:43] [V] [TRT] Tactic: -32 Time: 3.46257
[05/21/2022-03:08:43] [V] [TRT] Tactic: -64 Time: 3.40104
[05/21/2022-03:08:43] [V] [TRT] Tactic: -128 Time: 3.41357
[05/21/2022-03:08:43] [V] [TRT] Fastest Tactic: 512 Time: 3.1165
[05/21/2022-03:08:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 16
[05/21/2022-03:08:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(21632,10816:32,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1), Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64), Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(21632,10816:32,104,1), Float(21632,10816:32,104,1) -> Float(21632,10816:32,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1), Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1), Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(692224,1,6656,64) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(692224,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(346112,10816:2,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:43] [V] [TRT] *************** Autotuning format combination: Float(692224,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:08:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:43] [V] [TRT] Tactic: 0 Time: 0.958307
[05/21/2022-03:08:43] [V] [TRT] Tactic: 1 Time: 0.6672
[05/21/2022-03:08:43] [V] [TRT] Tactic: 2 Time: 0.630319
[05/21/2022-03:08:43] [V] [TRT] Tactic: 3 Time: 0.504271
[05/21/2022-03:08:43] [V] [TRT] Tactic: 4 Time: 0.467083
[05/21/2022-03:08:43] [V] [TRT] Tactic: 5 Time: 0.461413
[05/21/2022-03:08:43] [V] [TRT] Tactic: 6 Time: 0.439954
[05/21/2022-03:08:43] [V] [TRT] Tactic: 7 Time: 0.373906
[05/21/2022-03:08:43] [V] [TRT] Tactic: 8 Time: 0.370039
[05/21/2022-03:08:43] [V] [TRT] Tactic: 9 Time: 0.381289
[05/21/2022-03:08:43] [V] [TRT] Tactic: 28 Time: 0.948359
[05/21/2022-03:08:43] [V] [TRT] Fastest Tactic: 8 Time: 0.370039
[05/21/2022-03:08:43] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-03:08:43] [V] [TRT] Tactic: 128 Time: 3.13818
[05/21/2022-03:08:44] [V] [TRT] Tactic: 256 Time: 3.1387
[05/21/2022-03:08:44] [V] [TRT] Tactic: 512 Time: 3.14128
[05/21/2022-03:08:44] [V] [TRT] Tactic: -32 Time: 2.91117
[05/21/2022-03:08:44] [V] [TRT] Tactic: -64 Time: 2.90615
[05/21/2022-03:08:44] [V] [TRT] Tactic: -128 Time: 2.94006
[05/21/2022-03:08:44] [V] [TRT] Fastest Tactic: -64 Time: 2.90615
[05/21/2022-03:08:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:08:44] [V] [TRT] *************** Autotuning format combination: Float(692224,1,6656,64) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:08:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:44] [V] [TRT] Tactic: 0 Time: 0.958398
[05/21/2022-03:08:44] [V] [TRT] Tactic: 1 Time: 0.667741
[05/21/2022-03:08:44] [V] [TRT] Tactic: 2 Time: 0.631295
[05/21/2022-03:08:44] [V] [TRT] Tactic: 3 Time: 0.798834
[05/21/2022-03:08:44] [V] [TRT] Tactic: 4 Time: 0.742383
[05/21/2022-03:08:44] [V] [TRT] Tactic: 5 Time: 0.672396
[05/21/2022-03:08:44] [V] [TRT] Tactic: 6 Time: 1.09202
[05/21/2022-03:08:44] [V] [TRT] Tactic: 7 Time: 0.90765
[05/21/2022-03:08:44] [V] [TRT] Tactic: 8 Time: 0.886608
[05/21/2022-03:08:44] [V] [TRT] Tactic: 9 Time: 0.7786
[05/21/2022-03:08:44] [V] [TRT] Tactic: 28 Time: 0.948171
[05/21/2022-03:08:44] [V] [TRT] Fastest Tactic: 2 Time: 0.631295
[05/21/2022-03:08:44] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-03:08:44] [V] [TRT] Tactic: 128 Time: 3.13608
[05/21/2022-03:08:44] [V] [TRT] Tactic: 256 Time: 3.13734
[05/21/2022-03:08:44] [V] [TRT] Tactic: 512 Time: 3.14205
[05/21/2022-03:08:44] [V] [TRT] Tactic: -32 Time: 3.17435
[05/21/2022-03:08:44] [V] [TRT] Tactic: -64 Time: 3.46743
[05/21/2022-03:08:45] [V] [TRT] Tactic: -128 Time: 3.47352
[05/21/2022-03:08:45] [V] [TRT] Fastest Tactic: 128 Time: 3.13608
[05/21/2022-03:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 2
[05/21/2022-03:08:45] [V] [TRT] *************** Autotuning format combination: Float(21632,10816:32,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:08:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:45] [V] [TRT] Tactic: 24 Time: 0.522787
[05/21/2022-03:08:45] [V] [TRT] Tactic: 25 Time: 0.471419
[05/21/2022-03:08:45] [V] [TRT] Tactic: 26 Time: 0.465885
[05/21/2022-03:08:45] [V] [TRT] Tactic: 27 Time: 0.453372
[05/21/2022-03:08:45] [V] [TRT] Tactic: 31 Time: 0.522734
[05/21/2022-03:08:45] [V] [TRT] Fastest Tactic: 27 Time: 0.453372
[05/21/2022-03:08:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-03:08:45] [V] [TRT] Tactic: 128 Time: 3.13741
[05/21/2022-03:08:45] [V] [TRT] Tactic: 256 Time: 3.13909
[05/21/2022-03:08:45] [V] [TRT] Tactic: 512 Time: 3.14135
[05/21/2022-03:08:45] [V] [TRT] Tactic: -32 Time: 2.91127
[05/21/2022-03:08:45] [V] [TRT] Tactic: -64 Time: 2.90569
[05/21/2022-03:08:45] [V] [TRT] Tactic: -128 Time: 2.94154
[05/21/2022-03:08:45] [V] [TRT] Fastest Tactic: -64 Time: 2.90569
[05/21/2022-03:08:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:08:45] [V] [TRT] *************** Autotuning format combination: Half(692224,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:45] [V] [TRT] Tactic: 0 Time: 0.986419
[05/21/2022-03:08:45] [V] [TRT] Tactic: 1 Time: 0.697357
[05/21/2022-03:08:45] [V] [TRT] Tactic: 2 Time: 0.649746
[05/21/2022-03:08:45] [V] [TRT] Tactic: 3 Time: 0.515957
[05/21/2022-03:08:45] [V] [TRT] Tactic: 4 Time: 0.488372
[05/21/2022-03:08:45] [V] [TRT] Tactic: 5 Time: 0.478444
[05/21/2022-03:08:45] [V] [TRT] Tactic: 6 Time: 0.433861
[05/21/2022-03:08:45] [V] [TRT] Tactic: 7 Time: 0.389941
[05/21/2022-03:08:45] [V] [TRT] Tactic: 8 Time: 0.395866
[05/21/2022-03:08:45] [V] [TRT] Tactic: 9 Time: 0.392337
[05/21/2022-03:08:45] [V] [TRT] Tactic: 28 Time: 0.981458
[05/21/2022-03:08:45] [V] [TRT] Fastest Tactic: 7 Time: 0.389941
[05/21/2022-03:08:45] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-03:08:45] [V] [TRT] Tactic: 128 Time: 3.02192
[05/21/2022-03:08:45] [V] [TRT] Tactic: 256 Time: 2.98439
[05/21/2022-03:08:46] [V] [TRT] Tactic: 512 Time: 2.75717
[05/21/2022-03:08:46] [V] [TRT] Tactic: -32 Time: 2.92645
[05/21/2022-03:08:46] [V] [TRT] Tactic: -64 Time: 2.8997
[05/21/2022-03:08:46] [V] [TRT] Tactic: -128 Time: 2.93039
[05/21/2022-03:08:46] [V] [TRT] Fastest Tactic: 512 Time: 2.75717
[05/21/2022-03:08:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:08:46] [V] [TRT] *************** Autotuning format combination: Half(346112,10816:2,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:08:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWiseV2)
[05/21/2022-03:08:46] [V] [TRT] Tactic: 0 Time: 0.670462
[05/21/2022-03:08:46] [V] [TRT] Tactic: 1 Time: 0.515716
[05/21/2022-03:08:46] [V] [TRT] Tactic: 2 Time: 0.51569
[05/21/2022-03:08:46] [V] [TRT] Tactic: 3 Time: 0.452936
[05/21/2022-03:08:46] [V] [TRT] Tactic: 4 Time: 0.438711
[05/21/2022-03:08:46] [V] [TRT] Tactic: 5 Time: 0.449173
[05/21/2022-03:08:46] [V] [TRT] Tactic: 6 Time: 0.426478
[05/21/2022-03:08:46] [V] [TRT] Tactic: 7 Time: 0.411159
[05/21/2022-03:08:46] [V] [TRT] Tactic: 8 Time: 0.405059
[05/21/2022-03:08:46] [V] [TRT] Tactic: 9 Time: 0.430417
[05/21/2022-03:08:46] [V] [TRT] Tactic: 10 Time: 1.01637
[05/21/2022-03:08:46] [V] [TRT] Tactic: 11 Time: 0.72819
[05/21/2022-03:08:46] [V] [TRT] Tactic: 12 Time: 0.681576
[05/21/2022-03:08:46] [V] [TRT] Tactic: 13 Time: 0.53582
[05/21/2022-03:08:46] [V] [TRT] Tactic: 14 Time: 0.508489
[05/21/2022-03:08:46] [V] [TRT] Tactic: 15 Time: 0.514596
[05/21/2022-03:08:46] [V] [TRT] Tactic: 16 Time: 0.447233
[05/21/2022-03:08:46] [V] [TRT] Tactic: 17 Time: 0.400482
[05/21/2022-03:08:46] [V] [TRT] Tactic: 18 Time: 0.408379
[05/21/2022-03:08:46] [V] [TRT] Tactic: 19 Time: 0.426022
[05/21/2022-03:08:46] [V] [TRT] Tactic: 28 Time: 0.658971
[05/21/2022-03:08:46] [V] [TRT] Tactic: 29 Time: 1.02143
[05/21/2022-03:08:46] [V] [TRT] Fastest Tactic: 17 Time: 0.400482
[05/21/2022-03:08:46] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) (PointWise)
[05/21/2022-03:08:46] [V] [TRT] Tactic: 128 Time: 3.02373
[05/21/2022-03:08:46] [V] [TRT] Tactic: 256 Time: 2.98923
[05/21/2022-03:08:46] [V] [TRT] Tactic: 512 Time: 2.76408
[05/21/2022-03:08:46] [V] [TRT] Tactic: -32 Time: 2.92333
[05/21/2022-03:08:47] [V] [TRT] Tactic: -64 Time: 2.8998
[05/21/2022-03:08:47] [V] [TRT] Tactic: -128 Time: 2.92906
[05/21/2022-03:08:47] [V] [TRT] Fastest Tactic: 512 Time: 2.76408
[05/21/2022-03:08:47] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:08:47] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Float(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,13312,128) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Half(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Float(1384448,10816,104,1) -> Float(1384448,10816,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,13312,128) -> Float(1384448,1,13312,128) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Float(43264,10816:32,104,1) -> Float(43264,10816:32,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Half(1384448,10816,104,1) -> Half(1384448,10816,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(692224,10816:2,104,1) ***************
[05/21/2022-03:08:47] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:08:47] [V] [TRT] *************** Autotuning format combination: Float(1384448,10816,104,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:08:47] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:08:47] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:47] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:08:47] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:47] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:47] [V] [TRT] Tactic: 0 Time: 16.3223
[05/21/2022-03:08:47] [V] [TRT] Tactic: 1 Time: 11.4217
[05/21/2022-03:08:47] [V] [TRT] Tactic: 2 Time: 14.7145
[05/21/2022-03:08:51] [V] [TRT] Tactic: 5 Time: 240.018
[05/21/2022-03:08:51] [V] [TRT] Fastest Tactic: 1 Time: 11.4217
[05/21/2022-03:08:51] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:51] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:08:52] [V] [TRT] Tactic: 1062367460111450758 Time: 10.6511
[05/21/2022-03:08:52] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:08:52] [V] [TRT] Tactic: 1754984623894446479 Time: 12.1536
[05/21/2022-03:08:52] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:08:52] [V] [TRT] Tactic: 3611739942397549984 Time: 8.6282
[05/21/2022-03:08:52] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:08:52] [V] [TRT] Tactic: 4337000649858996379 Time: 8.68732
[05/21/2022-03:08:52] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:08:52] [V] [TRT] Tactic: 4501471010995462441 Time: 8.58519
[05/21/2022-03:08:52] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:08:53] [V] [TRT] Tactic: 5137655947464784826 Time: 8.38153
[05/21/2022-03:08:53] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:08:53] [V] [TRT] Tactic: 5288347012147084929 Time: 8.47378
[05/21/2022-03:08:53] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:08:53] [V] [TRT] Tactic: 6645123197870846056 Time: 8.61961
[05/21/2022-03:08:53] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:08:53] [V] [TRT] Tactic: 7144526460361122478 Time: 11.2543
[05/21/2022-03:08:53] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:08:53] [V] [TRT] Tactic: -9137461792520977713 Time: 8.66032
[05/21/2022-03:08:53] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:08:53] [V] [TRT] Tactic: -8262349710178828730 Time: 8.68063
[05/21/2022-03:08:53] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:08:54] [V] [TRT] Tactic: -8133971918129952780 Time: 9.64437
[05/21/2022-03:08:54] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:08:54] [V] [TRT] Tactic: -6092040395344634144 Time: 11.0068
[05/21/2022-03:08:54] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:08:54] [V] [TRT] Tactic: -4787320710726427159 Time: 12.1465
[05/21/2022-03:08:54] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:08:54] [V] [TRT] Tactic: -3456450830548107839 Time: 9.83566
[05/21/2022-03:08:54] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:08:54] [V] [TRT] Tactic: -1218658103698133241 Time: 9.65724
[05/21/2022-03:08:54] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:08:55] [V] [TRT] Tactic: -836875257600482091 Time: 9.4981
[05/21/2022-03:08:55] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:08:55] [V] [TRT] Tactic: -410470605513481746 Time: 8.40445
[05/21/2022-03:08:55] [V] [TRT] Fastest Tactic: 5137655947464784826 Time: 8.38153
[05/21/2022-03:08:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5137655947464784826
[05/21/2022-03:08:55] [V] [TRT] *************** Autotuning format combination: Float(1384448,1,13312,128) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:08:55] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:55] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:08:55] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-03:08:55] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:08:55] [V] [TRT] Tactic: -9153228964338181824 Time: 12.9416
[05/21/2022-03:08:55] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:08:55] [V] [TRT] Tactic: -7394439838318485025 Time: 8.38003
[05/21/2022-03:08:55] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 8.38003
[05/21/2022-03:08:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:08:55] [V] [TRT] *************** Autotuning format combination: Half(1384448,10816,104,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:08:55] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-03:08:56] [V] [TRT] Tactic: 0 Time: 16.3922
[05/21/2022-03:08:56] [V] [TRT] Tactic: 1 Time: 13.5775
[05/21/2022-03:08:56] [V] [TRT] Tactic: 2 Time: 14.0494
[05/21/2022-03:09:00] [V] [TRT] Tactic: 5 Time: 238.022
[05/21/2022-03:09:00] [V] [TRT] Fastest Tactic: 1 Time: 13.5775
[05/21/2022-03:09:00] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:09:00] [V] [TRT] *************** Autotuning format combination: Half(692224,10816:2,104,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:09:00] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:00] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:00] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:00] [V] [TRT] --------------- Timing Runner: 025_convolutional + 025_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:00] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:00] [V] [TRT] Tactic: 3564772625446233998 Time: 5.45831
[05/21/2022-03:09:00] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:09:00] [V] [TRT] Tactic: 3650389455493082349 Time: 5.61911
[05/21/2022-03:09:00] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:00] [V] [TRT] Tactic: 5319956359050645452 Time: 4.96683
[05/21/2022-03:09:00] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:00] [V] [TRT] Tactic: 7205456024582378848 Time: 4.33947
[05/21/2022-03:09:00] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:09:01] [V] [TRT] Tactic: -6490690591794140522 Time: 4.39397
[05/21/2022-03:09:01] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:09:01] [V] [TRT] Tactic: -4686027666808657977 Time: 4.38234
[05/21/2022-03:09:01] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:01] [V] [TRT] Tactic: -4212163711445252890 Time: 4.22506
[05/21/2022-03:09:01] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:01] [V] [TRT] Tactic: -3898373634979201110 Time: 4.33747
[05/21/2022-03:09:01] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:01] [V] [TRT] Tactic: -2409163523992614473 Time: 4.24563
[05/21/2022-03:09:01] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 4.22506
[05/21/2022-03:09:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-03:09:01] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:01] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:09:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:01] [V] [TRT] Tactic: 0 Time: 0.755391
[05/21/2022-03:09:01] [V] [TRT] Tactic: 1 Time: 0.559011
[05/21/2022-03:09:01] [V] [TRT] Tactic: 2 Time: 0.529694
[05/21/2022-03:09:01] [V] [TRT] Tactic: 3 Time: 0.466927
[05/21/2022-03:09:01] [V] [TRT] Tactic: 4 Time: 0.398665
[05/21/2022-03:09:01] [V] [TRT] Tactic: 5 Time: 0.411413
[05/21/2022-03:09:01] [V] [TRT] Tactic: 6 Time: 0.425287
[05/21/2022-03:09:01] [V] [TRT] Tactic: 7 Time: 0.345599
[05/21/2022-03:09:01] [V] [TRT] Tactic: 8 Time: 0.327708
[05/21/2022-03:09:01] [V] [TRT] Tactic: 9 Time: 0.351712
[05/21/2022-03:09:01] [V] [TRT] Tactic: 28 Time: 0.7433
[05/21/2022-03:09:01] [V] [TRT] Fastest Tactic: 8 Time: 0.327708
[05/21/2022-03:09:01] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-03:09:01] [V] [TRT] Tactic: 128 Time: 2.78233
[05/21/2022-03:09:01] [V] [TRT] Tactic: 256 Time: 2.78871
[05/21/2022-03:09:01] [V] [TRT] Tactic: 512 Time: 2.79361
[05/21/2022-03:09:01] [V] [TRT] Tactic: -32 Time: 2.89931
[05/21/2022-03:09:01] [V] [TRT] Tactic: -64 Time: 2.8946
[05/21/2022-03:09:02] [V] [TRT] Tactic: -128 Time: 2.89578
[05/21/2022-03:09:02] [V] [TRT] Fastest Tactic: 128 Time: 2.78233
[05/21/2022-03:09:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:02] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:09:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:02] [V] [TRT] Tactic: 0 Time: 0.754779
[05/21/2022-03:09:02] [V] [TRT] Tactic: 1 Time: 0.559707
[05/21/2022-03:09:02] [V] [TRT] Tactic: 2 Time: 0.53028
[05/21/2022-03:09:02] [V] [TRT] Tactic: 3 Time: 0.467774
[05/21/2022-03:09:02] [V] [TRT] Tactic: 4 Time: 0.398398
[05/21/2022-03:09:02] [V] [TRT] Tactic: 5 Time: 0.411231
[05/21/2022-03:09:02] [V] [TRT] Tactic: 6 Time: 0.42571
[05/21/2022-03:09:02] [V] [TRT] Tactic: 7 Time: 0.345677
[05/21/2022-03:09:02] [V] [TRT] Tactic: 8 Time: 0.327819
[05/21/2022-03:09:02] [V] [TRT] Tactic: 9 Time: 0.351563
[05/21/2022-03:09:02] [V] [TRT] Tactic: 28 Time: 0.74265
[05/21/2022-03:09:02] [V] [TRT] Fastest Tactic: 8 Time: 0.327819
[05/21/2022-03:09:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-03:09:02] [V] [TRT] Tactic: 128 Time: 2.7821
[05/21/2022-03:09:02] [V] [TRT] Tactic: 256 Time: 2.7875
[05/21/2022-03:09:02] [V] [TRT] Tactic: 512 Time: 2.79264
[05/21/2022-03:09:02] [V] [TRT] Tactic: -32 Time: 2.89821
[05/21/2022-03:09:02] [V] [TRT] Tactic: -64 Time: 2.8847
[05/21/2022-03:09:02] [V] [TRT] Tactic: -128 Time: 2.89609
[05/21/2022-03:09:02] [V] [TRT] Fastest Tactic: 128 Time: 2.7821
[05/21/2022-03:09:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:02] [V] [TRT] *************** Autotuning format combination: Float(21632,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:09:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:02] [V] [TRT] Tactic: 24 Time: 0.515976
[05/21/2022-03:09:02] [V] [TRT] Tactic: 25 Time: 0.472383
[05/21/2022-03:09:02] [V] [TRT] Tactic: 26 Time: 0.466133
[05/21/2022-03:09:02] [V] [TRT] Tactic: 27 Time: 0.452103
[05/21/2022-03:09:02] [V] [TRT] Tactic: 31 Time: 0.515586
[05/21/2022-03:09:02] [V] [TRT] Fastest Tactic: 27 Time: 0.452103
[05/21/2022-03:09:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-03:09:02] [V] [TRT] Tactic: 128 Time: 2.78227
[05/21/2022-03:09:02] [V] [TRT] Tactic: 256 Time: 2.78764
[05/21/2022-03:09:02] [V] [TRT] Tactic: 512 Time: 2.79301
[05/21/2022-03:09:03] [V] [TRT] Tactic: -32 Time: 2.90197
[05/21/2022-03:09:03] [V] [TRT] Tactic: -64 Time: 2.88524
[05/21/2022-03:09:03] [V] [TRT] Tactic: -128 Time: 2.89799
[05/21/2022-03:09:03] [V] [TRT] Fastest Tactic: 128 Time: 2.78227
[05/21/2022-03:09:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:09:03] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:03] [V] [TRT] Tactic: 0 Time: 0.770111
[05/21/2022-03:09:03] [V] [TRT] Tactic: 1 Time: 0.583672
[05/21/2022-03:09:03] [V] [TRT] Tactic: 2 Time: 0.542676
[05/21/2022-03:09:03] [V] [TRT] Tactic: 3 Time: 0.464388
[05/21/2022-03:09:03] [V] [TRT] Tactic: 4 Time: 0.422923
[05/21/2022-03:09:03] [V] [TRT] Tactic: 5 Time: 0.432812
[05/21/2022-03:09:03] [V] [TRT] Tactic: 6 Time: 0.413737
[05/21/2022-03:09:03] [V] [TRT] Tactic: 7 Time: 0.361159
[05/21/2022-03:09:03] [V] [TRT] Tactic: 8 Time: 0.361855
[05/21/2022-03:09:03] [V] [TRT] Tactic: 9 Time: 0.372832
[05/21/2022-03:09:03] [V] [TRT] Tactic: 28 Time: 0.772201
[05/21/2022-03:09:03] [V] [TRT] Fastest Tactic: 7 Time: 0.361159
[05/21/2022-03:09:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-03:09:03] [V] [TRT] Tactic: 128 Time: 2.86298
[05/21/2022-03:09:03] [V] [TRT] Tactic: 256 Time: 2.83914
[05/21/2022-03:09:03] [V] [TRT] Tactic: 512 Time: 2.65586
[05/21/2022-03:09:03] [V] [TRT] Tactic: -32 Time: 2.90063
[05/21/2022-03:09:03] [V] [TRT] Tactic: -64 Time: 2.86863
[05/21/2022-03:09:03] [V] [TRT] Tactic: -128 Time: 2.87785
[05/21/2022-03:09:03] [V] [TRT] Fastest Tactic: 512 Time: 2.65586
[05/21/2022-03:09:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:09:03] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:09:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:03] [V] [TRT] Tactic: 0 Time: 0.589811
[05/21/2022-03:09:03] [V] [TRT] Tactic: 1 Time: 0.47847
[05/21/2022-03:09:03] [V] [TRT] Tactic: 2 Time: 0.479479
[05/21/2022-03:09:03] [V] [TRT] Tactic: 3 Time: 0.438255
[05/21/2022-03:09:03] [V] [TRT] Tactic: 4 Time: 0.42597
[05/21/2022-03:09:03] [V] [TRT] Tactic: 5 Time: 0.432695
[05/21/2022-03:09:03] [V] [TRT] Tactic: 6 Time: 0.418086
[05/21/2022-03:09:03] [V] [TRT] Tactic: 7 Time: 0.405866
[05/21/2022-03:09:03] [V] [TRT] Tactic: 8 Time: 0.398301
[05/21/2022-03:09:03] [V] [TRT] Tactic: 9 Time: 0.422806
[05/21/2022-03:09:03] [V] [TRT] Tactic: 10 Time: 0.810632
[05/21/2022-03:09:04] [V] [TRT] Tactic: 11 Time: 0.603268
[05/21/2022-03:09:04] [V] [TRT] Tactic: 12 Time: 0.572721
[05/21/2022-03:09:04] [V] [TRT] Tactic: 13 Time: 0.475072
[05/21/2022-03:09:04] [V] [TRT] Tactic: 14 Time: 0.440234
[05/21/2022-03:09:04] [V] [TRT] Tactic: 15 Time: 0.451334
[05/21/2022-03:09:04] [V] [TRT] Tactic: 16 Time: 0.418503
[05/21/2022-03:09:04] [V] [TRT] Tactic: 17 Time: 0.368822
[05/21/2022-03:09:04] [V] [TRT] Tactic: 18 Time: 0.367077
[05/21/2022-03:09:04] [V] [TRT] Tactic: 19 Time: 0.397376
[05/21/2022-03:09:04] [V] [TRT] Tactic: 28 Time: 0.586895
[05/21/2022-03:09:04] [V] [TRT] Tactic: 29 Time: 0.797142
[05/21/2022-03:09:04] [V] [TRT] Fastest Tactic: 18 Time: 0.367077
[05/21/2022-03:09:04] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) (PointWise)
[05/21/2022-03:09:04] [V] [TRT] Tactic: 128 Time: 2.86237
[05/21/2022-03:09:04] [V] [TRT] Tactic: 256 Time: 2.8343
[05/21/2022-03:09:04] [V] [TRT] Tactic: 512 Time: 2.65624
[05/21/2022-03:09:04] [V] [TRT] Tactic: -32 Time: 2.90141
[05/21/2022-03:09:04] [V] [TRT] Tactic: -64 Time: 2.8702
[05/21/2022-03:09:04] [V] [TRT] Tactic: -128 Time: 2.87827
[05/21/2022-03:09:04] [V] [TRT] Fastest Tactic: 512 Time: 2.65624
[05/21/2022-03:09:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:09:04] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:04] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:09:04] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:04] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:04] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:04] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:04] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:04] [V] [TRT] Tactic: 0 Time: 3.88885
[05/21/2022-03:09:04] [V] [TRT] Tactic: 1 Time: 2.74053
[05/21/2022-03:09:04] [V] [TRT] Tactic: 2 Time: 3.65221
[05/21/2022-03:09:04] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2223505408, available: 536870912
[05/21/2022-03:09:04] [V] [TRT] Tactic: 5 Time: 9.19999
[05/21/2022-03:09:04] [V] [TRT] Fastest Tactic: 1 Time: 2.74053
[05/21/2022-03:09:04] [V] [TRT] Setting workspace to 2223505408enables more tactics for profiling
[05/21/2022-03:09:04] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:04] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:04] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:04] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:05] [V] [TRT] Tactic: 1062367460111450758 Time: 2.75314
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:09:05] [V] [TRT] Tactic: 1698681053543049347 Time: 2.58997
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:05] [V] [TRT] Tactic: 4501471010995462441 Time: 2.13504
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:05] [V] [TRT] Tactic: 5137655947464784826 Time: 2.06745
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:05] [V] [TRT] Tactic: 5288347012147084929 Time: 2.1336
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:09:05] [V] [TRT] Tactic: 5326823351883942011 Time: 2.05357
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:09:05] [V] [TRT] Tactic: 5500448035057547314 Time: 2.31952
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:05] [V] [TRT] Tactic: 6645123197870846056 Time: 2.11811
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:05] [V] [TRT] Tactic: 7144526460361122478 Time: 2.94105
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:05] [V] [TRT] Tactic: -8262349710178828730 Time: 2.17318
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:09:05] [V] [TRT] Tactic: -6576203419454146580 Time: 2.45522
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:05] [V] [TRT] Tactic: -4787320710726427159 Time: 3.07306
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:05] [V] [TRT] Tactic: -3456450830548107839 Time: 2.57442
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:05] [V] [TRT] Tactic: -1218658103698133241 Time: 2.41169
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:05] [V] [TRT] Tactic: -836875257600482091 Time: 2.35132
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:05] [V] [TRT] Tactic: -410470605513481746 Time: 2.11069
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:09:05] [V] [TRT] Tactic: -377491875521947884 Time: 2.12972
[05/21/2022-03:09:05] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:09:05] [V] [TRT] Tactic: -37215280111360163 Time: 2.02506
[05/21/2022-03:09:05] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 2.02506
[05/21/2022-03:09:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:09:05] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:09:05] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:05] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:05] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:09:06] [V] [TRT] Tactic: 3886731678879822788 Time: 2.17818
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:09:06] [V] [TRT] Tactic: 6629944304117643200 Time: 4.11451
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:06] [V] [TRT] Tactic: -9153228964338181824 Time: 4.18079
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:06] [V] [TRT] Tactic: -7394439838318485025 Time: 2.17016
[05/21/2022-03:09:06] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.17016
[05/21/2022-03:09:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:09:06] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:06] [V] [TRT] Tactic: 0 Time: 3.76658
[05/21/2022-03:09:06] [V] [TRT] Tactic: 1 Time: 2.47545
[05/21/2022-03:09:06] [V] [TRT] Tactic: 2 Time: 3.43189
[05/21/2022-03:09:06] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2223505408, available: 536870912
[05/21/2022-03:09:06] [V] [TRT] Tactic: 5 Time: 8.70566
[05/21/2022-03:09:06] [V] [TRT] Fastest Tactic: 1 Time: 2.47545
[05/21/2022-03:09:06] [V] [TRT] Setting workspace to 2223505408enables more tactics for profiling
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:09:06] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:06] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:06] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:06] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:06] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:09:06] [V] [TRT] Tactic: 3066127711859985668 Time: 1.32383
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:06] [V] [TRT] Tactic: 3564772625446233998 Time: 1.43393
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:06] [V] [TRT] Tactic: 5319956359050645452 Time: 1.37186
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:06] [V] [TRT] Tactic: 7205456024582378848 Time: 1.10113
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:09:06] [V] [TRT] Tactic: 8163473458334948789 Time: 1.05977
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:06] [V] [TRT] Tactic: -4212163711445252890 Time: 1.07574
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:06] [V] [TRT] Tactic: -3898373634979201110 Time: 1.09525
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:06] [V] [TRT] Tactic: -2409163523992614473 Time: 1.07615
[05/21/2022-03:09:06] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:09:06] [V] [TRT] Tactic: -1716393687483585322 Time: 1.06843
[05/21/2022-03:09:06] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 1.05977
[05/21/2022-03:09:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:09:06] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:06] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:09:06] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:07] [V] [TRT] Tactic: 0 Time: 0.484407
[05/21/2022-03:09:07] [V] [TRT] Tactic: 1 Time: 0.339114
[05/21/2022-03:09:07] [V] [TRT] Tactic: 2 Time: 0.320078
[05/21/2022-03:09:07] [V] [TRT] Tactic: 3 Time: 0.257057
[05/21/2022-03:09:07] [V] [TRT] Tactic: 4 Time: 0.238757
[05/21/2022-03:09:07] [V] [TRT] Tactic: 5 Time: 0.235742
[05/21/2022-03:09:07] [V] [TRT] Tactic: 6 Time: 0.225065
[05/21/2022-03:09:07] [V] [TRT] Tactic: 7 Time: 0.193132
[05/21/2022-03:09:07] [V] [TRT] Tactic: 8 Time: 0.189818
[05/21/2022-03:09:07] [V] [TRT] Tactic: 9 Time: 0.195697
[05/21/2022-03:09:07] [V] [TRT] Tactic: 28 Time: 0.47916
[05/21/2022-03:09:07] [V] [TRT] Fastest Tactic: 8 Time: 0.189818
[05/21/2022-03:09:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-03:09:07] [V] [TRT] Tactic: 128 Time: 1.57302
[05/21/2022-03:09:07] [V] [TRT] Tactic: 256 Time: 1.5726
[05/21/2022-03:09:07] [V] [TRT] Tactic: 512 Time: 1.57462
[05/21/2022-03:09:07] [V] [TRT] Tactic: -32 Time: 1.47882
[05/21/2022-03:09:07] [V] [TRT] Tactic: -64 Time: 1.46397
[05/21/2022-03:09:07] [V] [TRT] Tactic: -128 Time: 1.47821
[05/21/2022-03:09:07] [V] [TRT] Fastest Tactic: -64 Time: 1.46397
[05/21/2022-03:09:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:07] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:09:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:07] [V] [TRT] Tactic: 0 Time: 0.48416
[05/21/2022-03:09:07] [V] [TRT] Tactic: 1 Time: 0.339277
[05/21/2022-03:09:07] [V] [TRT] Tactic: 2 Time: 0.320586
[05/21/2022-03:09:07] [V] [TRT] Tactic: 3 Time: 0.257012
[05/21/2022-03:09:07] [V] [TRT] Tactic: 4 Time: 0.238997
[05/21/2022-03:09:07] [V] [TRT] Tactic: 5 Time: 0.235938
[05/21/2022-03:09:07] [V] [TRT] Tactic: 6 Time: 0.3214
[05/21/2022-03:09:07] [V] [TRT] Tactic: 7 Time: 0.280449
[05/21/2022-03:09:07] [V] [TRT] Tactic: 8 Time: 0.27377
[05/21/2022-03:09:07] [V] [TRT] Tactic: 9 Time: 0.260293
[05/21/2022-03:09:07] [V] [TRT] Tactic: 28 Time: 0.478678
[05/21/2022-03:09:07] [V] [TRT] Fastest Tactic: 5 Time: 0.235938
[05/21/2022-03:09:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-03:09:07] [V] [TRT] Tactic: 128 Time: 1.57338
[05/21/2022-03:09:07] [V] [TRT] Tactic: 256 Time: 1.57383
[05/21/2022-03:09:07] [V] [TRT] Tactic: 512 Time: 1.57404
[05/21/2022-03:09:07] [V] [TRT] Tactic: -32 Time: 1.51842
[05/21/2022-03:09:07] [V] [TRT] Tactic: -64 Time: 1.58398
[05/21/2022-03:09:07] [V] [TRT] Tactic: -128 Time: 1.74104
[05/21/2022-03:09:07] [V] [TRT] Fastest Tactic: -32 Time: 1.51842
[05/21/2022-03:09:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:09:07] [V] [TRT] *************** Autotuning format combination: Float(21632,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:09:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:07] [V] [TRT] Tactic: 24 Time: 0.268477
[05/21/2022-03:09:07] [V] [TRT] Tactic: 25 Time: 0.241836
[05/21/2022-03:09:07] [V] [TRT] Tactic: 26 Time: 0.238014
[05/21/2022-03:09:07] [V] [TRT] Tactic: 27 Time: 0.235592
[05/21/2022-03:09:07] [V] [TRT] Tactic: 31 Time: 0.269421
[05/21/2022-03:09:07] [V] [TRT] Fastest Tactic: 27 Time: 0.235592
[05/21/2022-03:09:07] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-03:09:07] [V] [TRT] Tactic: 128 Time: 1.57331
[05/21/2022-03:09:08] [V] [TRT] Tactic: 256 Time: 1.57415
[05/21/2022-03:09:08] [V] [TRT] Tactic: 512 Time: 1.574
[05/21/2022-03:09:08] [V] [TRT] Tactic: -32 Time: 1.47802
[05/21/2022-03:09:08] [V] [TRT] Tactic: -64 Time: 1.46488
[05/21/2022-03:09:08] [V] [TRT] Tactic: -128 Time: 1.47738
[05/21/2022-03:09:08] [V] [TRT] Fastest Tactic: -64 Time: 1.46488
[05/21/2022-03:09:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:09:08] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:08] [V] [TRT] Tactic: 0 Time: 0.498314
[05/21/2022-03:09:08] [V] [TRT] Tactic: 1 Time: 0.353952
[05/21/2022-03:09:08] [V] [TRT] Tactic: 2 Time: 0.329837
[05/21/2022-03:09:08] [V] [TRT] Tactic: 3 Time: 0.263249
[05/21/2022-03:09:08] [V] [TRT] Tactic: 4 Time: 0.249213
[05/21/2022-03:09:08] [V] [TRT] Tactic: 5 Time: 0.243958
[05/21/2022-03:09:08] [V] [TRT] Tactic: 6 Time: 0.223216
[05/21/2022-03:09:08] [V] [TRT] Tactic: 7 Time: 0.200417
[05/21/2022-03:09:08] [V] [TRT] Tactic: 8 Time: 0.202735
[05/21/2022-03:09:08] [V] [TRT] Tactic: 9 Time: 0.201204
[05/21/2022-03:09:08] [V] [TRT] Tactic: 28 Time: 0.495905
[05/21/2022-03:09:08] [V] [TRT] Fastest Tactic: 7 Time: 0.200417
[05/21/2022-03:09:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-03:09:08] [V] [TRT] Tactic: 128 Time: 1.51561
[05/21/2022-03:09:08] [V] [TRT] Tactic: 256 Time: 1.50189
[05/21/2022-03:09:08] [V] [TRT] Tactic: 512 Time: 1.37947
[05/21/2022-03:09:08] [V] [TRT] Tactic: -32 Time: 1.47816
[05/21/2022-03:09:08] [V] [TRT] Tactic: -64 Time: 1.45976
[05/21/2022-03:09:08] [V] [TRT] Tactic: -128 Time: 1.47274
[05/21/2022-03:09:08] [V] [TRT] Fastest Tactic: 512 Time: 1.37947
[05/21/2022-03:09:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:09:08] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:09:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:08] [V] [TRT] Tactic: 0 Time: 0.339622
[05/21/2022-03:09:08] [V] [TRT] Tactic: 1 Time: 0.262285
[05/21/2022-03:09:08] [V] [TRT] Tactic: 2 Time: 0.262871
[05/21/2022-03:09:08] [V] [TRT] Tactic: 3 Time: 0.234017
[05/21/2022-03:09:08] [V] [TRT] Tactic: 4 Time: 0.226666
[05/21/2022-03:09:08] [V] [TRT] Tactic: 5 Time: 0.229961
[05/21/2022-03:09:08] [V] [TRT] Tactic: 6 Time: 0.220117
[05/21/2022-03:09:08] [V] [TRT] Tactic: 7 Time: 0.209681
[05/21/2022-03:09:08] [V] [TRT] Tactic: 8 Time: 0.207155
[05/21/2022-03:09:08] [V] [TRT] Tactic: 9 Time: 0.220794
[05/21/2022-03:09:08] [V] [TRT] Tactic: 10 Time: 0.512819
[05/21/2022-03:09:08] [V] [TRT] Tactic: 11 Time: 0.369284
[05/21/2022-03:09:08] [V] [TRT] Tactic: 12 Time: 0.34526
[05/21/2022-03:09:08] [V] [TRT] Tactic: 13 Time: 0.273118
[05/21/2022-03:09:08] [V] [TRT] Tactic: 14 Time: 0.259258
[05/21/2022-03:09:08] [V] [TRT] Tactic: 15 Time: 0.261947
[05/21/2022-03:09:08] [V] [TRT] Tactic: 16 Time: 0.229928
[05/21/2022-03:09:08] [V] [TRT] Tactic: 17 Time: 0.20528
[05/21/2022-03:09:08] [V] [TRT] Tactic: 18 Time: 0.209375
[05/21/2022-03:09:08] [V] [TRT] Tactic: 19 Time: 0.217832
[05/21/2022-03:09:08] [V] [TRT] Tactic: 28 Time: 0.334284
[05/21/2022-03:09:08] [V] [TRT] Tactic: 29 Time: 0.515404
[05/21/2022-03:09:08] [V] [TRT] Fastest Tactic: 17 Time: 0.20528
[05/21/2022-03:09:08] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) (PointWise)
[05/21/2022-03:09:08] [V] [TRT] Tactic: 128 Time: 1.51447
[05/21/2022-03:09:09] [V] [TRT] Tactic: 256 Time: 1.49872
[05/21/2022-03:09:09] [V] [TRT] Tactic: 512 Time: 1.38164
[05/21/2022-03:09:09] [V] [TRT] Tactic: -32 Time: 1.4807
[05/21/2022-03:09:09] [V] [TRT] Tactic: -64 Time: 1.45988
[05/21/2022-03:09:09] [V] [TRT] Tactic: -128 Time: 1.47322
[05/21/2022-03:09:09] [V] [TRT] Fastest Tactic: 512 Time: 1.38164
[05/21/2022-03:09:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:09:09] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:09] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:09] [V] [TRT] Tactic: 0 Time: 0.483652
[05/21/2022-03:09:09] [V] [TRT] Tactic: 1 Time: 0.338984
[05/21/2022-03:09:09] [V] [TRT] Tactic: 2 Time: 0.320013
[05/21/2022-03:09:09] [V] [TRT] Tactic: 3 Time: 0.257416
[05/21/2022-03:09:09] [V] [TRT] Tactic: 4 Time: 0.238945
[05/21/2022-03:09:09] [V] [TRT] Tactic: 5 Time: 0.23571
[05/21/2022-03:09:09] [V] [TRT] Tactic: 6 Time: 0.224753
[05/21/2022-03:09:09] [V] [TRT] Tactic: 7 Time: 0.192884
[05/21/2022-03:09:09] [V] [TRT] Tactic: 8 Time: 0.189967
[05/21/2022-03:09:09] [V] [TRT] Tactic: 9 Time: 0.195553
[05/21/2022-03:09:09] [V] [TRT] Tactic: 28 Time: 0.478548
[05/21/2022-03:09:09] [V] [TRT] Fastest Tactic: 8 Time: 0.189967
[05/21/2022-03:09:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-03:09:09] [V] [TRT] Tactic: 128 Time: 1.57262
[05/21/2022-03:09:09] [V] [TRT] Tactic: 256 Time: 1.57255
[05/21/2022-03:09:09] [V] [TRT] Tactic: 512 Time: 1.57397
[05/21/2022-03:09:09] [V] [TRT] Tactic: -32 Time: 1.47948
[05/21/2022-03:09:09] [V] [TRT] Tactic: -64 Time: 1.46395
[05/21/2022-03:09:09] [V] [TRT] Tactic: -128 Time: 1.47778
[05/21/2022-03:09:09] [V] [TRT] Fastest Tactic: -64 Time: 1.46395
[05/21/2022-03:09:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:09] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:09] [V] [TRT] Tactic: 0 Time: 0.484434
[05/21/2022-03:09:09] [V] [TRT] Tactic: 1 Time: 0.338958
[05/21/2022-03:09:09] [V] [TRT] Tactic: 2 Time: 0.319772
[05/21/2022-03:09:09] [V] [TRT] Tactic: 3 Time: 0.258327
[05/21/2022-03:09:09] [V] [TRT] Tactic: 4 Time: 0.238646
[05/21/2022-03:09:09] [V] [TRT] Tactic: 5 Time: 0.236093
[05/21/2022-03:09:09] [V] [TRT] Tactic: 6 Time: 0.321719
[05/21/2022-03:09:09] [V] [TRT] Tactic: 7 Time: 0.279128
[05/21/2022-03:09:09] [V] [TRT] Tactic: 8 Time: 0.274186
[05/21/2022-03:09:09] [V] [TRT] Tactic: 9 Time: 0.260514
[05/21/2022-03:09:09] [V] [TRT] Tactic: 28 Time: 0.478854
[05/21/2022-03:09:09] [V] [TRT] Fastest Tactic: 5 Time: 0.236093
[05/21/2022-03:09:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-03:09:09] [V] [TRT] Tactic: 128 Time: 1.57292
[05/21/2022-03:09:09] [V] [TRT] Tactic: 256 Time: 1.573
[05/21/2022-03:09:09] [V] [TRT] Tactic: 512 Time: 1.57399
[05/21/2022-03:09:09] [V] [TRT] Tactic: -32 Time: 1.51787
[05/21/2022-03:09:09] [V] [TRT] Tactic: -64 Time: 1.58425
[05/21/2022-03:09:09] [V] [TRT] Tactic: -128 Time: 1.74055
[05/21/2022-03:09:09] [V] [TRT] Fastest Tactic: -32 Time: 1.51787
[05/21/2022-03:09:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:09:09] [V] [TRT] *************** Autotuning format combination: Float(21632,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:10] [V] [TRT] Tactic: 24 Time: 0.266972
[05/21/2022-03:09:10] [V] [TRT] Tactic: 25 Time: 0.240228
[05/21/2022-03:09:10] [V] [TRT] Tactic: 26 Time: 0.235755
[05/21/2022-03:09:10] [V] [TRT] Tactic: 27 Time: 0.234043
[05/21/2022-03:09:10] [V] [TRT] Tactic: 31 Time: 0.266029
[05/21/2022-03:09:10] [V] [TRT] Fastest Tactic: 27 Time: 0.234043
[05/21/2022-03:09:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-03:09:10] [V] [TRT] Tactic: 128 Time: 1.57322
[05/21/2022-03:09:10] [V] [TRT] Tactic: 256 Time: 1.57301
[05/21/2022-03:09:10] [V] [TRT] Tactic: 512 Time: 1.57497
[05/21/2022-03:09:10] [V] [TRT] Tactic: -32 Time: 1.4798
[05/21/2022-03:09:10] [V] [TRT] Tactic: -64 Time: 1.464
[05/21/2022-03:09:10] [V] [TRT] Tactic: -128 Time: 1.47843
[05/21/2022-03:09:10] [V] [TRT] Fastest Tactic: -64 Time: 1.464
[05/21/2022-03:09:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:09:10] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:10] [V] [TRT] Tactic: 0 Time: 0.498164
[05/21/2022-03:09:10] [V] [TRT] Tactic: 1 Time: 0.354095
[05/21/2022-03:09:10] [V] [TRT] Tactic: 2 Time: 0.329928
[05/21/2022-03:09:10] [V] [TRT] Tactic: 3 Time: 0.263281
[05/21/2022-03:09:10] [V] [TRT] Tactic: 4 Time: 0.249147
[05/21/2022-03:09:10] [V] [TRT] Tactic: 5 Time: 0.243639
[05/21/2022-03:09:10] [V] [TRT] Tactic: 6 Time: 0.222969
[05/21/2022-03:09:10] [V] [TRT] Tactic: 7 Time: 0.200326
[05/21/2022-03:09:10] [V] [TRT] Tactic: 8 Time: 0.202988
[05/21/2022-03:09:10] [V] [TRT] Tactic: 9 Time: 0.201478
[05/21/2022-03:09:10] [V] [TRT] Tactic: 28 Time: 0.495084
[05/21/2022-03:09:10] [V] [TRT] Fastest Tactic: 7 Time: 0.200326
[05/21/2022-03:09:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-03:09:10] [V] [TRT] Tactic: 128 Time: 1.51569
[05/21/2022-03:09:10] [V] [TRT] Tactic: 256 Time: 1.499
[05/21/2022-03:09:10] [V] [TRT] Tactic: 512 Time: 1.38645
[05/21/2022-03:09:10] [V] [TRT] Tactic: -32 Time: 1.47917
[05/21/2022-03:09:10] [V] [TRT] Tactic: -64 Time: 1.45704
[05/21/2022-03:09:10] [V] [TRT] Tactic: -128 Time: 1.47283
[05/21/2022-03:09:10] [V] [TRT] Fastest Tactic: 512 Time: 1.38645
[05/21/2022-03:09:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:09:10] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:10] [V] [TRT] Tactic: 0 Time: 0.339779
[05/21/2022-03:09:10] [V] [TRT] Tactic: 1 Time: 0.263177
[05/21/2022-03:09:10] [V] [TRT] Tactic: 2 Time: 0.262572
[05/21/2022-03:09:10] [V] [TRT] Tactic: 3 Time: 0.232995
[05/21/2022-03:09:10] [V] [TRT] Tactic: 4 Time: 0.225351
[05/21/2022-03:09:10] [V] [TRT] Tactic: 5 Time: 0.230651
[05/21/2022-03:09:10] [V] [TRT] Tactic: 6 Time: 0.219629
[05/21/2022-03:09:10] [V] [TRT] Tactic: 7 Time: 0.210033
[05/21/2022-03:09:10] [V] [TRT] Tactic: 8 Time: 0.206016
[05/21/2022-03:09:10] [V] [TRT] Tactic: 9 Time: 0.222025
[05/21/2022-03:09:10] [V] [TRT] Tactic: 10 Time: 0.512474
[05/21/2022-03:09:10] [V] [TRT] Tactic: 11 Time: 0.369115
[05/21/2022-03:09:10] [V] [TRT] Tactic: 12 Time: 0.345957
[05/21/2022-03:09:10] [V] [TRT] Tactic: 13 Time: 0.273457
[05/21/2022-03:09:10] [V] [TRT] Tactic: 14 Time: 0.259388
[05/21/2022-03:09:10] [V] [TRT] Tactic: 15 Time: 0.261869
[05/21/2022-03:09:10] [V] [TRT] Tactic: 16 Time: 0.230026
[05/21/2022-03:09:10] [V] [TRT] Tactic: 17 Time: 0.205117
[05/21/2022-03:09:10] [V] [TRT] Tactic: 18 Time: 0.209362
[05/21/2022-03:09:10] [V] [TRT] Tactic: 19 Time: 0.218385
[05/21/2022-03:09:11] [V] [TRT] Tactic: 28 Time: 0.333652
[05/21/2022-03:09:11] [V] [TRT] Tactic: 29 Time: 0.515312
[05/21/2022-03:09:11] [V] [TRT] Fastest Tactic: 17 Time: 0.205117
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) (PointWise)
[05/21/2022-03:09:11] [V] [TRT] Tactic: 128 Time: 1.51671
[05/21/2022-03:09:11] [V] [TRT] Tactic: 256 Time: 1.50204
[05/21/2022-03:09:11] [V] [TRT] Tactic: 512 Time: 1.38405
[05/21/2022-03:09:11] [V] [TRT] Tactic: -32 Time: 1.48087
[05/21/2022-03:09:11] [V] [TRT] Tactic: -64 Time: 1.45883
[05/21/2022-03:09:11] [V] [TRT] Tactic: -128 Time: 1.47318
[05/21/2022-03:09:11] [V] [TRT] Fastest Tactic: 512 Time: 1.38405
[05/21/2022-03:09:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:09:11] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:11] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:11] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:11] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:11] [V] [TRT] Tactic: 0 Time: 1.27969
[05/21/2022-03:09:11] [V] [TRT] Tactic: 1 Time: 0.7986
[05/21/2022-03:09:11] [V] [TRT] Tactic: 2 Time: 1.24189
[05/21/2022-03:09:11] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558039040, available: 536870912
[05/21/2022-03:09:11] [V] [TRT] Tactic: 5 Time: 2.90096
[05/21/2022-03:09:11] [V] [TRT] Fastest Tactic: 1 Time: 0.7986
[05/21/2022-03:09:11] [V] [TRT] Setting workspace to 558039040enables more tactics for profiling
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:11] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:11] [V] [TRT] Tactic: 1062367460111450758 Time: 0.792266
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:09:11] [V] [TRT] Tactic: 1698681053543049347 Time: 0.728503
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:11] [V] [TRT] Tactic: 4501471010995462441 Time: 0.606836
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:11] [V] [TRT] Tactic: 5137655947464784826 Time: 0.592129
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:11] [V] [TRT] Tactic: 5288347012147084929 Time: 0.613366
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:09:11] [V] [TRT] Tactic: 5326823351883942011 Time: 0.578229
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:09:11] [V] [TRT] Tactic: 5500448035057547314 Time: 0.648158
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:11] [V] [TRT] Tactic: 6645123197870846056 Time: 0.594994
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:11] [V] [TRT] Tactic: 7144526460361122478 Time: 0.824987
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:11] [V] [TRT] Tactic: -8262349710178828730 Time: 0.617669
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:09:11] [V] [TRT] Tactic: -6576203419454146580 Time: 0.725482
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:11] [V] [TRT] Tactic: -4787320710726427159 Time: 0.857441
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:11] [V] [TRT] Tactic: -3456450830548107839 Time: 0.74847
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:11] [V] [TRT] Tactic: -1218658103698133241 Time: 0.666048
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:11] [V] [TRT] Tactic: -836875257600482091 Time: 0.653613
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:11] [V] [TRT] Tactic: -410470605513481746 Time: 0.598483
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:09:11] [V] [TRT] Tactic: -377491875521947884 Time: 0.603509
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:09:11] [V] [TRT] Tactic: -37215280111360163 Time: 0.574401
[05/21/2022-03:09:11] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.574401
[05/21/2022-03:09:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:09:11] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:11] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:11] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:09:11] [V] [TRT] Tactic: 3886731678879822788 Time: 0.638848
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:09:11] [V] [TRT] Tactic: 6629944304117643200 Time: 1.39639
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:11] [V] [TRT] Tactic: -9153228964338181824 Time: 1.42137
[05/21/2022-03:09:11] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:11] [V] [TRT] Tactic: -7394439838318485025 Time: 0.65638
[05/21/2022-03:09:11] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.638848
[05/21/2022-03:09:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-03:09:11] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:11] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:11] [V] [TRT] Tactic: 0 Time: 1.2424
[05/21/2022-03:09:11] [V] [TRT] Tactic: 1 Time: 1.07275
[05/21/2022-03:09:12] [V] [TRT] Tactic: 2 Time: 1.10538
[05/21/2022-03:09:12] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558039040, available: 536870912
[05/21/2022-03:09:12] [V] [TRT] Tactic: 5 Time: 2.77997
[05/21/2022-03:09:12] [V] [TRT] Fastest Tactic: 1 Time: 1.07275
[05/21/2022-03:09:12] [V] [TRT] Setting workspace to 558039040enables more tactics for profiling
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:12] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:12] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:09:12] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:12] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:12] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:12] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:12] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:12] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: 029_convolutional + 029_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:09:12] [V] [TRT] Tactic: 3066127711859985668 Time: 0.402168
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:12] [V] [TRT] Tactic: 3564772625446233998 Time: 0.439303
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:12] [V] [TRT] Tactic: 5319956359050645452 Time: 0.415195
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:12] [V] [TRT] Tactic: 7205456024582378848 Time: 0.33181
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:09:12] [V] [TRT] Tactic: 8163473458334948789 Time: 0.319525
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:12] [V] [TRT] Tactic: -4212163711445252890 Time: 0.319056
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:12] [V] [TRT] Tactic: -3898373634979201110 Time: 0.326797
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:12] [V] [TRT] Tactic: -2409163523992614473 Time: 0.323385
[05/21/2022-03:09:12] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:09:12] [V] [TRT] Tactic: -1716393687483585322 Time: 0.316862
[05/21/2022-03:09:12] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.316862
[05/21/2022-03:09:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:09:12] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:12] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:12] [V] [TRT] Tactic: 0 Time: 0.382051
[05/21/2022-03:09:12] [V] [TRT] Tactic: 1 Time: 0.284987
[05/21/2022-03:09:12] [V] [TRT] Tactic: 2 Time: 0.269837
[05/21/2022-03:09:12] [V] [TRT] Tactic: 3 Time: 0.236947
[05/21/2022-03:09:12] [V] [TRT] Tactic: 4 Time: 0.204505
[05/21/2022-03:09:12] [V] [TRT] Tactic: 5 Time: 0.210573
[05/21/2022-03:09:12] [V] [TRT] Tactic: 6 Time: 0.217214
[05/21/2022-03:09:12] [V] [TRT] Tactic: 7 Time: 0.177683
[05/21/2022-03:09:12] [V] [TRT] Tactic: 8 Time: 0.168665
[05/21/2022-03:09:12] [V] [TRT] Tactic: 9 Time: 0.181068
[05/21/2022-03:09:12] [V] [TRT] Tactic: 28 Time: 0.375931
[05/21/2022-03:09:12] [V] [TRT] Fastest Tactic: 8 Time: 0.168665
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-03:09:12] [V] [TRT] Tactic: 128 Time: 1.39488
[05/21/2022-03:09:12] [V] [TRT] Tactic: 256 Time: 1.39876
[05/21/2022-03:09:12] [V] [TRT] Tactic: 512 Time: 1.4013
[05/21/2022-03:09:12] [V] [TRT] Tactic: -32 Time: 1.47464
[05/21/2022-03:09:12] [V] [TRT] Tactic: -64 Time: 1.45497
[05/21/2022-03:09:12] [V] [TRT] Tactic: -128 Time: 1.45545
[05/21/2022-03:09:12] [V] [TRT] Fastest Tactic: 128 Time: 1.39488
[05/21/2022-03:09:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:12] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:12] [V] [TRT] Tactic: 0 Time: 0.382676
[05/21/2022-03:09:12] [V] [TRT] Tactic: 1 Time: 0.284701
[05/21/2022-03:09:12] [V] [TRT] Tactic: 2 Time: 0.269974
[05/21/2022-03:09:12] [V] [TRT] Tactic: 3 Time: 0.241256
[05/21/2022-03:09:12] [V] [TRT] Tactic: 4 Time: 0.204512
[05/21/2022-03:09:12] [V] [TRT] Tactic: 5 Time: 0.210515
[05/21/2022-03:09:12] [V] [TRT] Tactic: 6 Time: 0.216179
[05/21/2022-03:09:12] [V] [TRT] Tactic: 7 Time: 0.177422
[05/21/2022-03:09:12] [V] [TRT] Tactic: 8 Time: 0.168594
[05/21/2022-03:09:12] [V] [TRT] Tactic: 9 Time: 0.181269
[05/21/2022-03:09:12] [V] [TRT] Tactic: 28 Time: 0.375866
[05/21/2022-03:09:12] [V] [TRT] Fastest Tactic: 8 Time: 0.168594
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-03:09:12] [V] [TRT] Tactic: 128 Time: 1.39518
[05/21/2022-03:09:12] [V] [TRT] Tactic: 256 Time: 1.3983
[05/21/2022-03:09:12] [V] [TRT] Tactic: 512 Time: 1.40029
[05/21/2022-03:09:12] [V] [TRT] Tactic: -32 Time: 1.47401
[05/21/2022-03:09:12] [V] [TRT] Tactic: -64 Time: 1.45398
[05/21/2022-03:09:12] [V] [TRT] Tactic: -128 Time: 1.45578
[05/21/2022-03:09:12] [V] [TRT] Fastest Tactic: 128 Time: 1.39518
[05/21/2022-03:09:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:12] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:12] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:12] [V] [TRT] Tactic: 24 Time: 0.263131
[05/21/2022-03:09:12] [V] [TRT] Tactic: 25 Time: 0.240046
[05/21/2022-03:09:13] [V] [TRT] Tactic: 26 Time: 0.234434
[05/21/2022-03:09:13] [V] [TRT] Tactic: 27 Time: 0.234922
[05/21/2022-03:09:13] [V] [TRT] Tactic: 31 Time: 0.262324
[05/21/2022-03:09:13] [V] [TRT] Fastest Tactic: 26 Time: 0.234434
[05/21/2022-03:09:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-03:09:13] [V] [TRT] Tactic: 128 Time: 1.39514
[05/21/2022-03:09:13] [V] [TRT] Tactic: 256 Time: 1.39896
[05/21/2022-03:09:13] [V] [TRT] Tactic: 512 Time: 1.40112
[05/21/2022-03:09:13] [V] [TRT] Tactic: -32 Time: 1.47419
[05/21/2022-03:09:13] [V] [TRT] Tactic: -64 Time: 1.45396
[05/21/2022-03:09:13] [V] [TRT] Tactic: -128 Time: 1.45663
[05/21/2022-03:09:13] [V] [TRT] Fastest Tactic: 128 Time: 1.39514
[05/21/2022-03:09:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:09:13] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:13] [V] [TRT] Tactic: 0 Time: 0.389277
[05/21/2022-03:09:13] [V] [TRT] Tactic: 1 Time: 0.296849
[05/21/2022-03:09:13] [V] [TRT] Tactic: 2 Time: 0.275827
[05/21/2022-03:09:13] [V] [TRT] Tactic: 3 Time: 0.237337
[05/21/2022-03:09:13] [V] [TRT] Tactic: 4 Time: 0.216224
[05/21/2022-03:09:13] [V] [TRT] Tactic: 5 Time: 0.220638
[05/21/2022-03:09:13] [V] [TRT] Tactic: 6 Time: 0.212025
[05/21/2022-03:09:13] [V] [TRT] Tactic: 7 Time: 0.185801
[05/21/2022-03:09:13] [V] [TRT] Tactic: 8 Time: 0.185716
[05/21/2022-03:09:13] [V] [TRT] Tactic: 9 Time: 0.191569
[05/21/2022-03:09:13] [V] [TRT] Tactic: 28 Time: 0.390651
[05/21/2022-03:09:13] [V] [TRT] Fastest Tactic: 8 Time: 0.185716
[05/21/2022-03:09:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-03:09:13] [V] [TRT] Tactic: 128 Time: 1.43595
[05/21/2022-03:09:13] [V] [TRT] Tactic: 256 Time: 1.42441
[05/21/2022-03:09:13] [V] [TRT] Tactic: 512 Time: 1.33184
[05/21/2022-03:09:13] [V] [TRT] Tactic: -32 Time: 1.47027
[05/21/2022-03:09:13] [V] [TRT] Tactic: -64 Time: 1.44417
[05/21/2022-03:09:13] [V] [TRT] Tactic: -128 Time: 1.44626
[05/21/2022-03:09:13] [V] [TRT] Fastest Tactic: 512 Time: 1.33184
[05/21/2022-03:09:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:13] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:13] [V] [TRT] Tactic: 0 Time: 0.299642
[05/21/2022-03:09:13] [V] [TRT] Tactic: 1 Time: 0.243294
[05/21/2022-03:09:13] [V] [TRT] Tactic: 2 Time: 0.243743
[05/21/2022-03:09:13] [V] [TRT] Tactic: 3 Time: 0.224746
[05/21/2022-03:09:13] [V] [TRT] Tactic: 4 Time: 0.218542
[05/21/2022-03:09:13] [V] [TRT] Tactic: 5 Time: 0.221426
[05/21/2022-03:09:13] [V] [TRT] Tactic: 6 Time: 0.216556
[05/21/2022-03:09:13] [V] [TRT] Tactic: 7 Time: 0.207591
[05/21/2022-03:09:13] [V] [TRT] Tactic: 8 Time: 0.207467
[05/21/2022-03:09:13] [V] [TRT] Tactic: 9 Time: 0.218704
[05/21/2022-03:09:13] [V] [TRT] Tactic: 10 Time: 0.410169
[05/21/2022-03:09:13] [V] [TRT] Tactic: 11 Time: 0.306914
[05/21/2022-03:09:13] [V] [TRT] Tactic: 12 Time: 0.291595
[05/21/2022-03:09:13] [V] [TRT] Tactic: 13 Time: 0.242689
[05/21/2022-03:09:13] [V] [TRT] Tactic: 14 Time: 0.224876
[05/21/2022-03:09:13] [V] [TRT] Tactic: 15 Time: 0.230488
[05/21/2022-03:09:13] [V] [TRT] Tactic: 16 Time: 0.214974
[05/21/2022-03:09:13] [V] [TRT] Tactic: 17 Time: 0.1897
[05/21/2022-03:09:13] [V] [TRT] Tactic: 18 Time: 0.189212
[05/21/2022-03:09:13] [V] [TRT] Tactic: 19 Time: 0.203946
[05/21/2022-03:09:13] [V] [TRT] Tactic: 28 Time: 0.294642
[05/21/2022-03:09:13] [V] [TRT] Tactic: 29 Time: 0.403418
[05/21/2022-03:09:13] [V] [TRT] Fastest Tactic: 18 Time: 0.189212
[05/21/2022-03:09:13] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) (PointWise)
[05/21/2022-03:09:13] [V] [TRT] Tactic: 128 Time: 1.43795
[05/21/2022-03:09:14] [V] [TRT] Tactic: 256 Time: 1.42325
[05/21/2022-03:09:14] [V] [TRT] Tactic: 512 Time: 1.32576
[05/21/2022-03:09:14] [V] [TRT] Tactic: -32 Time: 1.4703
[05/21/2022-03:09:14] [V] [TRT] Tactic: -64 Time: 1.44546
[05/21/2022-03:09:14] [V] [TRT] Tactic: -128 Time: 1.4482
[05/21/2022-03:09:14] [V] [TRT] Fastest Tactic: 512 Time: 1.32576
[05/21/2022-03:09:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:09:14] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:14] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:14] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:14] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:14] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:14] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:14] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:14] [V] [TRT] Tactic: 0 Time: 7.66046
[05/21/2022-03:09:14] [V] [TRT] Tactic: 1 Time: 4.53265
[05/21/2022-03:09:14] [V] [TRT] Tactic: 2 Time: 7.48665
[05/21/2022-03:09:14] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558563328, available: 536870912
[05/21/2022-03:09:15] [V] [TRT] Tactic: 5 Time: 42.7994
[05/21/2022-03:09:15] [V] [TRT] Tactic: 6 Time: 3.67342
[05/21/2022-03:09:15] [V] [TRT] Fastest Tactic: 6 Time: 3.67342
[05/21/2022-03:09:15] [V] [TRT] Setting workspace to 558563328enables more tactics for profiling
[05/21/2022-03:09:15] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:15] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:15] [V] [TRT] Tactic: 1062367460111450758 Time: 5.35017
[05/21/2022-03:09:15] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:09:15] [V] [TRT] Tactic: 1754984623894446479 Time: 5.97301
[05/21/2022-03:09:15] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:09:15] [V] [TRT] Tactic: 3611739942397549984 Time: 4.3737
[05/21/2022-03:09:15] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:09:15] [V] [TRT] Tactic: 3827454225649558724 Time: 4.84299
[05/21/2022-03:09:15] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:09:15] [V] [TRT] Tactic: 4337000649858996379 Time: 4.39156
[05/21/2022-03:09:15] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:15] [V] [TRT] Tactic: 4501471010995462441 Time: 4.32949
[05/21/2022-03:09:15] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:16] [V] [TRT] Tactic: 5137655947464784826 Time: 4.21029
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:16] [V] [TRT] Tactic: 5288347012147084929 Time: 4.25435
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:09:16] [V] [TRT] Tactic: 5921334924264294896 Time: 3.54788
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:16] [V] [TRT] Tactic: 6645123197870846056 Time: 4.36699
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:16] [V] [TRT] Tactic: 7144526460361122478 Time: 5.50325
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:09:16] [V] [TRT] Tactic: 7852627285308570038 Time: 4.88457
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:09:16] [V] [TRT] Tactic: -9137461792520977713 Time: 4.34622
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:09:16] [V] [TRT] Tactic: -8776506421218919509 Time: 4.7815
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:16] [V] [TRT] Tactic: -8262349710178828730 Time: 4.35716
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:09:16] [V] [TRT] Tactic: -8133971918129952780 Time: 4.79588
[05/21/2022-03:09:16] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:09:17] [V] [TRT] Tactic: -6092040395344634144 Time: 5.52169
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:17] [V] [TRT] Tactic: -4787320710726427159 Time: 5.9791
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:17] [V] [TRT] Tactic: -3456450830548107839 Time: 4.89569
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:09:17] [V] [TRT] Tactic: -2318106587342035239 Time: 4.91642
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:09:17] [V] [TRT] Tactic: -1343271414618805657 Time: 3.22277
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:17] [V] [TRT] Tactic: -1218658103698133241 Time: 4.70675
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:17] [V] [TRT] Tactic: -836875257600482091 Time: 4.48646
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:17] [V] [TRT] Tactic: -410470605513481746 Time: 4.19303
[05/21/2022-03:09:17] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 3.22277
[05/21/2022-03:09:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:09:17] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:17] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:17] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:17] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:17] [V] [TRT] Tactic: -9153228964338181824 Time: 5.47738
[05/21/2022-03:09:17] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:17] [V] [TRT] Tactic: -7394439838318485025 Time: 4.14767
[05/21/2022-03:09:17] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.14767
[05/21/2022-03:09:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:09:17] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:17] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:18] [V] [TRT] Tactic: 0 Time: 10.8904
[05/21/2022-03:09:18] [V] [TRT] Tactic: 1 Time: 8.53036
[05/21/2022-03:09:18] [V] [TRT] Tactic: 2 Time: 7.18158
[05/21/2022-03:09:18] [V] [TRT] Tactic: 4 skipped. Scratch requested: 558563328, available: 536870912
[05/21/2022-03:09:19] [V] [TRT] Tactic: 5 Time: 41.4225
[05/21/2022-03:09:19] [V] [TRT] Tactic: 6 Time: 4.73548
[05/21/2022-03:09:19] [V] [TRT] Fastest Tactic: 6 Time: 4.73548
[05/21/2022-03:09:19] [V] [TRT] Setting workspace to 558563328enables more tactics for profiling
[05/21/2022-03:09:19] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:19] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-03:09:19] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:19] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:19] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:19] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:19] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:19] [V] [TRT] --------------- Timing Runner: 030_convolutional + 030_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:19] [V] [TRT] Tactic: 3564772625446233998 Time: 2.70617
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:09:19] [V] [TRT] Tactic: 3650389455493082349 Time: 2.80938
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:09:19] [V] [TRT] Tactic: 4772821744921268633 Time: 1.87325
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:19] [V] [TRT] Tactic: 5319956359050645452 Time: 2.4391
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:19] [V] [TRT] Tactic: 7205456024582378848 Time: 2.18311
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:09:19] [V] [TRT] Tactic: -6490690591794140522 Time: 2.20655
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:09:19] [V] [TRT] Tactic: -4686027666808657977 Time: 2.19913
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:19] [V] [TRT] Tactic: -4212163711445252890 Time: 2.1109
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:19] [V] [TRT] Tactic: -3898373634979201110 Time: 2.17667
[05/21/2022-03:09:19] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:19] [V] [TRT] Tactic: -2409163523992614473 Time: 2.12378
[05/21/2022-03:09:19] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 1.87325
[05/21/2022-03:09:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:09:19] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:19] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:19] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-03:09:19] [V] [TRT] Tactic: 0 Time: 0.404655
[05/21/2022-03:09:19] [V] [TRT] Tactic: 1 Time: 0.305566
[05/21/2022-03:09:19] [V] [TRT] Tactic: 2 Time: 0.303372
[05/21/2022-03:09:19] [V] [TRT] Tactic: 3 Time: 0.265228
[05/21/2022-03:09:19] [V] [TRT] Tactic: 4 Time: 0.23765
[05/21/2022-03:09:19] [V] [TRT] Tactic: 5 Time: 0.22918
[05/21/2022-03:09:19] [V] [TRT] Tactic: 6 Time: 0.256836
[05/21/2022-03:09:19] [V] [TRT] Tactic: 7 Time: 0.217598
[05/21/2022-03:09:20] [V] [TRT] Tactic: 8 Time: 0.214134
[05/21/2022-03:09:20] [V] [TRT] Tactic: 9 Time: 0.220781
[05/21/2022-03:09:20] [V] [TRT] Tactic: 28 Time: 0.401439
[05/21/2022-03:09:20] [V] [TRT] Fastest Tactic: 8 Time: 0.214134
[05/21/2022-03:09:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-03:09:20] [V] [TRT] Tactic: 128 Time: 1.61545
[05/21/2022-03:09:20] [V] [TRT] Tactic: 256 Time: 1.6177
[05/21/2022-03:09:20] [V] [TRT] Tactic: 512 Time: 1.62079
[05/21/2022-03:09:20] [V] [TRT] Tactic: -32 Time: 1.72121
[05/21/2022-03:09:20] [V] [TRT] Tactic: -64 Time: 1.69349
[05/21/2022-03:09:20] [V] [TRT] Tactic: -128 Time: 1.69449
[05/21/2022-03:09:20] [V] [TRT] Fastest Tactic: 128 Time: 1.61545
[05/21/2022-03:09:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:20] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-03:09:20] [V] [TRT] Tactic: 0 Time: 0.404232
[05/21/2022-03:09:20] [V] [TRT] Tactic: 1 Time: 0.305872
[05/21/2022-03:09:20] [V] [TRT] Tactic: 2 Time: 0.301341
[05/21/2022-03:09:20] [V] [TRT] Tactic: 3 Time: 0.26444
[05/21/2022-03:09:20] [V] [TRT] Tactic: 4 Time: 0.237858
[05/21/2022-03:09:20] [V] [TRT] Tactic: 5 Time: 0.229733
[05/21/2022-03:09:20] [V] [TRT] Tactic: 6 Time: 0.256133
[05/21/2022-03:09:20] [V] [TRT] Tactic: 7 Time: 0.217904
[05/21/2022-03:09:20] [V] [TRT] Tactic: 8 Time: 0.213464
[05/21/2022-03:09:20] [V] [TRT] Tactic: 9 Time: 0.220911
[05/21/2022-03:09:20] [V] [TRT] Tactic: 28 Time: 0.401491
[05/21/2022-03:09:20] [V] [TRT] Fastest Tactic: 8 Time: 0.213464
[05/21/2022-03:09:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-03:09:20] [V] [TRT] Tactic: 128 Time: 1.6148
[05/21/2022-03:09:20] [V] [TRT] Tactic: 256 Time: 1.61628
[05/21/2022-03:09:20] [V] [TRT] Tactic: 512 Time: 1.61956
[05/21/2022-03:09:20] [V] [TRT] Tactic: -32 Time: 1.72347
[05/21/2022-03:09:20] [V] [TRT] Tactic: -64 Time: 1.69258
[05/21/2022-03:09:20] [V] [TRT] Tactic: -128 Time: 1.69424
[05/21/2022-03:09:20] [V] [TRT] Fastest Tactic: 128 Time: 1.6148
[05/21/2022-03:09:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:20] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-03:09:20] [V] [TRT] Tactic: 24 Time: 0.376556
[05/21/2022-03:09:20] [V] [TRT] Tactic: 25 Time: 0.323535
[05/21/2022-03:09:20] [V] [TRT] Tactic: 26 Time: 0.320189
[05/21/2022-03:09:20] [V] [TRT] Tactic: 27 Time: 0.317181
[05/21/2022-03:09:20] [V] [TRT] Tactic: 31 Time: 0.37793
[05/21/2022-03:09:20] [V] [TRT] Fastest Tactic: 27 Time: 0.317181
[05/21/2022-03:09:20] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-03:09:20] [V] [TRT] Tactic: 128 Time: 1.61491
[05/21/2022-03:09:20] [V] [TRT] Tactic: 256 Time: 1.61682
[05/21/2022-03:09:20] [V] [TRT] Tactic: 512 Time: 1.65351
[05/21/2022-03:09:20] [V] [TRT] Tactic: -32 Time: 1.72171
[05/21/2022-03:09:20] [V] [TRT] Tactic: -64 Time: 1.69275
[05/21/2022-03:09:21] [V] [TRT] Tactic: -128 Time: 1.69464
[05/21/2022-03:09:21] [V] [TRT] Fastest Tactic: 128 Time: 1.61491
[05/21/2022-03:09:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:09:21] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-03:09:21] [V] [TRT] Tactic: 0 Time: 0.412123
[05/21/2022-03:09:21] [V] [TRT] Tactic: 1 Time: 0.311927
[05/21/2022-03:09:21] [V] [TRT] Tactic: 2 Time: 0.295534
[05/21/2022-03:09:21] [V] [TRT] Tactic: 3 Time: 0.250078
[05/21/2022-03:09:21] [V] [TRT] Tactic: 4 Time: 0.249792
[05/21/2022-03:09:21] [V] [TRT] Tactic: 5 Time: 0.235495
[05/21/2022-03:09:21] [V] [TRT] Tactic: 6 Time: 0.223718
[05/21/2022-03:09:21] [V] [TRT] Tactic: 7 Time: 0.216308
[05/21/2022-03:09:21] [V] [TRT] Tactic: 8 Time: 0.206107
[05/21/2022-03:09:21] [V] [TRT] Tactic: 9 Time: 0.211061
[05/21/2022-03:09:21] [V] [TRT] Tactic: 28 Time: 0.407304
[05/21/2022-03:09:21] [V] [TRT] Fastest Tactic: 8 Time: 0.206107
[05/21/2022-03:09:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-03:09:21] [V] [TRT] Tactic: 128 Time: 1.67292
[05/21/2022-03:09:21] [V] [TRT] Tactic: 256 Time: 1.65861
[05/21/2022-03:09:21] [V] [TRT] Tactic: 512 Time: 1.56112
[05/21/2022-03:09:21] [V] [TRT] Tactic: -32 Time: 1.75748
[05/21/2022-03:09:21] [V] [TRT] Tactic: -64 Time: 1.71811
[05/21/2022-03:09:21] [V] [TRT] Tactic: -128 Time: 1.71719
[05/21/2022-03:09:21] [V] [TRT] Fastest Tactic: 512 Time: 1.56112
[05/21/2022-03:09:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:21] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWiseV2)
[05/21/2022-03:09:21] [V] [TRT] Tactic: 0 Time: 0.354062
[05/21/2022-03:09:21] [V] [TRT] Tactic: 1 Time: 0.321589
[05/21/2022-03:09:21] [V] [TRT] Tactic: 2 Time: 0.303594
[05/21/2022-03:09:21] [V] [TRT] Tactic: 3 Time: 0.294752
[05/21/2022-03:09:21] [V] [TRT] Tactic: 4 Time: 0.292162
[05/21/2022-03:09:21] [V] [TRT] Tactic: 5 Time: 0.277201
[05/21/2022-03:09:21] [V] [TRT] Tactic: 6 Time: 0.277747
[05/21/2022-03:09:21] [V] [TRT] Tactic: 7 Time: 0.273105
[05/21/2022-03:09:21] [V] [TRT] Tactic: 8 Time: 0.31778
[05/21/2022-03:09:21] [V] [TRT] Tactic: 9 Time: 0.369942
[05/21/2022-03:09:21] [V] [TRT] Tactic: 10 Time: 0.441615
[05/21/2022-03:09:21] [V] [TRT] Tactic: 11 Time: 0.346556
[05/21/2022-03:09:21] [V] [TRT] Tactic: 12 Time: 0.331556
[05/21/2022-03:09:21] [V] [TRT] Tactic: 13 Time: 0.277018
[05/21/2022-03:09:21] [V] [TRT] Tactic: 14 Time: 0.288535
[05/21/2022-03:09:21] [V] [TRT] Tactic: 15 Time: 0.273535
[05/21/2022-03:09:21] [V] [TRT] Tactic: 16 Time: 0.245729
[05/21/2022-03:09:21] [V] [TRT] Tactic: 17 Time: 0.253457
[05/21/2022-03:09:21] [V] [TRT] Tactic: 18 Time: 0.245338
[05/21/2022-03:09:21] [V] [TRT] Tactic: 19 Time: 0.25207
[05/21/2022-03:09:21] [V] [TRT] Tactic: 28 Time: 0.344076
[05/21/2022-03:09:21] [V] [TRT] Tactic: 29 Time: 0.43291
[05/21/2022-03:09:21] [V] [TRT] Fastest Tactic: 18 Time: 0.245338
[05/21/2022-03:09:21] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) (PointWise)
[05/21/2022-03:09:21] [V] [TRT] Tactic: 128 Time: 1.67466
[05/21/2022-03:09:21] [V] [TRT] Tactic: 256 Time: 1.66936
[05/21/2022-03:09:21] [V] [TRT] Tactic: 512 Time: 1.55901
[05/21/2022-03:09:21] [V] [TRT] Tactic: -32 Time: 1.75775
[05/21/2022-03:09:21] [V] [TRT] Tactic: -64 Time: 1.71824
[05/21/2022-03:09:22] [V] [TRT] Tactic: -128 Time: 1.71559
[05/21/2022-03:09:22] [V] [TRT] Fastest Tactic: 512 Time: 1.55901
[05/21/2022-03:09:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1), Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128), Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1), Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1), Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1), Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:09:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:22] [V] [TRT] Tactic: 0 Time: 0.484323
[05/21/2022-03:09:22] [V] [TRT] Tactic: 1 Time: 0.338945
[05/21/2022-03:09:22] [V] [TRT] Tactic: 2 Time: 0.320072
[05/21/2022-03:09:22] [V] [TRT] Tactic: 3 Time: 0.256608
[05/21/2022-03:09:22] [V] [TRT] Tactic: 4 Time: 0.239095
[05/21/2022-03:09:22] [V] [TRT] Tactic: 5 Time: 0.235651
[05/21/2022-03:09:22] [V] [TRT] Tactic: 6 Time: 0.224512
[05/21/2022-03:09:22] [V] [TRT] Tactic: 7 Time: 0.192506
[05/21/2022-03:09:22] [V] [TRT] Tactic: 8 Time: 0.190039
[05/21/2022-03:09:22] [V] [TRT] Tactic: 9 Time: 0.196009
[05/21/2022-03:09:22] [V] [TRT] Tactic: 28 Time: 0.479199
[05/21/2022-03:09:22] [V] [TRT] Fastest Tactic: 8 Time: 0.190039
[05/21/2022-03:09:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-03:09:22] [V] [TRT] Tactic: 128 Time: 1.57298
[05/21/2022-03:09:22] [V] [TRT] Tactic: 256 Time: 1.57316
[05/21/2022-03:09:22] [V] [TRT] Tactic: 512 Time: 1.57542
[05/21/2022-03:09:22] [V] [TRT] Tactic: -32 Time: 1.47812
[05/21/2022-03:09:22] [V] [TRT] Tactic: -64 Time: 1.46396
[05/21/2022-03:09:22] [V] [TRT] Tactic: -128 Time: 1.47755
[05/21/2022-03:09:22] [V] [TRT] Fastest Tactic: -64 Time: 1.46396
[05/21/2022-03:09:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:22] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:09:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:22] [V] [TRT] Tactic: 0 Time: 0.484434
[05/21/2022-03:09:22] [V] [TRT] Tactic: 1 Time: 0.339075
[05/21/2022-03:09:22] [V] [TRT] Tactic: 2 Time: 0.320657
[05/21/2022-03:09:22] [V] [TRT] Tactic: 3 Time: 0.25709
[05/21/2022-03:09:22] [V] [TRT] Tactic: 4 Time: 0.238978
[05/21/2022-03:09:22] [V] [TRT] Tactic: 5 Time: 0.235716
[05/21/2022-03:09:22] [V] [TRT] Tactic: 6 Time: 0.32153
[05/21/2022-03:09:22] [V] [TRT] Tactic: 7 Time: 0.279499
[05/21/2022-03:09:22] [V] [TRT] Tactic: 8 Time: 0.273691
[05/21/2022-03:09:22] [V] [TRT] Tactic: 9 Time: 0.260182
[05/21/2022-03:09:22] [V] [TRT] Tactic: 28 Time: 0.479212
[05/21/2022-03:09:22] [V] [TRT] Fastest Tactic: 5 Time: 0.235716
[05/21/2022-03:09:22] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-03:09:22] [V] [TRT] Tactic: 128 Time: 1.57257
[05/21/2022-03:09:22] [V] [TRT] Tactic: 256 Time: 1.5734
[05/21/2022-03:09:22] [V] [TRT] Tactic: 512 Time: 1.5745
[05/21/2022-03:09:23] [V] [TRT] Tactic: -32 Time: 1.51859
[05/21/2022-03:09:23] [V] [TRT] Tactic: -64 Time: 1.58369
[05/21/2022-03:09:23] [V] [TRT] Tactic: -128 Time: 1.74106
[05/21/2022-03:09:23] [V] [TRT] Fastest Tactic: -32 Time: 1.51859
[05/21/2022-03:09:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:09:23] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:09:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:23] [V] [TRT] Tactic: 24 Time: 0.267279
[05/21/2022-03:09:23] [V] [TRT] Tactic: 25 Time: 0.241432
[05/21/2022-03:09:23] [V] [TRT] Tactic: 26 Time: 0.235046
[05/21/2022-03:09:23] [V] [TRT] Tactic: 27 Time: 0.239395
[05/21/2022-03:09:23] [V] [TRT] Tactic: 31 Time: 0.266823
[05/21/2022-03:09:23] [V] [TRT] Fastest Tactic: 26 Time: 0.235046
[05/21/2022-03:09:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-03:09:23] [V] [TRT] Tactic: 128 Time: 1.57361
[05/21/2022-03:09:23] [V] [TRT] Tactic: 256 Time: 1.57319
[05/21/2022-03:09:23] [V] [TRT] Tactic: 512 Time: 1.57508
[05/21/2022-03:09:23] [V] [TRT] Tactic: -32 Time: 1.47851
[05/21/2022-03:09:23] [V] [TRT] Tactic: -64 Time: 1.46372
[05/21/2022-03:09:23] [V] [TRT] Tactic: -128 Time: 1.47852
[05/21/2022-03:09:23] [V] [TRT] Fastest Tactic: -64 Time: 1.46372
[05/21/2022-03:09:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:09:23] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:23] [V] [TRT] Tactic: 0 Time: 0.498385
[05/21/2022-03:09:23] [V] [TRT] Tactic: 1 Time: 0.353646
[05/21/2022-03:09:23] [V] [TRT] Tactic: 2 Time: 0.330013
[05/21/2022-03:09:23] [V] [TRT] Tactic: 3 Time: 0.263021
[05/21/2022-03:09:23] [V] [TRT] Tactic: 4 Time: 0.249544
[05/21/2022-03:09:23] [V] [TRT] Tactic: 5 Time: 0.244056
[05/21/2022-03:09:23] [V] [TRT] Tactic: 6 Time: 0.223125
[05/21/2022-03:09:23] [V] [TRT] Tactic: 7 Time: 0.199752
[05/21/2022-03:09:23] [V] [TRT] Tactic: 8 Time: 0.203073
[05/21/2022-03:09:23] [V] [TRT] Tactic: 9 Time: 0.201374
[05/21/2022-03:09:23] [V] [TRT] Tactic: 28 Time: 0.495358
[05/21/2022-03:09:23] [V] [TRT] Fastest Tactic: 7 Time: 0.199752
[05/21/2022-03:09:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-03:09:23] [V] [TRT] Tactic: 128 Time: 1.51664
[05/21/2022-03:09:23] [V] [TRT] Tactic: 256 Time: 1.50065
[05/21/2022-03:09:23] [V] [TRT] Tactic: 512 Time: 1.39174
[05/21/2022-03:09:23] [V] [TRT] Tactic: -32 Time: 1.48147
[05/21/2022-03:09:23] [V] [TRT] Tactic: -64 Time: 1.4591
[05/21/2022-03:09:23] [V] [TRT] Tactic: -128 Time: 1.47401
[05/21/2022-03:09:23] [V] [TRT] Fastest Tactic: 512 Time: 1.39174
[05/21/2022-03:09:23] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:09:23] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:09:23] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:23] [V] [TRT] Tactic: 0 Time: 0.339974
[05/21/2022-03:09:23] [V] [TRT] Tactic: 1 Time: 0.262558
[05/21/2022-03:09:23] [V] [TRT] Tactic: 2 Time: 0.263008
[05/21/2022-03:09:23] [V] [TRT] Tactic: 3 Time: 0.232799
[05/21/2022-03:09:23] [V] [TRT] Tactic: 4 Time: 0.224818
[05/21/2022-03:09:23] [V] [TRT] Tactic: 5 Time: 0.229779
[05/21/2022-03:09:23] [V] [TRT] Tactic: 6 Time: 0.219564
[05/21/2022-03:09:23] [V] [TRT] Tactic: 7 Time: 0.210156
[05/21/2022-03:09:23] [V] [TRT] Tactic: 8 Time: 0.207839
[05/21/2022-03:09:23] [V] [TRT] Tactic: 9 Time: 0.221393
[05/21/2022-03:09:23] [V] [TRT] Tactic: 10 Time: 0.513177
[05/21/2022-03:09:23] [V] [TRT] Tactic: 11 Time: 0.369284
[05/21/2022-03:09:24] [V] [TRT] Tactic: 12 Time: 0.345742
[05/21/2022-03:09:24] [V] [TRT] Tactic: 13 Time: 0.273431
[05/21/2022-03:09:24] [V] [TRT] Tactic: 14 Time: 0.259675
[05/21/2022-03:09:24] [V] [TRT] Tactic: 15 Time: 0.262526
[05/21/2022-03:09:24] [V] [TRT] Tactic: 16 Time: 0.229798
[05/21/2022-03:09:24] [V] [TRT] Tactic: 17 Time: 0.20571
[05/21/2022-03:09:24] [V] [TRT] Tactic: 18 Time: 0.20931
[05/21/2022-03:09:24] [V] [TRT] Tactic: 19 Time: 0.218431
[05/21/2022-03:09:24] [V] [TRT] Tactic: 28 Time: 0.333809
[05/21/2022-03:09:24] [V] [TRT] Tactic: 29 Time: 0.51597
[05/21/2022-03:09:24] [V] [TRT] Fastest Tactic: 17 Time: 0.20571
[05/21/2022-03:09:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) (PointWise)
[05/21/2022-03:09:24] [V] [TRT] Tactic: 128 Time: 1.51682
[05/21/2022-03:09:24] [V] [TRT] Tactic: 256 Time: 1.49893
[05/21/2022-03:09:24] [V] [TRT] Tactic: 512 Time: 1.38629
[05/21/2022-03:09:24] [V] [TRT] Tactic: -32 Time: 1.48184
[05/21/2022-03:09:24] [V] [TRT] Tactic: -64 Time: 1.45949
[05/21/2022-03:09:24] [V] [TRT] Tactic: -128 Time: 1.47243
[05/21/2022-03:09:24] [V] [TRT] Fastest Tactic: 512 Time: 1.38629
[05/21/2022-03:09:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:09:24] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Float(21632,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:09:24] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:24] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:09:24] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:24] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:24] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:24] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:24] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:24] [V] [TRT] Tactic: 0 Time: 14.3696
[05/21/2022-03:09:24] [V] [TRT] Tactic: 1 Time: 10.1292
[05/21/2022-03:09:25] [V] [TRT] Tactic: 2 Time: 13.303
[05/21/2022-03:09:25] [V] [TRT] Tactic: 5 skipped. Scratch requested: 579986432, available: 536870912
[05/21/2022-03:09:25] [V] [TRT] Fastest Tactic: 1 Time: 10.1292
[05/21/2022-03:09:25] [V] [TRT] Setting workspace to 579986432enables more tactics for profiling
[05/21/2022-03:09:25] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:25] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:25] [V] [TRT] Tactic: 1062367460111450758 Time: 11.1866
[05/21/2022-03:09:25] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:09:25] [V] [TRT] Tactic: 1754984623894446479 Time: 13.4356
[05/21/2022-03:09:25] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:09:25] [V] [TRT] Tactic: 3611739942397549984 Time: 9.28079
[05/21/2022-03:09:25] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:09:25] [V] [TRT] Tactic: 4337000649858996379 Time: 9.4104
[05/21/2022-03:09:25] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:26] [V] [TRT] Tactic: 4501471010995462441 Time: 9.25453
[05/21/2022-03:09:26] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:26] [V] [TRT] Tactic: 5137655947464784826 Time: 9.08156
[05/21/2022-03:09:26] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:26] [V] [TRT] Tactic: 5288347012147084929 Time: 9.17703
[05/21/2022-03:09:26] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:26] [V] [TRT] Tactic: 6645123197870846056 Time: 9.26874
[05/21/2022-03:09:26] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:26] [V] [TRT] Tactic: 7144526460361122478 Time: 12.4176
[05/21/2022-03:09:26] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:09:27] [V] [TRT] Tactic: -9137461792520977713 Time: 9.32447
[05/21/2022-03:09:27] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:27] [V] [TRT] Tactic: -8262349710178828730 Time: 9.33699
[05/21/2022-03:09:27] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:09:27] [V] [TRT] Tactic: -8133971918129952780 Time: 10.3201
[05/21/2022-03:09:27] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:09:27] [V] [TRT] Tactic: -6092040395344634144 Time: 11.7
[05/21/2022-03:09:27] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:28] [V] [TRT] Tactic: -4787320710726427159 Time: 13.4221
[05/21/2022-03:09:28] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:28] [V] [TRT] Tactic: -3456450830548107839 Time: 10.3557
[05/21/2022-03:09:28] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:28] [V] [TRT] Tactic: -1218658103698133241 Time: 10.1692
[05/21/2022-03:09:28] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:28] [V] [TRT] Tactic: -836875257600482091 Time: 9.83387
[05/21/2022-03:09:28] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:28] [V] [TRT] Tactic: -410470605513481746 Time: 9.05892
[05/21/2022-03:09:28] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 9.05892
[05/21/2022-03:09:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-03:09:28] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:09:28] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:28] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:28] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:28] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:29] [V] [TRT] Tactic: -9153228964338181824 Time: 12.7827
[05/21/2022-03:09:29] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:29] [V] [TRT] Tactic: -7394439838318485025 Time: 9.05245
[05/21/2022-03:09:29] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 9.05245
[05/21/2022-03:09:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:09:29] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:29] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:29] [V] [TRT] Tactic: 0 Time: 16.1184
[05/21/2022-03:09:29] [V] [TRT] Tactic: 1 Time: 16.4319
[05/21/2022-03:09:30] [V] [TRT] Tactic: 2 Time: 13.0958
[05/21/2022-03:09:30] [V] [TRT] Tactic: 5 skipped. Scratch requested: 578548224, available: 536870912
[05/21/2022-03:09:30] [V] [TRT] Fastest Tactic: 2 Time: 13.0958
[05/21/2022-03:09:30] [V] [TRT] Setting workspace to 578548224enables more tactics for profiling
[05/21/2022-03:09:30] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:30] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:09:30] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:09:30] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:30] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:30] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:30] [V] [TRT] --------------- Timing Runner: 056_convolutional + 056_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:30] [V] [TRT] Tactic: 3564772625446233998 Time: 5.71115
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:09:30] [V] [TRT] Tactic: 3650389455493082349 Time: 5.91947
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:30] [V] [TRT] Tactic: 5319956359050645452 Time: 5.17673
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:30] [V] [TRT] Tactic: 7205456024582378848 Time: 4.67003
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:09:30] [V] [TRT] Tactic: -6490690591794140522 Time: 4.69975
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:09:30] [V] [TRT] Tactic: -4686027666808657977 Time: 4.68801
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:30] [V] [TRT] Tactic: -4212163711445252890 Time: 4.53183
[05/21/2022-03:09:30] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:31] [V] [TRT] Tactic: -3898373634979201110 Time: 4.64999
[05/21/2022-03:09:31] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:31] [V] [TRT] Tactic: -2409163523992614473 Time: 4.56652
[05/21/2022-03:09:31] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 4.53183
[05/21/2022-03:09:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-03:09:31] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:31] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:09:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:31] [V] [TRT] Tactic: 0 Time: 0.382943
[05/21/2022-03:09:31] [V] [TRT] Tactic: 1 Time: 0.285026
[05/21/2022-03:09:31] [V] [TRT] Tactic: 2 Time: 0.269831
[05/21/2022-03:09:31] [V] [TRT] Tactic: 3 Time: 0.2378
[05/21/2022-03:09:31] [V] [TRT] Tactic: 4 Time: 0.204447
[05/21/2022-03:09:31] [V] [TRT] Tactic: 5 Time: 0.21071
[05/21/2022-03:09:31] [V] [TRT] Tactic: 6 Time: 0.216081
[05/21/2022-03:09:31] [V] [TRT] Tactic: 7 Time: 0.17763
[05/21/2022-03:09:31] [V] [TRT] Tactic: 8 Time: 0.169004
[05/21/2022-03:09:31] [V] [TRT] Tactic: 9 Time: 0.181373
[05/21/2022-03:09:31] [V] [TRT] Tactic: 28 Time: 0.376738
[05/21/2022-03:09:31] [V] [TRT] Fastest Tactic: 8 Time: 0.169004
[05/21/2022-03:09:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-03:09:31] [V] [TRT] Tactic: 128 Time: 1.39507
[05/21/2022-03:09:31] [V] [TRT] Tactic: 256 Time: 1.39804
[05/21/2022-03:09:31] [V] [TRT] Tactic: 512 Time: 1.40018
[05/21/2022-03:09:31] [V] [TRT] Tactic: -32 Time: 1.47361
[05/21/2022-03:09:31] [V] [TRT] Tactic: -64 Time: 1.45452
[05/21/2022-03:09:31] [V] [TRT] Tactic: -128 Time: 1.45624
[05/21/2022-03:09:31] [V] [TRT] Fastest Tactic: 128 Time: 1.39507
[05/21/2022-03:09:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:31] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:09:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:31] [V] [TRT] Tactic: 0 Time: 0.382721
[05/21/2022-03:09:31] [V] [TRT] Tactic: 1 Time: 0.284577
[05/21/2022-03:09:31] [V] [TRT] Tactic: 2 Time: 0.269466
[05/21/2022-03:09:31] [V] [TRT] Tactic: 3 Time: 0.237155
[05/21/2022-03:09:31] [V] [TRT] Tactic: 4 Time: 0.204355
[05/21/2022-03:09:31] [V] [TRT] Tactic: 5 Time: 0.210423
[05/21/2022-03:09:31] [V] [TRT] Tactic: 6 Time: 0.217083
[05/21/2022-03:09:31] [V] [TRT] Tactic: 7 Time: 0.177096
[05/21/2022-03:09:31] [V] [TRT] Tactic: 8 Time: 0.168952
[05/21/2022-03:09:31] [V] [TRT] Tactic: 9 Time: 0.181159
[05/21/2022-03:09:31] [V] [TRT] Tactic: 28 Time: 0.376133
[05/21/2022-03:09:31] [V] [TRT] Fastest Tactic: 8 Time: 0.168952
[05/21/2022-03:09:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-03:09:31] [V] [TRT] Tactic: 128 Time: 1.39535
[05/21/2022-03:09:31] [V] [TRT] Tactic: 256 Time: 1.39855
[05/21/2022-03:09:31] [V] [TRT] Tactic: 512 Time: 1.40123
[05/21/2022-03:09:31] [V] [TRT] Tactic: -32 Time: 1.47387
[05/21/2022-03:09:31] [V] [TRT] Tactic: -64 Time: 1.45392
[05/21/2022-03:09:31] [V] [TRT] Tactic: -128 Time: 1.45605
[05/21/2022-03:09:31] [V] [TRT] Fastest Tactic: 128 Time: 1.39535
[05/21/2022-03:09:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:31] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:09:31] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:32] [V] [TRT] Tactic: 24 Time: 0.263737
[05/21/2022-03:09:32] [V] [TRT] Tactic: 25 Time: 0.241055
[05/21/2022-03:09:32] [V] [TRT] Tactic: 26 Time: 0.235924
[05/21/2022-03:09:32] [V] [TRT] Tactic: 27 Time: 0.23334
[05/21/2022-03:09:32] [V] [TRT] Tactic: 31 Time: 0.262305
[05/21/2022-03:09:32] [V] [TRT] Fastest Tactic: 27 Time: 0.23334
[05/21/2022-03:09:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-03:09:32] [V] [TRT] Tactic: 128 Time: 1.3952
[05/21/2022-03:09:32] [V] [TRT] Tactic: 256 Time: 1.3988
[05/21/2022-03:09:32] [V] [TRT] Tactic: 512 Time: 1.40062
[05/21/2022-03:09:32] [V] [TRT] Tactic: -32 Time: 1.47339
[05/21/2022-03:09:32] [V] [TRT] Tactic: -64 Time: 1.45355
[05/21/2022-03:09:32] [V] [TRT] Tactic: -128 Time: 1.45657
[05/21/2022-03:09:32] [V] [TRT] Fastest Tactic: 128 Time: 1.3952
[05/21/2022-03:09:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:09:32] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:32] [V] [TRT] Tactic: 0 Time: 0.389805
[05/21/2022-03:09:32] [V] [TRT] Tactic: 1 Time: 0.296576
[05/21/2022-03:09:32] [V] [TRT] Tactic: 2 Time: 0.27638
[05/21/2022-03:09:32] [V] [TRT] Tactic: 3 Time: 0.237695
[05/21/2022-03:09:32] [V] [TRT] Tactic: 4 Time: 0.216387
[05/21/2022-03:09:32] [V] [TRT] Tactic: 5 Time: 0.220833
[05/21/2022-03:09:32] [V] [TRT] Tactic: 6 Time: 0.212279
[05/21/2022-03:09:32] [V] [TRT] Tactic: 7 Time: 0.185736
[05/21/2022-03:09:32] [V] [TRT] Tactic: 8 Time: 0.185937
[05/21/2022-03:09:32] [V] [TRT] Tactic: 9 Time: 0.191614
[05/21/2022-03:09:32] [V] [TRT] Tactic: 28 Time: 0.390658
[05/21/2022-03:09:32] [V] [TRT] Fastest Tactic: 7 Time: 0.185736
[05/21/2022-03:09:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-03:09:32] [V] [TRT] Tactic: 128 Time: 1.43764
[05/21/2022-03:09:32] [V] [TRT] Tactic: 256 Time: 1.42437
[05/21/2022-03:09:32] [V] [TRT] Tactic: 512 Time: 1.32581
[05/21/2022-03:09:32] [V] [TRT] Tactic: -32 Time: 1.46926
[05/21/2022-03:09:32] [V] [TRT] Tactic: -64 Time: 1.4435
[05/21/2022-03:09:32] [V] [TRT] Tactic: -128 Time: 1.44599
[05/21/2022-03:09:32] [V] [TRT] Fastest Tactic: 512 Time: 1.32581
[05/21/2022-03:09:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:09:32] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:09:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:32] [V] [TRT] Tactic: 0 Time: 0.299642
[05/21/2022-03:09:32] [V] [TRT] Tactic: 1 Time: 0.244544
[05/21/2022-03:09:32] [V] [TRT] Tactic: 2 Time: 0.244147
[05/21/2022-03:09:32] [V] [TRT] Tactic: 3 Time: 0.225391
[05/21/2022-03:09:32] [V] [TRT] Tactic: 4 Time: 0.219004
[05/21/2022-03:09:32] [V] [TRT] Tactic: 5 Time: 0.223073
[05/21/2022-03:09:32] [V] [TRT] Tactic: 6 Time: 0.215918
[05/21/2022-03:09:32] [V] [TRT] Tactic: 7 Time: 0.207591
[05/21/2022-03:09:32] [V] [TRT] Tactic: 8 Time: 0.206673
[05/21/2022-03:09:32] [V] [TRT] Tactic: 9 Time: 0.217031
[05/21/2022-03:09:32] [V] [TRT] Tactic: 10 Time: 0.409863
[05/21/2022-03:09:32] [V] [TRT] Tactic: 11 Time: 0.306842
[05/21/2022-03:09:32] [V] [TRT] Tactic: 12 Time: 0.291777
[05/21/2022-03:09:32] [V] [TRT] Tactic: 13 Time: 0.242572
[05/21/2022-03:09:32] [V] [TRT] Tactic: 14 Time: 0.224564
[05/21/2022-03:09:32] [V] [TRT] Tactic: 15 Time: 0.230475
[05/21/2022-03:09:32] [V] [TRT] Tactic: 16 Time: 0.21612
[05/21/2022-03:09:32] [V] [TRT] Tactic: 17 Time: 0.189727
[05/21/2022-03:09:32] [V] [TRT] Tactic: 18 Time: 0.188731
[05/21/2022-03:09:32] [V] [TRT] Tactic: 19 Time: 0.203646
[05/21/2022-03:09:32] [V] [TRT] Tactic: 28 Time: 0.293919
[05/21/2022-03:09:32] [V] [TRT] Tactic: 29 Time: 0.403613
[05/21/2022-03:09:32] [V] [TRT] Fastest Tactic: 18 Time: 0.188731
[05/21/2022-03:09:32] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) (PointWise)
[05/21/2022-03:09:33] [V] [TRT] Tactic: 128 Time: 1.43638
[05/21/2022-03:09:33] [V] [TRT] Tactic: 256 Time: 1.42656
[05/21/2022-03:09:33] [V] [TRT] Tactic: 512 Time: 1.33019
[05/21/2022-03:09:33] [V] [TRT] Tactic: -32 Time: 1.46922
[05/21/2022-03:09:33] [V] [TRT] Tactic: -64 Time: 1.44351
[05/21/2022-03:09:33] [V] [TRT] Tactic: -128 Time: 1.44746
[05/21/2022-03:09:33] [V] [TRT] Fastest Tactic: 512 Time: 1.33019
[05/21/2022-03:09:33] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:09:33] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:33] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:09:33] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:33] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:33] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:33] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:33] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:33] [V] [TRT] Tactic: 0 Time: 4.30434
[05/21/2022-03:09:33] [V] [TRT] Tactic: 1 Time: 2.57306
[05/21/2022-03:09:33] [V] [TRT] Tactic: 2 Time: 3.51438
[05/21/2022-03:09:33] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2287206400, available: 536870912
[05/21/2022-03:09:33] [V] [TRT] Tactic: 5 Time: 19.6297
[05/21/2022-03:09:33] [V] [TRT] Fastest Tactic: 1 Time: 2.57306
[05/21/2022-03:09:33] [V] [TRT] Setting workspace to 2287206400enables more tactics for profiling
[05/21/2022-03:09:33] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:33] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:33] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:33] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:33] [V] [TRT] Tactic: 1062367460111450758 Time: 2.81921
[05/21/2022-03:09:33] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:09:33] [V] [TRT] Tactic: 1698681053543049347 Time: 2.68462
[05/21/2022-03:09:33] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:33] [V] [TRT] Tactic: 4501471010995462441 Time: 2.15115
[05/21/2022-03:09:33] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:33] [V] [TRT] Tactic: 5137655947464784826 Time: 2.13544
[05/21/2022-03:09:33] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:34] [V] [TRT] Tactic: 5288347012147084929 Time: 2.15176
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:09:34] [V] [TRT] Tactic: 5326823351883942011 Time: 2.07357
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:09:34] [V] [TRT] Tactic: 5500448035057547314 Time: 2.35327
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:34] [V] [TRT] Tactic: 6645123197870846056 Time: 2.17631
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:34] [V] [TRT] Tactic: 7144526460361122478 Time: 3.04308
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:34] [V] [TRT] Tactic: -8262349710178828730 Time: 2.18964
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:09:34] [V] [TRT] Tactic: -6576203419454146580 Time: 2.50311
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:34] [V] [TRT] Tactic: -4787320710726427159 Time: 3.18119
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:34] [V] [TRT] Tactic: -3456450830548107839 Time: 2.62508
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:34] [V] [TRT] Tactic: -1218658103698133241 Time: 2.47118
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:34] [V] [TRT] Tactic: -836875257600482091 Time: 2.41391
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:34] [V] [TRT] Tactic: -410470605513481746 Time: 2.13752
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:09:34] [V] [TRT] Tactic: -377491875521947884 Time: 2.12956
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:09:34] [V] [TRT] Tactic: -37215280111360163 Time: 2.08856
[05/21/2022-03:09:34] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 2.07357
[05/21/2022-03:09:34] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:09:34] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:09:34] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:34] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:34] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:34] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:34] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:09:34] [V] [TRT] Tactic: 3886731678879822788 Time: 2.17067
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:09:34] [V] [TRT] Tactic: 6629944304117643200 Time: 3.78018
[05/21/2022-03:09:34] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:35] [V] [TRT] Tactic: -9153228964338181824 Time: 3.81649
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:35] [V] [TRT] Tactic: -7394439838318485025 Time: 2.16036
[05/21/2022-03:09:35] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.16036
[05/21/2022-03:09:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:09:35] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:35] [V] [TRT] Tactic: 0 Time: 3.81417
[05/21/2022-03:09:35] [V] [TRT] Tactic: 1 Time: 3.90798
[05/21/2022-03:09:35] [V] [TRT] Tactic: 2 Time: 3.42219
[05/21/2022-03:09:35] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2287206400, available: 536870912
[05/21/2022-03:09:35] [V] [TRT] Tactic: 5 Time: 19.5677
[05/21/2022-03:09:35] [V] [TRT] Fastest Tactic: 2 Time: 3.42219
[05/21/2022-03:09:35] [V] [TRT] Setting workspace to 2287206400enables more tactics for profiling
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:35] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:35] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:09:35] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:35] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:35] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:35] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:35] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:35] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:35] [V] [TRT] --------------- Timing Runner: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:09:35] [V] [TRT] Tactic: 3066127711859985668 Time: 1.25686
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:35] [V] [TRT] Tactic: 3564772625446233998 Time: 1.41505
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:35] [V] [TRT] Tactic: 5319956359050645452 Time: 1.31405
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:35] [V] [TRT] Tactic: 7205456024582378848 Time: 1.12394
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:09:35] [V] [TRT] Tactic: 8163473458334948789 Time: 1.07615
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:35] [V] [TRT] Tactic: -4212163711445252890 Time: 1.09096
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:35] [V] [TRT] Tactic: -3898373634979201110 Time: 1.11266
[05/21/2022-03:09:35] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:35] [V] [TRT] Tactic: -2409163523992614473 Time: 1.09285
[05/21/2022-03:09:36] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:09:36] [V] [TRT] Tactic: -1716393687483585322 Time: 1.07644
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 1.07615
[05/21/2022-03:09:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:09:36] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:36] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 0 Time: 0.247057
[05/21/2022-03:09:36] [V] [TRT] Tactic: 1 Time: 0.174466
[05/21/2022-03:09:36] [V] [TRT] Tactic: 2 Time: 0.164687
[05/21/2022-03:09:36] [V] [TRT] Tactic: 3 Time: 0.133268
[05/21/2022-03:09:36] [V] [TRT] Tactic: 4 Time: 0.123835
[05/21/2022-03:09:36] [V] [TRT] Tactic: 5 Time: 0.121842
[05/21/2022-03:09:36] [V] [TRT] Tactic: 6 Time: 0.117181
[05/21/2022-03:09:36] [V] [TRT] Tactic: 7 Time: 0.100345
[05/21/2022-03:09:36] [V] [TRT] Tactic: 8 Time: 0.0993166
[05/21/2022-03:09:36] [V] [TRT] Tactic: 9 Time: 0.101862
[05/21/2022-03:09:36] [V] [TRT] Tactic: 28 Time: 0.244447
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: 8 Time: 0.0993166
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 128 Time: 0.790853
[05/21/2022-03:09:36] [V] [TRT] Tactic: 256 Time: 0.791621
[05/21/2022-03:09:36] [V] [TRT] Tactic: 512 Time: 0.791328
[05/21/2022-03:09:36] [V] [TRT] Tactic: -32 Time: 0.774218
[05/21/2022-03:09:36] [V] [TRT] Tactic: -64 Time: 0.748171
[05/21/2022-03:09:36] [V] [TRT] Tactic: -128 Time: 0.746348
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: -128 Time: 0.746348
[05/21/2022-03:09:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:36] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 0 Time: 0.24709
[05/21/2022-03:09:36] [V] [TRT] Tactic: 1 Time: 0.174069
[05/21/2022-03:09:36] [V] [TRT] Tactic: 2 Time: 0.165013
[05/21/2022-03:09:36] [V] [TRT] Tactic: 3 Time: 0.133802
[05/21/2022-03:09:36] [V] [TRT] Tactic: 4 Time: 0.124023
[05/21/2022-03:09:36] [V] [TRT] Tactic: 5 Time: 0.122539
[05/21/2022-03:09:36] [V] [TRT] Tactic: 6 Time: 0.12097
[05/21/2022-03:09:36] [V] [TRT] Tactic: 7 Time: 0.101413
[05/21/2022-03:09:36] [V] [TRT] Tactic: 8 Time: 0.0999025
[05/21/2022-03:09:36] [V] [TRT] Tactic: 9 Time: 0.102064
[05/21/2022-03:09:36] [V] [TRT] Tactic: 28 Time: 0.244779
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: 8 Time: 0.0999025
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 128 Time: 0.791146
[05/21/2022-03:09:36] [V] [TRT] Tactic: 256 Time: 0.790833
[05/21/2022-03:09:36] [V] [TRT] Tactic: 512 Time: 0.791569
[05/21/2022-03:09:36] [V] [TRT] Tactic: -32 Time: 0.749909
[05/21/2022-03:09:36] [V] [TRT] Tactic: -64 Time: 0.759772
[05/21/2022-03:09:36] [V] [TRT] Tactic: -128 Time: 0.798769
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: -32 Time: 0.749909
[05/21/2022-03:09:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:36] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 24 Time: 0.136888
[05/21/2022-03:09:36] [V] [TRT] Tactic: 25 Time: 0.124701
[05/21/2022-03:09:36] [V] [TRT] Tactic: 26 Time: 0.122422
[05/21/2022-03:09:36] [V] [TRT] Tactic: 27 Time: 0.126621
[05/21/2022-03:09:36] [V] [TRT] Tactic: 31 Time: 0.137559
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: 26 Time: 0.122422
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 128 Time: 0.79084
[05/21/2022-03:09:36] [V] [TRT] Tactic: 256 Time: 0.790833
[05/21/2022-03:09:36] [V] [TRT] Tactic: 512 Time: 0.791204
[05/21/2022-03:09:36] [V] [TRT] Tactic: -32 Time: 0.774994
[05/21/2022-03:09:36] [V] [TRT] Tactic: -64 Time: 0.747773
[05/21/2022-03:09:36] [V] [TRT] Tactic: -128 Time: 0.747272
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: -128 Time: 0.747272
[05/21/2022-03:09:36] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:09:36] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 0 Time: 0.253711
[05/21/2022-03:09:36] [V] [TRT] Tactic: 1 Time: 0.181224
[05/21/2022-03:09:36] [V] [TRT] Tactic: 2 Time: 0.169915
[05/21/2022-03:09:36] [V] [TRT] Tactic: 3 Time: 0.136016
[05/21/2022-03:09:36] [V] [TRT] Tactic: 4 Time: 0.129277
[05/21/2022-03:09:36] [V] [TRT] Tactic: 5 Time: 0.12623
[05/21/2022-03:09:36] [V] [TRT] Tactic: 6 Time: 0.115671
[05/21/2022-03:09:36] [V] [TRT] Tactic: 7 Time: 0.104753
[05/21/2022-03:09:36] [V] [TRT] Tactic: 8 Time: 0.105631
[05/21/2022-03:09:36] [V] [TRT] Tactic: 9 Time: 0.104863
[05/21/2022-03:09:36] [V] [TRT] Tactic: 28 Time: 0.252376
[05/21/2022-03:09:36] [V] [TRT] Fastest Tactic: 7 Time: 0.104753
[05/21/2022-03:09:36] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-03:09:36] [V] [TRT] Tactic: 128 Time: 0.76181
[05/21/2022-03:09:36] [V] [TRT] Tactic: 256 Time: 0.754785
[05/21/2022-03:09:37] [V] [TRT] Tactic: 512 Time: 0.696504
[05/21/2022-03:09:37] [V] [TRT] Tactic: -32 Time: 0.776257
[05/21/2022-03:09:37] [V] [TRT] Tactic: -64 Time: 0.743105
[05/21/2022-03:09:37] [V] [TRT] Tactic: -128 Time: 0.745137
[05/21/2022-03:09:37] [V] [TRT] Fastest Tactic: 512 Time: 0.696504
[05/21/2022-03:09:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:09:37] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:09:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:37] [V] [TRT] Tactic: 0 Time: 0.174108
[05/21/2022-03:09:37] [V] [TRT] Tactic: 1 Time: 0.13595
[05/21/2022-03:09:37] [V] [TRT] Tactic: 2 Time: 0.135716
[05/21/2022-03:09:37] [V] [TRT] Tactic: 3 Time: 0.121204
[05/21/2022-03:09:37] [V] [TRT] Tactic: 4 Time: 0.116999
[05/21/2022-03:09:37] [V] [TRT] Tactic: 5 Time: 0.119987
[05/21/2022-03:09:37] [V] [TRT] Tactic: 6 Time: 0.115905
[05/21/2022-03:09:37] [V] [TRT] Tactic: 7 Time: 0.110729
[05/21/2022-03:09:37] [V] [TRT] Tactic: 8 Time: 0.110137
[05/21/2022-03:09:37] [V] [TRT] Tactic: 9 Time: 0.114909
[05/21/2022-03:09:37] [V] [TRT] Tactic: 10 Time: 0.261321
[05/21/2022-03:09:37] [V] [TRT] Tactic: 11 Time: 0.189499
[05/21/2022-03:09:37] [V] [TRT] Tactic: 12 Time: 0.177357
[05/21/2022-03:09:37] [V] [TRT] Tactic: 13 Time: 0.141556
[05/21/2022-03:09:37] [V] [TRT] Tactic: 14 Time: 0.133939
[05/21/2022-03:09:37] [V] [TRT] Tactic: 15 Time: 0.135254
[05/21/2022-03:09:37] [V] [TRT] Tactic: 16 Time: 0.119694
[05/21/2022-03:09:37] [V] [TRT] Tactic: 17 Time: 0.107422
[05/21/2022-03:09:37] [V] [TRT] Tactic: 18 Time: 0.108939
[05/21/2022-03:09:37] [V] [TRT] Tactic: 19 Time: 0.113073
[05/21/2022-03:09:37] [V] [TRT] Tactic: 28 Time: 0.170911
[05/21/2022-03:09:37] [V] [TRT] Tactic: 29 Time: 0.262988
[05/21/2022-03:09:37] [V] [TRT] Fastest Tactic: 17 Time: 0.107422
[05/21/2022-03:09:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) (PointWise)
[05/21/2022-03:09:37] [V] [TRT] Tactic: 128 Time: 0.762838
[05/21/2022-03:09:37] [V] [TRT] Tactic: 256 Time: 0.753457
[05/21/2022-03:09:37] [V] [TRT] Tactic: 512 Time: 0.696907
[05/21/2022-03:09:37] [V] [TRT] Tactic: -32 Time: 0.77569
[05/21/2022-03:09:37] [V] [TRT] Tactic: -64 Time: 0.742422
[05/21/2022-03:09:37] [V] [TRT] Tactic: -128 Time: 0.744369
[05/21/2022-03:09:37] [V] [TRT] Fastest Tactic: 512 Time: 0.696907
[05/21/2022-03:09:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:09:37] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:37] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:37] [V] [TRT] Tactic: 0 Time: 0.247337
[05/21/2022-03:09:37] [V] [TRT] Tactic: 1 Time: 0.174343
[05/21/2022-03:09:37] [V] [TRT] Tactic: 2 Time: 0.164525
[05/21/2022-03:09:37] [V] [TRT] Tactic: 3 Time: 0.133125
[05/21/2022-03:09:37] [V] [TRT] Tactic: 4 Time: 0.124277
[05/21/2022-03:09:37] [V] [TRT] Tactic: 5 Time: 0.121667
[05/21/2022-03:09:37] [V] [TRT] Tactic: 6 Time: 0.117376
[05/21/2022-03:09:37] [V] [TRT] Tactic: 7 Time: 0.100462
[05/21/2022-03:09:37] [V] [TRT] Tactic: 8 Time: 0.0989062
[05/21/2022-03:09:37] [V] [TRT] Tactic: 9 Time: 0.102005
[05/21/2022-03:09:37] [V] [TRT] Tactic: 28 Time: 0.244675
[05/21/2022-03:09:37] [V] [TRT] Fastest Tactic: 8 Time: 0.0989062
[05/21/2022-03:09:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-03:09:37] [V] [TRT] Tactic: 128 Time: 0.791302
[05/21/2022-03:09:37] [V] [TRT] Tactic: 256 Time: 0.791315
[05/21/2022-03:09:37] [V] [TRT] Tactic: 512 Time: 0.791524
[05/21/2022-03:09:37] [V] [TRT] Tactic: -32 Time: 0.774414
[05/21/2022-03:09:37] [V] [TRT] Tactic: -64 Time: 0.748131
[05/21/2022-03:09:37] [V] [TRT] Tactic: -128 Time: 0.746804
[05/21/2022-03:09:37] [V] [TRT] Fastest Tactic: -128 Time: 0.746804
[05/21/2022-03:09:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:37] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:37] [V] [TRT] Tactic: 0 Time: 0.246842
[05/21/2022-03:09:37] [V] [TRT] Tactic: 1 Time: 0.174473
[05/21/2022-03:09:37] [V] [TRT] Tactic: 2 Time: 0.164778
[05/21/2022-03:09:37] [V] [TRT] Tactic: 3 Time: 0.133815
[05/21/2022-03:09:37] [V] [TRT] Tactic: 4 Time: 0.123945
[05/21/2022-03:09:37] [V] [TRT] Tactic: 5 Time: 0.122142
[05/21/2022-03:09:37] [V] [TRT] Tactic: 6 Time: 0.11985
[05/21/2022-03:09:37] [V] [TRT] Tactic: 7 Time: 0.101133
[05/21/2022-03:09:37] [V] [TRT] Tactic: 8 Time: 0.09916
[05/21/2022-03:09:37] [V] [TRT] Tactic: 9 Time: 0.102266
[05/21/2022-03:09:37] [V] [TRT] Tactic: 28 Time: 0.244467
[05/21/2022-03:09:37] [V] [TRT] Fastest Tactic: 8 Time: 0.09916
[05/21/2022-03:09:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-03:09:37] [V] [TRT] Tactic: 128 Time: 0.791022
[05/21/2022-03:09:37] [V] [TRT] Tactic: 256 Time: 0.79056
[05/21/2022-03:09:37] [V] [TRT] Tactic: 512 Time: 0.791315
[05/21/2022-03:09:37] [V] [TRT] Tactic: -32 Time: 0.749948
[05/21/2022-03:09:37] [V] [TRT] Tactic: -64 Time: 0.75972
[05/21/2022-03:09:37] [V] [TRT] Tactic: -128 Time: 0.797793
[05/21/2022-03:09:37] [V] [TRT] Fastest Tactic: -32 Time: 0.749948
[05/21/2022-03:09:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:37] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:37] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:38] [V] [TRT] Tactic: 24 Time: 0.138112
[05/21/2022-03:09:38] [V] [TRT] Tactic: 25 Time: 0.123861
[05/21/2022-03:09:38] [V] [TRT] Tactic: 26 Time: 0.122259
[05/21/2022-03:09:38] [V] [TRT] Tactic: 27 Time: 0.124564
[05/21/2022-03:09:38] [V] [TRT] Tactic: 31 Time: 0.13804
[05/21/2022-03:09:38] [V] [TRT] Fastest Tactic: 26 Time: 0.122259
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-03:09:38] [V] [TRT] Tactic: 128 Time: 0.790566
[05/21/2022-03:09:38] [V] [TRT] Tactic: 256 Time: 0.790651
[05/21/2022-03:09:38] [V] [TRT] Tactic: 512 Time: 0.791237
[05/21/2022-03:09:38] [V] [TRT] Tactic: -32 Time: 0.774564
[05/21/2022-03:09:38] [V] [TRT] Tactic: -64 Time: 0.747461
[05/21/2022-03:09:38] [V] [TRT] Tactic: -128 Time: 0.746966
[05/21/2022-03:09:38] [V] [TRT] Fastest Tactic: -128 Time: 0.746966
[05/21/2022-03:09:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:09:38] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:38] [V] [TRT] Tactic: 0 Time: 0.253776
[05/21/2022-03:09:38] [V] [TRT] Tactic: 1 Time: 0.181517
[05/21/2022-03:09:38] [V] [TRT] Tactic: 2 Time: 0.169434
[05/21/2022-03:09:38] [V] [TRT] Tactic: 3 Time: 0.13599
[05/21/2022-03:09:38] [V] [TRT] Tactic: 4 Time: 0.128965
[05/21/2022-03:09:38] [V] [TRT] Tactic: 5 Time: 0.125606
[05/21/2022-03:09:38] [V] [TRT] Tactic: 6 Time: 0.115964
[05/21/2022-03:09:38] [V] [TRT] Tactic: 7 Time: 0.104818
[05/21/2022-03:09:38] [V] [TRT] Tactic: 8 Time: 0.105547
[05/21/2022-03:09:38] [V] [TRT] Tactic: 9 Time: 0.104759
[05/21/2022-03:09:38] [V] [TRT] Tactic: 28 Time: 0.252487
[05/21/2022-03:09:38] [V] [TRT] Fastest Tactic: 9 Time: 0.104759
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-03:09:38] [V] [TRT] Tactic: 128 Time: 0.762722
[05/21/2022-03:09:38] [V] [TRT] Tactic: 256 Time: 0.751524
[05/21/2022-03:09:38] [V] [TRT] Tactic: 512 Time: 0.69584
[05/21/2022-03:09:38] [V] [TRT] Tactic: -32 Time: 0.776732
[05/21/2022-03:09:38] [V] [TRT] Tactic: -64 Time: 0.741836
[05/21/2022-03:09:38] [V] [TRT] Tactic: -128 Time: 0.744525
[05/21/2022-03:09:38] [V] [TRT] Fastest Tactic: 512 Time: 0.69584
[05/21/2022-03:09:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:09:38] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:38] [V] [TRT] Tactic: 0 Time: 0.174472
[05/21/2022-03:09:38] [V] [TRT] Tactic: 1 Time: 0.136269
[05/21/2022-03:09:38] [V] [TRT] Tactic: 2 Time: 0.135983
[05/21/2022-03:09:38] [V] [TRT] Tactic: 3 Time: 0.121048
[05/21/2022-03:09:38] [V] [TRT] Tactic: 4 Time: 0.117272
[05/21/2022-03:09:38] [V] [TRT] Tactic: 5 Time: 0.119993
[05/21/2022-03:09:38] [V] [TRT] Tactic: 6 Time: 0.116348
[05/21/2022-03:09:38] [V] [TRT] Tactic: 7 Time: 0.111217
[05/21/2022-03:09:38] [V] [TRT] Tactic: 8 Time: 0.110143
[05/21/2022-03:09:38] [V] [TRT] Tactic: 9 Time: 0.115443
[05/21/2022-03:09:38] [V] [TRT] Tactic: 10 Time: 0.261257
[05/21/2022-03:09:38] [V] [TRT] Tactic: 11 Time: 0.189733
[05/21/2022-03:09:38] [V] [TRT] Tactic: 12 Time: 0.177454
[05/21/2022-03:09:38] [V] [TRT] Tactic: 13 Time: 0.141406
[05/21/2022-03:09:38] [V] [TRT] Tactic: 14 Time: 0.134317
[05/21/2022-03:09:38] [V] [TRT] Tactic: 15 Time: 0.135254
[05/21/2022-03:09:38] [V] [TRT] Tactic: 16 Time: 0.119948
[05/21/2022-03:09:38] [V] [TRT] Tactic: 17 Time: 0.107331
[05/21/2022-03:09:38] [V] [TRT] Tactic: 18 Time: 0.108737
[05/21/2022-03:09:38] [V] [TRT] Tactic: 19 Time: 0.112793
[05/21/2022-03:09:38] [V] [TRT] Tactic: 28 Time: 0.171523
[05/21/2022-03:09:38] [V] [TRT] Tactic: 29 Time: 0.262617
[05/21/2022-03:09:38] [V] [TRT] Fastest Tactic: 17 Time: 0.107331
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) (PointWise)
[05/21/2022-03:09:38] [V] [TRT] Tactic: 128 Time: 0.763288
[05/21/2022-03:09:38] [V] [TRT] Tactic: 256 Time: 0.75403
[05/21/2022-03:09:38] [V] [TRT] Tactic: 512 Time: 0.695579
[05/21/2022-03:09:38] [V] [TRT] Tactic: -32 Time: 0.778568
[05/21/2022-03:09:38] [V] [TRT] Tactic: -64 Time: 0.742572
[05/21/2022-03:09:38] [V] [TRT] Tactic: -128 Time: 0.74388
[05/21/2022-03:09:38] [V] [TRT] Fastest Tactic: 512 Time: 0.695579
[05/21/2022-03:09:38] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:09:38] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:38] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:38] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:38] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:38] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:38] [V] [TRT] Tactic: 0 Time: 1.18659
[05/21/2022-03:09:38] [V] [TRT] Tactic: 1 Time: 0.993249
[05/21/2022-03:09:38] [V] [TRT] Tactic: 2 Time: 1.07531
[05/21/2022-03:09:38] [V] [TRT] Tactic: 4 skipped. Scratch requested: 572915712, available: 536870912
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5 Time: 5.03917
[05/21/2022-03:09:39] [V] [TRT] Fastest Tactic: 1 Time: 0.993249
[05/21/2022-03:09:39] [V] [TRT] Setting workspace to 572915712enables more tactics for profiling
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:39] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:39] [V] [TRT] Tactic: 1062367460111450758 Time: 0.763724
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:09:39] [V] [TRT] Tactic: 1698681053543049347 Time: 0.71735
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:39] [V] [TRT] Tactic: 4501471010995462441 Time: 0.591335
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5137655947464784826 Time: 0.586022
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5288347012147084929 Time: 0.596328
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5326823351883942011 Time: 0.57224
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5500448035057547314 Time: 0.643691
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:39] [V] [TRT] Tactic: 6645123197870846056 Time: 0.601126
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:39] [V] [TRT] Tactic: 7144526460361122478 Time: 0.807897
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:39] [V] [TRT] Tactic: -8262349710178828730 Time: 0.60735
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:09:39] [V] [TRT] Tactic: -6576203419454146580 Time: 0.681719
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:39] [V] [TRT] Tactic: -4787320710726427159 Time: 0.846986
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:39] [V] [TRT] Tactic: -3456450830548107839 Time: 0.720137
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:39] [V] [TRT] Tactic: -1218658103698133241 Time: 0.668516
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:39] [V] [TRT] Tactic: -836875257600482091 Time: 0.652071
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:39] [V] [TRT] Tactic: -410470605513481746 Time: 0.580911
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:09:39] [V] [TRT] Tactic: -377491875521947884 Time: 0.586191
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:09:39] [V] [TRT] Tactic: -37215280111360163 Time: 0.56918
[05/21/2022-03:09:39] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 0.56918
[05/21/2022-03:09:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:09:39] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:39] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:09:39] [V] [TRT] Tactic: 3886731678879822788 Time: 0.599381
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:09:39] [V] [TRT] Tactic: 6629944304117643200 Time: 1.08418
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:39] [V] [TRT] Tactic: -9153228964338181824 Time: 1.10629
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:39] [V] [TRT] Tactic: -7394439838318485025 Time: 0.614798
[05/21/2022-03:09:39] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.599381
[05/21/2022-03:09:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-03:09:39] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:39] [V] [TRT] Tactic: 0 Time: 1.18426
[05/21/2022-03:09:39] [V] [TRT] Tactic: 1 Time: 1.02451
[05/21/2022-03:09:39] [V] [TRT] Tactic: 2 Time: 1.01502
[05/21/2022-03:09:39] [V] [TRT] Tactic: 4 skipped. Scratch requested: 572915712, available: 536870912
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5 Time: 4.76084
[05/21/2022-03:09:39] [V] [TRT] Fastest Tactic: 2 Time: 1.01502
[05/21/2022-03:09:39] [V] [TRT] Setting workspace to 572915712enables more tactics for profiling
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:39] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:39] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:09:39] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:39] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:39] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:39] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CublasConvolution)
[05/21/2022-03:09:39] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: 060_convolutional + 060_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:09:39] [V] [TRT] Tactic: 3066127711859985668 Time: 0.366439
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:39] [V] [TRT] Tactic: 3564772625446233998 Time: 0.403945
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5319956359050645452 Time: 0.37957
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:39] [V] [TRT] Tactic: 7205456024582378848 Time: 0.314193
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:09:39] [V] [TRT] Tactic: 8163473458334948789 Time: 0.301315
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:39] [V] [TRT] Tactic: -4212163711445252890 Time: 0.304095
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:39] [V] [TRT] Tactic: -3898373634979201110 Time: 0.308326
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:39] [V] [TRT] Tactic: -2409163523992614473 Time: 0.308717
[05/21/2022-03:09:39] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:09:39] [V] [TRT] Tactic: -1716393687483585322 Time: 0.300762
[05/21/2022-03:09:39] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.300762
[05/21/2022-03:09:39] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:09:39] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:39] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:39] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:39] [V] [TRT] Tactic: 0 Time: 0.195723
[05/21/2022-03:09:39] [V] [TRT] Tactic: 1 Time: 0.146582
[05/21/2022-03:09:39] [V] [TRT] Tactic: 2 Time: 0.138841
[05/21/2022-03:09:39] [V] [TRT] Tactic: 3 Time: 0.1222
[05/21/2022-03:09:39] [V] [TRT] Tactic: 4 Time: 0.106074
[05/21/2022-03:09:39] [V] [TRT] Tactic: 5 Time: 0.109531
[05/21/2022-03:09:39] [V] [TRT] Tactic: 6 Time: 0.112161
[05/21/2022-03:09:39] [V] [TRT] Tactic: 7 Time: 0.093086
[05/21/2022-03:09:40] [V] [TRT] Tactic: 8 Time: 0.0881381
[05/21/2022-03:09:40] [V] [TRT] Tactic: 9 Time: 0.0946159
[05/21/2022-03:09:40] [V] [TRT] Tactic: 28 Time: 0.192344
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 8 Time: 0.0881381
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 128 Time: 0.701523
[05/21/2022-03:09:40] [V] [TRT] Tactic: 256 Time: 0.703177
[05/21/2022-03:09:40] [V] [TRT] Tactic: 512 Time: 0.704303
[05/21/2022-03:09:40] [V] [TRT] Tactic: -32 Time: 0.771504
[05/21/2022-03:09:40] [V] [TRT] Tactic: -64 Time: 0.7428
[05/21/2022-03:09:40] [V] [TRT] Tactic: -128 Time: 0.736113
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 128 Time: 0.701523
[05/21/2022-03:09:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:40] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 0 Time: 0.195462
[05/21/2022-03:09:40] [V] [TRT] Tactic: 1 Time: 0.147279
[05/21/2022-03:09:40] [V] [TRT] Tactic: 2 Time: 0.138535
[05/21/2022-03:09:40] [V] [TRT] Tactic: 3 Time: 0.122702
[05/21/2022-03:09:40] [V] [TRT] Tactic: 4 Time: 0.106224
[05/21/2022-03:09:40] [V] [TRT] Tactic: 5 Time: 0.10916
[05/21/2022-03:09:40] [V] [TRT] Tactic: 6 Time: 0.113053
[05/21/2022-03:09:40] [V] [TRT] Tactic: 7 Time: 0.0927084
[05/21/2022-03:09:40] [V] [TRT] Tactic: 8 Time: 0.0880599
[05/21/2022-03:09:40] [V] [TRT] Tactic: 9 Time: 0.0947005
[05/21/2022-03:09:40] [V] [TRT] Tactic: 28 Time: 0.192044
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 8 Time: 0.0880599
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 128 Time: 0.70151
[05/21/2022-03:09:40] [V] [TRT] Tactic: 256 Time: 0.70291
[05/21/2022-03:09:40] [V] [TRT] Tactic: 512 Time: 0.704206
[05/21/2022-03:09:40] [V] [TRT] Tactic: -32 Time: 0.771133
[05/21/2022-03:09:40] [V] [TRT] Tactic: -64 Time: 0.742363
[05/21/2022-03:09:40] [V] [TRT] Tactic: -128 Time: 0.73653
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 128 Time: 0.70151
[05/21/2022-03:09:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:40] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 24 Time: 0.135026
[05/21/2022-03:09:40] [V] [TRT] Tactic: 25 Time: 0.122441
[05/21/2022-03:09:40] [V] [TRT] Tactic: 26 Time: 0.123099
[05/21/2022-03:09:40] [V] [TRT] Tactic: 27 Time: 0.122832
[05/21/2022-03:09:40] [V] [TRT] Tactic: 31 Time: 0.135599
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 25 Time: 0.122441
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 128 Time: 0.701973
[05/21/2022-03:09:40] [V] [TRT] Tactic: 256 Time: 0.70306
[05/21/2022-03:09:40] [V] [TRT] Tactic: 512 Time: 0.704733
[05/21/2022-03:09:40] [V] [TRT] Tactic: -32 Time: 0.771471
[05/21/2022-03:09:40] [V] [TRT] Tactic: -64 Time: 0.741869
[05/21/2022-03:09:40] [V] [TRT] Tactic: -128 Time: 0.735963
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 128 Time: 0.701973
[05/21/2022-03:09:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:09:40] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 0 Time: 0.199206
[05/21/2022-03:09:40] [V] [TRT] Tactic: 1 Time: 0.152617
[05/21/2022-03:09:40] [V] [TRT] Tactic: 2 Time: 0.142311
[05/21/2022-03:09:40] [V] [TRT] Tactic: 3 Time: 0.123288
[05/21/2022-03:09:40] [V] [TRT] Tactic: 4 Time: 0.112083
[05/21/2022-03:09:40] [V] [TRT] Tactic: 5 Time: 0.11431
[05/21/2022-03:09:40] [V] [TRT] Tactic: 6 Time: 0.110306
[05/21/2022-03:09:40] [V] [TRT] Tactic: 7 Time: 0.096543
[05/21/2022-03:09:40] [V] [TRT] Tactic: 8 Time: 0.0967188
[05/21/2022-03:09:40] [V] [TRT] Tactic: 9 Time: 0.0991014
[05/21/2022-03:09:40] [V] [TRT] Tactic: 28 Time: 0.199284
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 7 Time: 0.096543
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 128 Time: 0.722767
[05/21/2022-03:09:40] [V] [TRT] Tactic: 256 Time: 0.716354
[05/21/2022-03:09:40] [V] [TRT] Tactic: 512 Time: 0.67248
[05/21/2022-03:09:40] [V] [TRT] Tactic: -32 Time: 0.77125
[05/21/2022-03:09:40] [V] [TRT] Tactic: -64 Time: 0.736022
[05/21/2022-03:09:40] [V] [TRT] Tactic: -128 Time: 0.730886
[05/21/2022-03:09:40] [V] [TRT] Fastest Tactic: 512 Time: 0.67248
[05/21/2022-03:09:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:09:40] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:40] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:40] [V] [TRT] Tactic: 0 Time: 0.153327
[05/21/2022-03:09:40] [V] [TRT] Tactic: 1 Time: 0.126524
[05/21/2022-03:09:40] [V] [TRT] Tactic: 2 Time: 0.125879
[05/21/2022-03:09:40] [V] [TRT] Tactic: 3 Time: 0.116237
[05/21/2022-03:09:40] [V] [TRT] Tactic: 4 Time: 0.112298
[05/21/2022-03:09:40] [V] [TRT] Tactic: 5 Time: 0.115143
[05/21/2022-03:09:40] [V] [TRT] Tactic: 6 Time: 0.113542
[05/21/2022-03:09:40] [V] [TRT] Tactic: 7 Time: 0.109636
[05/21/2022-03:09:40] [V] [TRT] Tactic: 8 Time: 0.109088
[05/21/2022-03:09:40] [V] [TRT] Tactic: 9 Time: 0.113256
[05/21/2022-03:09:40] [V] [TRT] Tactic: 10 Time: 0.209408
[05/21/2022-03:09:40] [V] [TRT] Tactic: 11 Time: 0.158151
[05/21/2022-03:09:40] [V] [TRT] Tactic: 12 Time: 0.150084
[05/21/2022-03:09:40] [V] [TRT] Tactic: 13 Time: 0.126347
[05/21/2022-03:09:40] [V] [TRT] Tactic: 14 Time: 0.116563
[05/21/2022-03:09:40] [V] [TRT] Tactic: 15 Time: 0.118952
[05/21/2022-03:09:40] [V] [TRT] Tactic: 16 Time: 0.111934
[05/21/2022-03:09:40] [V] [TRT] Tactic: 17 Time: 0.0984441
[05/21/2022-03:09:40] [V] [TRT] Tactic: 18 Time: 0.0977279
[05/21/2022-03:09:41] [V] [TRT] Tactic: 19 Time: 0.105553
[05/21/2022-03:09:41] [V] [TRT] Tactic: 28 Time: 0.150807
[05/21/2022-03:09:41] [V] [TRT] Tactic: 29 Time: 0.205807
[05/21/2022-03:09:41] [V] [TRT] Fastest Tactic: 18 Time: 0.0977279
[05/21/2022-03:09:41] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) (PointWise)
[05/21/2022-03:09:41] [V] [TRT] Tactic: 128 Time: 0.724212
[05/21/2022-03:09:41] [V] [TRT] Tactic: 256 Time: 0.717025
[05/21/2022-03:09:41] [V] [TRT] Tactic: 512 Time: 0.673229
[05/21/2022-03:09:41] [V] [TRT] Tactic: -32 Time: 0.772227
[05/21/2022-03:09:41] [V] [TRT] Tactic: -64 Time: 0.736178
[05/21/2022-03:09:41] [V] [TRT] Tactic: -128 Time: 0.731823
[05/21/2022-03:09:41] [V] [TRT] Fastest Tactic: 512 Time: 0.673229
[05/21/2022-03:09:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:09:41] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:41] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:41] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:41] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:41] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:41] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:41] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:41] [V] [TRT] Tactic: 0 Time: 7.93901
[05/21/2022-03:09:41] [V] [TRT] Tactic: 1 Time: 5.06668
[05/21/2022-03:09:41] [V] [TRT] Tactic: 2 Time: 6.92266
[05/21/2022-03:09:41] [V] [TRT] Tactic: 4 skipped. Scratch requested: 575012864, available: 536870912
[05/21/2022-03:09:43] [V] [TRT] Tactic: 5 Time: 83.1179
[05/21/2022-03:09:43] [V] [TRT] Tactic: 6 Time: 4.16784
[05/21/2022-03:09:43] [V] [TRT] Fastest Tactic: 6 Time: 4.16784
[05/21/2022-03:09:43] [V] [TRT] Setting workspace to 575012864enables more tactics for profiling
[05/21/2022-03:09:43] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:43] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:43] [V] [TRT] Tactic: 1062367460111450758 Time: 5.68432
[05/21/2022-03:09:43] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:09:43] [V] [TRT] Tactic: 1754984623894446479 Time: 6.77025
[05/21/2022-03:09:43] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:09:43] [V] [TRT] Tactic: 3611739942397549984 Time: 4.66276
[05/21/2022-03:09:43] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:09:43] [V] [TRT] Tactic: 3827454225649558724 Time: 4.81861
[05/21/2022-03:09:43] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:09:43] [V] [TRT] Tactic: 4337000649858996379 Time: 4.72428
[05/21/2022-03:09:43] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:43] [V] [TRT] Tactic: 4501471010995462441 Time: 4.66901
[05/21/2022-03:09:43] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:44] [V] [TRT] Tactic: 5137655947464784826 Time: 4.54654
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:44] [V] [TRT] Tactic: 5288347012147084929 Time: 4.57907
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:09:44] [V] [TRT] Tactic: 5921334924264294896 Time: 3.69458
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:44] [V] [TRT] Tactic: 6645123197870846056 Time: 4.65465
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:44] [V] [TRT] Tactic: 7144526460361122478 Time: 5.98646
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:09:44] [V] [TRT] Tactic: 7852627285308570038 Time: 4.80814
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:09:44] [V] [TRT] Tactic: -9137461792520977713 Time: 4.72367
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:09:44] [V] [TRT] Tactic: -8776506421218919509 Time: 4.70305
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:44] [V] [TRT] Tactic: -8262349710178828730 Time: 4.70717
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:09:44] [V] [TRT] Tactic: -8133971918129952780 Time: 5.14764
[05/21/2022-03:09:44] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:09:45] [V] [TRT] Tactic: -6092040395344634144 Time: 5.90138
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:45] [V] [TRT] Tactic: -4787320710726427159 Time: 6.77904
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:45] [V] [TRT] Tactic: -3456450830548107839 Time: 5.12926
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:09:45] [V] [TRT] Tactic: -2318106587342035239 Time: 4.75258
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:09:45] [V] [TRT] Tactic: -1343271414618805657 Time: 3.33696
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:45] [V] [TRT] Tactic: -1218658103698133241 Time: 5.22033
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:45] [V] [TRT] Tactic: -836875257600482091 Time: 5.00606
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:45] [V] [TRT] Tactic: -410470605513481746 Time: 4.50465
[05/21/2022-03:09:45] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 3.33696
[05/21/2022-03:09:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:09:45] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:45] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:45] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:45] [V] [TRT] Tactic: -9153228964338181824 Time: 5.61253
[05/21/2022-03:09:45] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:46] [V] [TRT] Tactic: -7394439838318485025 Time: 4.4894
[05/21/2022-03:09:46] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 4.4894
[05/21/2022-03:09:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:09:46] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:46] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:46] [V] [TRT] Tactic: 0 Time: 8.06044
[05/21/2022-03:09:46] [V] [TRT] Tactic: 1 Time: 5.65133
[05/21/2022-03:09:46] [V] [TRT] Tactic: 2 Time: 6.75756
[05/21/2022-03:09:46] [V] [TRT] Tactic: 4 skipped. Scratch requested: 575012864, available: 536870912
[05/21/2022-03:09:47] [V] [TRT] Tactic: 5 Time: 83.1499
[05/21/2022-03:09:48] [V] [TRT] Tactic: 6 Time: 5.36083
[05/21/2022-03:09:48] [V] [TRT] Fastest Tactic: 6 Time: 5.36083
[05/21/2022-03:09:48] [V] [TRT] Setting workspace to 575012864enables more tactics for profiling
[05/21/2022-03:09:48] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:48] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-03:09:48] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:48] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:48] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:48] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:48] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:48] [V] [TRT] --------------- Timing Runner: 061_convolutional + 061_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:09:48] [V] [TRT] Tactic: 3564772625446233998 Time: 2.87753
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:09:48] [V] [TRT] Tactic: 3650389455493082349 Time: 2.98006
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:09:48] [V] [TRT] Tactic: 4772821744921268633 Time: 1.94073
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:09:48] [V] [TRT] Tactic: 5319956359050645452 Time: 2.61199
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:09:48] [V] [TRT] Tactic: 7205456024582378848 Time: 2.34828
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:09:48] [V] [TRT] Tactic: -6490690591794140522 Time: 2.37757
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:09:48] [V] [TRT] Tactic: -4686027666808657977 Time: 2.36225
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:09:48] [V] [TRT] Tactic: -4212163711445252890 Time: 2.26477
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:09:48] [V] [TRT] Tactic: -3898373634979201110 Time: 2.29992
[05/21/2022-03:09:48] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:09:48] [V] [TRT] Tactic: -2409163523992614473 Time: 2.29979
[05/21/2022-03:09:48] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 1.94073
[05/21/2022-03:09:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:09:48] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:48] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-03:09:48] [V] [TRT] Tactic: 0 Time: 0.207024
[05/21/2022-03:09:48] [V] [TRT] Tactic: 1 Time: 0.157357
[05/21/2022-03:09:48] [V] [TRT] Tactic: 2 Time: 0.156042
[05/21/2022-03:09:48] [V] [TRT] Tactic: 3 Time: 0.136016
[05/21/2022-03:09:48] [V] [TRT] Tactic: 4 Time: 0.12334
[05/21/2022-03:09:48] [V] [TRT] Tactic: 5 Time: 0.119674
[05/21/2022-03:09:48] [V] [TRT] Tactic: 6 Time: 0.133405
[05/21/2022-03:09:48] [V] [TRT] Tactic: 7 Time: 0.114303
[05/21/2022-03:09:48] [V] [TRT] Tactic: 8 Time: 0.109733
[05/21/2022-03:09:48] [V] [TRT] Tactic: 9 Time: 0.115052
[05/21/2022-03:09:48] [V] [TRT] Tactic: 28 Time: 0.205436
[05/21/2022-03:09:48] [V] [TRT] Fastest Tactic: 8 Time: 0.109733
[05/21/2022-03:09:48] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-03:09:48] [V] [TRT] Tactic: 128 Time: 0.811315
[05/21/2022-03:09:48] [V] [TRT] Tactic: 256 Time: 0.812728
[05/21/2022-03:09:48] [V] [TRT] Tactic: 512 Time: 0.813971
[05/21/2022-03:09:49] [V] [TRT] Tactic: -32 Time: 0.90347
[05/21/2022-03:09:49] [V] [TRT] Tactic: -64 Time: 0.8636
[05/21/2022-03:09:49] [V] [TRT] Tactic: -128 Time: 0.856289
[05/21/2022-03:09:49] [V] [TRT] Fastest Tactic: 128 Time: 0.811315
[05/21/2022-03:09:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:49] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-03:09:49] [V] [TRT] Tactic: 0 Time: 0.20681
[05/21/2022-03:09:49] [V] [TRT] Tactic: 1 Time: 0.157383
[05/21/2022-03:09:49] [V] [TRT] Tactic: 2 Time: 0.15541
[05/21/2022-03:09:49] [V] [TRT] Tactic: 3 Time: 0.137331
[05/21/2022-03:09:49] [V] [TRT] Tactic: 4 Time: 0.122904
[05/21/2022-03:09:49] [V] [TRT] Tactic: 5 Time: 0.119446
[05/21/2022-03:09:49] [V] [TRT] Tactic: 6 Time: 0.133171
[05/21/2022-03:09:49] [V] [TRT] Tactic: 7 Time: 0.114876
[05/21/2022-03:09:49] [V] [TRT] Tactic: 8 Time: 0.109394
[05/21/2022-03:09:49] [V] [TRT] Tactic: 9 Time: 0.113529
[05/21/2022-03:09:49] [V] [TRT] Tactic: 28 Time: 0.205436
[05/21/2022-03:09:49] [V] [TRT] Fastest Tactic: 8 Time: 0.109394
[05/21/2022-03:09:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-03:09:49] [V] [TRT] Tactic: 128 Time: 0.81166
[05/21/2022-03:09:49] [V] [TRT] Tactic: 256 Time: 0.812611
[05/21/2022-03:09:49] [V] [TRT] Tactic: 512 Time: 0.813411
[05/21/2022-03:09:49] [V] [TRT] Tactic: -32 Time: 0.904108
[05/21/2022-03:09:49] [V] [TRT] Tactic: -64 Time: 0.863926
[05/21/2022-03:09:49] [V] [TRT] Tactic: -128 Time: 0.857174
[05/21/2022-03:09:49] [V] [TRT] Fastest Tactic: 128 Time: 0.81166
[05/21/2022-03:09:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:49] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-03:09:49] [V] [TRT] Tactic: 24 Time: 0.191198
[05/21/2022-03:09:49] [V] [TRT] Tactic: 25 Time: 0.164329
[05/21/2022-03:09:49] [V] [TRT] Tactic: 26 Time: 0.166458
[05/21/2022-03:09:49] [V] [TRT] Tactic: 27 Time: 0.162116
[05/21/2022-03:09:49] [V] [TRT] Tactic: 31 Time: 0.193757
[05/21/2022-03:09:49] [V] [TRT] Fastest Tactic: 27 Time: 0.162116
[05/21/2022-03:09:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-03:09:49] [V] [TRT] Tactic: 128 Time: 0.811517
[05/21/2022-03:09:49] [V] [TRT] Tactic: 256 Time: 0.812396
[05/21/2022-03:09:49] [V] [TRT] Tactic: 512 Time: 0.8139
[05/21/2022-03:09:49] [V] [TRT] Tactic: -32 Time: 0.903223
[05/21/2022-03:09:49] [V] [TRT] Tactic: -64 Time: 0.864674
[05/21/2022-03:09:49] [V] [TRT] Tactic: -128 Time: 0.856797
[05/21/2022-03:09:49] [V] [TRT] Fastest Tactic: 128 Time: 0.811517
[05/21/2022-03:09:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:09:49] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-03:09:49] [V] [TRT] Tactic: 0 Time: 0.211009
[05/21/2022-03:09:49] [V] [TRT] Tactic: 1 Time: 0.160748
[05/21/2022-03:09:49] [V] [TRT] Tactic: 2 Time: 0.151862
[05/21/2022-03:09:49] [V] [TRT] Tactic: 3 Time: 0.12918
[05/21/2022-03:09:49] [V] [TRT] Tactic: 4 Time: 0.129746
[05/21/2022-03:09:49] [V] [TRT] Tactic: 5 Time: 0.121895
[05/21/2022-03:09:49] [V] [TRT] Tactic: 6 Time: 0.117337
[05/21/2022-03:09:49] [V] [TRT] Tactic: 7 Time: 0.113073
[05/21/2022-03:09:49] [V] [TRT] Tactic: 8 Time: 0.107233
[05/21/2022-03:09:49] [V] [TRT] Tactic: 9 Time: 0.110384
[05/21/2022-03:09:49] [V] [TRT] Tactic: 28 Time: 0.208548
[05/21/2022-03:09:49] [V] [TRT] Fastest Tactic: 8 Time: 0.107233
[05/21/2022-03:09:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-03:09:49] [V] [TRT] Tactic: 128 Time: 0.842279
[05/21/2022-03:09:49] [V] [TRT] Tactic: 256 Time: 0.832077
[05/21/2022-03:09:49] [V] [TRT] Tactic: 512 Time: 0.786178
[05/21/2022-03:09:49] [V] [TRT] Tactic: -32 Time: 0.924831
[05/21/2022-03:09:49] [V] [TRT] Tactic: -64 Time: 0.874453
[05/21/2022-03:09:49] [V] [TRT] Tactic: -128 Time: 0.867695
[05/21/2022-03:09:49] [V] [TRT] Fastest Tactic: 512 Time: 0.786178
[05/21/2022-03:09:49] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:49] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:49] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWiseV2)
[05/21/2022-03:09:49] [V] [TRT] Tactic: 0 Time: 0.179271
[05/21/2022-03:09:49] [V] [TRT] Tactic: 1 Time: 0.162728
[05/21/2022-03:09:49] [V] [TRT] Tactic: 2 Time: 0.155625
[05/21/2022-03:09:49] [V] [TRT] Tactic: 3 Time: 0.147969
[05/21/2022-03:09:49] [V] [TRT] Tactic: 4 Time: 0.145475
[05/21/2022-03:09:49] [V] [TRT] Tactic: 5 Time: 0.144603
[05/21/2022-03:09:49] [V] [TRT] Tactic: 6 Time: 0.146406
[05/21/2022-03:09:49] [V] [TRT] Tactic: 7 Time: 0.142057
[05/21/2022-03:09:49] [V] [TRT] Tactic: 8 Time: 0.165618
[05/21/2022-03:09:49] [V] [TRT] Tactic: 9 Time: 0.192428
[05/21/2022-03:09:49] [V] [TRT] Tactic: 10 Time: 0.225892
[05/21/2022-03:09:49] [V] [TRT] Tactic: 11 Time: 0.177962
[05/21/2022-03:09:49] [V] [TRT] Tactic: 12 Time: 0.169941
[05/21/2022-03:09:49] [V] [TRT] Tactic: 13 Time: 0.142839
[05/21/2022-03:09:49] [V] [TRT] Tactic: 14 Time: 0.1489
[05/21/2022-03:09:50] [V] [TRT] Tactic: 15 Time: 0.140651
[05/21/2022-03:09:50] [V] [TRT] Tactic: 16 Time: 0.128685
[05/21/2022-03:09:50] [V] [TRT] Tactic: 17 Time: 0.131699
[05/21/2022-03:09:50] [V] [TRT] Tactic: 18 Time: 0.127871
[05/21/2022-03:09:50] [V] [TRT] Tactic: 19 Time: 0.130553
[05/21/2022-03:09:50] [V] [TRT] Tactic: 28 Time: 0.178262
[05/21/2022-03:09:50] [V] [TRT] Tactic: 29 Time: 0.221133
[05/21/2022-03:09:50] [V] [TRT] Fastest Tactic: 18 Time: 0.127871
[05/21/2022-03:09:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) (PointWise)
[05/21/2022-03:09:50] [V] [TRT] Tactic: 128 Time: 0.843222
[05/21/2022-03:09:50] [V] [TRT] Tactic: 256 Time: 0.833093
[05/21/2022-03:09:50] [V] [TRT] Tactic: 512 Time: 0.789212
[05/21/2022-03:09:50] [V] [TRT] Tactic: -32 Time: 0.925195
[05/21/2022-03:09:50] [V] [TRT] Tactic: -64 Time: 0.874675
[05/21/2022-03:09:50] [V] [TRT] Tactic: -128 Time: 0.868216
[05/21/2022-03:09:50] [V] [TRT] Fastest Tactic: 512 Time: 0.789212
[05/21/2022-03:09:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1), Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256), Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1), Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1), Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1), Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:09:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:50] [V] [TRT] Tactic: 0 Time: 0.247116
[05/21/2022-03:09:50] [V] [TRT] Tactic: 1 Time: 0.174583
[05/21/2022-03:09:50] [V] [TRT] Tactic: 2 Time: 0.16487
[05/21/2022-03:09:50] [V] [TRT] Tactic: 3 Time: 0.133535
[05/21/2022-03:09:50] [V] [TRT] Tactic: 4 Time: 0.124232
[05/21/2022-03:09:50] [V] [TRT] Tactic: 5 Time: 0.122227
[05/21/2022-03:09:50] [V] [TRT] Tactic: 6 Time: 0.117318
[05/21/2022-03:09:50] [V] [TRT] Tactic: 7 Time: 0.10043
[05/21/2022-03:09:50] [V] [TRT] Tactic: 8 Time: 0.0991081
[05/21/2022-03:09:50] [V] [TRT] Tactic: 9 Time: 0.101777
[05/21/2022-03:09:50] [V] [TRT] Tactic: 28 Time: 0.244811
[05/21/2022-03:09:50] [V] [TRT] Fastest Tactic: 8 Time: 0.0991081
[05/21/2022-03:09:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-03:09:50] [V] [TRT] Tactic: 128 Time: 0.791159
[05/21/2022-03:09:50] [V] [TRT] Tactic: 256 Time: 0.790469
[05/21/2022-03:09:50] [V] [TRT] Tactic: 512 Time: 0.791178
[05/21/2022-03:09:50] [V] [TRT] Tactic: -32 Time: 0.774368
[05/21/2022-03:09:50] [V] [TRT] Tactic: -64 Time: 0.747454
[05/21/2022-03:09:50] [V] [TRT] Tactic: -128 Time: 0.747149
[05/21/2022-03:09:50] [V] [TRT] Fastest Tactic: -128 Time: 0.747149
[05/21/2022-03:09:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:09:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:50] [V] [TRT] Tactic: 0 Time: 0.246855
[05/21/2022-03:09:50] [V] [TRT] Tactic: 1 Time: 0.174798
[05/21/2022-03:09:50] [V] [TRT] Tactic: 2 Time: 0.165052
[05/21/2022-03:09:50] [V] [TRT] Tactic: 3 Time: 0.132598
[05/21/2022-03:09:50] [V] [TRT] Tactic: 4 Time: 0.124271
[05/21/2022-03:09:50] [V] [TRT] Tactic: 5 Time: 0.122272
[05/21/2022-03:09:50] [V] [TRT] Tactic: 6 Time: 0.118079
[05/21/2022-03:09:50] [V] [TRT] Tactic: 7 Time: 0.100853
[05/21/2022-03:09:50] [V] [TRT] Tactic: 8 Time: 0.099297
[05/21/2022-03:09:50] [V] [TRT] Tactic: 9 Time: 0.101843
[05/21/2022-03:09:50] [V] [TRT] Tactic: 28 Time: 0.244668
[05/21/2022-03:09:50] [V] [TRT] Fastest Tactic: 8 Time: 0.099297
[05/21/2022-03:09:50] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-03:09:50] [V] [TRT] Tactic: 128 Time: 0.790716
[05/21/2022-03:09:50] [V] [TRT] Tactic: 256 Time: 0.791452
[05/21/2022-03:09:51] [V] [TRT] Tactic: 512 Time: 0.791393
[05/21/2022-03:09:51] [V] [TRT] Tactic: -32 Time: 0.750931
[05/21/2022-03:09:51] [V] [TRT] Tactic: -64 Time: 0.76013
[05/21/2022-03:09:51] [V] [TRT] Tactic: -128 Time: 0.7978
[05/21/2022-03:09:51] [V] [TRT] Fastest Tactic: -32 Time: 0.750931
[05/21/2022-03:09:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:51] [V] [TRT] Tactic: 24 Time: 0.137611
[05/21/2022-03:09:51] [V] [TRT] Tactic: 25 Time: 0.124173
[05/21/2022-03:09:51] [V] [TRT] Tactic: 26 Time: 0.123431
[05/21/2022-03:09:51] [V] [TRT] Tactic: 27 Time: 0.124108
[05/21/2022-03:09:51] [V] [TRT] Tactic: 31 Time: 0.138236
[05/21/2022-03:09:51] [V] [TRT] Fastest Tactic: 26 Time: 0.123431
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-03:09:51] [V] [TRT] Tactic: 128 Time: 0.791517
[05/21/2022-03:09:51] [V] [TRT] Tactic: 256 Time: 0.791081
[05/21/2022-03:09:51] [V] [TRT] Tactic: 512 Time: 0.792506
[05/21/2022-03:09:51] [V] [TRT] Tactic: -32 Time: 0.775443
[05/21/2022-03:09:51] [V] [TRT] Tactic: -64 Time: 0.748574
[05/21/2022-03:09:51] [V] [TRT] Tactic: -128 Time: 0.746321
[05/21/2022-03:09:51] [V] [TRT] Fastest Tactic: -128 Time: 0.746321
[05/21/2022-03:09:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:51] [V] [TRT] Tactic: 0 Time: 0.254128
[05/21/2022-03:09:51] [V] [TRT] Tactic: 1 Time: 0.181921
[05/21/2022-03:09:51] [V] [TRT] Tactic: 2 Time: 0.169277
[05/21/2022-03:09:51] [V] [TRT] Tactic: 3 Time: 0.136647
[05/21/2022-03:09:51] [V] [TRT] Tactic: 4 Time: 0.129395
[05/21/2022-03:09:51] [V] [TRT] Tactic: 5 Time: 0.126393
[05/21/2022-03:09:51] [V] [TRT] Tactic: 6 Time: 0.116901
[05/21/2022-03:09:51] [V] [TRT] Tactic: 7 Time: 0.104584
[05/21/2022-03:09:51] [V] [TRT] Tactic: 8 Time: 0.105742
[05/21/2022-03:09:51] [V] [TRT] Tactic: 9 Time: 0.104583
[05/21/2022-03:09:51] [V] [TRT] Tactic: 28 Time: 0.252539
[05/21/2022-03:09:51] [V] [TRT] Fastest Tactic: 9 Time: 0.104583
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-03:09:51] [V] [TRT] Tactic: 128 Time: 0.762083
[05/21/2022-03:09:51] [V] [TRT] Tactic: 256 Time: 0.755566
[05/21/2022-03:09:51] [V] [TRT] Tactic: 512 Time: 0.695898
[05/21/2022-03:09:51] [V] [TRT] Tactic: -32 Time: 0.775827
[05/21/2022-03:09:51] [V] [TRT] Tactic: -64 Time: 0.743359
[05/21/2022-03:09:51] [V] [TRT] Tactic: -128 Time: 0.743594
[05/21/2022-03:09:51] [V] [TRT] Fastest Tactic: 512 Time: 0.695898
[05/21/2022-03:09:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWiseV2)
[05/21/2022-03:09:51] [V] [TRT] Tactic: 0 Time: 0.17416
[05/21/2022-03:09:51] [V] [TRT] Tactic: 1 Time: 0.136328
[05/21/2022-03:09:51] [V] [TRT] Tactic: 2 Time: 0.135468
[05/21/2022-03:09:51] [V] [TRT] Tactic: 3 Time: 0.122611
[05/21/2022-03:09:51] [V] [TRT] Tactic: 4 Time: 0.119043
[05/21/2022-03:09:51] [V] [TRT] Tactic: 5 Time: 0.119577
[05/21/2022-03:09:51] [V] [TRT] Tactic: 6 Time: 0.117604
[05/21/2022-03:09:51] [V] [TRT] Tactic: 7 Time: 0.110443
[05/21/2022-03:09:51] [V] [TRT] Tactic: 8 Time: 0.110638
[05/21/2022-03:09:51] [V] [TRT] Tactic: 9 Time: 0.116178
[05/21/2022-03:09:51] [V] [TRT] Tactic: 10 Time: 0.261484
[05/21/2022-03:09:51] [V] [TRT] Tactic: 11 Time: 0.189264
[05/21/2022-03:09:51] [V] [TRT] Tactic: 12 Time: 0.177656
[05/21/2022-03:09:51] [V] [TRT] Tactic: 13 Time: 0.14123
[05/21/2022-03:09:51] [V] [TRT] Tactic: 14 Time: 0.13403
[05/21/2022-03:09:51] [V] [TRT] Tactic: 15 Time: 0.135534
[05/21/2022-03:09:51] [V] [TRT] Tactic: 16 Time: 0.119974
[05/21/2022-03:09:51] [V] [TRT] Tactic: 17 Time: 0.10707
[05/21/2022-03:09:51] [V] [TRT] Tactic: 18 Time: 0.108737
[05/21/2022-03:09:51] [V] [TRT] Tactic: 19 Time: 0.11308
[05/21/2022-03:09:51] [V] [TRT] Tactic: 28 Time: 0.170352
[05/21/2022-03:09:51] [V] [TRT] Tactic: 29 Time: 0.262474
[05/21/2022-03:09:51] [V] [TRT] Fastest Tactic: 17 Time: 0.10707
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) (PointWise)
[05/21/2022-03:09:51] [V] [TRT] Tactic: 128 Time: 0.762311
[05/21/2022-03:09:51] [V] [TRT] Tactic: 256 Time: 0.754206
[05/21/2022-03:09:51] [V] [TRT] Tactic: 512 Time: 0.695566
[05/21/2022-03:09:51] [V] [TRT] Tactic: -32 Time: 0.777331
[05/21/2022-03:09:51] [V] [TRT] Tactic: -64 Time: 0.742897
[05/21/2022-03:09:51] [V] [TRT] Tactic: -128 Time: 0.74418
[05/21/2022-03:09:51] [V] [TRT] Fastest Tactic: 512 Time: 0.695566
[05/21/2022-03:09:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:09:51] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:09:51] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:09:51] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:09:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:09:51] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:51] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:52] [V] [TRT] Tactic: 0 Time: 21.78
[05/21/2022-03:09:52] [V] [TRT] Tactic: 1 Time: 16.7991
[05/21/2022-03:09:52] [V] [TRT] Tactic: 2 Time: 13.6013
[05/21/2022-03:09:52] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2289879040, available: 536870912
[05/21/2022-03:09:52] [V] [TRT] Fastest Tactic: 2 Time: 13.6013
[05/21/2022-03:09:52] [V] [TRT] Setting workspace to 2289879040enables more tactics for profiling
[05/21/2022-03:09:53] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:53] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:09:53] [V] [TRT] Tactic: 1062367460111450758 Time: 15.1205
[05/21/2022-03:09:53] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:09:53] [V] [TRT] Tactic: 1754984623894446479 Time: 17.3377
[05/21/2022-03:09:53] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:09:53] [V] [TRT] Tactic: 3611739942397549984 Time: 12.2872
[05/21/2022-03:09:54] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:09:54] [V] [TRT] Tactic: 4337000649858996379 Time: 12.4564
[05/21/2022-03:09:54] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:09:54] [V] [TRT] Tactic: 4501471010995462441 Time: 12.2463
[05/21/2022-03:09:54] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:09:54] [V] [TRT] Tactic: 5137655947464784826 Time: 12.0361
[05/21/2022-03:09:54] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:09:55] [V] [TRT] Tactic: 5288347012147084929 Time: 12.1011
[05/21/2022-03:09:55] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:09:55] [V] [TRT] Tactic: 6645123197870846056 Time: 12.2433
[05/21/2022-03:09:55] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:09:55] [V] [TRT] Tactic: 7144526460361122478 Time: 16.074
[05/21/2022-03:09:55] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:09:56] [V] [TRT] Tactic: -9137461792520977713 Time: 12.3383
[05/21/2022-03:09:56] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:09:56] [V] [TRT] Tactic: -8262349710178828730 Time: 12.2325
[05/21/2022-03:09:56] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:09:56] [V] [TRT] Tactic: -8133971918129952780 Time: 13.7153
[05/21/2022-03:09:56] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:09:56] [V] [TRT] Tactic: -6092040395344634144 Time: 15.6421
[05/21/2022-03:09:57] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:09:57] [V] [TRT] Tactic: -4787320710726427159 Time: 17.2945
[05/21/2022-03:09:57] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:09:57] [V] [TRT] Tactic: -3456450830548107839 Time: 13.8107
[05/21/2022-03:09:57] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:09:57] [V] [TRT] Tactic: -1218658103698133241 Time: 13.5721
[05/21/2022-03:09:58] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:09:58] [V] [TRT] Tactic: -836875257600482091 Time: 13.1811
[05/21/2022-03:09:58] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:09:58] [V] [TRT] Tactic: -410470605513481746 Time: 11.9901
[05/21/2022-03:09:58] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 11.9901
[05/21/2022-03:09:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-03:09:58] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:09:58] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:58] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:09:58] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-03:09:58] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:09:58] [V] [TRT] Tactic: -9153228964338181824 Time: 15.4036
[05/21/2022-03:09:58] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:09:59] [V] [TRT] Tactic: -7394439838318485025 Time: 11.8416
[05/21/2022-03:09:59] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 11.8416
[05/21/2022-03:09:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:09:59] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:09:59] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-03:09:59] [V] [TRT] Tactic: 0 Time: 24.4755
[05/21/2022-03:10:00] [V] [TRT] Tactic: 1 Time: 24.2643
[05/21/2022-03:10:00] [V] [TRT] Tactic: 2 Time: 13.2565
[05/21/2022-03:10:00] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2289132544, available: 536870912
[05/21/2022-03:10:00] [V] [TRT] Fastest Tactic: 2 Time: 13.2565
[05/21/2022-03:10:00] [V] [TRT] Setting workspace to 2289132544enables more tactics for profiling
[05/21/2022-03:10:00] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:10:00] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:10:00] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:00] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:00] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:00] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:00] [V] [TRT] --------------- Timing Runner: 087_convolutional + 087_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:00] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:10:00] [V] [TRT] Tactic: 3564772625446233998 Time: 7.52913
[05/21/2022-03:10:00] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:10:00] [V] [TRT] Tactic: 3650389455493082349 Time: 7.80689
[05/21/2022-03:10:01] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:10:01] [V] [TRT] Tactic: 5319956359050645452 Time: 6.82699
[05/21/2022-03:10:01] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:10:01] [V] [TRT] Tactic: 7205456024582378848 Time: 6.14434
[05/21/2022-03:10:01] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:10:01] [V] [TRT] Tactic: -6490690591794140522 Time: 6.20246
[05/21/2022-03:10:01] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:10:01] [V] [TRT] Tactic: -4686027666808657977 Time: 6.18069
[05/21/2022-03:10:01] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:10:01] [V] [TRT] Tactic: -4212163711445252890 Time: 5.94828
[05/21/2022-03:10:01] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:10:02] [V] [TRT] Tactic: -3898373634979201110 Time: 6.12153
[05/21/2022-03:10:02] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:10:02] [V] [TRT] Tactic: -2409163523992614473 Time: 6.04292
[05/21/2022-03:10:02] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 5.94828
[05/21/2022-03:10:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-03:10:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:02] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:10:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:02] [V] [TRT] Tactic: 0 Time: 0.196048
[05/21/2022-03:10:02] [V] [TRT] Tactic: 1 Time: 0.1461
[05/21/2022-03:10:02] [V] [TRT] Tactic: 2 Time: 0.138698
[05/21/2022-03:10:02] [V] [TRT] Tactic: 3 Time: 0.122513
[05/21/2022-03:10:02] [V] [TRT] Tactic: 4 Time: 0.106198
[05/21/2022-03:10:02] [V] [TRT] Tactic: 5 Time: 0.109095
[05/21/2022-03:10:02] [V] [TRT] Tactic: 6 Time: 0.113216
[05/21/2022-03:10:02] [V] [TRT] Tactic: 7 Time: 0.0929883
[05/21/2022-03:10:02] [V] [TRT] Tactic: 8 Time: 0.0881511
[05/21/2022-03:10:02] [V] [TRT] Tactic: 9 Time: 0.0953714
[05/21/2022-03:10:02] [V] [TRT] Tactic: 28 Time: 0.192572
[05/21/2022-03:10:02] [V] [TRT] Fastest Tactic: 8 Time: 0.0881511
[05/21/2022-03:10:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-03:10:02] [V] [TRT] Tactic: 128 Time: 0.701888
[05/21/2022-03:10:02] [V] [TRT] Tactic: 256 Time: 0.703366
[05/21/2022-03:10:02] [V] [TRT] Tactic: 512 Time: 0.70403
[05/21/2022-03:10:02] [V] [TRT] Tactic: -32 Time: 0.771426
[05/21/2022-03:10:02] [V] [TRT] Tactic: -64 Time: 0.743028
[05/21/2022-03:10:02] [V] [TRT] Tactic: -128 Time: 0.736322
[05/21/2022-03:10:02] [V] [TRT] Fastest Tactic: 128 Time: 0.701888
[05/21/2022-03:10:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:02] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:10:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:02] [V] [TRT] Tactic: 0 Time: 0.195859
[05/21/2022-03:10:02] [V] [TRT] Tactic: 1 Time: 0.146993
[05/21/2022-03:10:02] [V] [TRT] Tactic: 2 Time: 0.139128
[05/21/2022-03:10:02] [V] [TRT] Tactic: 3 Time: 0.122617
[05/21/2022-03:10:02] [V] [TRT] Tactic: 4 Time: 0.106107
[05/21/2022-03:10:02] [V] [TRT] Tactic: 5 Time: 0.109251
[05/21/2022-03:10:02] [V] [TRT] Tactic: 6 Time: 0.112676
[05/21/2022-03:10:02] [V] [TRT] Tactic: 7 Time: 0.0933332
[05/21/2022-03:10:02] [V] [TRT] Tactic: 8 Time: 0.088522
[05/21/2022-03:10:02] [V] [TRT] Tactic: 9 Time: 0.094824
[05/21/2022-03:10:02] [V] [TRT] Tactic: 28 Time: 0.192598
[05/21/2022-03:10:02] [V] [TRT] Fastest Tactic: 8 Time: 0.088522
[05/21/2022-03:10:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-03:10:02] [V] [TRT] Tactic: 128 Time: 0.702174
[05/21/2022-03:10:02] [V] [TRT] Tactic: 256 Time: 0.703477
[05/21/2022-03:10:02] [V] [TRT] Tactic: 512 Time: 0.704036
[05/21/2022-03:10:02] [V] [TRT] Tactic: -32 Time: 0.772038
[05/21/2022-03:10:02] [V] [TRT] Tactic: -64 Time: 0.742474
[05/21/2022-03:10:02] [V] [TRT] Tactic: -128 Time: 0.735651
[05/21/2022-03:10:02] [V] [TRT] Fastest Tactic: 128 Time: 0.702174
[05/21/2022-03:10:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:02] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:10:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:02] [V] [TRT] Tactic: 24 Time: 0.135541
[05/21/2022-03:10:02] [V] [TRT] Tactic: 25 Time: 0.12362
[05/21/2022-03:10:02] [V] [TRT] Tactic: 26 Time: 0.12209
[05/21/2022-03:10:02] [V] [TRT] Tactic: 27 Time: 0.121009
[05/21/2022-03:10:02] [V] [TRT] Tactic: 31 Time: 0.133991
[05/21/2022-03:10:02] [V] [TRT] Fastest Tactic: 27 Time: 0.121009
[05/21/2022-03:10:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-03:10:02] [V] [TRT] Tactic: 128 Time: 0.701764
[05/21/2022-03:10:02] [V] [TRT] Tactic: 256 Time: 0.703346
[05/21/2022-03:10:02] [V] [TRT] Tactic: 512 Time: 0.704551
[05/21/2022-03:10:02] [V] [TRT] Tactic: -32 Time: 0.771029
[05/21/2022-03:10:02] [V] [TRT] Tactic: -64 Time: 0.741654
[05/21/2022-03:10:02] [V] [TRT] Tactic: -128 Time: 0.73595
[05/21/2022-03:10:02] [V] [TRT] Fastest Tactic: 128 Time: 0.701764
[05/21/2022-03:10:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:10:02] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:02] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:02] [V] [TRT] Tactic: 0 Time: 0.199186
[05/21/2022-03:10:02] [V] [TRT] Tactic: 1 Time: 0.15306
[05/21/2022-03:10:02] [V] [TRT] Tactic: 2 Time: 0.14207
[05/21/2022-03:10:02] [V] [TRT] Tactic: 3 Time: 0.123203
[05/21/2022-03:10:02] [V] [TRT] Tactic: 4 Time: 0.112175
[05/21/2022-03:10:02] [V] [TRT] Tactic: 5 Time: 0.114017
[05/21/2022-03:10:02] [V] [TRT] Tactic: 6 Time: 0.110482
[05/21/2022-03:10:02] [V] [TRT] Tactic: 7 Time: 0.0965755
[05/21/2022-03:10:02] [V] [TRT] Tactic: 8 Time: 0.0966863
[05/21/2022-03:10:03] [V] [TRT] Tactic: 9 Time: 0.099388
[05/21/2022-03:10:03] [V] [TRT] Tactic: 28 Time: 0.199557
[05/21/2022-03:10:03] [V] [TRT] Fastest Tactic: 7 Time: 0.0965755
[05/21/2022-03:10:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-03:10:03] [V] [TRT] Tactic: 128 Time: 0.722702
[05/21/2022-03:10:03] [V] [TRT] Tactic: 256 Time: 0.715417
[05/21/2022-03:10:03] [V] [TRT] Tactic: 512 Time: 0.669649
[05/21/2022-03:10:03] [V] [TRT] Tactic: -32 Time: 0.770879
[05/21/2022-03:10:03] [V] [TRT] Tactic: -64 Time: 0.736211
[05/21/2022-03:10:03] [V] [TRT] Tactic: -128 Time: 0.732018
[05/21/2022-03:10:03] [V] [TRT] Fastest Tactic: 512 Time: 0.669649
[05/21/2022-03:10:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:10:03] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:10:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:03] [V] [TRT] Tactic: 0 Time: 0.153717
[05/21/2022-03:10:03] [V] [TRT] Tactic: 1 Time: 0.126387
[05/21/2022-03:10:03] [V] [TRT] Tactic: 2 Time: 0.125488
[05/21/2022-03:10:03] [V] [TRT] Tactic: 3 Time: 0.116569
[05/21/2022-03:10:03] [V] [TRT] Tactic: 4 Time: 0.112825
[05/21/2022-03:10:03] [V] [TRT] Tactic: 5 Time: 0.11571
[05/21/2022-03:10:03] [V] [TRT] Tactic: 6 Time: 0.113613
[05/21/2022-03:10:03] [V] [TRT] Tactic: 7 Time: 0.108796
[05/21/2022-03:10:03] [V] [TRT] Tactic: 8 Time: 0.108639
[05/21/2022-03:10:03] [V] [TRT] Tactic: 9 Time: 0.113431
[05/21/2022-03:10:03] [V] [TRT] Tactic: 10 Time: 0.209537
[05/21/2022-03:10:03] [V] [TRT] Tactic: 11 Time: 0.157526
[05/21/2022-03:10:03] [V] [TRT] Tactic: 12 Time: 0.149902
[05/21/2022-03:10:03] [V] [TRT] Tactic: 13 Time: 0.126575
[05/21/2022-03:10:03] [V] [TRT] Tactic: 14 Time: 0.117025
[05/21/2022-03:10:03] [V] [TRT] Tactic: 15 Time: 0.118815
[05/21/2022-03:10:03] [V] [TRT] Tactic: 16 Time: 0.112233
[05/21/2022-03:10:03] [V] [TRT] Tactic: 17 Time: 0.0988671
[05/21/2022-03:10:03] [V] [TRT] Tactic: 18 Time: 0.0978124
[05/21/2022-03:10:03] [V] [TRT] Tactic: 19 Time: 0.105924
[05/21/2022-03:10:03] [V] [TRT] Tactic: 28 Time: 0.150892
[05/21/2022-03:10:03] [V] [TRT] Tactic: 29 Time: 0.205625
[05/21/2022-03:10:03] [V] [TRT] Fastest Tactic: 18 Time: 0.0978124
[05/21/2022-03:10:03] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) (PointWise)
[05/21/2022-03:10:03] [V] [TRT] Tactic: 128 Time: 0.72375
[05/21/2022-03:10:03] [V] [TRT] Tactic: 256 Time: 0.715312
[05/21/2022-03:10:03] [V] [TRT] Tactic: 512 Time: 0.670436
[05/21/2022-03:10:03] [V] [TRT] Tactic: -32 Time: 0.77222
[05/21/2022-03:10:03] [V] [TRT] Tactic: -64 Time: 0.735762
[05/21/2022-03:10:03] [V] [TRT] Tactic: -128 Time: 0.73166
[05/21/2022-03:10:03] [V] [TRT] Fastest Tactic: 512 Time: 0.670436
[05/21/2022-03:10:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:10:03] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:03] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:10:03] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:03] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:10:03] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:03] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:03] [V] [TRT] Tactic: 0 Time: 4.72424
[05/21/2022-03:10:03] [V] [TRT] Tactic: 1 Time: 3.96578
[05/21/2022-03:10:03] [V] [TRT] Tactic: 2 Time: 3.4756
[05/21/2022-03:10:03] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2422472704, available: 536870912
[05/21/2022-03:10:05] [V] [TRT] Tactic: 5 Time: 83.3471
[05/21/2022-03:10:05] [V] [TRT] Fastest Tactic: 2 Time: 3.4756
[05/21/2022-03:10:05] [V] [TRT] Setting workspace to 2422472704enables more tactics for profiling
[05/21/2022-03:10:05] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:05] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:05] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:10:05] [V] [TRT] Tactic: 1062367460111450758 Time: 3.37886
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:10:05] [V] [TRT] Tactic: 1698681053543049347 Time: 3.25449
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:10:05] [V] [TRT] Tactic: 4501471010995462441 Time: 2.76678
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:10:05] [V] [TRT] Tactic: 5137655947464784826 Time: 2.72003
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:10:05] [V] [TRT] Tactic: 5288347012147084929 Time: 2.74829
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:10:05] [V] [TRT] Tactic: 5326823351883942011 Time: 2.65656
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:10:05] [V] [TRT] Tactic: 5500448035057547314 Time: 2.87779
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:10:05] [V] [TRT] Tactic: 6645123197870846056 Time: 2.77147
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:10:05] [V] [TRT] Tactic: 7144526460361122478 Time: 3.59514
[05/21/2022-03:10:05] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:10:06] [V] [TRT] Tactic: -8262349710178828730 Time: 2.79842
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:10:06] [V] [TRT] Tactic: -6576203419454146580 Time: 2.97469
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:10:06] [V] [TRT] Tactic: -4787320710726427159 Time: 3.78628
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:10:06] [V] [TRT] Tactic: -3456450830548107839 Time: 3.15975
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:10:06] [V] [TRT] Tactic: -1218658103698133241 Time: 3.01074
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:10:06] [V] [TRT] Tactic: -836875257600482091 Time: 2.94661
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:10:06] [V] [TRT] Tactic: -410470605513481746 Time: 2.73516
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:10:06] [V] [TRT] Tactic: -377491875521947884 Time: 2.72317
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:10:06] [V] [TRT] Tactic: -37215280111360163 Time: 2.65221
[05/21/2022-03:10:06] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 2.65221
[05/21/2022-03:10:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:10:06] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:10:06] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:06] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:06] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:06] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:10:06] [V] [TRT] Tactic: 3886731678879822788 Time: 2.72309
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:10:06] [V] [TRT] Tactic: 6629944304117643200 Time: 4.12008
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:10:06] [V] [TRT] Tactic: -9153228964338181824 Time: 4.1093
[05/21/2022-03:10:06] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:10:07] [V] [TRT] Tactic: -7394439838318485025 Time: 2.72048
[05/21/2022-03:10:07] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.72048
[05/21/2022-03:10:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:10:07] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:07] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:07] [V] [TRT] Tactic: 0 Time: 4.7488
[05/21/2022-03:10:07] [V] [TRT] Tactic: 1 Time: 4.27831
[05/21/2022-03:10:07] [V] [TRT] Tactic: 2 Time: 3.47546
[05/21/2022-03:10:07] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2422472704, available: 536870912
[05/21/2022-03:10:08] [V] [TRT] Tactic: 5 Time: 84.0044
[05/21/2022-03:10:08] [V] [TRT] Fastest Tactic: 2 Time: 3.47546
[05/21/2022-03:10:08] [V] [TRT] Setting workspace to 2422472704enables more tactics for profiling
[05/21/2022-03:10:08] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:08] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:08] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:08] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:10:08] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:08] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:08] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:08] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:10:08] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:08] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:08] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:08] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:08] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:08] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:08] [V] [TRT] --------------- Timing Runner: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:08] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:10:08] [V] [TRT] Tactic: 3066127711859985668 Time: 1.57423
[05/21/2022-03:10:08] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:10:08] [V] [TRT] Tactic: 3564772625446233998 Time: 1.72943
[05/21/2022-03:10:08] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:10:09] [V] [TRT] Tactic: 5319956359050645452 Time: 1.65399
[05/21/2022-03:10:09] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:10:09] [V] [TRT] Tactic: 7205456024582378848 Time: 1.42822
[05/21/2022-03:10:09] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:10:09] [V] [TRT] Tactic: 8163473458334948789 Time: 1.3639
[05/21/2022-03:10:09] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:10:09] [V] [TRT] Tactic: -4212163711445252890 Time: 1.37568
[05/21/2022-03:10:09] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:10:09] [V] [TRT] Tactic: -3898373634979201110 Time: 1.4023
[05/21/2022-03:10:09] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:10:09] [V] [TRT] Tactic: -2409163523992614473 Time: 1.39766
[05/21/2022-03:10:09] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:10:09] [V] [TRT] Tactic: -1716393687483585322 Time: 1.35119
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 1.35119
[05/21/2022-03:10:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:10:09] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:09] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 0 Time: 0.127552
[05/21/2022-03:10:09] [V] [TRT] Tactic: 1 Time: 0.0908855
[05/21/2022-03:10:09] [V] [TRT] Tactic: 2 Time: 0.0860546
[05/21/2022-03:10:09] [V] [TRT] Tactic: 3 Time: 0.0696355
[05/21/2022-03:10:09] [V] [TRT] Tactic: 4 Time: 0.0653385
[05/21/2022-03:10:09] [V] [TRT] Tactic: 5 Time: 0.0642513
[05/21/2022-03:10:09] [V] [TRT] Tactic: 6 Time: 0.0637044
[05/21/2022-03:10:09] [V] [TRT] Tactic: 7 Time: 0.0537175
[05/21/2022-03:10:09] [V] [TRT] Tactic: 8 Time: 0.0524802
[05/21/2022-03:10:09] [V] [TRT] Tactic: 9 Time: 0.0539453
[05/21/2022-03:10:09] [V] [TRT] Tactic: 28 Time: 0.126354
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: 8 Time: 0.0524802
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 128 Time: 0.400111
[05/21/2022-03:10:09] [V] [TRT] Tactic: 256 Time: 0.399388
[05/21/2022-03:10:09] [V] [TRT] Tactic: 512 Time: 0.400091
[05/21/2022-03:10:09] [V] [TRT] Tactic: -32 Time: 0.410163
[05/21/2022-03:10:09] [V] [TRT] Tactic: -64 Time: 0.382331
[05/21/2022-03:10:09] [V] [TRT] Tactic: -128 Time: 0.383171
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: -64 Time: 0.382331
[05/21/2022-03:10:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:09] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 0 Time: 0.12791
[05/21/2022-03:10:09] [V] [TRT] Tactic: 1 Time: 0.0913413
[05/21/2022-03:10:09] [V] [TRT] Tactic: 2 Time: 0.0860611
[05/21/2022-03:10:09] [V] [TRT] Tactic: 3 Time: 0.0701564
[05/21/2022-03:10:09] [V] [TRT] Tactic: 4 Time: 0.0657549
[05/21/2022-03:10:09] [V] [TRT] Tactic: 5 Time: 0.0640885
[05/21/2022-03:10:09] [V] [TRT] Tactic: 6 Time: 0.0645963
[05/21/2022-03:10:09] [V] [TRT] Tactic: 7 Time: 0.05459
[05/21/2022-03:10:09] [V] [TRT] Tactic: 8 Time: 0.0525844
[05/21/2022-03:10:09] [V] [TRT] Tactic: 9 Time: 0.0545769
[05/21/2022-03:10:09] [V] [TRT] Tactic: 28 Time: 0.126321
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: 8 Time: 0.0525844
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 128 Time: 0.39959
[05/21/2022-03:10:09] [V] [TRT] Tactic: 256 Time: 0.399759
[05/21/2022-03:10:09] [V] [TRT] Tactic: 512 Time: 0.39944
[05/21/2022-03:10:09] [V] [TRT] Tactic: -32 Time: 0.393854
[05/21/2022-03:10:09] [V] [TRT] Tactic: -64 Time: 0.382148
[05/21/2022-03:10:09] [V] [TRT] Tactic: -128 Time: 0.386439
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: -64 Time: 0.382148
[05/21/2022-03:10:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:09] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 24 Time: 0.0718295
[05/21/2022-03:10:09] [V] [TRT] Tactic: 25 Time: 0.066185
[05/21/2022-03:10:09] [V] [TRT] Tactic: 26 Time: 0.0659764
[05/21/2022-03:10:09] [V] [TRT] Tactic: 27 Time: 0.0701499
[05/21/2022-03:10:09] [V] [TRT] Tactic: 31 Time: 0.071673
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: 26 Time: 0.0659764
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 128 Time: 0.399935
[05/21/2022-03:10:09] [V] [TRT] Tactic: 256 Time: 0.398978
[05/21/2022-03:10:09] [V] [TRT] Tactic: 512 Time: 0.399889
[05/21/2022-03:10:09] [V] [TRT] Tactic: -32 Time: 0.410944
[05/21/2022-03:10:09] [V] [TRT] Tactic: -64 Time: 0.381855
[05/21/2022-03:10:09] [V] [TRT] Tactic: -128 Time: 0.382819
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: -64 Time: 0.381855
[05/21/2022-03:10:09] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:10:09] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 0 Time: 0.130983
[05/21/2022-03:10:09] [V] [TRT] Tactic: 1 Time: 0.0943422
[05/21/2022-03:10:09] [V] [TRT] Tactic: 2 Time: 0.0879425
[05/21/2022-03:10:09] [V] [TRT] Tactic: 3 Time: 0.0717515
[05/21/2022-03:10:09] [V] [TRT] Tactic: 4 Time: 0.0678254
[05/21/2022-03:10:09] [V] [TRT] Tactic: 5 Time: 0.0662044
[05/21/2022-03:10:09] [V] [TRT] Tactic: 6 Time: 0.0624741
[05/21/2022-03:10:09] [V] [TRT] Tactic: 7 Time: 0.0558139
[05/21/2022-03:10:09] [V] [TRT] Tactic: 8 Time: 0.0561069
[05/21/2022-03:10:09] [V] [TRT] Tactic: 9 Time: 0.0557293
[05/21/2022-03:10:09] [V] [TRT] Tactic: 28 Time: 0.130208
[05/21/2022-03:10:09] [V] [TRT] Fastest Tactic: 9 Time: 0.0557293
[05/21/2022-03:10:09] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-03:10:09] [V] [TRT] Tactic: 128 Time: 0.384551
[05/21/2022-03:10:09] [V] [TRT] Tactic: 256 Time: 0.382825
[05/21/2022-03:10:10] [V] [TRT] Tactic: 512 Time: 0.353646
[05/21/2022-03:10:10] [V] [TRT] Tactic: -32 Time: 0.411595
[05/21/2022-03:10:10] [V] [TRT] Tactic: -64 Time: 0.403301
[05/21/2022-03:10:10] [V] [TRT] Tactic: -128 Time: 0.404993
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: 512 Time: 0.353646
[05/21/2022-03:10:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:10:10] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 0 Time: 0.0909964
[05/21/2022-03:10:10] [V] [TRT] Tactic: 1 Time: 0.0713543
[05/21/2022-03:10:10] [V] [TRT] Tactic: 2 Time: 0.0704294
[05/21/2022-03:10:10] [V] [TRT] Tactic: 3 Time: 0.0648179
[05/21/2022-03:10:10] [V] [TRT] Tactic: 4 Time: 0.0627669
[05/21/2022-03:10:10] [V] [TRT] Tactic: 5 Time: 0.0634504
[05/21/2022-03:10:10] [V] [TRT] Tactic: 6 Time: 0.0628057
[05/21/2022-03:10:10] [V] [TRT] Tactic: 7 Time: 0.0603123
[05/21/2022-03:10:10] [V] [TRT] Tactic: 8 Time: 0.0592906
[05/21/2022-03:10:10] [V] [TRT] Tactic: 9 Time: 0.062194
[05/21/2022-03:10:10] [V] [TRT] Tactic: 10 Time: 0.134863
[05/21/2022-03:10:10] [V] [TRT] Tactic: 11 Time: 0.0981513
[05/21/2022-03:10:10] [V] [TRT] Tactic: 12 Time: 0.0922914
[05/21/2022-03:10:10] [V] [TRT] Tactic: 13 Time: 0.0748111
[05/21/2022-03:10:10] [V] [TRT] Tactic: 14 Time: 0.0703775
[05/21/2022-03:10:10] [V] [TRT] Tactic: 15 Time: 0.0706967
[05/21/2022-03:10:10] [V] [TRT] Tactic: 16 Time: 0.0639649
[05/21/2022-03:10:10] [V] [TRT] Tactic: 17 Time: 0.0565496
[05/21/2022-03:10:10] [V] [TRT] Tactic: 18 Time: 0.0576042
[05/21/2022-03:10:10] [V] [TRT] Tactic: 19 Time: 0.0600325
[05/21/2022-03:10:10] [V] [TRT] Tactic: 28 Time: 0.0889257
[05/21/2022-03:10:10] [V] [TRT] Tactic: 29 Time: 0.135084
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: 17 Time: 0.0565496
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) (PointWise)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 128 Time: 0.384987
[05/21/2022-03:10:10] [V] [TRT] Tactic: 256 Time: 0.381829
[05/21/2022-03:10:10] [V] [TRT] Tactic: 512 Time: 0.353971
[05/21/2022-03:10:10] [V] [TRT] Tactic: -32 Time: 0.412461
[05/21/2022-03:10:10] [V] [TRT] Tactic: -64 Time: 0.403633
[05/21/2022-03:10:10] [V] [TRT] Tactic: -128 Time: 0.405866
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: 512 Time: 0.353971
[05/21/2022-03:10:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:10:10] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:10] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 0 Time: 0.127917
[05/21/2022-03:10:10] [V] [TRT] Tactic: 1 Time: 0.090664
[05/21/2022-03:10:10] [V] [TRT] Tactic: 2 Time: 0.0856771
[05/21/2022-03:10:10] [V] [TRT] Tactic: 3 Time: 0.0704494
[05/21/2022-03:10:10] [V] [TRT] Tactic: 4 Time: 0.0652344
[05/21/2022-03:10:10] [V] [TRT] Tactic: 5 Time: 0.0639975
[05/21/2022-03:10:10] [V] [TRT] Tactic: 6 Time: 0.0641927
[05/21/2022-03:10:10] [V] [TRT] Tactic: 7 Time: 0.0541079
[05/21/2022-03:10:10] [V] [TRT] Tactic: 8 Time: 0.052676
[05/21/2022-03:10:10] [V] [TRT] Tactic: 9 Time: 0.0538996
[05/21/2022-03:10:10] [V] [TRT] Tactic: 28 Time: 0.12625
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: 8 Time: 0.052676
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 128 Time: 0.400032
[05/21/2022-03:10:10] [V] [TRT] Tactic: 256 Time: 0.399349
[05/21/2022-03:10:10] [V] [TRT] Tactic: 512 Time: 0.399623
[05/21/2022-03:10:10] [V] [TRT] Tactic: -32 Time: 0.410456
[05/21/2022-03:10:10] [V] [TRT] Tactic: -64 Time: 0.381471
[05/21/2022-03:10:10] [V] [TRT] Tactic: -128 Time: 0.382793
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: -64 Time: 0.381471
[05/21/2022-03:10:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:10] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 0 Time: 0.127636
[05/21/2022-03:10:10] [V] [TRT] Tactic: 1 Time: 0.0908136
[05/21/2022-03:10:10] [V] [TRT] Tactic: 2 Time: 0.0858918
[05/21/2022-03:10:10] [V] [TRT] Tactic: 3 Time: 0.070384
[05/21/2022-03:10:10] [V] [TRT] Tactic: 4 Time: 0.0655011
[05/21/2022-03:10:10] [V] [TRT] Tactic: 5 Time: 0.0640949
[05/21/2022-03:10:10] [V] [TRT] Tactic: 6 Time: 0.0645704
[05/21/2022-03:10:10] [V] [TRT] Tactic: 7 Time: 0.0538476
[05/21/2022-03:10:10] [V] [TRT] Tactic: 8 Time: 0.0525197
[05/21/2022-03:10:10] [V] [TRT] Tactic: 9 Time: 0.0541731
[05/21/2022-03:10:10] [V] [TRT] Tactic: 28 Time: 0.126055
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: 8 Time: 0.0525197
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 128 Time: 0.398984
[05/21/2022-03:10:10] [V] [TRT] Tactic: 256 Time: 0.399043
[05/21/2022-03:10:10] [V] [TRT] Tactic: 512 Time: 0.399303
[05/21/2022-03:10:10] [V] [TRT] Tactic: -32 Time: 0.392943
[05/21/2022-03:10:10] [V] [TRT] Tactic: -64 Time: 0.381803
[05/21/2022-03:10:10] [V] [TRT] Tactic: -128 Time: 0.386309
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: -64 Time: 0.381803
[05/21/2022-03:10:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:10] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 24 Time: 0.0717707
[05/21/2022-03:10:10] [V] [TRT] Tactic: 25 Time: 0.0658789
[05/21/2022-03:10:10] [V] [TRT] Tactic: 26 Time: 0.0659572
[05/21/2022-03:10:10] [V] [TRT] Tactic: 27 Time: 0.0709115
[05/21/2022-03:10:10] [V] [TRT] Tactic: 31 Time: 0.0720054
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: 25 Time: 0.0658789
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 128 Time: 0.399889
[05/21/2022-03:10:10] [V] [TRT] Tactic: 256 Time: 0.399772
[05/21/2022-03:10:10] [V] [TRT] Tactic: 512 Time: 0.398757
[05/21/2022-03:10:10] [V] [TRT] Tactic: -32 Time: 0.41015
[05/21/2022-03:10:10] [V] [TRT] Tactic: -64 Time: 0.382109
[05/21/2022-03:10:10] [V] [TRT] Tactic: -128 Time: 0.382871
[05/21/2022-03:10:10] [V] [TRT] Fastest Tactic: -64 Time: 0.382109
[05/21/2022-03:10:10] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:10:10] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:10] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:10] [V] [TRT] Tactic: 0 Time: 0.131217
[05/21/2022-03:10:10] [V] [TRT] Tactic: 1 Time: 0.0943425
[05/21/2022-03:10:10] [V] [TRT] Tactic: 2 Time: 0.0880079
[05/21/2022-03:10:10] [V] [TRT] Tactic: 3 Time: 0.0724737
[05/21/2022-03:10:10] [V] [TRT] Tactic: 4 Time: 0.0675393
[05/21/2022-03:10:11] [V] [TRT] Tactic: 5 Time: 0.066328
[05/21/2022-03:10:11] [V] [TRT] Tactic: 6 Time: 0.0626105
[05/21/2022-03:10:11] [V] [TRT] Tactic: 7 Time: 0.055742
[05/21/2022-03:10:11] [V] [TRT] Tactic: 8 Time: 0.0559699
[05/21/2022-03:10:11] [V] [TRT] Tactic: 9 Time: 0.0554754
[05/21/2022-03:10:11] [V] [TRT] Tactic: 28 Time: 0.130124
[05/21/2022-03:10:11] [V] [TRT] Fastest Tactic: 9 Time: 0.0554754
[05/21/2022-03:10:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-03:10:11] [V] [TRT] Tactic: 128 Time: 0.385332
[05/21/2022-03:10:11] [V] [TRT] Tactic: 256 Time: 0.381927
[05/21/2022-03:10:11] [V] [TRT] Tactic: 512 Time: 0.352754
[05/21/2022-03:10:11] [V] [TRT] Tactic: -32 Time: 0.411992
[05/21/2022-03:10:11] [V] [TRT] Tactic: -64 Time: 0.403997
[05/21/2022-03:10:11] [V] [TRT] Tactic: -128 Time: 0.403809
[05/21/2022-03:10:11] [V] [TRT] Fastest Tactic: 512 Time: 0.352754
[05/21/2022-03:10:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:10:11] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:11] [V] [TRT] Tactic: 0 Time: 0.0906117
[05/21/2022-03:10:11] [V] [TRT] Tactic: 1 Time: 0.0719531
[05/21/2022-03:10:11] [V] [TRT] Tactic: 2 Time: 0.0705272
[05/21/2022-03:10:11] [V] [TRT] Tactic: 3 Time: 0.0649215
[05/21/2022-03:10:11] [V] [TRT] Tactic: 4 Time: 0.0635871
[05/21/2022-03:10:11] [V] [TRT] Tactic: 5 Time: 0.0634636
[05/21/2022-03:10:11] [V] [TRT] Tactic: 6 Time: 0.0619921
[05/21/2022-03:10:11] [V] [TRT] Tactic: 7 Time: 0.058561
[05/21/2022-03:10:11] [V] [TRT] Tactic: 8 Time: 0.0580079
[05/21/2022-03:10:11] [V] [TRT] Tactic: 9 Time: 0.0607683
[05/21/2022-03:10:11] [V] [TRT] Tactic: 10 Time: 0.134811
[05/21/2022-03:10:11] [V] [TRT] Tactic: 11 Time: 0.0986849
[05/21/2022-03:10:11] [V] [TRT] Tactic: 12 Time: 0.0920572
[05/21/2022-03:10:11] [V] [TRT] Tactic: 13 Time: 0.074603
[05/21/2022-03:10:11] [V] [TRT] Tactic: 14 Time: 0.0700587
[05/21/2022-03:10:11] [V] [TRT] Tactic: 15 Time: 0.0701304
[05/21/2022-03:10:11] [V] [TRT] Tactic: 16 Time: 0.0641408
[05/21/2022-03:10:11] [V] [TRT] Tactic: 17 Time: 0.0570573
[05/21/2022-03:10:11] [V] [TRT] Tactic: 18 Time: 0.0575585
[05/21/2022-03:10:11] [V] [TRT] Tactic: 19 Time: 0.0597005
[05/21/2022-03:10:11] [V] [TRT] Tactic: 28 Time: 0.0888871
[05/21/2022-03:10:11] [V] [TRT] Tactic: 29 Time: 0.135469
[05/21/2022-03:10:11] [V] [TRT] Fastest Tactic: 17 Time: 0.0570573
[05/21/2022-03:10:11] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) (PointWise)
[05/21/2022-03:10:11] [V] [TRT] Tactic: 128 Time: 0.385892
[05/21/2022-03:10:11] [V] [TRT] Tactic: 256 Time: 0.380261
[05/21/2022-03:10:11] [V] [TRT] Tactic: 512 Time: 0.352708
[05/21/2022-03:10:11] [V] [TRT] Tactic: -32 Time: 0.412539
[05/21/2022-03:10:11] [V] [TRT] Tactic: -64 Time: 0.404317
[05/21/2022-03:10:11] [V] [TRT] Tactic: -128 Time: 0.406035
[05/21/2022-03:10:11] [V] [TRT] Fastest Tactic: 512 Time: 0.352708
[05/21/2022-03:10:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:10:11] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:11] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:11] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:11] [V] [TRT] Tactic: 589823 Time: 1.44339
[05/21/2022-03:10:11] [V] [TRT] Tactic: 655359 Time: 1.11138
[05/21/2022-03:10:11] [V] [TRT] Tactic: 786431 Time: 1.53939
[05/21/2022-03:10:11] [V] [TRT] Tactic: 851967 Time: 1.65177
[05/21/2022-03:10:11] [V] [TRT] Tactic: 1179647 Time: 1.71324
[05/21/2022-03:10:12] [V] [TRT] Tactic: 1310719 Time: 3.20568
[05/21/2022-03:10:12] [V] [TRT] Tactic: 1376255 Time: 1.2129
[05/21/2022-03:10:12] [V] [TRT] Tactic: 1441791 Time: 2.02894
[05/21/2022-03:10:12] [V] [TRT] Tactic: 1507327 Time: 1.79313
[05/21/2022-03:10:12] [V] [TRT] Tactic: 1638399 Time: 2.3106
[05/21/2022-03:10:12] [V] [TRT] Tactic: 1835007 Time: 1.6202
[05/21/2022-03:10:12] [V] [TRT] Tactic: 1900543 Time: 1.50356
[05/21/2022-03:10:12] [V] [TRT] Tactic: 2097151 Time: 1.79565
[05/21/2022-03:10:12] [V] [TRT] Tactic: 2162687 Time: 1.15501
[05/21/2022-03:10:12] [V] [TRT] Tactic: 2293759 Time: 1.37293
[05/21/2022-03:10:13] [V] [TRT] Tactic: 2359295 Time: 1.57137
[05/21/2022-03:10:13] [V] [TRT] Tactic: 2686975 Time: 1.481
[05/21/2022-03:10:13] [V] [TRT] Tactic: 3080191 Time: 1.3246
[05/21/2022-03:10:13] [V] [TRT] Tactic: 3342335 Time: 1.61573
[05/21/2022-03:10:13] [V] [TRT] Tactic: 3407871 Time: 1.45617
[05/21/2022-03:10:13] [V] [TRT] Tactic: 3538943 Time: 1.49348
[05/21/2022-03:10:13] [V] [TRT] Tactic: 3670015 Time: 0.968099
[05/21/2022-03:10:13] [V] [TRT] Tactic: 3932159 Time: 1.88909
[05/21/2022-03:10:13] [V] [TRT] Tactic: 3997695 Time: 1.57635
[05/21/2022-03:10:13] [V] [TRT] Tactic: 4063231 Time: 1.44353
[05/21/2022-03:10:13] [V] [TRT] Tactic: 4194303 Time: 1.46091
[05/21/2022-03:10:14] [V] [TRT] Tactic: 4259839 Time: 1.86077
[05/21/2022-03:10:14] [V] [TRT] Tactic: 4325375 Time: 1.92592
[05/21/2022-03:10:14] [V] [TRT] Tactic: 4521983 Time: 1.87709
[05/21/2022-03:10:14] [V] [TRT] Tactic: 4587519 Time: 1.75166
[05/21/2022-03:10:14] [V] [TRT] Tactic: 4653055 Time: 1.69641
[05/21/2022-03:10:14] [V] [TRT] Tactic: 4915199 Time: 1.46451
[05/21/2022-03:10:14] [V] [TRT] Tactic: 4980735 Time: 1.937
[05/21/2022-03:10:14] [V] [TRT] Tactic: 5177343 Time: 2.08146
[05/21/2022-03:10:14] [V] [TRT] Tactic: 5242879 Time: 1.32094
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5373951 Time: 2.01036
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5439487 Time: 1.65883
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5570559 Time: 1.11843
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5636095 Time: 1.43841
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5701631 Time: 1.68611
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5767167 Time: 2.41264
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5832703 Time: 1.44811
[05/21/2022-03:10:15] [V] [TRT] Tactic: 5898239 Time: 1.24055
[05/21/2022-03:10:15] [V] [TRT] Tactic: 6029311 Time: 1.30895
[05/21/2022-03:10:15] [V] [TRT] Tactic: 6225919 Time: 1.38484
[05/21/2022-03:10:15] [V] [TRT] Tactic: 6291455 Time: 1.70527
[05/21/2022-03:10:16] [V] [TRT] Tactic: 6422527 Time: 1.38178
[05/21/2022-03:10:16] [V] [TRT] Tactic: 6750207 Time: 1.49496
[05/21/2022-03:10:16] [V] [TRT] Tactic: 6815743 Time: 1.4604
[05/21/2022-03:10:16] [V] [TRT] Tactic: 6946815 Time: 2.07273
[05/21/2022-03:10:16] [V] [TRT] Tactic: 7012351 Time: 1.79117
[05/21/2022-03:10:16] [V] [TRT] Tactic: 7077887 Time: 1.50053
[05/21/2022-03:10:16] [V] [TRT] Tactic: 7143423 Time: 2.20924
[05/21/2022-03:10:16] [V] [TRT] Tactic: 7208959 Time: 1.7221
[05/21/2022-03:10:16] [V] [TRT] Tactic: 7340031 Time: 1.35465
[05/21/2022-03:10:16] [V] [TRT] Tactic: 7405567 Time: 1.49226
[05/21/2022-03:10:17] [V] [TRT] Tactic: 7536639 Time: 1.65365
[05/21/2022-03:10:17] [V] [TRT] Tactic: 7602175 Time: 1.93497
[05/21/2022-03:10:17] [V] [TRT] Tactic: 7733247 Time: 1.36309
[05/21/2022-03:10:17] [V] [TRT] Tactic: 7798783 Time: 1.54106
[05/21/2022-03:10:17] [V] [TRT] Tactic: 8191999 Time: 2.35309
[05/21/2022-03:10:17] [V] [TRT] Tactic: 8257535 Time: 1.51561
[05/21/2022-03:10:17] [V] [TRT] Tactic: 8323071 Time: 1.47053
[05/21/2022-03:10:17] [V] [TRT] Tactic: 8650751 Time: 2.28148
[05/21/2022-03:10:17] [V] [TRT] Tactic: 8716287 Time: 1.57514
[05/21/2022-03:10:18] [V] [TRT] Tactic: 9109503 Time: 1.90753
[05/21/2022-03:10:18] [V] [TRT] Tactic: 9568255 Time: 1.4646
[05/21/2022-03:10:18] [V] [TRT] Tactic: 9895935 Time: 1.46104
[05/21/2022-03:10:18] [V] [TRT] Tactic: 10223615 Time: 1.47601
[05/21/2022-03:10:18] [V] [TRT] Tactic: 10354687 Time: 1.87693
[05/21/2022-03:10:18] [V] [TRT] Tactic: 10551295 Time: 1.44924
[05/21/2022-03:10:18] [V] [TRT] Tactic: 10747903 Time: 1.27193
[05/21/2022-03:10:18] [V] [TRT] Tactic: 10944511 Time: 1.93665
[05/21/2022-03:10:18] [V] [TRT] Fastest Tactic: 3670015 Time: 0.968099
[05/21/2022-03:10:18] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:10:18] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:18] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:18] [V] [TRT] Tactic: 0 Time: 1.27604
[05/21/2022-03:10:18] [V] [TRT] Tactic: 1 Time: 1.1176
[05/21/2022-03:10:18] [V] [TRT] Tactic: 2 Time: 1.08385
[05/21/2022-03:10:18] [V] [TRT] Tactic: 4 skipped. Scratch requested: 606208000, available: 536870912
[05/21/2022-03:10:19] [V] [TRT] Tactic: 5 Time: 18.6531
[05/21/2022-03:10:19] [V] [TRT] Fastest Tactic: 2 Time: 1.08385
[05/21/2022-03:10:19] [V] [TRT] Setting workspace to 606208000enables more tactics for profiling
[05/21/2022-03:10:19] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:19] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:19] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:10:19] [V] [TRT] Tactic: 1062367460111450758 Time: 0.91821
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:10:19] [V] [TRT] Tactic: 1698681053543049347 Time: 0.859199
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:10:19] [V] [TRT] Tactic: 4501471010995462441 Time: 0.722344
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:10:19] [V] [TRT] Tactic: 5137655947464784826 Time: 0.723509
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:10:19] [V] [TRT] Tactic: 5288347012147084929 Time: 0.721205
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:10:19] [V] [TRT] Tactic: 5326823351883942011 Time: 0.696042
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:10:19] [V] [TRT] Tactic: 5500448035057547314 Time: 0.772051
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:10:19] [V] [TRT] Tactic: 6645123197870846056 Time: 0.748229
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:10:19] [V] [TRT] Tactic: 7144526460361122478 Time: 0.974401
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:10:19] [V] [TRT] Tactic: -8262349710178828730 Time: 0.732741
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:10:19] [V] [TRT] Tactic: -6576203419454146580 Time: 0.799609
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:10:19] [V] [TRT] Tactic: -4787320710726427159 Time: 1.0234
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:10:19] [V] [TRT] Tactic: -3456450830548107839 Time: 0.855358
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:10:19] [V] [TRT] Tactic: -1218658103698133241 Time: 0.804609
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:10:19] [V] [TRT] Tactic: -836875257600482091 Time: 0.786406
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:10:19] [V] [TRT] Tactic: -410470605513481746 Time: 0.710781
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:10:19] [V] [TRT] Tactic: -377491875521947884 Time: 0.715833
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:10:19] [V] [TRT] Tactic: -37215280111360163 Time: 0.716133
[05/21/2022-03:10:19] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.696042
[05/21/2022-03:10:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:10:19] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:19] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:19] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:19] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:19] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:19] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:10:19] [V] [TRT] Tactic: 3886731678879822788 Time: 0.720111
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:10:19] [V] [TRT] Tactic: 6629944304117643200 Time: 1.14702
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:10:19] [V] [TRT] Tactic: -9153228964338181824 Time: 1.15878
[05/21/2022-03:10:19] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:10:19] [V] [TRT] Tactic: -7394439838318485025 Time: 0.721628
[05/21/2022-03:10:19] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 0.720111
[05/21/2022-03:10:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-03:10:19] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:19] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:19] [V] [TRT] Tactic: 0 Time: 1.27836
[05/21/2022-03:10:19] [V] [TRT] Tactic: 1 Time: 1.09907
[05/21/2022-03:10:19] [V] [TRT] Tactic: 2 Time: 1.06572
[05/21/2022-03:10:19] [V] [TRT] Tactic: 4 skipped. Scratch requested: 606208000, available: 536870912
[05/21/2022-03:10:20] [V] [TRT] Tactic: 5 Time: 19.0161
[05/21/2022-03:10:20] [V] [TRT] Fastest Tactic: 2 Time: 1.06572
[05/21/2022-03:10:20] [V] [TRT] Setting workspace to 606208000enables more tactics for profiling
[05/21/2022-03:10:20] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:20] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:20] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:20] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:10:20] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:20] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:20] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:20] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:20] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:20] [V] [TRT] Tactic: 589823 Time: 0.766237
[05/21/2022-03:10:20] [V] [TRT] Tactic: 655359 Time: 0.671523
[05/21/2022-03:10:20] [V] [TRT] Tactic: 786431 Time: 0.975905
[05/21/2022-03:10:20] [V] [TRT] Tactic: 851967 Time: 0.897376
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1179647 Time: 0.742552
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1310719 Time: 1.64962
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1376255 Time: 0.604577
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1441791 Time: 0.999023
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1507327 Time: 0.939277
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1638399 Time: 1.24009
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1835007 Time: 1.02712
[05/21/2022-03:10:20] [V] [TRT] Tactic: 1900543 Time: 0.80414
[05/21/2022-03:10:21] [V] [TRT] Tactic: 2097151 Time: 1.2331
[05/21/2022-03:10:21] [V] [TRT] Tactic: 2162687 Time: 0.666302
[05/21/2022-03:10:21] [V] [TRT] Tactic: 2293759 Time: 0.719857
[05/21/2022-03:10:21] [V] [TRT] Tactic: 2359295 Time: 0.816797
[05/21/2022-03:10:21] [V] [TRT] Tactic: 2686975 Time: 1.20346
[05/21/2022-03:10:21] [V] [TRT] Tactic: 3080191 Time: 0.718105
[05/21/2022-03:10:21] [V] [TRT] Tactic: 3342335 Time: 0.857904
[05/21/2022-03:10:21] [V] [TRT] Tactic: 3407871 Time: 0.722096
[05/21/2022-03:10:21] [V] [TRT] Tactic: 3538943 Time: 0.722455
[05/21/2022-03:10:21] [V] [TRT] Tactic: 3670015 Time: 0.722552
[05/21/2022-03:10:21] [V] [TRT] Tactic: 3932159 Time: 0.855124
[05/21/2022-03:10:21] [V] [TRT] Tactic: 3997695 Time: 0.976666
[05/21/2022-03:10:21] [V] [TRT] Tactic: 4063231 Time: 0.76459
[05/21/2022-03:10:21] [V] [TRT] Tactic: 4194303 Time: 0.851595
[05/21/2022-03:10:21] [V] [TRT] Tactic: 4259839 Time: 1.21404
[05/21/2022-03:10:21] [V] [TRT] Tactic: 4325375 Time: 0.985547
[05/21/2022-03:10:21] [V] [TRT] Tactic: 4521983 Time: 0.969772
[05/21/2022-03:10:22] [V] [TRT] Tactic: 4587519 Time: 1.02313
[05/21/2022-03:10:22] [V] [TRT] Tactic: 4653055 Time: 0.883847
[05/21/2022-03:10:22] [V] [TRT] Tactic: 4915199 Time: 0.852506
[05/21/2022-03:10:22] [V] [TRT] Tactic: 4980735 Time: 0.995612
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5177343 Time: 0.868984
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5242879 Time: 0.644049
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5373951 Time: 0.863014
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5439487 Time: 0.928275
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5570559 Time: 0.757305
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5636095 Time: 0.761126
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5701631 Time: 0.780937
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5767167 Time: 1.10674
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5832703 Time: 0.703008
[05/21/2022-03:10:22] [V] [TRT] Tactic: 5898239 Time: 0.738587
[05/21/2022-03:10:22] [V] [TRT] Tactic: 6029311 Time: 0.642103
[05/21/2022-03:10:22] [V] [TRT] Tactic: 6225919 Time: 0.636764
[05/21/2022-03:10:22] [V] [TRT] Tactic: 6291455 Time: 0.737129
[05/21/2022-03:10:22] [V] [TRT] Tactic: 6422527 Time: 0.70123
[05/21/2022-03:10:23] [V] [TRT] Tactic: 6750207 Time: 0.869225
[05/21/2022-03:10:23] [V] [TRT] Tactic: 6815743 Time: 0.716165
[05/21/2022-03:10:23] [V] [TRT] Tactic: 6946815 Time: 1.01813
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7012351 Time: 1.22357
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7077887 Time: 0.691667
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7143423 Time: 1.1003
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7208959 Time: 0.834967
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7340031 Time: 0.773834
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7405567 Time: 0.739662
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7536639 Time: 0.827071
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7602175 Time: 0.923014
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7733247 Time: 0.740215
[05/21/2022-03:10:23] [V] [TRT] Tactic: 7798783 Time: 0.972721
[05/21/2022-03:10:23] [V] [TRT] Tactic: 8191999 Time: 1.17122
[05/21/2022-03:10:23] [V] [TRT] Tactic: 8257535 Time: 0.864844
[05/21/2022-03:10:23] [V] [TRT] Tactic: 8323071 Time: 0.840944
[05/21/2022-03:10:24] [V] [TRT] Tactic: 8650751 Time: 1.09613
[05/21/2022-03:10:24] [V] [TRT] Tactic: 8716287 Time: 0.730788
[05/21/2022-03:10:24] [V] [TRT] Tactic: 9109503 Time: 1.22555
[05/21/2022-03:10:24] [V] [TRT] Tactic: 9568255 Time: 0.851615
[05/21/2022-03:10:24] [V] [TRT] Tactic: 9895935 Time: 0.848255
[05/21/2022-03:10:24] [V] [TRT] Tactic: 10223615 Time: 1.20097
[05/21/2022-03:10:24] [V] [TRT] Tactic: 10354687 Time: 1.22988
[05/21/2022-03:10:24] [V] [TRT] Tactic: 10551295 Time: 0.728724
[05/21/2022-03:10:24] [V] [TRT] Tactic: 10747903 Time: 0.641146
[05/21/2022-03:10:24] [V] [TRT] Tactic: 10944511 Time: 0.995384
[05/21/2022-03:10:24] [V] [TRT] Fastest Tactic: 1376255 Time: 0.604577
[05/21/2022-03:10:24] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:24] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CublasConvolution)
[05/21/2022-03:10:24] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:24] [V] [TRT] --------------- Timing Runner: 091_convolutional + 091_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:10:24] [V] [TRT] Tactic: 3066127711859985668 Time: 0.423483
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:10:24] [V] [TRT] Tactic: 3564772625446233998 Time: 0.468516
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:10:24] [V] [TRT] Tactic: 5319956359050645452 Time: 0.447051
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:10:24] [V] [TRT] Tactic: 7205456024582378848 Time: 0.384525
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:10:24] [V] [TRT] Tactic: 8163473458334948789 Time: 0.371224
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:10:24] [V] [TRT] Tactic: -4212163711445252890 Time: 0.371361
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:10:24] [V] [TRT] Tactic: -3898373634979201110 Time: 0.380632
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:10:24] [V] [TRT] Tactic: -2409163523992614473 Time: 0.375723
[05/21/2022-03:10:24] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:10:24] [V] [TRT] Tactic: -1716393687483585322 Time: 0.366979
[05/21/2022-03:10:24] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.366979
[05/21/2022-03:10:24] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:10:24] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:24] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:24] [V] [TRT] Tactic: 0 Time: 0.101087
[05/21/2022-03:10:24] [V] [TRT] Tactic: 1 Time: 0.0766081
[05/21/2022-03:10:24] [V] [TRT] Tactic: 2 Time: 0.0723502
[05/21/2022-03:10:24] [V] [TRT] Tactic: 3 Time: 0.064388
[05/21/2022-03:10:24] [V] [TRT] Tactic: 4 Time: 0.0558201
[05/21/2022-03:10:24] [V] [TRT] Tactic: 5 Time: 0.0570572
[05/21/2022-03:10:24] [V] [TRT] Tactic: 6 Time: 0.0598894
[05/21/2022-03:10:24] [V] [TRT] Tactic: 7 Time: 0.049642
[05/21/2022-03:10:24] [V] [TRT] Tactic: 8 Time: 0.046979
[05/21/2022-03:10:24] [V] [TRT] Tactic: 9 Time: 0.0510223
[05/21/2022-03:10:24] [V] [TRT] Tactic: 28 Time: 0.0991146
[05/21/2022-03:10:24] [V] [TRT] Fastest Tactic: 8 Time: 0.046979
[05/21/2022-03:10:24] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-03:10:24] [V] [TRT] Tactic: 128 Time: 0.355071
[05/21/2022-03:10:24] [V] [TRT] Tactic: 256 Time: 0.354967
[05/21/2022-03:10:24] [V] [TRT] Tactic: 512 Time: 0.355963
[05/21/2022-03:10:24] [V] [TRT] Tactic: -32 Time: 0.40918
[05/21/2022-03:10:24] [V] [TRT] Tactic: -64 Time: 0.37914
[05/21/2022-03:10:25] [V] [TRT] Tactic: -128 Time: 0.37638
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 256 Time: 0.354967
[05/21/2022-03:10:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:25] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 0 Time: 0.101257
[05/21/2022-03:10:25] [V] [TRT] Tactic: 1 Time: 0.0766018
[05/21/2022-03:10:25] [V] [TRT] Tactic: 2 Time: 0.0724611
[05/21/2022-03:10:25] [V] [TRT] Tactic: 3 Time: 0.0639584
[05/21/2022-03:10:25] [V] [TRT] Tactic: 4 Time: 0.0556511
[05/21/2022-03:10:25] [V] [TRT] Tactic: 5 Time: 0.0574154
[05/21/2022-03:10:25] [V] [TRT] Tactic: 6 Time: 0.0602344
[05/21/2022-03:10:25] [V] [TRT] Tactic: 7 Time: 0.0505991
[05/21/2022-03:10:25] [V] [TRT] Tactic: 8 Time: 0.0470376
[05/21/2022-03:10:25] [V] [TRT] Tactic: 9 Time: 0.0507422
[05/21/2022-03:10:25] [V] [TRT] Tactic: 28 Time: 0.0994664
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 8 Time: 0.0470376
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 128 Time: 0.354876
[05/21/2022-03:10:25] [V] [TRT] Tactic: 256 Time: 0.354746
[05/21/2022-03:10:25] [V] [TRT] Tactic: 512 Time: 0.355892
[05/21/2022-03:10:25] [V] [TRT] Tactic: -32 Time: 0.40834
[05/21/2022-03:10:25] [V] [TRT] Tactic: -64 Time: 0.378079
[05/21/2022-03:10:25] [V] [TRT] Tactic: -128 Time: 0.376192
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 256 Time: 0.354746
[05/21/2022-03:10:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:25] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 24 Time: 0.0709504
[05/21/2022-03:10:25] [V] [TRT] Tactic: 25 Time: 0.066517
[05/21/2022-03:10:25] [V] [TRT] Tactic: 26 Time: 0.0655405
[05/21/2022-03:10:25] [V] [TRT] Tactic: 27 Time: 0.0703581
[05/21/2022-03:10:25] [V] [TRT] Tactic: 31 Time: 0.0711327
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 26 Time: 0.0655405
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 128 Time: 0.354558
[05/21/2022-03:10:25] [V] [TRT] Tactic: 256 Time: 0.355091
[05/21/2022-03:10:25] [V] [TRT] Tactic: 512 Time: 0.355722
[05/21/2022-03:10:25] [V] [TRT] Tactic: -32 Time: 0.407995
[05/21/2022-03:10:25] [V] [TRT] Tactic: -64 Time: 0.378509
[05/21/2022-03:10:25] [V] [TRT] Tactic: -128 Time: 0.376159
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 128 Time: 0.354558
[05/21/2022-03:10:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:10:25] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 0 Time: 0.102474
[05/21/2022-03:10:25] [V] [TRT] Tactic: 1 Time: 0.0796286
[05/21/2022-03:10:25] [V] [TRT] Tactic: 2 Time: 0.0738803
[05/21/2022-03:10:25] [V] [TRT] Tactic: 3 Time: 0.0650261
[05/21/2022-03:10:25] [V] [TRT] Tactic: 4 Time: 0.0584766
[05/21/2022-03:10:25] [V] [TRT] Tactic: 5 Time: 0.0598761
[05/21/2022-03:10:25] [V] [TRT] Tactic: 6 Time: 0.058965
[05/21/2022-03:10:25] [V] [TRT] Tactic: 7 Time: 0.0514518
[05/21/2022-03:10:25] [V] [TRT] Tactic: 8 Time: 0.0510025
[05/21/2022-03:10:25] [V] [TRT] Tactic: 9 Time: 0.0519271
[05/21/2022-03:10:25] [V] [TRT] Tactic: 28 Time: 0.102865
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 8 Time: 0.0510025
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 128 Time: 0.366041
[05/21/2022-03:10:25] [V] [TRT] Tactic: 256 Time: 0.360573
[05/21/2022-03:10:25] [V] [TRT] Tactic: 512 Time: 0.340059
[05/21/2022-03:10:25] [V] [TRT] Tactic: -32 Time: 0.409355
[05/21/2022-03:10:25] [V] [TRT] Tactic: -64 Time: 0.401491
[05/21/2022-03:10:25] [V] [TRT] Tactic: -128 Time: 0.395938
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 512 Time: 0.340059
[05/21/2022-03:10:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:25] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 0 Time: 0.080436
[05/21/2022-03:10:25] [V] [TRT] Tactic: 1 Time: 0.0653712
[05/21/2022-03:10:25] [V] [TRT] Tactic: 2 Time: 0.0651109
[05/21/2022-03:10:25] [V] [TRT] Tactic: 3 Time: 0.062194
[05/21/2022-03:10:25] [V] [TRT] Tactic: 4 Time: 0.0600195
[05/21/2022-03:10:25] [V] [TRT] Tactic: 5 Time: 0.0607098
[05/21/2022-03:10:25] [V] [TRT] Tactic: 6 Time: 0.0608854
[05/21/2022-03:10:25] [V] [TRT] Tactic: 7 Time: 0.0584895
[05/21/2022-03:10:25] [V] [TRT] Tactic: 8 Time: 0.0572072
[05/21/2022-03:10:25] [V] [TRT] Tactic: 9 Time: 0.0601692
[05/21/2022-03:10:25] [V] [TRT] Tactic: 10 Time: 0.107878
[05/21/2022-03:10:25] [V] [TRT] Tactic: 11 Time: 0.0817319
[05/21/2022-03:10:25] [V] [TRT] Tactic: 12 Time: 0.0773047
[05/21/2022-03:10:25] [V] [TRT] Tactic: 13 Time: 0.066022
[05/21/2022-03:10:25] [V] [TRT] Tactic: 14 Time: 0.0607614
[05/21/2022-03:10:25] [V] [TRT] Tactic: 15 Time: 0.0624414
[05/21/2022-03:10:25] [V] [TRT] Tactic: 16 Time: 0.0601236
[05/21/2022-03:10:25] [V] [TRT] Tactic: 17 Time: 0.0525325
[05/21/2022-03:10:25] [V] [TRT] Tactic: 18 Time: 0.0516405
[05/21/2022-03:10:25] [V] [TRT] Tactic: 19 Time: 0.0557554
[05/21/2022-03:10:25] [V] [TRT] Tactic: 28 Time: 0.0785026
[05/21/2022-03:10:25] [V] [TRT] Tactic: 29 Time: 0.106647
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 18 Time: 0.0516405
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) (PointWise)
[05/21/2022-03:10:25] [V] [TRT] Tactic: 128 Time: 0.364902
[05/21/2022-03:10:25] [V] [TRT] Tactic: 256 Time: 0.362246
[05/21/2022-03:10:25] [V] [TRT] Tactic: 512 Time: 0.341048
[05/21/2022-03:10:25] [V] [TRT] Tactic: -32 Time: 0.41054
[05/21/2022-03:10:25] [V] [TRT] Tactic: -64 Time: 0.400866
[05/21/2022-03:10:25] [V] [TRT] Tactic: -128 Time: 0.397272
[05/21/2022-03:10:25] [V] [TRT] Fastest Tactic: 512 Time: 0.341048
[05/21/2022-03:10:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:10:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:25] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:25] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:26] [V] [TRT] Tactic: 524287 Time: 6.06565
[05/21/2022-03:10:26] [V] [TRT] Tactic: 720895 Time: 6.62246
[05/21/2022-03:10:26] [V] [TRT] Tactic: 983039 Time: 5.59076
[05/21/2022-03:10:27] [V] [TRT] Tactic: 1048575 Time: 6.30648
[05/21/2022-03:10:27] [V] [TRT] Tactic: 1703935 Time: 6.25229
[05/21/2022-03:10:28] [V] [TRT] Tactic: 1769471 Time: 5.61459
[05/21/2022-03:10:28] [V] [TRT] Tactic: 1966079 Time: 6.16254
[05/21/2022-03:10:28] [V] [TRT] Tactic: 2031615 Time: 5.89844
[05/21/2022-03:10:29] [V] [TRT] Tactic: 2228223 Time: 7.50717
[05/21/2022-03:10:29] [V] [TRT] Tactic: 2424831 Time: 8.27894
[05/21/2022-03:10:30] [V] [TRT] Tactic: 2621439 Time: 7.24761
[05/21/2022-03:10:30] [V] [TRT] Tactic: 2752511 Time: 5.37823
[05/21/2022-03:10:30] [V] [TRT] Tactic: 2818047 Time: 7.46853
[05/21/2022-03:10:31] [V] [TRT] Tactic: 2883583 Time: 6.25044
[05/21/2022-03:10:31] [V] [TRT] Tactic: 3014655 Time: 5.56714
[05/21/2022-03:10:31] [V] [TRT] Tactic: 3145727 Time: 5.34672
[05/21/2022-03:10:32] [V] [TRT] Tactic: 3473407 Time: 6.31239
[05/21/2022-03:10:32] [V] [TRT] Tactic: 3604479 Time: 5.51928
[05/21/2022-03:10:33] [V] [TRT] Tactic: 3735551 Time: 8.42521
[05/21/2022-03:10:33] [V] [TRT] Tactic: 4390911 Time: 5.22829
[05/21/2022-03:10:33] [V] [TRT] Tactic: 5046271 Time: 6.08794
[05/21/2022-03:10:34] [V] [TRT] Tactic: 5963775 Time: 5.52206
[05/21/2022-03:10:34] [V] [TRT] Tactic: 6160383 Time: 5.89404
[05/21/2022-03:10:34] [V] [TRT] Tactic: 6488063 Time: 5.08749
[05/21/2022-03:10:35] [V] [TRT] Tactic: 6881279 Time: 5.38582
[05/21/2022-03:10:35] [V] [TRT] Tactic: 7274495 Time: 7.14542
[05/21/2022-03:10:36] [V] [TRT] Tactic: 7864319 Time: 7.55044
[05/21/2022-03:10:36] [V] [TRT] Tactic: 7995391 Time: 6.58251
[05/21/2022-03:10:36] [V] [TRT] Tactic: 8585215 Time: 5.35348
[05/21/2022-03:10:37] [V] [TRT] Tactic: 8847359 Time: 5.44558
[05/21/2022-03:10:37] [V] [TRT] Tactic: 8978431 Time: 5.54531
[05/21/2022-03:10:37] [V] [TRT] Tactic: 9043967 Time: 5.1013
[05/21/2022-03:10:38] [V] [TRT] Tactic: 9175039 Time: 5.51887
[05/21/2022-03:10:38] [V] [TRT] Tactic: 9502719 Time: 5.39079
[05/21/2022-03:10:38] [V] [TRT] Tactic: 9830399 Time: 5.92344
[05/21/2022-03:10:39] [V] [TRT] Tactic: 9961471 Time: 6.02411
[05/21/2022-03:10:39] [V] [TRT] Tactic: 10027007 Time: 5.44258
[05/21/2022-03:10:39] [V] [TRT] Tactic: 10092543 Time: 5.22665
[05/21/2022-03:10:40] [V] [TRT] Tactic: 10289151 Time: 6.17504
[05/21/2022-03:10:40] [V] [TRT] Tactic: 10485759 Time: 5.49674
[05/21/2022-03:10:41] [V] [TRT] Tactic: 10682367 Time: 7.42462
[05/21/2022-03:10:41] [V] [TRT] Tactic: 10813439 Time: 6.55379
[05/21/2022-03:10:41] [V] [TRT] Fastest Tactic: 6488063 Time: 5.08749
[05/21/2022-03:10:41] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:10:41] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:41] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:41] [V] [TRT] Tactic: 0 Time: 8.27384
[05/21/2022-03:10:41] [V] [TRT] Tactic: 1 Time: 6.41933
[05/21/2022-03:10:41] [V] [TRT] Tactic: 2 Time: 6.96361
[05/21/2022-03:10:41] [V] [TRT] Tactic: 4 skipped. Scratch requested: 614596608, available: 536870912
[05/21/2022-03:10:41] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1145307136, available: 536870912
[05/21/2022-03:10:42] [V] [TRT] Tactic: 6 Time: 4.97925
[05/21/2022-03:10:42] [V] [TRT] Fastest Tactic: 6 Time: 4.97925
[05/21/2022-03:10:42] [V] [TRT] Setting workspace to 614596608enables more tactics for profiling
[05/21/2022-03:10:42] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:42] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:10:42] [V] [TRT] Tactic: 1062367460111450758 Time: 8.08019
[05/21/2022-03:10:42] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:10:42] [V] [TRT] Tactic: 1754984623894446479 Time: 9.4544
[05/21/2022-03:10:42] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:10:42] [V] [TRT] Tactic: 3611739942397549984 Time: 6.1874
[05/21/2022-03:10:42] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:10:42] [V] [TRT] Tactic: 3827454225649558724 Time: 4.2401
[05/21/2022-03:10:42] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:10:42] [V] [TRT] Tactic: 4337000649858996379 Time: 6.29193
[05/21/2022-03:10:42] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:10:43] [V] [TRT] Tactic: 4501471010995462441 Time: 6.19407
[05/21/2022-03:10:43] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:10:43] [V] [TRT] Tactic: 5137655947464784826 Time: 5.97861
[05/21/2022-03:10:43] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:10:43] [V] [TRT] Tactic: 5288347012147084929 Time: 6.05346
[05/21/2022-03:10:43] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:10:43] [V] [TRT] Tactic: 5921334924264294896 Time: 3.52511
[05/21/2022-03:10:43] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:10:43] [V] [TRT] Tactic: 6645123197870846056 Time: 6.19384
[05/21/2022-03:10:43] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:10:43] [V] [TRT] Tactic: 7144526460361122478 Time: 8.17837
[05/21/2022-03:10:43] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:10:43] [V] [TRT] Tactic: 7852627285308570038 Time: 4.48623
[05/21/2022-03:10:43] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:10:44] [V] [TRT] Tactic: -9137461792520977713 Time: 6.23547
[05/21/2022-03:10:44] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:10:44] [V] [TRT] Tactic: -8776506421218919509 Time: 4.21477
[05/21/2022-03:10:44] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:10:44] [V] [TRT] Tactic: -8262349710178828730 Time: 6.23812
[05/21/2022-03:10:44] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:10:44] [V] [TRT] Tactic: -8133971918129952780 Time: 6.85698
[05/21/2022-03:10:44] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:10:44] [V] [TRT] Tactic: -6092040395344634144 Time: 8.50076
[05/21/2022-03:10:44] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:10:44] [V] [TRT] Tactic: -4787320710726427159 Time: 9.41748
[05/21/2022-03:10:44] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:10:45] [V] [TRT] Tactic: -3456450830548107839 Time: 7.08311
[05/21/2022-03:10:45] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:10:45] [V] [TRT] Tactic: -2318106587342035239 Time: 4.17966
[05/21/2022-03:10:45] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:10:45] [V] [TRT] Tactic: -1343271414618805657 Time: 3.18503
[05/21/2022-03:10:45] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:10:45] [V] [TRT] Tactic: -1218658103698133241 Time: 6.79381
[05/21/2022-03:10:45] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:10:45] [V] [TRT] Tactic: -836875257600482091 Time: 6.56741
[05/21/2022-03:10:45] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:10:45] [V] [TRT] Tactic: -410470605513481746 Time: 5.94072
[05/21/2022-03:10:45] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 3.18503
[05/21/2022-03:10:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:10:45] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:45] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:45] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:45] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:10:46] [V] [TRT] Tactic: -9153228964338181824 Time: 7.01867
[05/21/2022-03:10:46] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:10:46] [V] [TRT] Tactic: -7394439838318485025 Time: 5.83481
[05/21/2022-03:10:46] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 5.83481
[05/21/2022-03:10:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:10:46] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:46] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:46] [V] [TRT] Tactic: 0 Time: 8.17876
[05/21/2022-03:10:46] [V] [TRT] Tactic: 1 Time: 7.31537
[05/21/2022-03:10:46] [V] [TRT] Tactic: 2 Time: 6.78643
[05/21/2022-03:10:46] [V] [TRT] Tactic: 4 skipped. Scratch requested: 614596608, available: 536870912
[05/21/2022-03:10:46] [V] [TRT] Tactic: 5 skipped. Scratch requested: 1145307136, available: 536870912
[05/21/2022-03:10:46] [V] [TRT] Tactic: 6 Time: 6.9345
[05/21/2022-03:10:46] [V] [TRT] Fastest Tactic: 2 Time: 6.78643
[05/21/2022-03:10:46] [V] [TRT] Setting workspace to 614596608enables more tactics for profiling
[05/21/2022-03:10:46] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:46] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:10:46] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:46] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:47] [V] [TRT] Tactic: 524287 Time: 3.20786
[05/21/2022-03:10:47] [V] [TRT] Tactic: 720895 Time: 3.77185
[05/21/2022-03:10:47] [V] [TRT] Tactic: 983039 Time: 3.10013
[05/21/2022-03:10:47] [V] [TRT] Tactic: 1048575 Time: 3.39857
[05/21/2022-03:10:47] [V] [TRT] Tactic: 1703935 Time: 3.48233
[05/21/2022-03:10:48] [V] [TRT] Tactic: 1769471 Time: 21.3848
[05/21/2022-03:10:49] [V] [TRT] Tactic: 1966079 Time: 3.80687
[05/21/2022-03:10:49] [V] [TRT] Tactic: 2031615 Time: 3.06878
[05/21/2022-03:10:49] [V] [TRT] Tactic: 2228223 Time: 4.20648
[05/21/2022-03:10:49] [V] [TRT] Tactic: 2424831 Time: 6.16948
[05/21/2022-03:10:50] [V] [TRT] Tactic: 2621439 Time: 3.76288
[05/21/2022-03:10:50] [V] [TRT] Tactic: 2752511 Time: 2.87596
[05/21/2022-03:10:50] [V] [TRT] Tactic: 2818047 Time: 4.0045
[05/21/2022-03:10:50] [V] [TRT] Tactic: 2883583 Time: 3.56706
[05/21/2022-03:10:50] [V] [TRT] Tactic: 3014655 Time: 3.12805
[05/21/2022-03:10:51] [V] [TRT] Tactic: 3145727 Time: 2.83201
[05/21/2022-03:10:51] [V] [TRT] Tactic: 3473407 Time: 3.66667
[05/21/2022-03:10:51] [V] [TRT] Tactic: 3604479 Time: 3.10648
[05/21/2022-03:10:51] [V] [TRT] Tactic: 3735551 Time: 4.19385
[05/21/2022-03:10:51] [V] [TRT] Tactic: 4390911 Time: 2.87385
[05/21/2022-03:10:52] [V] [TRT] Tactic: 5046271 Time: 3.22486
[05/21/2022-03:10:52] [V] [TRT] Tactic: 5963775 Time: 2.89103
[05/21/2022-03:10:52] [V] [TRT] Tactic: 6160383 Time: 3.34529
[05/21/2022-03:10:52] [V] [TRT] Tactic: 6488063 Time: 2.82905
[05/21/2022-03:10:52] [V] [TRT] Tactic: 6881279 Time: 2.79754
[05/21/2022-03:10:53] [V] [TRT] Tactic: 7274495 Time: 4.02613
[05/21/2022-03:10:53] [V] [TRT] Tactic: 7864319 Time: 4.05931
[05/21/2022-03:10:53] [V] [TRT] Tactic: 7995391 Time: 3.73958
[05/21/2022-03:10:53] [V] [TRT] Tactic: 8585215 Time: 3.00796
[05/21/2022-03:10:53] [V] [TRT] Tactic: 8847359 Time: 2.86695
[05/21/2022-03:10:54] [V] [TRT] Tactic: 8978431 Time: 3.20081
[05/21/2022-03:10:54] [V] [TRT] Tactic: 9043967 Time: 2.759
[05/21/2022-03:10:54] [V] [TRT] Tactic: 9175039 Time: 3.10973
[05/21/2022-03:10:54] [V] [TRT] Tactic: 9502719 Time: 2.83041
[05/21/2022-03:10:54] [V] [TRT] Tactic: 9830399 Time: 3.12634
[05/21/2022-03:10:55] [V] [TRT] Tactic: 9961471 Time: 3.31965
[05/21/2022-03:10:55] [V] [TRT] Tactic: 10027007 Time: 2.92176
[05/21/2022-03:10:55] [V] [TRT] Tactic: 10092543 Time: 2.87687
[05/21/2022-03:10:55] [V] [TRT] Tactic: 10289151 Time: 3.79324
[05/21/2022-03:10:55] [V] [TRT] Tactic: 10485759 Time: 2.86899
[05/21/2022-03:10:56] [V] [TRT] Tactic: 10682367 Time: 3.71206
[05/21/2022-03:10:56] [V] [TRT] Tactic: 10813439 Time: 3.74396
[05/21/2022-03:10:56] [V] [TRT] Fastest Tactic: 9043967 Time: 2.759
[05/21/2022-03:10:56] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CudnnConvolution)
[05/21/2022-03:10:56] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:10:56] [V] [TRT] --------------- Timing Runner: 092_convolutional + 092_convolutional_bn (CaskConvolution)
[05/21/2022-03:10:56] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:10:56] [V] [TRT] Tactic: 3564772625446233998 Time: 4.09779
[05/21/2022-03:10:56] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:10:56] [V] [TRT] Tactic: 3650389455493082349 Time: 4.23643
[05/21/2022-03:10:56] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:10:56] [V] [TRT] Tactic: 4772821744921268633 Time: 1.78752
[05/21/2022-03:10:56] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:10:56] [V] [TRT] Tactic: 5319956359050645452 Time: 3.53447
[05/21/2022-03:10:56] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:10:56] [V] [TRT] Tactic: 7205456024582378848 Time: 3.11616
[05/21/2022-03:10:56] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:10:56] [V] [TRT] Tactic: -6490690591794140522 Time: 3.1572
[05/21/2022-03:10:56] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:10:57] [V] [TRT] Tactic: -4686027666808657977 Time: 3.12752
[05/21/2022-03:10:57] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:10:57] [V] [TRT] Tactic: -4212163711445252890 Time: 2.97655
[05/21/2022-03:10:57] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:10:57] [V] [TRT] Tactic: -3898373634979201110 Time: 3.10295
[05/21/2022-03:10:57] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:10:57] [V] [TRT] Tactic: -2409163523992614473 Time: 3.03048
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 1.78752
[05/21/2022-03:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:10:57] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:57] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1), Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 0 Time: 0.107168
[05/21/2022-03:10:57] [V] [TRT] Tactic: 1 Time: 0.0825849
[05/21/2022-03:10:57] [V] [TRT] Tactic: 2 Time: 0.0800654
[05/21/2022-03:10:57] [V] [TRT] Tactic: 3 Time: 0.0718878
[05/21/2022-03:10:57] [V] [TRT] Tactic: 4 Time: 0.0653124
[05/21/2022-03:10:57] [V] [TRT] Tactic: 5 Time: 0.0640365
[05/21/2022-03:10:57] [V] [TRT] Tactic: 6 Time: 0.071387
[05/21/2022-03:10:57] [V] [TRT] Tactic: 7 Time: 0.0605274
[05/21/2022-03:10:57] [V] [TRT] Tactic: 8 Time: 0.0591538
[05/21/2022-03:10:57] [V] [TRT] Tactic: 9 Time: 0.0628971
[05/21/2022-03:10:57] [V] [TRT] Tactic: 28 Time: 0.106185
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 8 Time: 0.0591538
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 128 Time: 0.410098
[05/21/2022-03:10:57] [V] [TRT] Tactic: 256 Time: 0.410267
[05/21/2022-03:10:57] [V] [TRT] Tactic: 512 Time: 0.41097
[05/21/2022-03:10:57] [V] [TRT] Tactic: -32 Time: 0.479531
[05/21/2022-03:10:57] [V] [TRT] Tactic: -64 Time: 0.440886
[05/21/2022-03:10:57] [V] [TRT] Tactic: -128 Time: 0.436732
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 128 Time: 0.410098
[05/21/2022-03:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:57] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512), Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 0 Time: 0.107077
[05/21/2022-03:10:57] [V] [TRT] Tactic: 1 Time: 0.0824869
[05/21/2022-03:10:57] [V] [TRT] Tactic: 2 Time: 0.0812175
[05/21/2022-03:10:57] [V] [TRT] Tactic: 3 Time: 0.0726498
[05/21/2022-03:10:57] [V] [TRT] Tactic: 4 Time: 0.0653514
[05/21/2022-03:10:57] [V] [TRT] Tactic: 5 Time: 0.063151
[05/21/2022-03:10:57] [V] [TRT] Tactic: 6 Time: 0.0712563
[05/21/2022-03:10:57] [V] [TRT] Tactic: 7 Time: 0.0604295
[05/21/2022-03:10:57] [V] [TRT] Tactic: 8 Time: 0.0589259
[05/21/2022-03:10:57] [V] [TRT] Tactic: 9 Time: 0.0624871
[05/21/2022-03:10:57] [V] [TRT] Tactic: 28 Time: 0.106862
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 8 Time: 0.0589259
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 128 Time: 0.410202
[05/21/2022-03:10:57] [V] [TRT] Tactic: 256 Time: 0.410274
[05/21/2022-03:10:57] [V] [TRT] Tactic: 512 Time: 0.410938
[05/21/2022-03:10:57] [V] [TRT] Tactic: -32 Time: 0.479271
[05/21/2022-03:10:57] [V] [TRT] Tactic: -64 Time: 0.440657
[05/21/2022-03:10:57] [V] [TRT] Tactic: -128 Time: 0.436621
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 128 Time: 0.410202
[05/21/2022-03:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:57] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1), Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 24 Time: 0.101107
[05/21/2022-03:10:57] [V] [TRT] Tactic: 25 Time: 0.0870119
[05/21/2022-03:10:57] [V] [TRT] Tactic: 26 Time: 0.0854622
[05/21/2022-03:10:57] [V] [TRT] Tactic: 27 Time: 0.0919598
[05/21/2022-03:10:57] [V] [TRT] Tactic: 31 Time: 0.100254
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 26 Time: 0.0854622
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 128 Time: 0.410234
[05/21/2022-03:10:57] [V] [TRT] Tactic: 256 Time: 0.410325
[05/21/2022-03:10:57] [V] [TRT] Tactic: 512 Time: 0.410755
[05/21/2022-03:10:57] [V] [TRT] Tactic: -32 Time: 0.478366
[05/21/2022-03:10:57] [V] [TRT] Tactic: -64 Time: 0.440228
[05/21/2022-03:10:57] [V] [TRT] Tactic: -128 Time: 0.437331
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 128 Time: 0.410234
[05/21/2022-03:10:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:10:57] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1), Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 0 Time: 0.109063
[05/21/2022-03:10:57] [V] [TRT] Tactic: 1 Time: 0.0840169
[05/21/2022-03:10:57] [V] [TRT] Tactic: 2 Time: 0.0792709
[05/21/2022-03:10:57] [V] [TRT] Tactic: 3 Time: 0.0686914
[05/21/2022-03:10:57] [V] [TRT] Tactic: 4 Time: 0.0682879
[05/21/2022-03:10:57] [V] [TRT] Tactic: 5 Time: 0.06375
[05/21/2022-03:10:57] [V] [TRT] Tactic: 6 Time: 0.062943
[05/21/2022-03:10:57] [V] [TRT] Tactic: 7 Time: 0.0602344
[05/21/2022-03:10:57] [V] [TRT] Tactic: 8 Time: 0.0572985
[05/21/2022-03:10:57] [V] [TRT] Tactic: 9 Time: 0.0590236
[05/21/2022-03:10:57] [V] [TRT] Tactic: 28 Time: 0.106973
[05/21/2022-03:10:57] [V] [TRT] Fastest Tactic: 8 Time: 0.0572985
[05/21/2022-03:10:57] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-03:10:57] [V] [TRT] Tactic: 128 Time: 0.426042
[05/21/2022-03:10:57] [V] [TRT] Tactic: 256 Time: 0.420365
[05/21/2022-03:10:57] [V] [TRT] Tactic: 512 Time: 0.400593
[05/21/2022-03:10:58] [V] [TRT] Tactic: -32 Time: 0.491049
[05/21/2022-03:10:58] [V] [TRT] Tactic: -64 Time: 0.474434
[05/21/2022-03:10:58] [V] [TRT] Tactic: -128 Time: 0.477657
[05/21/2022-03:10:58] [V] [TRT] Fastest Tactic: 512 Time: 0.400593
[05/21/2022-03:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1), Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWiseV2)
[05/21/2022-03:10:58] [V] [TRT] Tactic: 0 Time: 0.0927279
[05/21/2022-03:10:58] [V] [TRT] Tactic: 1 Time: 0.0841666
[05/21/2022-03:10:58] [V] [TRT] Tactic: 2 Time: 0.0799414
[05/21/2022-03:10:58] [V] [TRT] Tactic: 3 Time: 0.0778971
[05/21/2022-03:10:58] [V] [TRT] Tactic: 4 Time: 0.0771288
[05/21/2022-03:10:58] [V] [TRT] Tactic: 5 Time: 0.0770509
[05/21/2022-03:10:58] [V] [TRT] Tactic: 6 Time: 0.0779622
[05/21/2022-03:10:58] [V] [TRT] Tactic: 7 Time: 0.0757161
[05/21/2022-03:10:58] [V] [TRT] Tactic: 8 Time: 0.0850457
[05/21/2022-03:10:58] [V] [TRT] Tactic: 9 Time: 0.0992447
[05/21/2022-03:10:58] [V] [TRT] Tactic: 10 Time: 0.116719
[05/21/2022-03:10:58] [V] [TRT] Tactic: 11 Time: 0.0925585
[05/21/2022-03:10:58] [V] [TRT] Tactic: 12 Time: 0.0884246
[05/21/2022-03:10:58] [V] [TRT] Tactic: 13 Time: 0.0752541
[05/21/2022-03:10:58] [V] [TRT] Tactic: 14 Time: 0.0781119
[05/21/2022-03:10:58] [V] [TRT] Tactic: 15 Time: 0.0740687
[05/21/2022-03:10:58] [V] [TRT] Tactic: 16 Time: 0.068607
[05/21/2022-03:10:58] [V] [TRT] Tactic: 17 Time: 0.0698504
[05/21/2022-03:10:58] [V] [TRT] Tactic: 18 Time: 0.0672979
[05/21/2022-03:10:58] [V] [TRT] Tactic: 19 Time: 0.0691472
[05/21/2022-03:10:58] [V] [TRT] Tactic: 28 Time: 0.0917514
[05/21/2022-03:10:58] [V] [TRT] Tactic: 29 Time: 0.114388
[05/21/2022-03:10:58] [V] [TRT] Fastest Tactic: 18 Time: 0.0672979
[05/21/2022-03:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) (PointWise)
[05/21/2022-03:10:58] [V] [TRT] Tactic: 128 Time: 0.426322
[05/21/2022-03:10:58] [V] [TRT] Tactic: 256 Time: 0.421237
[05/21/2022-03:10:58] [V] [TRT] Tactic: 512 Time: 0.401549
[05/21/2022-03:10:58] [V] [TRT] Tactic: -32 Time: 0.491087
[05/21/2022-03:10:58] [V] [TRT] Tactic: -64 Time: 0.474518
[05/21/2022-03:10:58] [V] [TRT] Tactic: -128 Time: 0.47765
[05/21/2022-03:10:58] [V] [TRT] Fastest Tactic: 512 Time: 0.401549
[05/21/2022-03:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1), Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512), Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1), Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1), Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1), Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1), Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512), Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1), Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1), Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1), Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1), Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512), Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1), Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1), Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1), Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:58] [V] [TRT] Tactic: 0 Time: 0.127982
[05/21/2022-03:10:58] [V] [TRT] Tactic: 1 Time: 0.0909244
[05/21/2022-03:10:58] [V] [TRT] Tactic: 2 Time: 0.0864191
[05/21/2022-03:10:58] [V] [TRT] Tactic: 3 Time: 0.0702411
[05/21/2022-03:10:58] [V] [TRT] Tactic: 4 Time: 0.0648114
[05/21/2022-03:10:58] [V] [TRT] Tactic: 5 Time: 0.0640559
[05/21/2022-03:10:58] [V] [TRT] Tactic: 6 Time: 0.0632683
[05/21/2022-03:10:58] [V] [TRT] Tactic: 7 Time: 0.0535546
[05/21/2022-03:10:58] [V] [TRT] Tactic: 8 Time: 0.0524415
[05/21/2022-03:10:58] [V] [TRT] Tactic: 9 Time: 0.0538934
[05/21/2022-03:10:58] [V] [TRT] Tactic: 28 Time: 0.126335
[05/21/2022-03:10:58] [V] [TRT] Fastest Tactic: 8 Time: 0.0524415
[05/21/2022-03:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-03:10:58] [V] [TRT] Tactic: 128 Time: 0.399681
[05/21/2022-03:10:58] [V] [TRT] Tactic: 256 Time: 0.399544
[05/21/2022-03:10:58] [V] [TRT] Tactic: 512 Time: 0.39942
[05/21/2022-03:10:58] [V] [TRT] Tactic: -32 Time: 0.411061
[05/21/2022-03:10:58] [V] [TRT] Tactic: -64 Time: 0.382545
[05/21/2022-03:10:58] [V] [TRT] Tactic: -128 Time: 0.383698
[05/21/2022-03:10:58] [V] [TRT] Fastest Tactic: -64 Time: 0.382545
[05/21/2022-03:10:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:58] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:58] [V] [TRT] Tactic: 0 Time: 0.127624
[05/21/2022-03:10:58] [V] [TRT] Tactic: 1 Time: 0.0914452
[05/21/2022-03:10:58] [V] [TRT] Tactic: 2 Time: 0.0858854
[05/21/2022-03:10:58] [V] [TRT] Tactic: 3 Time: 0.0703905
[05/21/2022-03:10:58] [V] [TRT] Tactic: 4 Time: 0.0654102
[05/21/2022-03:10:58] [V] [TRT] Tactic: 5 Time: 0.0644403
[05/21/2022-03:10:58] [V] [TRT] Tactic: 6 Time: 0.0629166
[05/21/2022-03:10:58] [V] [TRT] Tactic: 7 Time: 0.0538995
[05/21/2022-03:10:58] [V] [TRT] Tactic: 8 Time: 0.0529949
[05/21/2022-03:10:58] [V] [TRT] Tactic: 9 Time: 0.0544006
[05/21/2022-03:10:58] [V] [TRT] Tactic: 28 Time: 0.126797
[05/21/2022-03:10:58] [V] [TRT] Fastest Tactic: 8 Time: 0.0529949
[05/21/2022-03:10:58] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-03:10:58] [V] [TRT] Tactic: 128 Time: 0.399811
[05/21/2022-03:10:59] [V] [TRT] Tactic: 256 Time: 0.399577
[05/21/2022-03:10:59] [V] [TRT] Tactic: 512 Time: 0.399512
[05/21/2022-03:10:59] [V] [TRT] Tactic: -32 Time: 0.393047
[05/21/2022-03:10:59] [V] [TRT] Tactic: -64 Time: 0.382038
[05/21/2022-03:10:59] [V] [TRT] Tactic: -128 Time: 0.386335
[05/21/2022-03:10:59] [V] [TRT] Fastest Tactic: -64 Time: 0.382038
[05/21/2022-03:10:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:59] [V] [TRT] Tactic: 24 Time: 0.0723697
[05/21/2022-03:10:59] [V] [TRT] Tactic: 25 Time: 0.0661459
[05/21/2022-03:10:59] [V] [TRT] Tactic: 26 Time: 0.0654298
[05/21/2022-03:10:59] [V] [TRT] Tactic: 27 Time: 0.0704297
[05/21/2022-03:10:59] [V] [TRT] Tactic: 31 Time: 0.072259
[05/21/2022-03:10:59] [V] [TRT] Fastest Tactic: 26 Time: 0.0654298
[05/21/2022-03:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-03:10:59] [V] [TRT] Tactic: 128 Time: 0.399688
[05/21/2022-03:10:59] [V] [TRT] Tactic: 256 Time: 0.400072
[05/21/2022-03:10:59] [V] [TRT] Tactic: 512 Time: 0.399421
[05/21/2022-03:10:59] [V] [TRT] Tactic: -32 Time: 0.410397
[05/21/2022-03:10:59] [V] [TRT] Tactic: -64 Time: 0.383288
[05/21/2022-03:10:59] [V] [TRT] Tactic: -128 Time: 0.38304
[05/21/2022-03:10:59] [V] [TRT] Fastest Tactic: -128 Time: 0.38304
[05/21/2022-03:10:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 26
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:59] [V] [TRT] Tactic: 0 Time: 0.13112
[05/21/2022-03:10:59] [V] [TRT] Tactic: 1 Time: 0.0949609
[05/21/2022-03:10:59] [V] [TRT] Tactic: 2 Time: 0.0885285
[05/21/2022-03:10:59] [V] [TRT] Tactic: 3 Time: 0.0722657
[05/21/2022-03:10:59] [V] [TRT] Tactic: 4 Time: 0.0678125
[05/21/2022-03:10:59] [V] [TRT] Tactic: 5 Time: 0.0661915
[05/21/2022-03:10:59] [V] [TRT] Tactic: 6 Time: 0.0626109
[05/21/2022-03:10:59] [V] [TRT] Tactic: 7 Time: 0.0556446
[05/21/2022-03:10:59] [V] [TRT] Tactic: 8 Time: 0.0564194
[05/21/2022-03:10:59] [V] [TRT] Tactic: 9 Time: 0.0552735
[05/21/2022-03:10:59] [V] [TRT] Tactic: 28 Time: 0.13
[05/21/2022-03:10:59] [V] [TRT] Fastest Tactic: 9 Time: 0.0552735
[05/21/2022-03:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-03:10:59] [V] [TRT] Tactic: 128 Time: 0.385365
[05/21/2022-03:10:59] [V] [TRT] Tactic: 256 Time: 0.382702
[05/21/2022-03:10:59] [V] [TRT] Tactic: 512 Time: 0.353476
[05/21/2022-03:10:59] [V] [TRT] Tactic: -32 Time: 0.413418
[05/21/2022-03:10:59] [V] [TRT] Tactic: -64 Time: 0.405918
[05/21/2022-03:10:59] [V] [TRT] Tactic: -128 Time: 0.406921
[05/21/2022-03:10:59] [V] [TRT] Fastest Tactic: 512 Time: 0.353476
[05/21/2022-03:10:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWiseV2)
[05/21/2022-03:10:59] [V] [TRT] Tactic: 0 Time: 0.0907163
[05/21/2022-03:10:59] [V] [TRT] Tactic: 1 Time: 0.0719204
[05/21/2022-03:10:59] [V] [TRT] Tactic: 2 Time: 0.070495
[05/21/2022-03:10:59] [V] [TRT] Tactic: 3 Time: 0.0649479
[05/21/2022-03:10:59] [V] [TRT] Tactic: 4 Time: 0.0629429
[05/21/2022-03:10:59] [V] [TRT] Tactic: 5 Time: 0.0632355
[05/21/2022-03:10:59] [V] [TRT] Tactic: 6 Time: 0.0616016
[05/21/2022-03:10:59] [V] [TRT] Tactic: 7 Time: 0.0592841
[05/21/2022-03:10:59] [V] [TRT] Tactic: 8 Time: 0.0579229
[05/21/2022-03:10:59] [V] [TRT] Tactic: 9 Time: 0.0610483
[05/21/2022-03:10:59] [V] [TRT] Tactic: 10 Time: 0.134818
[05/21/2022-03:10:59] [V] [TRT] Tactic: 11 Time: 0.0986265
[05/21/2022-03:10:59] [V] [TRT] Tactic: 12 Time: 0.0924741
[05/21/2022-03:10:59] [V] [TRT] Tactic: 13 Time: 0.0741862
[05/21/2022-03:10:59] [V] [TRT] Tactic: 14 Time: 0.0705211
[05/21/2022-03:10:59] [V] [TRT] Tactic: 15 Time: 0.0703775
[05/21/2022-03:10:59] [V] [TRT] Tactic: 16 Time: 0.0646291
[05/21/2022-03:10:59] [V] [TRT] Tactic: 17 Time: 0.0569075
[05/21/2022-03:10:59] [V] [TRT] Tactic: 18 Time: 0.0574346
[05/21/2022-03:10:59] [V] [TRT] Tactic: 19 Time: 0.0597332
[05/21/2022-03:10:59] [V] [TRT] Tactic: 28 Time: 0.0892121
[05/21/2022-03:10:59] [V] [TRT] Tactic: 29 Time: 0.1353
[05/21/2022-03:10:59] [V] [TRT] Fastest Tactic: 17 Time: 0.0569075
[05/21/2022-03:10:59] [V] [TRT] --------------- Timing Runner: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) (PointWise)
[05/21/2022-03:10:59] [V] [TRT] Tactic: 128 Time: 0.385586
[05/21/2022-03:10:59] [V] [TRT] Tactic: 256 Time: 0.38252
[05/21/2022-03:10:59] [V] [TRT] Tactic: 512 Time: 0.353522
[05/21/2022-03:10:59] [V] [TRT] Tactic: -32 Time: 0.413763
[05/21/2022-03:10:59] [V] [TRT] Tactic: -64 Time: 0.405879
[05/21/2022-03:10:59] [V] [TRT] Tactic: -128 Time: 0.405111
[05/21/2022-03:10:59] [V] [TRT] Fastest Tactic: 512 Time: 0.353522
[05/21/2022-03:10:59] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:10:59] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:10:59] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:10:59] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:10:59] [V] [TRT] Tactic: 589823 Time: 2.725
[05/21/2022-03:11:00] [V] [TRT] Tactic: 655359 Time: 1.93865
[05/21/2022-03:11:00] [V] [TRT] Tactic: 786431 Time: 2.91663
[05/21/2022-03:11:00] [V] [TRT] Tactic: 851967 Time: 3.00738
[05/21/2022-03:11:00] [V] [TRT] Tactic: 1179647 Time: 3.32923
[05/21/2022-03:11:00] [V] [TRT] Tactic: 1310719 Time: 6.17537
[05/21/2022-03:11:00] [V] [TRT] Tactic: 1376255 Time: 2.20445
[05/21/2022-03:11:01] [V] [TRT] Tactic: 1441791 Time: 3.72904
[05/21/2022-03:11:01] [V] [TRT] Tactic: 1507327 Time: 3.36765
[05/21/2022-03:11:01] [V] [TRT] Tactic: 1638399 Time: 4.48478
[05/21/2022-03:11:01] [V] [TRT] Tactic: 1835007 Time: 3.03292
[05/21/2022-03:11:01] [V] [TRT] Tactic: 1900543 Time: 2.79158
[05/21/2022-03:11:02] [V] [TRT] Tactic: 2097151 Time: 3.27577
[05/21/2022-03:11:02] [V] [TRT] Tactic: 2162687 Time: 2.16107
[05/21/2022-03:11:02] [V] [TRT] Tactic: 2293759 Time: 2.55462
[05/21/2022-03:11:02] [V] [TRT] Tactic: 2359295 Time: 2.90402
[05/21/2022-03:11:02] [V] [TRT] Tactic: 2686975 Time: 2.76993
[05/21/2022-03:11:02] [V] [TRT] Tactic: 3080191 Time: 2.36298
[05/21/2022-03:11:02] [V] [TRT] Tactic: 3342335 Time: 2.9665
[05/21/2022-03:11:03] [V] [TRT] Tactic: 3407871 Time: 2.66347
[05/21/2022-03:11:03] [V] [TRT] Tactic: 3538943 Time: 2.96675
[05/21/2022-03:11:03] [V] [TRT] Tactic: 3670015 Time: 1.66792
[05/21/2022-03:11:03] [V] [TRT] Tactic: 3932159 Time: 2.94972
[05/21/2022-03:11:03] [V] [TRT] Tactic: 3997695 Time: 3.05415
[05/21/2022-03:11:03] [V] [TRT] Tactic: 4063231 Time: 2.58688
[05/21/2022-03:11:04] [V] [TRT] Tactic: 4194303 Time: 2.74211
[05/21/2022-03:11:04] [V] [TRT] Tactic: 4259839 Time: 3.40059
[05/21/2022-03:11:04] [V] [TRT] Tactic: 4325375 Time: 3.72611
[05/21/2022-03:11:04] [V] [TRT] Tactic: 4521983 Time: 3.63767
[05/21/2022-03:11:04] [V] [TRT] Tactic: 4587519 Time: 3.39008
[05/21/2022-03:11:04] [V] [TRT] Tactic: 4653055 Time: 3.15585
[05/21/2022-03:11:05] [V] [TRT] Tactic: 4915199 Time: 2.7531
[05/21/2022-03:11:05] [V] [TRT] Tactic: 4980735 Time: 3.70852
[05/21/2022-03:11:05] [V] [TRT] Tactic: 5177343 Time: 3.96708
[05/21/2022-03:11:05] [V] [TRT] Tactic: 5242879 Time: 2.45124
[05/21/2022-03:11:05] [V] [TRT] Tactic: 5373951 Time: 3.70654
[05/21/2022-03:11:06] [V] [TRT] Tactic: 5439487 Time: 3.08367
[05/21/2022-03:11:06] [V] [TRT] Tactic: 5570559 Time: 1.99928
[05/21/2022-03:11:06] [V] [TRT] Tactic: 5636095 Time: 2.58857
[05/21/2022-03:11:06] [V] [TRT] Tactic: 5701631 Time: 3.15243
[05/21/2022-03:11:06] [V] [TRT] Tactic: 5767167 Time: 4.73059
[05/21/2022-03:11:06] [V] [TRT] Tactic: 5832703 Time: 2.67504
[05/21/2022-03:11:07] [V] [TRT] Tactic: 5898239 Time: 2.28505
[05/21/2022-03:11:07] [V] [TRT] Tactic: 6029311 Time: 2.45301
[05/21/2022-03:11:07] [V] [TRT] Tactic: 6225919 Time: 2.7357
[05/21/2022-03:11:07] [V] [TRT] Tactic: 6291455 Time: 3.34182
[05/21/2022-03:11:07] [V] [TRT] Tactic: 6422527 Time: 2.51557
[05/21/2022-03:11:07] [V] [TRT] Tactic: 6750207 Time: 3.00527
[05/21/2022-03:11:07] [V] [TRT] Tactic: 6815743 Time: 2.54432
[05/21/2022-03:11:08] [V] [TRT] Tactic: 6946815 Time: 3.89962
[05/21/2022-03:11:08] [V] [TRT] Tactic: 7012351 Time: 3.2774
[05/21/2022-03:11:08] [V] [TRT] Tactic: 7077887 Time: 2.96932
[05/21/2022-03:11:08] [V] [TRT] Tactic: 7143423 Time: 4.29376
[05/21/2022-03:11:08] [V] [TRT] Tactic: 7208959 Time: 3.17831
[05/21/2022-03:11:09] [V] [TRT] Tactic: 7340031 Time: 2.4043
[05/21/2022-03:11:09] [V] [TRT] Tactic: 7405567 Time: 2.80937
[05/21/2022-03:11:09] [V] [TRT] Tactic: 7536639 Time: 3.27468
[05/21/2022-03:11:09] [V] [TRT] Tactic: 7602175 Time: 3.73115
[05/21/2022-03:11:09] [V] [TRT] Tactic: 7733247 Time: 2.47704
[05/21/2022-03:11:09] [V] [TRT] Tactic: 7798783 Time: 2.91273
[05/21/2022-03:11:10] [V] [TRT] Tactic: 8191999 Time: 4.49402
[05/21/2022-03:11:10] [V] [TRT] Tactic: 8257535 Time: 2.82402
[05/21/2022-03:11:10] [V] [TRT] Tactic: 8323071 Time: 2.7826
[05/21/2022-03:11:10] [V] [TRT] Tactic: 8650751 Time: 4.3802
[05/21/2022-03:11:10] [V] [TRT] Tactic: 8716287 Time: 3.00777
[05/21/2022-03:11:11] [V] [TRT] Tactic: 9109503 Time: 3.41948
[05/21/2022-03:11:11] [V] [TRT] Tactic: 9568255 Time: 2.75942
[05/21/2022-03:11:11] [V] [TRT] Tactic: 9895935 Time: 2.73702
[05/21/2022-03:11:11] [V] [TRT] Tactic: 10223615 Time: 2.76918
[05/21/2022-03:11:11] [V] [TRT] Tactic: 10354687 Time: 3.67976
[05/21/2022-03:11:11] [V] [TRT] Tactic: 10551295 Time: 2.78323
[05/21/2022-03:11:12] [V] [TRT] Tactic: 10747903 Time: 2.30322
[05/21/2022-03:11:12] [V] [TRT] Tactic: 10944511 Time: 3.71567
[05/21/2022-03:11:12] [V] [TRT] Fastest Tactic: 3670015 Time: 1.66792
[05/21/2022-03:11:12] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:11:12] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:12] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-03:11:12] [V] [TRT] Tactic: 0 Time: 2.45508
[05/21/2022-03:11:12] [V] [TRT] Tactic: 1 Time: 2.05497
[05/21/2022-03:11:12] [V] [TRT] Tactic: 2 Time: 1.97859
[05/21/2022-03:11:12] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1212416000, available: 536870912
[05/21/2022-03:11:13] [V] [TRT] Tactic: 5 Time: 36.3671
[05/21/2022-03:11:13] [V] [TRT] Fastest Tactic: 2 Time: 1.97859
[05/21/2022-03:11:13] [V] [TRT] Setting workspace to 1212416000enables more tactics for profiling
[05/21/2022-03:11:13] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-03:11:13] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:13] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:11:13] [V] [TRT] Tactic: 1062367460111450758 Time: 1.81331
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:11:13] [V] [TRT] Tactic: 1698681053543049347 Time: 1.72369
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:11:13] [V] [TRT] Tactic: 4501471010995462441 Time: 1.38833
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:11:13] [V] [TRT] Tactic: 5137655947464784826 Time: 1.36843
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:11:13] [V] [TRT] Tactic: 5288347012147084929 Time: 1.38291
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:11:13] [V] [TRT] Tactic: 5326823351883942011 Time: 1.33489
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:11:13] [V] [TRT] Tactic: 5500448035057547314 Time: 1.44109
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:11:13] [V] [TRT] Tactic: 6645123197870846056 Time: 1.3954
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:11:13] [V] [TRT] Tactic: 7144526460361122478 Time: 1.89451
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:11:13] [V] [TRT] Tactic: -8262349710178828730 Time: 1.40725
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:11:13] [V] [TRT] Tactic: -6576203419454146580 Time: 1.60079
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:11:13] [V] [TRT] Tactic: -4787320710726427159 Time: 1.99874
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:11:13] [V] [TRT] Tactic: -3456450830548107839 Time: 1.68076
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:11:13] [V] [TRT] Tactic: -1218658103698133241 Time: 1.51249
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:11:13] [V] [TRT] Tactic: -836875257600482091 Time: 1.48394
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:11:13] [V] [TRT] Tactic: -410470605513481746 Time: 1.36441
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:11:13] [V] [TRT] Tactic: -377491875521947884 Time: 1.36616
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:11:13] [V] [TRT] Tactic: -37215280111360163 Time: 1.34933
[05/21/2022-03:11:13] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 1.33489
[05/21/2022-03:11:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:11:13] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:11:13] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-03:11:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:13] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-03:11:13] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:13] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:11:13] [V] [TRT] Tactic: 3886731678879822788 Time: 1.37695
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:11:13] [V] [TRT] Tactic: 6629944304117643200 Time: 2.06683
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:11:13] [V] [TRT] Tactic: -9153228964338181824 Time: 2.07114
[05/21/2022-03:11:13] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:11:13] [V] [TRT] Tactic: -7394439838318485025 Time: 1.38135
[05/21/2022-03:11:13] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 1.37695
[05/21/2022-03:11:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-03:11:13] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:11:14] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-03:11:14] [V] [TRT] Tactic: 0 Time: 2.43009
[05/21/2022-03:11:14] [V] [TRT] Tactic: 1 Time: 2.05396
[05/21/2022-03:11:14] [V] [TRT] Tactic: 2 Time: 1.90607
[05/21/2022-03:11:14] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1212416000, available: 536870912
[05/21/2022-03:11:14] [V] [TRT] Tactic: 5 Time: 36.0372
[05/21/2022-03:11:14] [V] [TRT] Fastest Tactic: 2 Time: 1.90607
[05/21/2022-03:11:14] [V] [TRT] Setting workspace to 1212416000enables more tactics for profiling
[05/21/2022-03:11:14] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-03:11:14] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:14] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-03:11:14] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:11:14] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:11:14] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-03:11:14] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:14] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:11:14] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:11:14] [V] [TRT] Tactic: 589823 Time: 1.44639
[05/21/2022-03:11:14] [V] [TRT] Tactic: 655359 Time: 1.24217
[05/21/2022-03:11:15] [V] [TRT] Tactic: 786431 Time: 1.80668
[05/21/2022-03:11:15] [V] [TRT] Tactic: 851967 Time: 1.65085
[05/21/2022-03:11:15] [V] [TRT] Tactic: 1179647 Time: 1.53859
[05/21/2022-03:11:15] [V] [TRT] Tactic: 1310719 Time: 3.165
[05/21/2022-03:11:15] [V] [TRT] Tactic: 1376255 Time: 1.14738
[05/21/2022-03:11:15] [V] [TRT] Tactic: 1441791 Time: 1.83412
[05/21/2022-03:11:15] [V] [TRT] Tactic: 1507327 Time: 1.74535
[05/21/2022-03:11:15] [V] [TRT] Tactic: 1638399 Time: 2.30685
[05/21/2022-03:11:15] [V] [TRT] Tactic: 1835007 Time: 1.9552
[05/21/2022-03:11:16] [V] [TRT] Tactic: 1900543 Time: 1.46486
[05/21/2022-03:11:16] [V] [TRT] Tactic: 2097151 Time: 2.2278
[05/21/2022-03:11:16] [V] [TRT] Tactic: 2162687 Time: 1.2349
[05/21/2022-03:11:16] [V] [TRT] Tactic: 2293759 Time: 1.41885
[05/21/2022-03:11:16] [V] [TRT] Tactic: 2359295 Time: 1.50544
[05/21/2022-03:11:16] [V] [TRT] Tactic: 2686975 Time: 2.30536
[05/21/2022-03:11:16] [V] [TRT] Tactic: 3080191 Time: 1.32713
[05/21/2022-03:11:16] [V] [TRT] Tactic: 3342335 Time: 1.54582
[05/21/2022-03:11:16] [V] [TRT] Tactic: 3407871 Time: 1.43146
[05/21/2022-03:11:16] [V] [TRT] Tactic: 3538943 Time: 1.46038
[05/21/2022-03:11:17] [V] [TRT] Tactic: 3670015 Time: 1.36564
[05/21/2022-03:11:17] [V] [TRT] Tactic: 3932159 Time: 1.63381
[05/21/2022-03:11:17] [V] [TRT] Tactic: 3997695 Time: 1.91529
[05/21/2022-03:11:17] [V] [TRT] Tactic: 4063231 Time: 1.41561
[05/21/2022-03:11:17] [V] [TRT] Tactic: 4194303 Time: 1.55357
[05/21/2022-03:11:17] [V] [TRT] Tactic: 4259839 Time: 2.18555
[05/21/2022-03:11:17] [V] [TRT] Tactic: 4325375 Time: 1.8681
[05/21/2022-03:11:17] [V] [TRT] Tactic: 4521983 Time: 1.8471
[05/21/2022-03:11:17] [V] [TRT] Tactic: 4587519 Time: 1.90982
[05/21/2022-03:11:18] [V] [TRT] Tactic: 4653055 Time: 1.63608
[05/21/2022-03:11:18] [V] [TRT] Tactic: 4915199 Time: 1.59729
[05/21/2022-03:11:18] [V] [TRT] Tactic: 4980735 Time: 1.87132
[05/21/2022-03:11:18] [V] [TRT] Tactic: 5177343 Time: 1.90887
[05/21/2022-03:11:18] [V] [TRT] Tactic: 5242879 Time: 1.28132
[05/21/2022-03:11:18] [V] [TRT] Tactic: 5373951 Time: 1.83701
[05/21/2022-03:11:18] [V] [TRT] Tactic: 5439487 Time: 1.70944
[05/21/2022-03:11:18] [V] [TRT] Tactic: 5570559 Time: 1.39503
[05/21/2022-03:11:18] [V] [TRT] Tactic: 5636095 Time: 1.41667
[05/21/2022-03:11:18] [V] [TRT] Tactic: 5701631 Time: 1.56339
[05/21/2022-03:11:19] [V] [TRT] Tactic: 5767167 Time: 2.21391
[05/21/2022-03:11:19] [V] [TRT] Tactic: 5832703 Time: 1.40587
[05/21/2022-03:11:19] [V] [TRT] Tactic: 5898239 Time: 1.37162
[05/21/2022-03:11:19] [V] [TRT] Tactic: 6029311 Time: 1.29089
[05/21/2022-03:11:19] [V] [TRT] Tactic: 6225919 Time: 1.3524
[05/21/2022-03:11:19] [V] [TRT] Tactic: 6291455 Time: 1.54752
[05/21/2022-03:11:19] [V] [TRT] Tactic: 6422527 Time: 1.35939
[05/21/2022-03:11:19] [V] [TRT] Tactic: 6750207 Time: 1.67212
[05/21/2022-03:11:19] [V] [TRT] Tactic: 6815743 Time: 1.37845
[05/21/2022-03:11:19] [V] [TRT] Tactic: 6946815 Time: 1.91689
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7012351 Time: 2.22477
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7077887 Time: 1.4271
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7143423 Time: 2.11391
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7208959 Time: 1.69146
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7340031 Time: 1.50962
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7405567 Time: 1.43403
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7536639 Time: 1.77584
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7602175 Time: 1.76385
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7733247 Time: 1.40738
[05/21/2022-03:11:20] [V] [TRT] Tactic: 7798783 Time: 1.80609
[05/21/2022-03:11:21] [V] [TRT] Tactic: 8191999 Time: 2.23469
[05/21/2022-03:11:21] [V] [TRT] Tactic: 8257535 Time: 1.64751
[05/21/2022-03:11:21] [V] [TRT] Tactic: 8323071 Time: 1.57701
[05/21/2022-03:11:21] [V] [TRT] Tactic: 8650751 Time: 2.08611
[05/21/2022-03:11:21] [V] [TRT] Tactic: 8716287 Time: 1.53656
[05/21/2022-03:11:21] [V] [TRT] Tactic: 9109503 Time: 2.35923
[05/21/2022-03:11:21] [V] [TRT] Tactic: 9568255 Time: 1.60434
[05/21/2022-03:11:21] [V] [TRT] Tactic: 9895935 Time: 1.55053
[05/21/2022-03:11:21] [V] [TRT] Tactic: 10223615 Time: 2.30439
[05/21/2022-03:11:22] [V] [TRT] Tactic: 10354687 Time: 2.27009
[05/21/2022-03:11:22] [V] [TRT] Tactic: 10551295 Time: 1.41354
[05/21/2022-03:11:22] [V] [TRT] Tactic: 10747903 Time: 1.21839
[05/21/2022-03:11:22] [V] [TRT] Tactic: 10944511 Time: 1.87458
[05/21/2022-03:11:22] [V] [TRT] Fastest Tactic: 1376255 Time: 1.14738
[05/21/2022-03:11:22] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CudnnConvolution)
[05/21/2022-03:11:22] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:22] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CublasConvolution)
[05/21/2022-03:11:22] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:11:22] [V] [TRT] --------------- Timing Runner: 106_convolutional + 106_convolutional_bn (CaskConvolution)
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:11:22] [V] [TRT] Tactic: 3066127711859985668 Time: 0.777936
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:11:22] [V] [TRT] Tactic: 3564772625446233998 Time: 0.894766
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:11:22] [V] [TRT] Tactic: 5319956359050645452 Time: 0.821562
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:11:22] [V] [TRT] Tactic: 7205456024582378848 Time: 0.728399
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:11:22] [V] [TRT] Tactic: 8163473458334948789 Time: 0.700527
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:11:22] [V] [TRT] Tactic: -4212163711445252890 Time: 0.692279
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:11:22] [V] [TRT] Tactic: -3898373634979201110 Time: 0.707175
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:11:22] [V] [TRT] Tactic: -2409163523992614473 Time: 0.715488
[05/21/2022-03:11:22] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:11:22] [V] [TRT] Tactic: -1716393687483585322 Time: 0.681042
[05/21/2022-03:11:22] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.681042
[05/21/2022-03:11:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:11:22] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:11:22] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:11:22] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:11:23] [V] [TRT] Tactic: 0 Time: 0.079694
[05/21/2022-03:11:24] [V] [TRT] Tactic: 1 Time: 0.591712
[05/21/2022-03:11:25] [V] [TRT] Tactic: 2 Time: 0.564603
[05/21/2022-03:11:26] [V] [TRT] Tactic: 3 Time: 0.412773
[05/21/2022-03:11:26] [V] [TRT] Tactic: 4 Time: 0.38084
[05/21/2022-03:11:27] [V] [TRT] Tactic: 5 Time: 0.400501
[05/21/2022-03:11:28] [V] [TRT] Tactic: 6 Time: 0.326484
[05/21/2022-03:11:29] [V] [TRT] Tactic: 7 Time: 0.286615
[05/21/2022-03:11:30] [V] [TRT] Tactic: 8 Time: 0.273125
[05/21/2022-03:11:31] [V] [TRT] Tactic: 9 Time: 0.323144
[05/21/2022-03:11:31] [V] [TRT] Tactic: 28 Time: 0.858945
[05/21/2022-03:11:31] [V] [TRT] Fastest Tactic: 0 Time: 0.079694
[05/21/2022-03:11:31] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-03:11:31] [V] [TRT] Tactic: 128 Time: 2.03852
[05/21/2022-03:11:32] [V] [TRT] Tactic: 256 Time: 2.04452
[05/21/2022-03:11:32] [V] [TRT] Tactic: 512 Time: 2.069
[05/21/2022-03:11:32] [V] [TRT] Tactic: -32 Time: 2.27848
[05/21/2022-03:11:32] [V] [TRT] Tactic: -64 Time: 2.16876
[05/21/2022-03:11:32] [V] [TRT] Tactic: -128 Time: 1.08654
[05/21/2022-03:11:32] [V] [TRT] Fastest Tactic: -128 Time: 1.08654
[05/21/2022-03:11:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[05/21/2022-03:11:32] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:11:32] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:11:32] [V] [TRT] Tactic: 0 Time: 0.44293
[05/21/2022-03:11:32] [V] [TRT] Tactic: 1 Time: 0.29873
[05/21/2022-03:11:32] [V] [TRT] Tactic: 2 Time: 0.280632
[05/21/2022-03:11:32] [V] [TRT] Tactic: 3 Time: 0.20748
[05/21/2022-03:11:32] [V] [TRT] Tactic: 4 Time: 0.19293
[05/21/2022-03:11:32] [V] [TRT] Tactic: 5 Time: 0.201283
[05/21/2022-03:11:32] [V] [TRT] Tactic: 6 Time: 0.165573
[05/21/2022-03:11:32] [V] [TRT] Tactic: 7 Time: 0.147285
[05/21/2022-03:11:32] [V] [TRT] Tactic: 8 Time: 0.14082
[05/21/2022-03:11:32] [V] [TRT] Tactic: 9 Time: 0.159577
[05/21/2022-03:11:32] [V] [TRT] Tactic: 28 Time: 0.432122
[05/21/2022-03:11:32] [V] [TRT] Fastest Tactic: 8 Time: 0.14082
[05/21/2022-03:11:32] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-03:11:32] [V] [TRT] Tactic: 128 Time: 1.02051
[05/21/2022-03:11:32] [V] [TRT] Tactic: 256 Time: 1.02261
[05/21/2022-03:11:32] [V] [TRT] Tactic: 512 Time: 1.03471
[05/21/2022-03:11:32] [V] [TRT] Tactic: -32 Time: 1.13587
[05/21/2022-03:11:32] [V] [TRT] Tactic: -64 Time: 1.08434
[05/21/2022-03:11:32] [V] [TRT] Tactic: -128 Time: 1.08656
[05/21/2022-03:11:32] [V] [TRT] Fastest Tactic: 128 Time: 1.02051
[05/21/2022-03:11:32] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:11:32] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:11:32] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:11:33] [V] [TRT] Tactic: 24 Time: 0.49099
[05/21/2022-03:11:34] [V] [TRT] Tactic: 25 Time: 0.45543
[05/21/2022-03:11:35] [V] [TRT] Tactic: 26 Time: 0.435834
[05/21/2022-03:11:35] [V] [TRT] Tactic: 27 Time: 0.423633
[05/21/2022-03:11:36] [V] [TRT] Tactic: 31 Time: 0.491348
[05/21/2022-03:11:36] [V] [TRT] Fastest Tactic: 27 Time: 0.423633
[05/21/2022-03:11:36] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-03:11:36] [V] [TRT] Tactic: 128 Time: 2.03859
[05/21/2022-03:11:36] [V] [TRT] Tactic: 256 Time: 2.0479
[05/21/2022-03:11:36] [V] [TRT] Tactic: 512 Time: 2.0677
[05/21/2022-03:11:36] [V] [TRT] Tactic: -32 Time: 2.27327
[05/21/2022-03:11:37] [V] [TRT] Tactic: -64 Time: 2.16899
[05/21/2022-03:11:37] [V] [TRT] Tactic: -128 Time: 2.17628
[05/21/2022-03:11:37] [V] [TRT] Fastest Tactic: 128 Time: 2.03859
[05/21/2022-03:11:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:11:37] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:11:37] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:11:37] [V] [TRT] Tactic: 0 Time: 0.882513
[05/21/2022-03:11:38] [V] [TRT] Tactic: 1 Time: 0.612454
[05/21/2022-03:11:39] [V] [TRT] Tactic: 2 Time: 0.586601
[05/21/2022-03:11:40] [V] [TRT] Tactic: 3 Time: 0.432389
[05/21/2022-03:11:41] [V] [TRT] Tactic: 4 Time: 0.394323
[05/21/2022-03:11:42] [V] [TRT] Tactic: 5 Time: 0.419316
[05/21/2022-03:11:43] [V] [TRT] Tactic: 6 Time: 0.342702
[05/21/2022-03:11:43] [V] [TRT] Tactic: 7 Time: 0.303516
[05/21/2022-03:11:44] [V] [TRT] Tactic: 8 Time: 0.304291
[05/21/2022-03:11:45] [V] [TRT] Tactic: 9 Time: 0.342819
[05/21/2022-03:11:46] [V] [TRT] Tactic: 28 Time: 0.85737
[05/21/2022-03:11:46] [V] [TRT] Fastest Tactic: 7 Time: 0.303516
[05/21/2022-03:11:46] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-03:11:46] [V] [TRT] Tactic: 128 Time: 1.85029
[05/21/2022-03:11:46] [V] [TRT] Tactic: 256 Time: 1.83808
[05/21/2022-03:11:46] [V] [TRT] Tactic: 512 Time: 1.79544
[05/21/2022-03:11:46] [V] [TRT] Tactic: -32 Time: 2.22315
[05/21/2022-03:11:46] [V] [TRT] Tactic: -64 Time: 2.16087
[05/21/2022-03:11:46] [V] [TRT] Tactic: -128 Time: 2.18123
[05/21/2022-03:11:46] [V] [TRT] Fastest Tactic: 512 Time: 1.79544
[05/21/2022-03:11:46] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:11:46] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:11:46] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:11:47] [V] [TRT] Tactic: 0 Time: 0.278737
[05/21/2022-03:11:48] [V] [TRT] Tactic: 1 Time: 0.400365
[05/21/2022-03:11:49] [V] [TRT] Tactic: 2 Time: 0.411823
[05/21/2022-03:11:50] [V] [TRT] Tactic: 3 Time: 0.315638
[05/21/2022-03:11:51] [V] [TRT] Tactic: 4 Time: 0.32194
[05/21/2022-03:11:51] [V] [TRT] Tactic: 5 Time: 0.361797
[05/21/2022-03:11:52] [V] [TRT] Tactic: 6 Time: 0.285521
[05/21/2022-03:11:53] [V] [TRT] Tactic: 7 Time: 0.283887
[05/21/2022-03:11:54] [V] [TRT] Tactic: 8 Time: 0.3103
[05/21/2022-03:11:55] [V] [TRT] Tactic: 9 Time: 0.35319
[05/21/2022-03:11:56] [V] [TRT] Tactic: 10 Time: 0.9597
[05/21/2022-03:11:57] [V] [TRT] Tactic: 11 Time: 0.66403
[05/21/2022-03:11:57] [V] [TRT] Tactic: 12 Time: 0.637917
[05/21/2022-03:11:58] [V] [TRT] Tactic: 13 Time: 0.464714
[05/21/2022-03:11:59] [V] [TRT] Tactic: 14 Time: 0.41972
[05/21/2022-03:12:00] [V] [TRT] Tactic: 15 Time: 0.44707
[05/21/2022-03:12:01] [V] [TRT] Tactic: 16 Time: 0.369381
[05/21/2022-03:12:02] [V] [TRT] Tactic: 17 Time: 0.319375
[05/21/2022-03:12:03] [V] [TRT] Tactic: 18 Time: 0.324466
[05/21/2022-03:12:03] [V] [TRT] Tactic: 19 Time: 0.381524
[05/21/2022-03:12:04] [V] [TRT] Tactic: 28 Time: 0.540951
[05/21/2022-03:12:05] [V] [TRT] Tactic: 29 Time: 0.934473
[05/21/2022-03:12:05] [V] [TRT] Fastest Tactic: 0 Time: 0.278737
[05/21/2022-03:12:05] [V] [TRT] --------------- Timing Runner: PWN(106_convolutional_lrelu) (PointWise)
[05/21/2022-03:12:05] [V] [TRT] Tactic: 128 Time: 1.85214
[05/21/2022-03:12:05] [V] [TRT] Tactic: 256 Time: 1.83675
[05/21/2022-03:12:05] [V] [TRT] Tactic: 512 Time: 1.01285
[05/21/2022-03:12:05] [V] [TRT] Tactic: -32 Time: 1.10994
[05/21/2022-03:12:05] [V] [TRT] Tactic: -64 Time: 1.0814
[05/21/2022-03:12:05] [V] [TRT] Tactic: -128 Time: 1.08123
[05/21/2022-03:12:05] [V] [TRT] Fastest Tactic: 512 Time: 1.01285
[05/21/2022-03:12:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 0
[05/21/2022-03:12:05] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:05] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:12:05] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:12:05] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:05] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:12:05] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:05] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-03:12:06] [V] [TRT] Tactic: 0 Time: 15.332
[05/21/2022-03:12:06] [V] [TRT] Tactic: 1 Time: 15.2153
[05/21/2022-03:12:06] [V] [TRT] Tactic: 2 Time: 13.1878
[05/21/2022-03:12:06] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1228013568, available: 536870912
[05/21/2022-03:12:06] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2288386048, available: 536870912
[05/21/2022-03:12:06] [V] [TRT] Tactic: 6 Time: 10.3271
[05/21/2022-03:12:06] [V] [TRT] Fastest Tactic: 6 Time: 10.3271
[05/21/2022-03:12:06] [V] [TRT] Setting workspace to 1228013568enables more tactics for profiling
[05/21/2022-03:12:06] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:07] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:12:07] [V] [TRT] Tactic: 1062367460111450758 Time: 15.5741
[05/21/2022-03:12:07] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:12:07] [V] [TRT] Tactic: 1754984623894446479 Time: 18.1802
[05/21/2022-03:12:07] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:12:07] [V] [TRT] Tactic: 3611739942397549984 Time: 12.3178
[05/21/2022-03:12:08] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:12:08] [V] [TRT] Tactic: 3827454225649558724 Time: 9.9768
[05/21/2022-03:12:08] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:12:08] [V] [TRT] Tactic: 4337000649858996379 Time: 12.5625
[05/21/2022-03:12:08] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:12:08] [V] [TRT] Tactic: 4501471010995462441 Time: 12.3733
[05/21/2022-03:12:08] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:12:09] [V] [TRT] Tactic: 5137655947464784826 Time: 11.9787
[05/21/2022-03:12:09] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:12:09] [V] [TRT] Tactic: 5288347012147084929 Time: 12.0969
[05/21/2022-03:12:09] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:12:09] [V] [TRT] Tactic: 5921334924264294896 Time: 7.28223
[05/21/2022-03:12:09] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:12:09] [V] [TRT] Tactic: 6645123197870846056 Time: 12.3974
[05/21/2022-03:12:09] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:12:10] [V] [TRT] Tactic: 7144526460361122478 Time: 15.6643
[05/21/2022-03:12:10] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:12:10] [V] [TRT] Tactic: 7852627285308570038 Time: 9.85727
[05/21/2022-03:12:10] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:12:10] [V] [TRT] Tactic: -9137461792520977713 Time: 12.4662
[05/21/2022-03:12:10] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:12:11] [V] [TRT] Tactic: -8776506421218919509 Time: 9.62517
[05/21/2022-03:12:11] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:12:11] [V] [TRT] Tactic: -8262349710178828730 Time: 12.4815
[05/21/2022-03:12:11] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:12:11] [V] [TRT] Tactic: -8133971918129952780 Time: 13.6191
[05/21/2022-03:12:11] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:12:12] [V] [TRT] Tactic: -6092040395344634144 Time: 16.1297
[05/21/2022-03:12:12] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:12:12] [V] [TRT] Tactic: -4787320710726427159 Time: 18.0607
[05/21/2022-03:12:12] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:12:12] [V] [TRT] Tactic: -3456450830548107839 Time: 13.6717
[05/21/2022-03:12:12] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:12:13] [V] [TRT] Tactic: -2318106587342035239 Time: 9.45782
[05/21/2022-03:12:13] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:12:13] [V] [TRT] Tactic: -1343271414618805657 Time: 6.43667
[05/21/2022-03:12:13] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:12:13] [V] [TRT] Tactic: -1218658103698133241 Time: 13.574
[05/21/2022-03:12:13] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:12:13] [V] [TRT] Tactic: -836875257600482091 Time: 13.1293
[05/21/2022-03:12:14] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:12:14] [V] [TRT] Tactic: -410470605513481746 Time: 11.8825
[05/21/2022-03:12:14] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 6.43667
[05/21/2022-03:12:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:12:14] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:12:14] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-03:12:14] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:14] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:14] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:12:14] [V] [TRT] Tactic: -9153228964338181824 Time: 14.0382
[05/21/2022-03:12:14] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:12:14] [V] [TRT] Tactic: -7394439838318485025 Time: 11.7964
[05/21/2022-03:12:14] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 11.7964
[05/21/2022-03:12:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:12:14] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:12:14] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-03:12:15] [V] [TRT] Tactic: 0 Time: 22.139
[05/21/2022-03:12:15] [V] [TRT] Tactic: 1 Time: 13.4991
[05/21/2022-03:12:15] [V] [TRT] Tactic: 2 Time: 12.4997
[05/21/2022-03:12:15] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1228013568, available: 536870912
[05/21/2022-03:12:15] [V] [TRT] Tactic: 5 skipped. Scratch requested: 2288386048, available: 536870912
[05/21/2022-03:12:16] [V] [TRT] Tactic: 6 Time: 13.2385
[05/21/2022-03:12:16] [V] [TRT] Fastest Tactic: 2 Time: 12.4997
[05/21/2022-03:12:16] [V] [TRT] Setting workspace to 1228013568enables more tactics for profiling
[05/21/2022-03:12:16] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:16] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:16] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:12:16] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:12:16] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:12:16] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:16] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CudnnConvolution)
[05/21/2022-03:12:16] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:16] [V] [TRT] --------------- Timing Runner: 107_convolutional + 107_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:16] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:12:16] [V] [TRT] Tactic: 3564772625446233998 Time: 7.72544
[05/21/2022-03:12:16] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:12:16] [V] [TRT] Tactic: 3650389455493082349 Time: 8.03878
[05/21/2022-03:12:16] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:12:16] [V] [TRT] Tactic: 4772821744921268633 Time: 3.66499
[05/21/2022-03:12:16] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:12:17] [V] [TRT] Tactic: 5319956359050645452 Time: 6.78815
[05/21/2022-03:12:17] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:12:17] [V] [TRT] Tactic: 7205456024582378848 Time: 6.21671
[05/21/2022-03:12:17] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:12:17] [V] [TRT] Tactic: -6490690591794140522 Time: 6.28255
[05/21/2022-03:12:17] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:12:17] [V] [TRT] Tactic: -4686027666808657977 Time: 6.23699
[05/21/2022-03:12:17] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:12:17] [V] [TRT] Tactic: -4212163711445252890 Time: 5.94125
[05/21/2022-03:12:17] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:12:17] [V] [TRT] Tactic: -3898373634979201110 Time: 6.15475
[05/21/2022-03:12:17] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:12:18] [V] [TRT] Tactic: -2409163523992614473 Time: 6.03296
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 3.66499
[05/21/2022-03:12:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:12:18] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:18] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 0 Time: 0.1536
[05/21/2022-03:12:18] [V] [TRT] Tactic: 1 Time: 0.110885
[05/21/2022-03:12:18] [V] [TRT] Tactic: 2 Time: 0.0977406
[05/21/2022-03:12:18] [V] [TRT] Tactic: 3 Time: 0.0940884
[05/21/2022-03:12:18] [V] [TRT] Tactic: 4 Time: 0.0772656
[05/21/2022-03:12:18] [V] [TRT] Tactic: 5 Time: 0.0726302
[05/21/2022-03:12:18] [V] [TRT] Tactic: 6 Time: 0.0939387
[05/21/2022-03:12:18] [V] [TRT] Tactic: 7 Time: 0.0754686
[05/21/2022-03:12:18] [V] [TRT] Tactic: 8 Time: 0.0748048
[05/21/2022-03:12:18] [V] [TRT] Tactic: 9 Time: 0.0735677
[05/21/2022-03:12:18] [V] [TRT] Tactic: 28 Time: 0.149739
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 5 Time: 0.0726302
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 128 Time: 0.345898
[05/21/2022-03:12:18] [V] [TRT] Tactic: 256 Time: 0.347012
[05/21/2022-03:12:18] [V] [TRT] Tactic: 512 Time: 0.349746
[05/21/2022-03:12:18] [V] [TRT] Tactic: -32 Time: 0.381471
[05/21/2022-03:12:18] [V] [TRT] Tactic: -64 Time: 0.364844
[05/21/2022-03:12:18] [V] [TRT] Tactic: -128 Time: 0.363086
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 128 Time: 0.345898
[05/21/2022-03:12:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:12:18] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 0 Time: 0.153086
[05/21/2022-03:12:18] [V] [TRT] Tactic: 1 Time: 0.110306
[05/21/2022-03:12:18] [V] [TRT] Tactic: 2 Time: 0.0977473
[05/21/2022-03:12:18] [V] [TRT] Tactic: 3 Time: 0.0939779
[05/21/2022-03:12:18] [V] [TRT] Tactic: 4 Time: 0.0770509
[05/21/2022-03:12:18] [V] [TRT] Tactic: 5 Time: 0.0729036
[05/21/2022-03:12:18] [V] [TRT] Tactic: 6 Time: 0.0937238
[05/21/2022-03:12:18] [V] [TRT] Tactic: 7 Time: 0.0754427
[05/21/2022-03:12:18] [V] [TRT] Tactic: 8 Time: 0.0731645
[05/21/2022-03:12:18] [V] [TRT] Tactic: 9 Time: 0.0733136
[05/21/2022-03:12:18] [V] [TRT] Tactic: 28 Time: 0.149961
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 5 Time: 0.0729036
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 128 Time: 0.34638
[05/21/2022-03:12:18] [V] [TRT] Tactic: 256 Time: 0.346973
[05/21/2022-03:12:18] [V] [TRT] Tactic: 512 Time: 0.349167
[05/21/2022-03:12:18] [V] [TRT] Tactic: -32 Time: 0.381334
[05/21/2022-03:12:18] [V] [TRT] Tactic: -64 Time: 0.364557
[05/21/2022-03:12:18] [V] [TRT] Tactic: -128 Time: 0.363568
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 128 Time: 0.34638
[05/21/2022-03:12:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:12:18] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 24 Time: 0.095879
[05/21/2022-03:12:18] [V] [TRT] Tactic: 25 Time: 0.0916666
[05/21/2022-03:12:18] [V] [TRT] Tactic: 26 Time: 0.0936132
[05/21/2022-03:12:18] [V] [TRT] Tactic: 27 Time: 0.0907945
[05/21/2022-03:12:18] [V] [TRT] Tactic: 31 Time: 0.0964388
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 27 Time: 0.0907945
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 128 Time: 0.346211
[05/21/2022-03:12:18] [V] [TRT] Tactic: 256 Time: 0.346816
[05/21/2022-03:12:18] [V] [TRT] Tactic: 512 Time: 0.349447
[05/21/2022-03:12:18] [V] [TRT] Tactic: -32 Time: 0.381328
[05/21/2022-03:12:18] [V] [TRT] Tactic: -64 Time: 0.365
[05/21/2022-03:12:18] [V] [TRT] Tactic: -128 Time: 0.363021
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 128 Time: 0.346211
[05/21/2022-03:12:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:12:18] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 0 Time: 0.152207
[05/21/2022-03:12:18] [V] [TRT] Tactic: 1 Time: 0.10888
[05/21/2022-03:12:18] [V] [TRT] Tactic: 2 Time: 0.10377
[05/21/2022-03:12:18] [V] [TRT] Tactic: 3 Time: 0.0863608
[05/21/2022-03:12:18] [V] [TRT] Tactic: 4 Time: 0.0694726
[05/21/2022-03:12:18] [V] [TRT] Tactic: 5 Time: 0.0725846
[05/21/2022-03:12:18] [V] [TRT] Tactic: 6 Time: 0.0789711
[05/21/2022-03:12:18] [V] [TRT] Tactic: 7 Time: 0.0584957
[05/21/2022-03:12:18] [V] [TRT] Tactic: 8 Time: 0.0526041
[05/21/2022-03:12:18] [V] [TRT] Tactic: 9 Time: 0.0582749
[05/21/2022-03:12:18] [V] [TRT] Tactic: 28 Time: 0.148112
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 8 Time: 0.0526041
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 128 Time: 0.312826
[05/21/2022-03:12:18] [V] [TRT] Tactic: 256 Time: 0.311257
[05/21/2022-03:12:18] [V] [TRT] Tactic: 512 Time: 0.303021
[05/21/2022-03:12:18] [V] [TRT] Tactic: -32 Time: 0.36418
[05/21/2022-03:12:18] [V] [TRT] Tactic: -64 Time: 0.342591
[05/21/2022-03:12:18] [V] [TRT] Tactic: -128 Time: 0.343275
[05/21/2022-03:12:18] [V] [TRT] Fastest Tactic: 512 Time: 0.303021
[05/21/2022-03:12:18] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:12:18] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:12:18] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:12:18] [V] [TRT] Tactic: 0 Time: 0.100058
[05/21/2022-03:12:18] [V] [TRT] Tactic: 1 Time: 0.0813217
[05/21/2022-03:12:18] [V] [TRT] Tactic: 2 Time: 0.0872656
[05/21/2022-03:12:18] [V] [TRT] Tactic: 3 Time: 0.0734245
[05/21/2022-03:12:18] [V] [TRT] Tactic: 4 Time: 0.0752996
[05/21/2022-03:12:18] [V] [TRT] Tactic: 5 Time: 0.0792772
[05/21/2022-03:12:18] [V] [TRT] Tactic: 6 Time: 0.0728776
[05/21/2022-03:12:18] [V] [TRT] Tactic: 7 Time: 0.0734244
[05/21/2022-03:12:18] [V] [TRT] Tactic: 8 Time: 0.0779558
[05/21/2022-03:12:18] [V] [TRT] Tactic: 9 Time: 0.0837432
[05/21/2022-03:12:18] [V] [TRT] Tactic: 10 Time: 0.164967
[05/21/2022-03:12:18] [V] [TRT] Tactic: 11 Time: 0.11612
[05/21/2022-03:12:18] [V] [TRT] Tactic: 12 Time: 0.112096
[05/21/2022-03:12:18] [V] [TRT] Tactic: 13 Time: 0.0887041
[05/21/2022-03:12:18] [V] [TRT] Tactic: 14 Time: 0.0732617
[05/21/2022-03:12:18] [V] [TRT] Tactic: 15 Time: 0.0779426
[05/21/2022-03:12:19] [V] [TRT] Tactic: 16 Time: 0.0816018
[05/21/2022-03:12:19] [V] [TRT] Tactic: 17 Time: 0.0592449
[05/21/2022-03:12:19] [V] [TRT] Tactic: 18 Time: 0.055495
[05/21/2022-03:12:19] [V] [TRT] Tactic: 19 Time: 0.0655011
[05/21/2022-03:12:19] [V] [TRT] Tactic: 28 Time: 0.0982421
[05/21/2022-03:12:19] [V] [TRT] Tactic: 29 Time: 0.160508
[05/21/2022-03:12:19] [V] [TRT] Fastest Tactic: 18 Time: 0.055495
[05/21/2022-03:12:19] [V] [TRT] --------------- Timing Runner: PWN(107_convolutional_lrelu) (PointWise)
[05/21/2022-03:12:19] [V] [TRT] Tactic: 128 Time: 0.313106
[05/21/2022-03:12:19] [V] [TRT] Tactic: 256 Time: 0.310768
[05/21/2022-03:12:19] [V] [TRT] Tactic: 512 Time: 0.302786
[05/21/2022-03:12:19] [V] [TRT] Tactic: -32 Time: 0.364765
[05/21/2022-03:12:19] [V] [TRT] Tactic: -64 Time: 0.342585
[05/21/2022-03:12:19] [V] [TRT] Tactic: -128 Time: 0.343783
[05/21/2022-03:12:19] [V] [TRT] Fastest Tactic: 512 Time: 0.302786
[05/21/2022-03:12:19] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:12:19] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:19] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:12:19] [V] [TRT] --------------- Timing Runner: 109_maxpool (TiledPooling)
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733505 Time: 5.79887
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733506 Time: 3.1285
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733508 Time: 3.58085
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733511 Time: 1.79609
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733512 Time: 1.79609
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733517 Time: 0.914023
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733761 Time: 3.1362
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733762 Time: 3.37255
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733764 Time: 1.93107
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733767 Time: 0.982858
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733768 Time: 0.98265
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7733773 Time: 0.621751
[05/21/2022-03:12:19] [V] [TRT] Tactic: 7734017 Time: 4.47166
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734018 Time: 2.41257
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734020 Time: 1.38314
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734023 Time: 0.705313
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734024 Time: 0.705606
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734029 Time: 0.527337
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734273 Time: 3.5798
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734274 Time: 1.93224
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734276 Time: 1.10926
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734279 Time: 0.567481
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734280 Time: 0.567044
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734285 Time: 0.495547
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734529 Time: 2.68771
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734530 Time: 1.45198
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734532 Time: 0.845567
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734535 Time: 0.62905
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734536 Time: 0.629753
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734541 Time: 0.425072
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734785 Time: 2.68731
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734786 Time: 1.45204
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734788 Time: 0.845026
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734791 Time: 0.629368
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734792 Time: 0.629056
[05/21/2022-03:12:20] [V] [TRT] Tactic: 7734797 Time: 0.525534
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735041 Time: 1.79693
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735042 Time: 0.984017
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735044 Time: 0.568119
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735047 Time: 0.42597
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735048 Time: 0.497962
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735053 Time: 0.356582
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735297 Time: 1.79659
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735298 Time: 0.983978
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735300 Time: 0.5678
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735303 Time: 0.499004
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735304 Time: 0.498835
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735309 Time: 0.39209
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735553 Time: 1.81744
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735554 Time: 0.98457
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735556 Time: 0.833672
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735559 Time: 0.495651
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735560 Time: 0.558555
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735565 Time: 0.390508
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735809 Time: 1.81706
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735810 Time: 0.984108
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735812 Time: 0.83403
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735815 Time: 0.558333
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735816 Time: 0.694414
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7735821 Time: 0.460033
[05/21/2022-03:12:21] [V] [TRT] Tactic: 7736065 Time: 1.8175
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736066 Time: 0.983789
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736068 Time: 0.833144
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736071 Time: 0.694772
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736072 Time: 0.69528
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736077 Time: 0.457181
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736321 Time: 1.8176
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736322 Time: 0.984323
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736324 Time: 0.833262
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736327 Time: 0.694375
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736328 Time: 0.695404
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7736333 Time: 0.494505
[05/21/2022-03:12:22] [V] [TRT] Fastest Tactic: 7735053 Time: 0.356582
[05/21/2022-03:12:22] [V] [TRT] --------------- Timing Runner: 109_maxpool (CudnnPooling)
[05/21/2022-03:12:22] [V] [TRT] Tactic: -1 Time: 0.641205
[05/21/2022-03:12:22] [V] [TRT] Fastest Tactic: -1 Time: 0.641205
[05/21/2022-03:12:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: TiledPooling Tactic: 7735053
[05/21/2022-03:12:22] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:22] [V] [TRT] --------------- Timing Runner: 109_maxpool (TiledPooling)
[05/21/2022-03:12:22] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-03:12:22] [V] [TRT] --------------- Timing Runner: 109_maxpool (CudnnPooling)
[05/21/2022-03:12:22] [V] [TRT] Tactic: -1 Time: 0.630742
[05/21/2022-03:12:22] [V] [TRT] Fastest Tactic: -1 Time: 0.630742
[05/21/2022-03:12:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-03:12:22] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:12:22] [V] [TRT] --------------- Timing Runner: 109_maxpool (TiledPooling)
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733505 Time: 3.66249
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733506 Time: 1.97697
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733508 Time: 2.26385
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733511 Time: 1.13658
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733512 Time: 1.13709
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733517 Time: 0.51821
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733761 Time: 1.97899
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733762 Time: 2.13655
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733764 Time: 1.22373
[05/21/2022-03:12:22] [V] [TRT] Tactic: 7733767 Time: 0.557083
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7733768 Time: 0.556556
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7733773 Time: 0.3464
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734017 Time: 2.82956
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734018 Time: 1.52824
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734020 Time: 0.877617
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734023 Time: 0.401159
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734024 Time: 0.401302
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734029 Time: 0.311309
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734273 Time: 2.26718
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734274 Time: 1.22492
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734276 Time: 0.704577
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734279 Time: 0.323483
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734280 Time: 0.323776
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734285 Time: 0.286484
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734529 Time: 1.70444
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734530 Time: 0.922279
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734532 Time: 0.47985
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734535 Time: 0.369896
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734536 Time: 0.370234
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734541 Time: 0.255248
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734785 Time: 1.70246
[05/21/2022-03:12:23] [V] [TRT] Tactic: 7734786 Time: 0.92181
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7734788 Time: 0.479616
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7734791 Time: 0.369954
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7734792 Time: 0.369785
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7734797 Time: 0.318398
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735041 Time: 1.13965
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735042 Time: 0.557467
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735044 Time: 0.323502
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735047 Time: 0.252728
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735048 Time: 0.288392
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735053 Time: 0.218268
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735297 Time: 1.13951
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735298 Time: 0.557272
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735300 Time: 0.323646
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735303 Time: 0.28806
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735304 Time: 0.289349
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735309 Time: 0.232363
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735553 Time: 1.02584
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735554 Time: 0.557135
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735556 Time: 0.487168
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735559 Time: 0.284772
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735560 Time: 0.332617
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735565 Time: 0.230541
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735809 Time: 1.02571
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735810 Time: 0.557213
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735812 Time: 0.487409
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735815 Time: 0.332213
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735816 Time: 0.418705
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7735821 Time: 0.273704
[05/21/2022-03:12:24] [V] [TRT] Tactic: 7736065 Time: 1.02583
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736066 Time: 0.557435
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736068 Time: 0.487318
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736071 Time: 0.419154
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736072 Time: 0.418652
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736077 Time: 0.271758
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736321 Time: 1.02587
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736322 Time: 0.557415
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736324 Time: 0.487617
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736327 Time: 0.4186
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736328 Time: 0.418789
[05/21/2022-03:12:25] [V] [TRT] Tactic: 7736333 Time: 0.289414
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: 7735053 Time: 0.218268
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 109_maxpool (CudaPooling)
[05/21/2022-03:12:25] [V] [TRT] Tactic: -3 Time: 0.24627
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: -3 Time: 0.24627
[05/21/2022-03:12:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: TiledPooling Tactic: 7735053
[05/21/2022-03:12:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:25] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 111_maxpool (TiledPooling)
[05/21/2022-03:12:25] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 111_maxpool (CudnnPooling)
[05/21/2022-03:12:25] [V] [TRT] Tactic: -1 Time: 1.41769
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: -1 Time: 1.41769
[05/21/2022-03:12:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-03:12:25] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 111_maxpool (TiledPooling)
[05/21/2022-03:12:25] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 111_maxpool (CudnnPooling)
[05/21/2022-03:12:25] [V] [TRT] Tactic: -1 Time: 1.37753
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: -1 Time: 1.37753
[05/21/2022-03:12:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-03:12:25] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 111_maxpool (TiledPooling)
[05/21/2022-03:12:25] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 111_maxpool (CudaPooling)
[05/21/2022-03:12:25] [V] [TRT] Tactic: -3 Time: 0.527982
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: -3 Time: 0.527982
[05/21/2022-03:12:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaPooling Tactic: -3
[05/21/2022-03:12:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:25] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 113_maxpool (TiledPooling)
[05/21/2022-03:12:25] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 113_maxpool (CudnnPooling)
[05/21/2022-03:12:25] [V] [TRT] Tactic: -1 Time: 2.16548
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: -1 Time: 2.16548
[05/21/2022-03:12:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-03:12:25] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 113_maxpool (TiledPooling)
[05/21/2022-03:12:25] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 113_maxpool (CudnnPooling)
[05/21/2022-03:12:25] [V] [TRT] Tactic: -1 Time: 2.17281
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: -1 Time: 2.17281
[05/21/2022-03:12:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnPooling Tactic: -1
[05/21/2022-03:12:25] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 113_maxpool (TiledPooling)
[05/21/2022-03:12:25] [V] [TRT] TiledPooling has no valid tactics for this config, skipping
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 113_maxpool (CudaPooling)
[05/21/2022-03:12:25] [V] [TRT] Tactic: -3 Time: 0.877806
[05/21/2022-03:12:25] [V] [TRT] Fastest Tactic: -3 Time: 0.877806
[05/21/2022-03:12:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudaPooling Tactic: -3
[05/21/2022-03:12:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:12:25] [V] [TRT] *************** Autotuning format combination: Float(346112,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:12:25] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:12:25] [V] [TRT] Tactic: 589823 Time: 5.30453
[05/21/2022-03:12:26] [V] [TRT] Tactic: 655359 Time: 3.87821
[05/21/2022-03:12:26] [V] [TRT] Tactic: 786431 Time: 5.66719
[05/21/2022-03:12:26] [V] [TRT] Tactic: 851967 Time: 5.69169
[05/21/2022-03:12:26] [V] [TRT] Tactic: 1179647 Time: 5.91562
[05/21/2022-03:12:27] [V] [TRT] Tactic: 1310719 Time: 12.1203
[05/21/2022-03:12:27] [V] [TRT] Tactic: 1376255 Time: 4.25194
[05/21/2022-03:12:28] [V] [TRT] Tactic: 1441791 Time: 7.09818
[05/21/2022-03:12:28] [V] [TRT] Tactic: 1507327 Time: 6.46378
[05/21/2022-03:12:28] [V] [TRT] Tactic: 1638399 Time: 8.40942
[05/21/2022-03:12:29] [V] [TRT] Tactic: 1835007 Time: 5.86524
[05/21/2022-03:12:29] [V] [TRT] Tactic: 1900543 Time: 5.31774
[05/21/2022-03:12:29] [V] [TRT] Tactic: 2097151 Time: 6.24015
[05/21/2022-03:12:30] [V] [TRT] Tactic: 2162687 Time: 4.15049
[05/21/2022-03:12:30] [V] [TRT] Tactic: 2293759 Time: 4.63493
[05/21/2022-03:12:30] [V] [TRT] Tactic: 2359295 Time: 5.52781
[05/21/2022-03:12:30] [V] [TRT] Tactic: 2686975 Time: 5.4051
[05/21/2022-03:12:31] [V] [TRT] Tactic: 3080191 Time: 4.42195
[05/21/2022-03:12:31] [V] [TRT] Tactic: 3342335 Time: 5.66244
[05/21/2022-03:12:31] [V] [TRT] Tactic: 3407871 Time: 5.4278
[05/21/2022-03:12:32] [V] [TRT] Tactic: 3538943 Time: 5.62072
[05/21/2022-03:12:32] [V] [TRT] Tactic: 3670015 Time: 3.24864
[05/21/2022-03:12:32] [V] [TRT] Tactic: 3932159 Time: 5.96646
[05/21/2022-03:12:32] [V] [TRT] Tactic: 3997695 Time: 5.70593
[05/21/2022-03:12:33] [V] [TRT] Tactic: 4063231 Time: 4.90142
[05/21/2022-03:12:33] [V] [TRT] Tactic: 4194303 Time: 5.24928
[05/21/2022-03:12:33] [V] [TRT] Tactic: 4259839 Time: 6.4737
[05/21/2022-03:12:34] [V] [TRT] Tactic: 4325375 Time: 7.30576
[05/21/2022-03:12:34] [V] [TRT] Tactic: 4521983 Time: 7.13244
[05/21/2022-03:12:34] [V] [TRT] Tactic: 4587519 Time: 6.52825
[05/21/2022-03:12:35] [V] [TRT] Tactic: 4653055 Time: 5.95977
[05/21/2022-03:12:35] [V] [TRT] Tactic: 4915199 Time: 5.30389
[05/21/2022-03:12:35] [V] [TRT] Tactic: 4980735 Time: 7.19051
[05/21/2022-03:12:36] [V] [TRT] Tactic: 5177343 Time: 6.95472
[05/21/2022-03:12:36] [V] [TRT] Tactic: 5242879 Time: 4.2242
[05/21/2022-03:12:36] [V] [TRT] Tactic: 5373951 Time: 6.42221
[05/21/2022-03:12:37] [V] [TRT] Tactic: 5439487 Time: 5.90221
[05/21/2022-03:12:37] [V] [TRT] Tactic: 5570559 Time: 3.7177
[05/21/2022-03:12:37] [V] [TRT] Tactic: 5636095 Time: 4.92178
[05/21/2022-03:12:38] [V] [TRT] Tactic: 5701631 Time: 6.04947
[05/21/2022-03:12:38] [V] [TRT] Tactic: 5767167 Time: 9.04163
[05/21/2022-03:12:38] [V] [TRT] Tactic: 5832703 Time: 5.43882
[05/21/2022-03:12:39] [V] [TRT] Tactic: 5898239 Time: 4.26343
[05/21/2022-03:12:39] [V] [TRT] Tactic: 6029311 Time: 4.30913
[05/21/2022-03:12:39] [V] [TRT] Tactic: 6225919 Time: 5.03918
[05/21/2022-03:12:39] [V] [TRT] Tactic: 6291455 Time: 5.91024
[05/21/2022-03:12:40] [V] [TRT] Tactic: 6422527 Time: 4.55525
[05/21/2022-03:12:40] [V] [TRT] Tactic: 6750207 Time: 5.92357
[05/21/2022-03:12:40] [V] [TRT] Tactic: 6815743 Time: 4.40079
[05/21/2022-03:12:41] [V] [TRT] Tactic: 6946815 Time: 7.65718
[05/21/2022-03:12:41] [V] [TRT] Tactic: 7012351 Time: 6.25046
[05/21/2022-03:12:41] [V] [TRT] Tactic: 7077887 Time: 5.61056
[05/21/2022-03:12:42] [V] [TRT] Tactic: 7143423 Time: 8.30947
[05/21/2022-03:12:42] [V] [TRT] Tactic: 7208959 Time: 6.49495
[05/21/2022-03:12:42] [V] [TRT] Tactic: 7340031 Time: 4.42887
[05/21/2022-03:12:43] [V] [TRT] Tactic: 7405567 Time: 5.1269
[05/21/2022-03:12:43] [V] [TRT] Tactic: 7536639 Time: 5.87141
[05/21/2022-03:12:43] [V] [TRT] Tactic: 7602175 Time: 7.39329
[05/21/2022-03:12:44] [V] [TRT] Tactic: 7733247 Time: 4.52911
[05/21/2022-03:12:44] [V] [TRT] Tactic: 7798783 Time: 5.63444
[05/21/2022-03:12:44] [V] [TRT] Tactic: 8191999 Time: 8.68539
[05/21/2022-03:12:45] [V] [TRT] Tactic: 8257535 Time: 5.35175
[05/21/2022-03:12:45] [V] [TRT] Tactic: 8323071 Time: 5.32611
[05/21/2022-03:12:45] [V] [TRT] Tactic: 8650751 Time: 8.76977
[05/21/2022-03:12:46] [V] [TRT] Tactic: 8716287 Time: 5.32365
[05/21/2022-03:12:46] [V] [TRT] Tactic: 9109503 Time: 6.45262
[05/21/2022-03:12:46] [V] [TRT] Tactic: 9568255 Time: 5.29922
[05/21/2022-03:12:47] [V] [TRT] Tactic: 9895935 Time: 5.24949
[05/21/2022-03:12:47] [V] [TRT] Tactic: 10223615 Time: 5.40263
[05/21/2022-03:12:47] [V] [TRT] Tactic: 10354687 Time: 6.82941
[05/21/2022-03:12:47] [V] [TRT] Tactic: 10551295 Time: 5.25124
[05/21/2022-03:12:48] [V] [TRT] Tactic: 10747903 Time: 4.40503
[05/21/2022-03:12:48] [V] [TRT] Tactic: 10944511 Time: 7.19325
[05/21/2022-03:12:48] [V] [TRT] Fastest Tactic: 3670015 Time: 3.24864
[05/21/2022-03:12:48] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:12:48] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:48] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-03:12:48] [V] [TRT] Tactic: 0 Time: 4.8673
[05/21/2022-03:12:48] [V] [TRT] Tactic: 1 Time: 3.85389
[05/21/2022-03:12:48] [V] [TRT] Tactic: 2 Time: 3.45696
[05/21/2022-03:12:48] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2424832000, available: 536870912
[05/21/2022-03:12:50] [V] [TRT] Tactic: 5 Time: 72.3692
[05/21/2022-03:12:50] [V] [TRT] Fastest Tactic: 2 Time: 3.45696
[05/21/2022-03:12:50] [V] [TRT] Setting workspace to 2424832000enables more tactics for profiling
[05/21/2022-03:12:50] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-03:12:50] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:50] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:12:50] [V] [TRT] Tactic: 1062367460111450758 Time: 3.61419
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:12:50] [V] [TRT] Tactic: 1698681053543049347 Time: 3.42697
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:12:50] [V] [TRT] Tactic: 4501471010995462441 Time: 2.74094
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:12:50] [V] [TRT] Tactic: 5137655947464784826 Time: 2.69803
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:12:50] [V] [TRT] Tactic: 5288347012147084929 Time: 2.72815
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:12:50] [V] [TRT] Tactic: 5326823351883942011 Time: 2.62777
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:12:50] [V] [TRT] Tactic: 5500448035057547314 Time: 2.90274
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:12:50] [V] [TRT] Tactic: 6645123197870846056 Time: 2.75451
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:12:50] [V] [TRT] Tactic: 7144526460361122478 Time: 3.79511
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:12:50] [V] [TRT] Tactic: -8262349710178828730 Time: 2.78607
[05/21/2022-03:12:50] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:12:51] [V] [TRT] Tactic: -6576203419454146580 Time: 3.08922
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:12:51] [V] [TRT] Tactic: -4787320710726427159 Time: 3.98728
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:12:51] [V] [TRT] Tactic: -3456450830548107839 Time: 3.24745
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:12:51] [V] [TRT] Tactic: -1218658103698133241 Time: 3.04245
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:12:51] [V] [TRT] Tactic: -836875257600482091 Time: 2.97221
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:12:51] [V] [TRT] Tactic: -410470605513481746 Time: 2.68467
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:12:51] [V] [TRT] Tactic: -377491875521947884 Time: 2.70283
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:12:51] [V] [TRT] Tactic: -37215280111360163 Time: 2.64048
[05/21/2022-03:12:51] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 2.62777
[05/21/2022-03:12:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:12:51] [V] [TRT] *************** Autotuning format combination: Float(346112,1,26624,2048) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:12:51] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-03:12:51] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:51] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-03:12:51] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:51] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:12:51] [V] [TRT] Tactic: 3886731678879822788 Time: 2.75984
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:12:51] [V] [TRT] Tactic: 6629944304117643200 Time: 4.03045
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:12:51] [V] [TRT] Tactic: -9153228964338181824 Time: 4.02045
[05/21/2022-03:12:51] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:12:51] [V] [TRT] Tactic: -7394439838318485025 Time: 2.75722
[05/21/2022-03:12:51] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.75722
[05/21/2022-03:12:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:12:51] [V] [TRT] *************** Autotuning format combination: Half(346112,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:51] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-03:12:52] [V] [TRT] Tactic: 0 Time: 4.53459
[05/21/2022-03:12:52] [V] [TRT] Tactic: 1 Time: 3.93495
[05/21/2022-03:12:52] [V] [TRT] Tactic: 2 Time: 3.50224
[05/21/2022-03:12:52] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2424832000, available: 536870912
[05/21/2022-03:12:53] [V] [TRT] Tactic: 5 Time: 72.444
[05/21/2022-03:12:53] [V] [TRT] Fastest Tactic: 2 Time: 3.50224
[05/21/2022-03:12:53] [V] [TRT] Setting workspace to 2424832000enables more tactics for profiling
[05/21/2022-03:12:53] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-03:12:53] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:53] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:53] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:12:53] [V] [TRT] *************** Autotuning format combination: Half(173056,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:12:53] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-03:12:53] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:12:53] [V] [TRT] *************** Autotuning format combination: Half(173056,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:12:53] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:12:53] [V] [TRT] Tactic: 589823 Time: 2.80191
[05/21/2022-03:12:53] [V] [TRT] Tactic: 655359 Time: 2.35686
[05/21/2022-03:12:54] [V] [TRT] Tactic: 786431 Time: 3.56426
[05/21/2022-03:12:54] [V] [TRT] Tactic: 851967 Time: 3.04285
[05/21/2022-03:12:54] [V] [TRT] Tactic: 1179647 Time: 3.08694
[05/21/2022-03:12:54] [V] [TRT] Tactic: 1310719 Time: 6.19348
[05/21/2022-03:12:54] [V] [TRT] Tactic: 1376255 Time: 2.14926
[05/21/2022-03:12:54] [V] [TRT] Tactic: 1441791 Time: 3.4264
[05/21/2022-03:12:55] [V] [TRT] Tactic: 1507327 Time: 3.34407
[05/21/2022-03:12:55] [V] [TRT] Tactic: 1638399 Time: 4.54224
[05/21/2022-03:12:55] [V] [TRT] Tactic: 1835007 Time: 3.91211
[05/21/2022-03:12:55] [V] [TRT] Tactic: 1900543 Time: 2.82557
[05/21/2022-03:12:56] [V] [TRT] Tactic: 2097151 Time: 4.25299
[05/21/2022-03:12:56] [V] [TRT] Tactic: 2162687 Time: 2.37604
[05/21/2022-03:12:56] [V] [TRT] Tactic: 2293759 Time: 2.69197
[05/21/2022-03:12:56] [V] [TRT] Tactic: 2359295 Time: 2.78628
[05/21/2022-03:12:56] [V] [TRT] Tactic: 2686975 Time: 4.49802
[05/21/2022-03:12:56] [V] [TRT] Tactic: 3080191 Time: 2.46123
[05/21/2022-03:12:56] [V] [TRT] Tactic: 3342335 Time: 2.94878
[05/21/2022-03:12:57] [V] [TRT] Tactic: 3407871 Time: 2.67259
[05/21/2022-03:12:57] [V] [TRT] Tactic: 3538943 Time: 3.03562
[05/21/2022-03:12:57] [V] [TRT] Tactic: 3670015 Time: 2.62782
[05/21/2022-03:12:57] [V] [TRT] Tactic: 3932159 Time: 3.46256
[05/21/2022-03:12:57] [V] [TRT] Tactic: 3997695 Time: 3.79869
[05/21/2022-03:12:57] [V] [TRT] Tactic: 4063231 Time: 2.59804
[05/21/2022-03:12:58] [V] [TRT] Tactic: 4194303 Time: 2.94129
[05/21/2022-03:12:58] [V] [TRT] Tactic: 4259839 Time: 4.25639
[05/21/2022-03:12:58] [V] [TRT] Tactic: 4325375 Time: 3.69679
[05/21/2022-03:12:58] [V] [TRT] Tactic: 4521983 Time: 3.6049
[05/21/2022-03:12:58] [V] [TRT] Tactic: 4587519 Time: 3.65093
[05/21/2022-03:12:59] [V] [TRT] Tactic: 4653055 Time: 3.10572
[05/21/2022-03:12:59] [V] [TRT] Tactic: 4915199 Time: 3.08684
[05/21/2022-03:12:59] [V] [TRT] Tactic: 4980735 Time: 3.63432
[05/21/2022-03:12:59] [V] [TRT] Tactic: 5177343 Time: 3.78217
[05/21/2022-03:12:59] [V] [TRT] Tactic: 5242879 Time: 2.69522
[05/21/2022-03:13:00] [V] [TRT] Tactic: 5373951 Time: 3.58686
[05/21/2022-03:13:00] [V] [TRT] Tactic: 5439487 Time: 3.48354
[05/21/2022-03:13:00] [V] [TRT] Tactic: 5570559 Time: 2.66547
[05/21/2022-03:13:00] [V] [TRT] Tactic: 5636095 Time: 2.59827
[05/21/2022-03:13:00] [V] [TRT] Tactic: 5701631 Time: 3.02991
[05/21/2022-03:13:00] [V] [TRT] Tactic: 5767167 Time: 4.45202
[05/21/2022-03:13:01] [V] [TRT] Tactic: 5832703 Time: 2.664
[05/21/2022-03:13:01] [V] [TRT] Tactic: 5898239 Time: 2.59395
[05/21/2022-03:13:01] [V] [TRT] Tactic: 6029311 Time: 2.46078
[05/21/2022-03:13:01] [V] [TRT] Tactic: 6225919 Time: 2.78973
[05/21/2022-03:13:01] [V] [TRT] Tactic: 6291455 Time: 3.10378
[05/21/2022-03:13:01] [V] [TRT] Tactic: 6422527 Time: 2.59322
[05/21/2022-03:13:02] [V] [TRT] Tactic: 6750207 Time: 3.49782
[05/21/2022-03:13:02] [V] [TRT] Tactic: 6815743 Time: 2.95673
[05/21/2022-03:13:02] [V] [TRT] Tactic: 6946815 Time: 3.67852
[05/21/2022-03:13:02] [V] [TRT] Tactic: 7012351 Time: 4.25644
[05/21/2022-03:13:02] [V] [TRT] Tactic: 7077887 Time: 3.02079
[05/21/2022-03:13:02] [V] [TRT] Tactic: 7143423 Time: 4.18544
[05/21/2022-03:13:03] [V] [TRT] Tactic: 7208959 Time: 3.02621
[05/21/2022-03:13:03] [V] [TRT] Tactic: 7340031 Time: 2.78984
[05/21/2022-03:13:03] [V] [TRT] Tactic: 7405567 Time: 2.8038
[05/21/2022-03:13:03] [V] [TRT] Tactic: 7536639 Time: 3.58807
[05/21/2022-03:13:03] [V] [TRT] Tactic: 7602175 Time: 3.46389
[05/21/2022-03:13:03] [V] [TRT] Tactic: 7733247 Time: 2.63051
[05/21/2022-03:13:04] [V] [TRT] Tactic: 7798783 Time: 3.41105
[05/21/2022-03:13:04] [V] [TRT] Tactic: 8191999 Time: 4.49051
[05/21/2022-03:13:04] [V] [TRT] Tactic: 8257535 Time: 3.18564
[05/21/2022-03:13:04] [V] [TRT] Tactic: 8323071 Time: 3.18539
[05/21/2022-03:13:04] [V] [TRT] Tactic: 8650751 Time: 4.0804
[05/21/2022-03:13:05] [V] [TRT] Tactic: 8716287 Time: 3.08163
[05/21/2022-03:13:05] [V] [TRT] Tactic: 9109503 Time: 4.51736
[05/21/2022-03:13:05] [V] [TRT] Tactic: 9568255 Time: 3.10235
[05/21/2022-03:13:05] [V] [TRT] Tactic: 9895935 Time: 2.94096
[05/21/2022-03:13:05] [V] [TRT] Tactic: 10223615 Time: 4.48873
[05/21/2022-03:13:06] [V] [TRT] Tactic: 10354687 Time: 4.41716
[05/21/2022-03:13:06] [V] [TRT] Tactic: 10551295 Time: 2.78661
[05/21/2022-03:13:06] [V] [TRT] Tactic: 10747903 Time: 2.29954
[05/21/2022-03:13:06] [V] [TRT] Tactic: 10944511 Time: 3.63516
[05/21/2022-03:13:06] [V] [TRT] Fastest Tactic: 1376255 Time: 2.14926
[05/21/2022-03:13:06] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CudnnConvolution)
[05/21/2022-03:13:06] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:06] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CublasConvolution)
[05/21/2022-03:13:06] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:06] [V] [TRT] --------------- Timing Runner: 115_convolutional + 115_convolutional_bn (CaskConvolution)
[05/21/2022-03:13:06] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:13:06] [V] [TRT] Tactic: 3066127711859985668 Time: 1.56663
[05/21/2022-03:13:06] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:13:06] [V] [TRT] Tactic: 3564772625446233998 Time: 1.78538
[05/21/2022-03:13:06] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:13:06] [V] [TRT] Tactic: 5319956359050645452 Time: 1.65217
[05/21/2022-03:13:06] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:13:06] [V] [TRT] Tactic: 7205456024582378848 Time: 1.3847
[05/21/2022-03:13:06] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:13:06] [V] [TRT] Tactic: 8163473458334948789 Time: 1.3215
[05/21/2022-03:13:06] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:13:07] [V] [TRT] Tactic: -4212163711445252890 Time: 1.34479
[05/21/2022-03:13:07] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:13:07] [V] [TRT] Tactic: -3898373634979201110 Time: 1.37359
[05/21/2022-03:13:07] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:13:07] [V] [TRT] Tactic: -2409163523992614473 Time: 1.36081
[05/21/2022-03:13:07] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:13:07] [V] [TRT] Tactic: -1716393687483585322 Time: 1.33005
[05/21/2022-03:13:07] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 1.3215
[05/21/2022-03:13:07] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:13:07] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:13:07] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:13:07] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:13:08] [V] [TRT] Tactic: 0 Time: 1.19163
[05/21/2022-03:13:09] [V] [TRT] Tactic: 1 Time: 0.782077
[05/21/2022-03:13:09] [V] [TRT] Tactic: 2 Time: 0.73097
[05/21/2022-03:13:10] [V] [TRT] Tactic: 3 Time: 0.502135
[05/21/2022-03:13:11] [V] [TRT] Tactic: 4 Time: 0.490117
[05/21/2022-03:13:12] [V] [TRT] Tactic: 5 Time: 0.463705
[05/21/2022-03:13:13] [V] [TRT] Tactic: 6 Time: 0.374622
[05/21/2022-03:13:14] [V] [TRT] Tactic: 7 Time: 0.342721
[05/21/2022-03:13:14] [V] [TRT] Tactic: 8 Time: 0.338652
[05/21/2022-03:13:15] [V] [TRT] Tactic: 9 Time: 0.349694
[05/21/2022-03:13:16] [V] [TRT] Tactic: 28 Time: 1.1668
[05/21/2022-03:13:16] [V] [TRT] Fastest Tactic: 8 Time: 0.338652
[05/21/2022-03:13:16] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-03:13:16] [V] [TRT] Tactic: 128 Time: 2.55239
[05/21/2022-03:13:16] [V] [TRT] Tactic: 256 Time: 2.56204
[05/21/2022-03:13:16] [V] [TRT] Tactic: 512 Time: 2.58493
[05/21/2022-03:13:16] [V] [TRT] Tactic: -32 Time: 2.38924
[05/21/2022-03:13:16] [V] [TRT] Tactic: -64 Time: 2.20659
[05/21/2022-03:13:17] [V] [TRT] Tactic: -128 Time: 2.24572
[05/21/2022-03:13:17] [V] [TRT] Fastest Tactic: -64 Time: 2.20659
[05/21/2022-03:13:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:13:17] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:13:17] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:13:17] [V] [TRT] Tactic: 0 Time: 1.04277
[05/21/2022-03:13:17] [V] [TRT] Tactic: 1 Time: 0.390267
[05/21/2022-03:13:17] [V] [TRT] Tactic: 2 Time: 0.363399
[05/21/2022-03:13:17] [V] [TRT] Tactic: 3 Time: 0.254219
[05/21/2022-03:13:17] [V] [TRT] Tactic: 4 Time: 0.244714
[05/21/2022-03:13:17] [V] [TRT] Tactic: 5 Time: 0.23457
[05/21/2022-03:13:17] [V] [TRT] Tactic: 6 Time: 0.188275
[05/21/2022-03:13:17] [V] [TRT] Tactic: 7 Time: 0.171881
[05/21/2022-03:13:17] [V] [TRT] Tactic: 8 Time: 0.170781
[05/21/2022-03:13:17] [V] [TRT] Tactic: 9 Time: 0.178743
[05/21/2022-03:13:17] [V] [TRT] Tactic: 28 Time: 0.582298
[05/21/2022-03:13:17] [V] [TRT] Fastest Tactic: 8 Time: 0.170781
[05/21/2022-03:13:17] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-03:13:17] [V] [TRT] Tactic: 128 Time: 1.27609
[05/21/2022-03:13:17] [V] [TRT] Tactic: 256 Time: 1.28036
[05/21/2022-03:13:17] [V] [TRT] Tactic: 512 Time: 1.28997
[05/21/2022-03:13:17] [V] [TRT] Tactic: -32 Time: 1.11009
[05/21/2022-03:13:17] [V] [TRT] Tactic: -64 Time: 1.11342
[05/21/2022-03:13:17] [V] [TRT] Tactic: -128 Time: 1.15409
[05/21/2022-03:13:17] [V] [TRT] Fastest Tactic: -32 Time: 1.11009
[05/21/2022-03:13:17] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:13:17] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:13:17] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:13:18] [V] [TRT] Tactic: 24 Time: 0.500716
[05/21/2022-03:13:19] [V] [TRT] Tactic: 25 Time: 0.461087
[05/21/2022-03:13:20] [V] [TRT] Tactic: 26 Time: 0.438327
[05/21/2022-03:13:20] [V] [TRT] Tactic: 27 Time: 0.424492
[05/21/2022-03:13:21] [V] [TRT] Tactic: 31 Time: 0.499518
[05/21/2022-03:13:21] [V] [TRT] Fastest Tactic: 27 Time: 0.424492
[05/21/2022-03:13:21] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-03:13:21] [V] [TRT] Tactic: 128 Time: 2.55154
[05/21/2022-03:13:21] [V] [TRT] Tactic: 256 Time: 2.56419
[05/21/2022-03:13:21] [V] [TRT] Tactic: 512 Time: 2.5803
[05/21/2022-03:13:21] [V] [TRT] Tactic: -32 Time: 2.01786
[05/21/2022-03:13:22] [V] [TRT] Tactic: -64 Time: 1.10389
[05/21/2022-03:13:22] [V] [TRT] Tactic: -128 Time: 1.12858
[05/21/2022-03:13:22] [V] [TRT] Fastest Tactic: -64 Time: 1.10389
[05/21/2022-03:13:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 27
[05/21/2022-03:13:22] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:13:22] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:13:22] [V] [TRT] Tactic: 0 Time: 1.20081
[05/21/2022-03:13:23] [V] [TRT] Tactic: 1 Time: 0.804557
[05/21/2022-03:13:24] [V] [TRT] Tactic: 2 Time: 0.753828
[05/21/2022-03:13:25] [V] [TRT] Tactic: 3 Time: 0.532513
[05/21/2022-03:13:26] [V] [TRT] Tactic: 4 Time: 0.509427
[05/21/2022-03:13:27] [V] [TRT] Tactic: 5 Time: 0.4839
[05/21/2022-03:13:28] [V] [TRT] Tactic: 6 Time: 0.397481
[05/21/2022-03:13:28] [V] [TRT] Tactic: 7 Time: 0.358639
[05/21/2022-03:13:29] [V] [TRT] Tactic: 8 Time: 0.368613
[05/21/2022-03:13:30] [V] [TRT] Tactic: 9 Time: 0.381263
[05/21/2022-03:13:31] [V] [TRT] Tactic: 28 Time: 1.17836
[05/21/2022-03:13:31] [V] [TRT] Fastest Tactic: 7 Time: 0.358639
[05/21/2022-03:13:31] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-03:13:31] [V] [TRT] Tactic: 128 Time: 2.03077
[05/21/2022-03:13:31] [V] [TRT] Tactic: 256 Time: 2.01913
[05/21/2022-03:13:31] [V] [TRT] Tactic: 512 Time: 1.92825
[05/21/2022-03:13:31] [V] [TRT] Tactic: -32 Time: 2.255
[05/21/2022-03:13:31] [V] [TRT] Tactic: -64 Time: 2.21499
[05/21/2022-03:13:31] [V] [TRT] Tactic: -128 Time: 1.1338
[05/21/2022-03:13:31] [V] [TRT] Fastest Tactic: -128 Time: 1.1338
[05/21/2022-03:13:31] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:13:31] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:13:31] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:13:32] [V] [TRT] Tactic: 0 Time: 0.350788
[05/21/2022-03:13:33] [V] [TRT] Tactic: 1 Time: 0.240117
[05/21/2022-03:13:34] [V] [TRT] Tactic: 2 Time: 0.499343
[05/21/2022-03:13:35] [V] [TRT] Tactic: 3 Time: 0.347259
[05/21/2022-03:13:36] [V] [TRT] Tactic: 4 Time: 0.366764
[05/21/2022-03:13:37] [V] [TRT] Tactic: 5 Time: 0.398965
[05/21/2022-03:13:37] [V] [TRT] Tactic: 6 Time: 0.296302
[05/21/2022-03:13:38] [V] [TRT] Tactic: 7 Time: 0.309408
[05/21/2022-03:13:39] [V] [TRT] Tactic: 8 Time: 0.323027
[05/21/2022-03:13:40] [V] [TRT] Tactic: 9 Time: 0.37444
[05/21/2022-03:13:41] [V] [TRT] Tactic: 10 Time: 1.25673
[05/21/2022-03:13:42] [V] [TRT] Tactic: 11 Time: 0.847148
[05/21/2022-03:13:43] [V] [TRT] Tactic: 12 Time: 0.805586
[05/21/2022-03:13:44] [V] [TRT] Tactic: 13 Time: 0.560553
[05/21/2022-03:13:44] [V] [TRT] Tactic: 14 Time: 0.519609
[05/21/2022-03:13:45] [V] [TRT] Tactic: 15 Time: 0.535
[05/21/2022-03:13:46] [V] [TRT] Tactic: 16 Time: 0.419629
[05/21/2022-03:13:47] [V] [TRT] Tactic: 17 Time: 0.355495
[05/21/2022-03:13:48] [V] [TRT] Tactic: 18 Time: 0.393795
[05/21/2022-03:13:49] [V] [TRT] Tactic: 19 Time: 0.419655
[05/21/2022-03:13:50] [V] [TRT] Tactic: 28 Time: 0.691276
[05/21/2022-03:13:51] [V] [TRT] Tactic: 29 Time: 1.24258
[05/21/2022-03:13:51] [V] [TRT] Fastest Tactic: 1 Time: 0.240117
[05/21/2022-03:13:51] [V] [TRT] --------------- Timing Runner: PWN(117_convolutional_lrelu) (PointWise)
[05/21/2022-03:13:51] [V] [TRT] Tactic: 128 Time: 2.0337
[05/21/2022-03:13:51] [V] [TRT] Tactic: 256 Time: 2.02175
[05/21/2022-03:13:51] [V] [TRT] Tactic: 512 Time: 1.92315
[05/21/2022-03:13:51] [V] [TRT] Tactic: -32 Time: 2.24295
[05/21/2022-03:13:51] [V] [TRT] Tactic: -64 Time: 2.21525
[05/21/2022-03:13:51] [V] [TRT] Tactic: -128 Time: 1.12313
[05/21/2022-03:13:51] [V] [TRT] Fastest Tactic: -128 Time: 1.12313
[05/21/2022-03:13:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 1
[05/21/2022-03:13:51] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:13:51] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:13:51] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:13:51] [V] [TRT] Tactic: 589823 Time: 3.35795
[05/21/2022-03:13:51] [V] [TRT] Tactic: 655359 Time: 1.76089
[05/21/2022-03:13:51] [V] [TRT] Tactic: 786431 Time: 2.63973
[05/21/2022-03:13:51] [V] [TRT] Tactic: 851967 Time: 1.74733
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1179647 Time: 1.81163
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1310719 Time: 3.02672
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1376255 Time: 0.932506
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1441791 Time: 1.42421
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1507327 Time: 1.25215
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1638399 Time: 1.53898
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1835007 Time: 1.16354
[05/21/2022-03:13:52] [V] [TRT] Tactic: 1900543 Time: 0.978652
[05/21/2022-03:13:52] [V] [TRT] Tactic: 2097151 Time: 1.12035
[05/21/2022-03:13:52] [V] [TRT] Tactic: 2162687 Time: 0.727871
[05/21/2022-03:13:52] [V] [TRT] Tactic: 2293759 Time: 0.810729
[05/21/2022-03:13:52] [V] [TRT] Tactic: 2359295 Time: 0.956172
[05/21/2022-03:13:53] [V] [TRT] Tactic: 2686975 Time: 0.917702
[05/21/2022-03:13:53] [V] [TRT] Tactic: 3080191 Time: 0.697435
[05/21/2022-03:13:53] [V] [TRT] Tactic: 3342335 Time: 0.864258
[05/21/2022-03:13:53] [V] [TRT] Tactic: 3407871 Time: 0.773118
[05/21/2022-03:13:53] [V] [TRT] Tactic: 3538943 Time: 0.805566
[05/21/2022-03:13:53] [V] [TRT] Tactic: 3670015 Time: 0.586042
[05/21/2022-03:13:53] [V] [TRT] Tactic: 3932159 Time: 0.876165
[05/21/2022-03:13:53] [V] [TRT] Tactic: 3997695 Time: 0.838385
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4063231 Time: 0.773483
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4194303 Time: 0.823086
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4259839 Time: 0.990215
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4325375 Time: 1.03587
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4521983 Time: 0.922897
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4587519 Time: 0.884505
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4653055 Time: 0.840716
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4915199 Time: 0.745234
[05/21/2022-03:13:53] [V] [TRT] Tactic: 4980735 Time: 0.955527
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5177343 Time: 1.01017
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5242879 Time: 0.617337
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5373951 Time: 0.980098
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5439487 Time: 0.78571
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5570559 Time: 0.565508
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5636095 Time: 0.723242
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5701631 Time: 0.745612
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5767167 Time: 1.06654
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5832703 Time: 0.6786
[05/21/2022-03:13:54] [V] [TRT] Tactic: 5898239 Time: 0.616217
[05/21/2022-03:13:54] [V] [TRT] Tactic: 6029311 Time: 0.588822
[05/21/2022-03:13:54] [V] [TRT] Tactic: 6225919 Time: 0.664876
[05/21/2022-03:13:54] [V] [TRT] Tactic: 6291455 Time: 0.847025
[05/21/2022-03:13:54] [V] [TRT] Tactic: 6422527 Time: 0.585638
[05/21/2022-03:13:54] [V] [TRT] Tactic: 6750207 Time: 0.750657
[05/21/2022-03:13:54] [V] [TRT] Tactic: 6815743 Time: 0.659544
[05/21/2022-03:13:54] [V] [TRT] Tactic: 6946815 Time: 1.0181
[05/21/2022-03:13:54] [V] [TRT] Tactic: 7012351 Time: 0.895267
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7077887 Time: 0.735957
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7143423 Time: 1.09882
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7208959 Time: 0.788131
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7340031 Time: 0.660898
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7405567 Time: 0.742545
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7536639 Time: 0.715332
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7602175 Time: 0.957871
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7733247 Time: 0.663092
[05/21/2022-03:13:55] [V] [TRT] Tactic: 7798783 Time: 0.805156
[05/21/2022-03:13:55] [V] [TRT] Tactic: 8191999 Time: 1.12602
[05/21/2022-03:13:55] [V] [TRT] Tactic: 8257535 Time: 0.763476
[05/21/2022-03:13:55] [V] [TRT] Tactic: 8323071 Time: 0.718014
[05/21/2022-03:13:55] [V] [TRT] Tactic: 8650751 Time: 1.0885
[05/21/2022-03:13:55] [V] [TRT] Tactic: 8716287 Time: 0.74278
[05/21/2022-03:13:55] [V] [TRT] Tactic: 9109503 Time: 0.952396
[05/21/2022-03:13:55] [V] [TRT] Tactic: 9568255 Time: 0.744648
[05/21/2022-03:13:55] [V] [TRT] Tactic: 9895935 Time: 0.766621
[05/21/2022-03:13:55] [V] [TRT] Tactic: 10223615 Time: 0.736973
[05/21/2022-03:13:56] [V] [TRT] Tactic: 10354687 Time: 0.961458
[05/21/2022-03:13:56] [V] [TRT] Tactic: 10551295 Time: 0.684141
[05/21/2022-03:13:56] [V] [TRT] Tactic: 10747903 Time: 0.634121
[05/21/2022-03:13:56] [V] [TRT] Tactic: 10944511 Time: 0.95582
[05/21/2022-03:13:56] [V] [TRT] Fastest Tactic: 5570559 Time: 0.565508
[05/21/2022-03:13:56] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:13:56] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:56] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-03:13:56] [V] [TRT] Tactic: 0 Time: 0.6625
[05/21/2022-03:13:56] [V] [TRT] Tactic: 1 Time: 0.551198
[05/21/2022-03:13:56] [V] [TRT] Tactic: 2 Time: 0.661882
[05/21/2022-03:13:57] [V] [TRT] Tactic: 4 Time: 30.1109
[05/21/2022-03:13:57] [V] [TRT] Tactic: 5 Time: 9.03341
[05/21/2022-03:13:57] [V] [TRT] Fastest Tactic: 1 Time: 0.551198
[05/21/2022-03:13:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-03:13:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:13:57] [V] [TRT] Tactic: 1062367460111450758 Time: 0.480918
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:13:57] [V] [TRT] Tactic: 1698681053543049347 Time: 0.437617
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:13:57] [V] [TRT] Tactic: 4501471010995462441 Time: 0.36931
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:13:57] [V] [TRT] Tactic: 5137655947464784826 Time: 0.378737
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:13:57] [V] [TRT] Tactic: 5288347012147084929 Time: 0.367298
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:13:57] [V] [TRT] Tactic: 5326823351883942011 Time: 0.358333
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:13:57] [V] [TRT] Tactic: 5500448035057547314 Time: 0.399785
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:13:57] [V] [TRT] Tactic: 6645123197870846056 Time: 0.384056
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:13:57] [V] [TRT] Tactic: 7144526460361122478 Time: 0.533301
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:13:57] [V] [TRT] Tactic: -8262349710178828730 Time: 0.372936
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:13:57] [V] [TRT] Tactic: -6576203419454146580 Time: 0.427441
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:13:57] [V] [TRT] Tactic: -4787320710726427159 Time: 0.568926
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:13:57] [V] [TRT] Tactic: -3456450830548107839 Time: 0.453548
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:13:57] [V] [TRT] Tactic: -1218658103698133241 Time: 0.416634
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:13:57] [V] [TRT] Tactic: -836875257600482091 Time: 0.406152
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:13:57] [V] [TRT] Tactic: -410470605513481746 Time: 0.36388
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:13:57] [V] [TRT] Tactic: -377491875521947884 Time: 0.362793
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:13:57] [V] [TRT] Tactic: -37215280111360163 Time: 0.361615
[05/21/2022-03:13:57] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.358333
[05/21/2022-03:13:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:13:57] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(43264,1,3328,256) ***************
[05/21/2022-03:13:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-03:13:57] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-03:13:57] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:13:57] [V] [TRT] Tactic: 3886731678879822788 Time: 0.37429
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:13:57] [V] [TRT] Tactic: 6629944304117643200 Time: 0.578503
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:13:57] [V] [TRT] Tactic: -9153228964338181824 Time: 0.586107
[05/21/2022-03:13:57] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:13:57] [V] [TRT] Tactic: -7394439838318485025 Time: 0.37403
[05/21/2022-03:13:57] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.37403
[05/21/2022-03:13:57] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:13:57] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:13:57] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-03:13:57] [V] [TRT] Tactic: 0 Time: 0.716387
[05/21/2022-03:13:57] [V] [TRT] Tactic: 1 Time: 0.570872
[05/21/2022-03:13:57] [V] [TRT] Tactic: 2 Time: 0.638867
[05/21/2022-03:13:58] [V] [TRT] Tactic: 4 Time: 29.4494
[05/21/2022-03:13:58] [V] [TRT] Tactic: 5 Time: 9.26878
[05/21/2022-03:13:58] [V] [TRT] Fastest Tactic: 1 Time: 0.570872
[05/21/2022-03:13:58] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-03:13:58] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:58] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-03:13:58] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:58] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:13:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:13:58] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-03:13:58] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:13:58] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(21632,169:2,13,1) ***************
[05/21/2022-03:13:58] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:13:58] [V] [TRT] Tactic: 589823 Time: 0.370521
[05/21/2022-03:13:58] [V] [TRT] Tactic: 655359 Time: 0.365755
[05/21/2022-03:13:58] [V] [TRT] Tactic: 786431 Time: 0.493509
[05/21/2022-03:13:58] [V] [TRT] Tactic: 851967 Time: 0.453079
[05/21/2022-03:13:58] [V] [TRT] Tactic: 1179647 Time: 0.374453
[05/21/2022-03:13:58] [V] [TRT] Tactic: 1310719 Time: 0.888958
[05/21/2022-03:13:58] [V] [TRT] Tactic: 1376255 Time: 0.290879
[05/21/2022-03:13:58] [V] [TRT] Tactic: 1441791 Time: 0.501823
[05/21/2022-03:13:58] [V] [TRT] Tactic: 1507327 Time: 0.465352
[05/21/2022-03:13:58] [V] [TRT] Tactic: 1638399 Time: 0.62082
[05/21/2022-03:13:59] [V] [TRT] Tactic: 1835007 Time: 0.513073
[05/21/2022-03:13:59] [V] [TRT] Tactic: 1900543 Time: 0.387741
[05/21/2022-03:13:59] [V] [TRT] Tactic: 2097151 Time: 0.620293
[05/21/2022-03:13:59] [V] [TRT] Tactic: 2162687 Time: 0.358848
[05/21/2022-03:13:59] [V] [TRT] Tactic: 2293759 Time: 0.352663
[05/21/2022-03:13:59] [V] [TRT] Tactic: 2359295 Time: 0.394564
[05/21/2022-03:13:59] [V] [TRT] Tactic: 2686975 Time: 0.629108
[05/21/2022-03:13:59] [V] [TRT] Tactic: 3080191 Time: 0.328229
[05/21/2022-03:13:59] [V] [TRT] Tactic: 3342335 Time: 0.413704
[05/21/2022-03:13:59] [V] [TRT] Tactic: 3407871 Time: 0.332474
[05/21/2022-03:13:59] [V] [TRT] Tactic: 3538943 Time: 0.360697
[05/21/2022-03:13:59] [V] [TRT] Tactic: 3670015 Time: 0.456569
[05/21/2022-03:13:59] [V] [TRT] Tactic: 3932159 Time: 0.377988
[05/21/2022-03:13:59] [V] [TRT] Tactic: 3997695 Time: 0.497507
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4063231 Time: 0.388158
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4194303 Time: 0.43263
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4259839 Time: 0.619427
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4325375 Time: 0.504837
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4521983 Time: 0.513463
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4587519 Time: 0.524557
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4653055 Time: 0.445944
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4915199 Time: 0.434271
[05/21/2022-03:13:59] [V] [TRT] Tactic: 4980735 Time: 0.496426
[05/21/2022-03:13:59] [V] [TRT] Tactic: 5177343 Time: 0.439284
[05/21/2022-03:13:59] [V] [TRT] Tactic: 5242879 Time: 0.296517
[05/21/2022-03:13:59] [V] [TRT] Tactic: 5373951 Time: 0.436048
[05/21/2022-03:13:59] [V] [TRT] Tactic: 5439487 Time: 0.432604
[05/21/2022-03:14:00] [V] [TRT] Tactic: 5570559 Time: 0.389349
[05/21/2022-03:14:00] [V] [TRT] Tactic: 5636095 Time: 0.389258
[05/21/2022-03:14:00] [V] [TRT] Tactic: 5701631 Time: 0.347396
[05/21/2022-03:14:00] [V] [TRT] Tactic: 5767167 Time: 0.528223
[05/21/2022-03:14:00] [V] [TRT] Tactic: 5832703 Time: 0.319512
[05/21/2022-03:14:00] [V] [TRT] Tactic: 5898239 Time: 0.373132
[05/21/2022-03:14:00] [V] [TRT] Tactic: 6029311 Time: 0.322259
[05/21/2022-03:14:00] [V] [TRT] Tactic: 6225919 Time: 0.314427
[05/21/2022-03:14:00] [V] [TRT] Tactic: 6291455 Time: 0.374232
[05/21/2022-03:14:00] [V] [TRT] Tactic: 6422527 Time: 0.306178
[05/21/2022-03:14:00] [V] [TRT] Tactic: 6750207 Time: 0.440338
[05/21/2022-03:14:00] [V] [TRT] Tactic: 6815743 Time: 0.31875
[05/21/2022-03:14:00] [V] [TRT] Tactic: 6946815 Time: 0.493145
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7012351 Time: 0.617715
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7077887 Time: 0.345645
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7143423 Time: 0.557858
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7208959 Time: 0.377116
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7340031 Time: 0.391719
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7405567 Time: 0.380885
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7536639 Time: 0.382578
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7602175 Time: 0.457311
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7733247 Time: 0.37804
[05/21/2022-03:14:00] [V] [TRT] Tactic: 7798783 Time: 0.494733
[05/21/2022-03:14:00] [V] [TRT] Tactic: 8191999 Time: 0.570788
[05/21/2022-03:14:00] [V] [TRT] Tactic: 8257535 Time: 0.443906
[05/21/2022-03:14:00] [V] [TRT] Tactic: 8323071 Time: 0.403177
[05/21/2022-03:14:00] [V] [TRT] Tactic: 8650751 Time: 0.531244
[05/21/2022-03:14:00] [V] [TRT] Tactic: 8716287 Time: 0.353366
[05/21/2022-03:14:00] [V] [TRT] Tactic: 9109503 Time: 0.623659
[05/21/2022-03:14:01] [V] [TRT] Tactic: 9568255 Time: 0.435352
[05/21/2022-03:14:01] [V] [TRT] Tactic: 9895935 Time: 0.431921
[05/21/2022-03:14:01] [V] [TRT] Tactic: 10223615 Time: 0.631914
[05/21/2022-03:14:01] [V] [TRT] Tactic: 10354687 Time: 0.618789
[05/21/2022-03:14:01] [V] [TRT] Tactic: 10551295 Time: 0.351126
[05/21/2022-03:14:01] [V] [TRT] Tactic: 10747903 Time: 0.328965
[05/21/2022-03:14:01] [V] [TRT] Tactic: 10944511 Time: 0.495788
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: 1376255 Time: 0.290879
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:01] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:01] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: 118_convolutional + 118_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:14:01] [V] [TRT] Tactic: 3066127711859985668 Time: 0.223952
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:01] [V] [TRT] Tactic: 3564772625446233998 Time: 0.252487
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:01] [V] [TRT] Tactic: 5319956359050645452 Time: 0.23332
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:01] [V] [TRT] Tactic: 7205456024582378848 Time: 0.201341
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:14:01] [V] [TRT] Tactic: 8163473458334948789 Time: 0.191517
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:01] [V] [TRT] Tactic: -4212163711445252890 Time: 0.192344
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:01] [V] [TRT] Tactic: -3898373634979201110 Time: 0.197337
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:01] [V] [TRT] Tactic: -2409163523992614473 Time: 0.198027
[05/21/2022-03:14:01] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:14:01] [V] [TRT] Tactic: -1716393687483585322 Time: 0.19071
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.19071
[05/21/2022-03:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:14:01] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:01] [V] [TRT] *************** Autotuning format combination: Float(43264,169,13,1) -> Float(43264,169,13,1) ***************
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:01] [V] [TRT] Tactic: 0 Time: 0.0413346
[05/21/2022-03:14:01] [V] [TRT] Tactic: 1 Time: 0.0314519
[05/21/2022-03:14:01] [V] [TRT] Tactic: 2 Time: 0.0272719
[05/21/2022-03:14:01] [V] [TRT] Tactic: 3 Time: 0.0283008
[05/21/2022-03:14:01] [V] [TRT] Tactic: 4 Time: 0.0226951
[05/21/2022-03:14:01] [V] [TRT] Tactic: 5 Time: 0.0212891
[05/21/2022-03:14:01] [V] [TRT] Tactic: 6 Time: 0.0279166
[05/21/2022-03:14:01] [V] [TRT] Tactic: 7 Time: 0.0230793
[05/21/2022-03:14:01] [V] [TRT] Tactic: 8 Time: 0.0219401
[05/21/2022-03:14:01] [V] [TRT] Tactic: 9 Time: 0.0218295
[05/21/2022-03:14:01] [V] [TRT] Tactic: 28 Time: 0.0407488
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: 5 Time: 0.0212891
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:01] [V] [TRT] Tactic: 128 Time: 0.0913282
[05/21/2022-03:14:01] [V] [TRT] Tactic: 256 Time: 0.0911264
[05/21/2022-03:14:01] [V] [TRT] Tactic: 512 Time: 0.0923176
[05/21/2022-03:14:01] [V] [TRT] Tactic: -32 Time: 0.108386
[05/21/2022-03:14:01] [V] [TRT] Tactic: -64 Time: 0.101094
[05/21/2022-03:14:01] [V] [TRT] Tactic: -128 Time: 0.0990755
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: 256 Time: 0.0911264
[05/21/2022-03:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:01] [V] [TRT] *************** Autotuning format combination: Float(43264,1,3328,256) -> Float(43264,1,3328,256) ***************
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:01] [V] [TRT] Tactic: 0 Time: 0.0416861
[05/21/2022-03:14:01] [V] [TRT] Tactic: 1 Time: 0.0312109
[05/21/2022-03:14:01] [V] [TRT] Tactic: 2 Time: 0.027591
[05/21/2022-03:14:01] [V] [TRT] Tactic: 3 Time: 0.0276758
[05/21/2022-03:14:01] [V] [TRT] Tactic: 4 Time: 0.022513
[05/21/2022-03:14:01] [V] [TRT] Tactic: 5 Time: 0.0216015
[05/21/2022-03:14:01] [V] [TRT] Tactic: 6 Time: 0.0283723
[05/21/2022-03:14:01] [V] [TRT] Tactic: 7 Time: 0.023125
[05/21/2022-03:14:01] [V] [TRT] Tactic: 8 Time: 0.0216406
[05/21/2022-03:14:01] [V] [TRT] Tactic: 9 Time: 0.022051
[05/21/2022-03:14:01] [V] [TRT] Tactic: 28 Time: 0.040599
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: 5 Time: 0.0216015
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:01] [V] [TRT] Tactic: 128 Time: 0.0909246
[05/21/2022-03:14:01] [V] [TRT] Tactic: 256 Time: 0.0914257
[05/21/2022-03:14:01] [V] [TRT] Tactic: 512 Time: 0.0924152
[05/21/2022-03:14:01] [V] [TRT] Tactic: -32 Time: 0.108008
[05/21/2022-03:14:01] [V] [TRT] Tactic: -64 Time: 0.101256
[05/21/2022-03:14:01] [V] [TRT] Tactic: -128 Time: 0.0990036
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: 128 Time: 0.0909246
[05/21/2022-03:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:01] [V] [TRT] *************** Autotuning format combination: Float(1352,169:32,13,1) -> Float(1352,169:32,13,1) ***************
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:01] [V] [TRT] Tactic: 24 Time: 0.0287562
[05/21/2022-03:14:01] [V] [TRT] Tactic: 25 Time: 0.0269986
[05/21/2022-03:14:01] [V] [TRT] Tactic: 26 Time: 0.0284442
[05/21/2022-03:14:01] [V] [TRT] Tactic: 27 Time: 0.0275325
[05/21/2022-03:14:01] [V] [TRT] Tactic: 31 Time: 0.0289063
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: 25 Time: 0.0269986
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:01] [V] [TRT] Tactic: 128 Time: 0.0913541
[05/21/2022-03:14:01] [V] [TRT] Tactic: 256 Time: 0.0914194
[05/21/2022-03:14:01] [V] [TRT] Tactic: 512 Time: 0.0920571
[05/21/2022-03:14:01] [V] [TRT] Tactic: -32 Time: 0.108848
[05/21/2022-03:14:01] [V] [TRT] Tactic: -64 Time: 0.101172
[05/21/2022-03:14:01] [V] [TRT] Tactic: -128 Time: 0.0992967
[05/21/2022-03:14:01] [V] [TRT] Fastest Tactic: 128 Time: 0.0913541
[05/21/2022-03:14:01] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:01] [V] [TRT] *************** Autotuning format combination: Half(43264,169,13,1) -> Half(43264,169,13,1) ***************
[05/21/2022-03:14:01] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:01] [V] [TRT] Tactic: 0 Time: 0.0404103
[05/21/2022-03:14:01] [V] [TRT] Tactic: 1 Time: 0.0288215
[05/21/2022-03:14:01] [V] [TRT] Tactic: 2 Time: 0.0278385
[05/21/2022-03:14:01] [V] [TRT] Tactic: 3 Time: 0.0218034
[05/21/2022-03:14:01] [V] [TRT] Tactic: 4 Time: 0.0195247
[05/21/2022-03:14:01] [V] [TRT] Tactic: 5 Time: 0.019935
[05/21/2022-03:14:01] [V] [TRT] Tactic: 6 Time: 0.0172721
[05/21/2022-03:14:01] [V] [TRT] Tactic: 7 Time: 0.0149675
[05/21/2022-03:14:01] [V] [TRT] Tactic: 8 Time: 0.0149477
[05/21/2022-03:14:02] [V] [TRT] Tactic: 9 Time: 0.0171875
[05/21/2022-03:14:02] [V] [TRT] Tactic: 28 Time: 0.0402017
[05/21/2022-03:14:02] [V] [TRT] Fastest Tactic: 8 Time: 0.0149477
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:02] [V] [TRT] Tactic: 128 Time: 0.082181
[05/21/2022-03:14:02] [V] [TRT] Tactic: 256 Time: 0.0820245
[05/21/2022-03:14:02] [V] [TRT] Tactic: 512 Time: 0.0799154
[05/21/2022-03:14:02] [V] [TRT] Tactic: -32 Time: 0.0960678
[05/21/2022-03:14:02] [V] [TRT] Tactic: -64 Time: 0.0962694
[05/21/2022-03:14:02] [V] [TRT] Tactic: -128 Time: 0.0976954
[05/21/2022-03:14:02] [V] [TRT] Fastest Tactic: 512 Time: 0.0799154
[05/21/2022-03:14:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:14:02] [V] [TRT] *************** Autotuning format combination: Half(21632,169:2,13,1) -> Half(21632,169:2,13,1) ***************
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:02] [V] [TRT] Tactic: 0 Time: 0.0266408
[05/21/2022-03:14:02] [V] [TRT] Tactic: 1 Time: 0.0199479
[05/21/2022-03:14:02] [V] [TRT] Tactic: 2 Time: 0.0200976
[05/21/2022-03:14:02] [V] [TRT] Tactic: 3 Time: 0.0163413
[05/21/2022-03:14:02] [V] [TRT] Tactic: 4 Time: 0.0173633
[05/21/2022-03:14:02] [V] [TRT] Tactic: 5 Time: 0.0202084
[05/21/2022-03:14:02] [V] [TRT] Tactic: 6 Time: 0.0150328
[05/21/2022-03:14:02] [V] [TRT] Tactic: 7 Time: 0.0172331
[05/21/2022-03:14:02] [V] [TRT] Tactic: 8 Time: 0.0201692
[05/21/2022-03:14:02] [V] [TRT] Tactic: 9 Time: 0.0230077
[05/21/2022-03:14:02] [V] [TRT] Tactic: 10 Time: 0.0445312
[05/21/2022-03:14:02] [V] [TRT] Tactic: 11 Time: 0.0312045
[05/21/2022-03:14:02] [V] [TRT] Tactic: 12 Time: 0.0303583
[05/21/2022-03:14:02] [V] [TRT] Tactic: 13 Time: 0.0219271
[05/21/2022-03:14:02] [V] [TRT] Tactic: 14 Time: 0.0211588
[05/21/2022-03:14:02] [V] [TRT] Tactic: 15 Time: 0.0218034
[05/21/2022-03:14:02] [V] [TRT] Tactic: 16 Time: 0.0195051
[05/21/2022-03:14:02] [V] [TRT] Tactic: 17 Time: 0.0167576
[05/21/2022-03:14:02] [V] [TRT] Tactic: 18 Time: 0.0172785
[05/21/2022-03:14:02] [V] [TRT] Tactic: 19 Time: 0.0196353
[05/21/2022-03:14:02] [V] [TRT] Tactic: 28 Time: 0.0262695
[05/21/2022-03:14:02] [V] [TRT] Tactic: 29 Time: 0.0427411
[05/21/2022-03:14:02] [V] [TRT] Fastest Tactic: 6 Time: 0.0150328
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: PWN(118_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:02] [V] [TRT] Tactic: 128 Time: 0.0822981
[05/21/2022-03:14:02] [V] [TRT] Tactic: 256 Time: 0.0817316
[05/21/2022-03:14:02] [V] [TRT] Tactic: 512 Time: 0.0799153
[05/21/2022-03:14:02] [V] [TRT] Tactic: -32 Time: 0.096341
[05/21/2022-03:14:02] [V] [TRT] Tactic: -64 Time: 0.0961393
[05/21/2022-03:14:02] [V] [TRT] Tactic: -128 Time: 0.0978642
[05/21/2022-03:14:02] [V] [TRT] Fastest Tactic: 512 Time: 0.0799153
[05/21/2022-03:14:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 6
[05/21/2022-03:14:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:02] [V] [TRT] *************** Autotuning format combination: Float(43264,169,13,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: 119_upsample (Resize)
[05/21/2022-03:14:02] [V] [TRT] Tactic: 0 Time: 0.153789
[05/21/2022-03:14:02] [V] [TRT] Fastest Tactic: 0 Time: 0.153789
[05/21/2022-03:14:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-03:14:02] [V] [TRT] *************** Autotuning format combination: Half(43264,169,13,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: 119_upsample (Resize)
[05/21/2022-03:14:02] [V] [TRT] Tactic: 0 Time: 0.159245
[05/21/2022-03:14:02] [V] [TRT] Fastest Tactic: 0 Time: 0.159245
[05/21/2022-03:14:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-03:14:02] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:02] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:02] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:14:02] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:02] [V] [TRT] Tactic: 0 Time: 2.19469
[05/21/2022-03:14:02] [V] [TRT] Tactic: 1 Time: 1.82337
[05/21/2022-03:14:02] [V] [TRT] Tactic: 2 Time: 2.01809
[05/21/2022-03:14:02] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1145831424, available: 536870912
[05/21/2022-03:14:02] [V] [TRT] Tactic: 5 Time: 9.2373
[05/21/2022-03:14:02] [V] [TRT] Fastest Tactic: 1 Time: 1.82337
[05/21/2022-03:14:02] [V] [TRT] Setting workspace to 1145831424enables more tactics for profiling
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:02] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:02] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:02] [V] [TRT] Tactic: 1062367460111450758 Time: 1.36277
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:14:02] [V] [TRT] Tactic: 1698681053543049347 Time: 1.36232
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:02] [V] [TRT] Tactic: 4501471010995462441 Time: 1.08311
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:02] [V] [TRT] Tactic: 5137655947464784826 Time: 1.09115
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:02] [V] [TRT] Tactic: 5288347012147084929 Time: 1.0843
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:14:02] [V] [TRT] Tactic: 5326823351883942011 Time: 1.05813
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:14:02] [V] [TRT] Tactic: 5500448035057547314 Time: 1.21615
[05/21/2022-03:14:02] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:03] [V] [TRT] Tactic: 6645123197870846056 Time: 1.10137
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:03] [V] [TRT] Tactic: 7144526460361122478 Time: 1.52221
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:03] [V] [TRT] Tactic: -8262349710178828730 Time: 1.1027
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:14:03] [V] [TRT] Tactic: -6576203419454146580 Time: 1.22952
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:03] [V] [TRT] Tactic: -4787320710726427159 Time: 1.59102
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:03] [V] [TRT] Tactic: -3456450830548107839 Time: 1.28994
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:03] [V] [TRT] Tactic: -1218658103698133241 Time: 1.23872
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:03] [V] [TRT] Tactic: -836875257600482091 Time: 1.20887
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:03] [V] [TRT] Tactic: -410470605513481746 Time: 1.07079
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:14:03] [V] [TRT] Tactic: -377491875521947884 Time: 1.06677
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:14:03] [V] [TRT] Tactic: -37215280111360163 Time: 1.06516
[05/21/2022-03:14:03] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 1.05813
[05/21/2022-03:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:14:03] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:14:03] [V] [TRT] Tactic: 3886731678879822788 Time: 1.09258
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:14:03] [V] [TRT] Tactic: 6629944304117643200 Time: 1.88962
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:14:03] [V] [TRT] Tactic: -9153228964338181824 Time: 1.90083
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:14:03] [V] [TRT] Tactic: -7394439838318485025 Time: 1.10881
[05/21/2022-03:14:03] [V] [TRT] Fastest Tactic: 3886731678879822788 Time: 1.09258
[05/21/2022-03:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 3886731678879822788
[05/21/2022-03:14:03] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:03] [V] [TRT] Tactic: 0 Time: 2.42202
[05/21/2022-03:14:03] [V] [TRT] Tactic: 1 Time: 1.92089
[05/21/2022-03:14:03] [V] [TRT] Tactic: 2 Time: 1.92929
[05/21/2022-03:14:03] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1145831424, available: 536870912
[05/21/2022-03:14:03] [V] [TRT] Tactic: 5 Time: 9.63917
[05/21/2022-03:14:03] [V] [TRT] Fastest Tactic: 1 Time: 1.92089
[05/21/2022-03:14:03] [V] [TRT] Setting workspace to 1145831424enables more tactics for profiling
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:14:03] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:03] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:03] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:03] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:03] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:03] [V] [TRT] --------------- Timing Runner: 121_convolutional + 121_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:14:03] [V] [TRT] Tactic: 3066127711859985668 Time: 0.65388
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:03] [V] [TRT] Tactic: 3564772625446233998 Time: 0.730827
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:03] [V] [TRT] Tactic: 5319956359050645452 Time: 0.679596
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:03] [V] [TRT] Tactic: 7205456024582378848 Time: 0.572024
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:14:03] [V] [TRT] Tactic: 8163473458334948789 Time: 0.545456
[05/21/2022-03:14:03] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:04] [V] [TRT] Tactic: -4212163711445252890 Time: 0.55276
[05/21/2022-03:14:04] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:04] [V] [TRT] Tactic: -3898373634979201110 Time: 0.565261
[05/21/2022-03:14:04] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:04] [V] [TRT] Tactic: -2409163523992614473 Time: 0.560768
[05/21/2022-03:14:04] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:14:04] [V] [TRT] Tactic: -1716393687483585322 Time: 0.544297
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.544297
[05/21/2022-03:14:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:14:04] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:04] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 0 Time: 0.203821
[05/21/2022-03:14:04] [V] [TRT] Tactic: 1 Time: 0.13543
[05/21/2022-03:14:04] [V] [TRT] Tactic: 2 Time: 0.12584
[05/21/2022-03:14:04] [V] [TRT] Tactic: 3 Time: 0.0992123
[05/21/2022-03:14:04] [V] [TRT] Tactic: 4 Time: 0.086543
[05/21/2022-03:14:04] [V] [TRT] Tactic: 5 Time: 0.0811782
[05/21/2022-03:14:04] [V] [TRT] Tactic: 6 Time: 0.0947266
[05/21/2022-03:14:04] [V] [TRT] Tactic: 7 Time: 0.0770315
[05/21/2022-03:14:04] [V] [TRT] Tactic: 8 Time: 0.0746027
[05/21/2022-03:14:04] [V] [TRT] Tactic: 9 Time: 0.0737111
[05/21/2022-03:14:04] [V] [TRT] Tactic: 28 Time: 0.199297
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: 9 Time: 0.0737111
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 128 Time: 0.431921
[05/21/2022-03:14:04] [V] [TRT] Tactic: 256 Time: 0.433509
[05/21/2022-03:14:04] [V] [TRT] Tactic: 512 Time: 0.435709
[05/21/2022-03:14:04] [V] [TRT] Tactic: -32 Time: 0.383321
[05/21/2022-03:14:04] [V] [TRT] Tactic: -64 Time: 0.369993
[05/21/2022-03:14:04] [V] [TRT] Tactic: -128 Time: 0.373502
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: -64 Time: 0.369993
[05/21/2022-03:14:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:14:04] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 0 Time: 0.204004
[05/21/2022-03:14:04] [V] [TRT] Tactic: 1 Time: 0.13513
[05/21/2022-03:14:04] [V] [TRT] Tactic: 2 Time: 0.125794
[05/21/2022-03:14:04] [V] [TRT] Tactic: 3 Time: 0.101068
[05/21/2022-03:14:04] [V] [TRT] Tactic: 4 Time: 0.0867968
[05/21/2022-03:14:04] [V] [TRT] Tactic: 5 Time: 0.0813541
[05/21/2022-03:14:04] [V] [TRT] Tactic: 6 Time: 0.0956576
[05/21/2022-03:14:04] [V] [TRT] Tactic: 7 Time: 0.0778776
[05/21/2022-03:14:04] [V] [TRT] Tactic: 8 Time: 0.0753644
[05/21/2022-03:14:04] [V] [TRT] Tactic: 9 Time: 0.0740167
[05/21/2022-03:14:04] [V] [TRT] Tactic: 28 Time: 0.199746
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: 9 Time: 0.0740167
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 128 Time: 0.431582
[05/21/2022-03:14:04] [V] [TRT] Tactic: 256 Time: 0.432539
[05/21/2022-03:14:04] [V] [TRT] Tactic: 512 Time: 0.434987
[05/21/2022-03:14:04] [V] [TRT] Tactic: -32 Time: 0.37821
[05/21/2022-03:14:04] [V] [TRT] Tactic: -64 Time: 0.389108
[05/21/2022-03:14:04] [V] [TRT] Tactic: -128 Time: 0.426309
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: -32 Time: 0.37821
[05/21/2022-03:14:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:14:04] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 24 Time: 0.0913866
[05/21/2022-03:14:04] [V] [TRT] Tactic: 25 Time: 0.0903385
[05/21/2022-03:14:04] [V] [TRT] Tactic: 26 Time: 0.0916276
[05/21/2022-03:14:04] [V] [TRT] Tactic: 27 Time: 0.0907031
[05/21/2022-03:14:04] [V] [TRT] Tactic: 31 Time: 0.091289
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: 25 Time: 0.0903385
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 128 Time: 0.432246
[05/21/2022-03:14:04] [V] [TRT] Tactic: 256 Time: 0.433053
[05/21/2022-03:14:04] [V] [TRT] Tactic: 512 Time: 0.435124
[05/21/2022-03:14:04] [V] [TRT] Tactic: -32 Time: 0.383822
[05/21/2022-03:14:04] [V] [TRT] Tactic: -64 Time: 0.369557
[05/21/2022-03:14:04] [V] [TRT] Tactic: -128 Time: 0.373561
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: -64 Time: 0.369557
[05/21/2022-03:14:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:04] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 0 Time: 0.205866
[05/21/2022-03:14:04] [V] [TRT] Tactic: 1 Time: 0.138665
[05/21/2022-03:14:04] [V] [TRT] Tactic: 2 Time: 0.130417
[05/21/2022-03:14:04] [V] [TRT] Tactic: 3 Time: 0.0955207
[05/21/2022-03:14:04] [V] [TRT] Tactic: 4 Time: 0.0879952
[05/21/2022-03:14:04] [V] [TRT] Tactic: 5 Time: 0.0843229
[05/21/2022-03:14:04] [V] [TRT] Tactic: 6 Time: 0.0839324
[05/21/2022-03:14:04] [V] [TRT] Tactic: 7 Time: 0.0631575
[05/21/2022-03:14:04] [V] [TRT] Tactic: 8 Time: 0.0641211
[05/21/2022-03:14:04] [V] [TRT] Tactic: 9 Time: 0.0649155
[05/21/2022-03:14:04] [V] [TRT] Tactic: 28 Time: 0.202793
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: 7 Time: 0.0631575
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 128 Time: 0.343581
[05/21/2022-03:14:04] [V] [TRT] Tactic: 256 Time: 0.341511
[05/21/2022-03:14:04] [V] [TRT] Tactic: 512 Time: 0.325423
[05/21/2022-03:14:04] [V] [TRT] Tactic: -32 Time: 0.367982
[05/21/2022-03:14:04] [V] [TRT] Tactic: -64 Time: 0.348171
[05/21/2022-03:14:04] [V] [TRT] Tactic: -128 Time: 0.355618
[05/21/2022-03:14:04] [V] [TRT] Fastest Tactic: 512 Time: 0.325423
[05/21/2022-03:14:04] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:14:04] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:04] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:04] [V] [TRT] Tactic: 0 Time: 0.12138
[05/21/2022-03:14:04] [V] [TRT] Tactic: 1 Time: 0.0867448
[05/21/2022-03:14:04] [V] [TRT] Tactic: 2 Time: 0.090599
[05/21/2022-03:14:04] [V] [TRT] Tactic: 3 Time: 0.0747785
[05/21/2022-03:14:04] [V] [TRT] Tactic: 4 Time: 0.0777149
[05/21/2022-03:14:04] [V] [TRT] Tactic: 5 Time: 0.0858072
[05/21/2022-03:14:04] [V] [TRT] Tactic: 6 Time: 0.0726496
[05/21/2022-03:14:04] [V] [TRT] Tactic: 7 Time: 0.0747981
[05/21/2022-03:14:04] [V] [TRT] Tactic: 8 Time: 0.0813672
[05/21/2022-03:14:04] [V] [TRT] Tactic: 9 Time: 0.0847007
[05/21/2022-03:14:04] [V] [TRT] Tactic: 10 Time: 0.216478
[05/21/2022-03:14:04] [V] [TRT] Tactic: 11 Time: 0.146823
[05/21/2022-03:14:05] [V] [TRT] Tactic: 12 Time: 0.138353
[05/21/2022-03:14:05] [V] [TRT] Tactic: 13 Time: 0.0993685
[05/21/2022-03:14:05] [V] [TRT] Tactic: 14 Time: 0.0896874
[05/21/2022-03:14:05] [V] [TRT] Tactic: 15 Time: 0.0924151
[05/21/2022-03:14:05] [V] [TRT] Tactic: 16 Time: 0.0846287
[05/21/2022-03:14:05] [V] [TRT] Tactic: 17 Time: 0.0636066
[05/21/2022-03:14:05] [V] [TRT] Tactic: 18 Time: 0.0672854
[05/21/2022-03:14:05] [V] [TRT] Tactic: 19 Time: 0.0721484
[05/21/2022-03:14:05] [V] [TRT] Tactic: 28 Time: 0.119498
[05/21/2022-03:14:05] [V] [TRT] Tactic: 29 Time: 0.213255
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 17 Time: 0.0636066
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(121_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 128 Time: 0.343425
[05/21/2022-03:14:05] [V] [TRT] Tactic: 256 Time: 0.341315
[05/21/2022-03:14:05] [V] [TRT] Tactic: 512 Time: 0.325742
[05/21/2022-03:14:05] [V] [TRT] Tactic: -32 Time: 0.368223
[05/21/2022-03:14:05] [V] [TRT] Tactic: -64 Time: 0.348242
[05/21/2022-03:14:05] [V] [TRT] Tactic: -128 Time: 0.355508
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 512 Time: 0.325742
[05/21/2022-03:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:14:05] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 0 Time: 0.152943
[05/21/2022-03:14:05] [V] [TRT] Tactic: 1 Time: 0.110631
[05/21/2022-03:14:05] [V] [TRT] Tactic: 2 Time: 0.0972525
[05/21/2022-03:14:05] [V] [TRT] Tactic: 3 Time: 0.093789
[05/21/2022-03:14:05] [V] [TRT] Tactic: 4 Time: 0.076979
[05/21/2022-03:14:05] [V] [TRT] Tactic: 5 Time: 0.0726496
[05/21/2022-03:14:05] [V] [TRT] Tactic: 6 Time: 0.0926108
[05/21/2022-03:14:05] [V] [TRT] Tactic: 7 Time: 0.0760481
[05/21/2022-03:14:05] [V] [TRT] Tactic: 8 Time: 0.073294
[05/21/2022-03:14:05] [V] [TRT] Tactic: 9 Time: 0.0733202
[05/21/2022-03:14:05] [V] [TRT] Tactic: 28 Time: 0.14901
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 5 Time: 0.0726496
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 128 Time: 0.345501
[05/21/2022-03:14:05] [V] [TRT] Tactic: 256 Time: 0.346185
[05/21/2022-03:14:05] [V] [TRT] Tactic: 512 Time: 0.349082
[05/21/2022-03:14:05] [V] [TRT] Tactic: -32 Time: 0.380924
[05/21/2022-03:14:05] [V] [TRT] Tactic: -64 Time: 0.364428
[05/21/2022-03:14:05] [V] [TRT] Tactic: -128 Time: 0.36332
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 128 Time: 0.345501
[05/21/2022-03:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 0 Time: 0.152793
[05/21/2022-03:14:05] [V] [TRT] Tactic: 1 Time: 0.111211
[05/21/2022-03:14:05] [V] [TRT] Tactic: 2 Time: 0.0975194
[05/21/2022-03:14:05] [V] [TRT] Tactic: 3 Time: 0.0943033
[05/21/2022-03:14:05] [V] [TRT] Tactic: 4 Time: 0.0771744
[05/21/2022-03:14:05] [V] [TRT] Tactic: 5 Time: 0.072285
[05/21/2022-03:14:05] [V] [TRT] Tactic: 6 Time: 0.0926695
[05/21/2022-03:14:05] [V] [TRT] Tactic: 7 Time: 0.0747723
[05/21/2022-03:14:05] [V] [TRT] Tactic: 8 Time: 0.0744597
[05/21/2022-03:14:05] [V] [TRT] Tactic: 9 Time: 0.0728711
[05/21/2022-03:14:05] [V] [TRT] Tactic: 28 Time: 0.149759
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 5 Time: 0.072285
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 128 Time: 0.346335
[05/21/2022-03:14:05] [V] [TRT] Tactic: 256 Time: 0.346426
[05/21/2022-03:14:05] [V] [TRT] Tactic: 512 Time: 0.349375
[05/21/2022-03:14:05] [V] [TRT] Tactic: -32 Time: 0.381237
[05/21/2022-03:14:05] [V] [TRT] Tactic: -64 Time: 0.36418
[05/21/2022-03:14:05] [V] [TRT] Tactic: -128 Time: 0.362982
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 128 Time: 0.346335
[05/21/2022-03:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 24 Time: 0.0961718
[05/21/2022-03:14:05] [V] [TRT] Tactic: 25 Time: 0.0919596
[05/21/2022-03:14:05] [V] [TRT] Tactic: 26 Time: 0.0920838
[05/21/2022-03:14:05] [V] [TRT] Tactic: 27 Time: 0.0919791
[05/21/2022-03:14:05] [V] [TRT] Tactic: 31 Time: 0.0958853
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 25 Time: 0.0919596
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 128 Time: 0.345963
[05/21/2022-03:14:05] [V] [TRT] Tactic: 256 Time: 0.347188
[05/21/2022-03:14:05] [V] [TRT] Tactic: 512 Time: 0.349153
[05/21/2022-03:14:05] [V] [TRT] Tactic: -32 Time: 0.380573
[05/21/2022-03:14:05] [V] [TRT] Tactic: -64 Time: 0.364531
[05/21/2022-03:14:05] [V] [TRT] Tactic: -128 Time: 0.363268
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 128 Time: 0.345963
[05/21/2022-03:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 0 Time: 0.15222
[05/21/2022-03:14:05] [V] [TRT] Tactic: 1 Time: 0.10862
[05/21/2022-03:14:05] [V] [TRT] Tactic: 2 Time: 0.103926
[05/21/2022-03:14:05] [V] [TRT] Tactic: 3 Time: 0.085866
[05/21/2022-03:14:05] [V] [TRT] Tactic: 4 Time: 0.0696615
[05/21/2022-03:14:05] [V] [TRT] Tactic: 5 Time: 0.0719469
[05/21/2022-03:14:05] [V] [TRT] Tactic: 6 Time: 0.0790106
[05/21/2022-03:14:05] [V] [TRT] Tactic: 7 Time: 0.0581772
[05/21/2022-03:14:05] [V] [TRT] Tactic: 8 Time: 0.0524479
[05/21/2022-03:14:05] [V] [TRT] Tactic: 9 Time: 0.0584764
[05/21/2022-03:14:05] [V] [TRT] Tactic: 28 Time: 0.148008
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 8 Time: 0.0524479
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 128 Time: 0.313014
[05/21/2022-03:14:05] [V] [TRT] Tactic: 256 Time: 0.311309
[05/21/2022-03:14:05] [V] [TRT] Tactic: 512 Time: 0.302696
[05/21/2022-03:14:05] [V] [TRT] Tactic: -32 Time: 0.364161
[05/21/2022-03:14:05] [V] [TRT] Tactic: -64 Time: 0.342305
[05/21/2022-03:14:05] [V] [TRT] Tactic: -128 Time: 0.343235
[05/21/2022-03:14:05] [V] [TRT] Fastest Tactic: 512 Time: 0.302696
[05/21/2022-03:14:05] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:14:05] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:05] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:05] [V] [TRT] Tactic: 0 Time: 0.0997071
[05/21/2022-03:14:05] [V] [TRT] Tactic: 1 Time: 0.0816345
[05/21/2022-03:14:05] [V] [TRT] Tactic: 2 Time: 0.0868099
[05/21/2022-03:14:05] [V] [TRT] Tactic: 3 Time: 0.0719792
[05/21/2022-03:14:05] [V] [TRT] Tactic: 4 Time: 0.0748762
[05/21/2022-03:14:05] [V] [TRT] Tactic: 5 Time: 0.0800717
[05/21/2022-03:14:05] [V] [TRT] Tactic: 6 Time: 0.0723502
[05/21/2022-03:14:05] [V] [TRT] Tactic: 7 Time: 0.0734634
[05/21/2022-03:14:06] [V] [TRT] Tactic: 8 Time: 0.0780337
[05/21/2022-03:14:06] [V] [TRT] Tactic: 9 Time: 0.0832748
[05/21/2022-03:14:06] [V] [TRT] Tactic: 10 Time: 0.165273
[05/21/2022-03:14:06] [V] [TRT] Tactic: 11 Time: 0.115977
[05/21/2022-03:14:06] [V] [TRT] Tactic: 12 Time: 0.111849
[05/21/2022-03:14:06] [V] [TRT] Tactic: 13 Time: 0.0879101
[05/21/2022-03:14:06] [V] [TRT] Tactic: 14 Time: 0.0734309
[05/21/2022-03:14:06] [V] [TRT] Tactic: 15 Time: 0.0782164
[05/21/2022-03:14:06] [V] [TRT] Tactic: 16 Time: 0.0812954
[05/21/2022-03:14:06] [V] [TRT] Tactic: 17 Time: 0.0591601
[05/21/2022-03:14:06] [V] [TRT] Tactic: 18 Time: 0.0556967
[05/21/2022-03:14:06] [V] [TRT] Tactic: 19 Time: 0.06541
[05/21/2022-03:14:06] [V] [TRT] Tactic: 28 Time: 0.0970506
[05/21/2022-03:14:06] [V] [TRT] Tactic: 29 Time: 0.160514
[05/21/2022-03:14:06] [V] [TRT] Fastest Tactic: 18 Time: 0.0556967
[05/21/2022-03:14:06] [V] [TRT] --------------- Timing Runner: PWN(123_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:06] [V] [TRT] Tactic: 128 Time: 0.312878
[05/21/2022-03:14:06] [V] [TRT] Tactic: 256 Time: 0.311335
[05/21/2022-03:14:06] [V] [TRT] Tactic: 512 Time: 0.303008
[05/21/2022-03:14:06] [V] [TRT] Tactic: -32 Time: 0.364792
[05/21/2022-03:14:06] [V] [TRT] Tactic: -64 Time: 0.3425
[05/21/2022-03:14:06] [V] [TRT] Tactic: -128 Time: 0.34362
[05/21/2022-03:14:06] [V] [TRT] Fastest Tactic: 512 Time: 0.303008
[05/21/2022-03:14:06] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:14:06] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:06] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:06] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:06] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:06] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:14:06] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:06] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:06] [V] [TRT] Tactic: 0 Time: 15.3028
[05/21/2022-03:14:06] [V] [TRT] Tactic: 1 Time: 9.86493
[05/21/2022-03:14:06] [V] [TRT] Tactic: 2 Time: 12.66
[05/21/2022-03:14:06] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1147797504, available: 536870912
[05/21/2022-03:14:06] [V] [TRT] Tactic: 5 skipped. Scratch requested: 573767680, available: 536870912
[05/21/2022-03:14:07] [V] [TRT] Tactic: 6 Time: 7.90503
[05/21/2022-03:14:07] [V] [TRT] Fastest Tactic: 6 Time: 7.90503
[05/21/2022-03:14:07] [V] [TRT] Setting workspace to 573767680enables more tactics for profiling
[05/21/2022-03:14:07] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:07] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:07] [V] [TRT] Tactic: 1062367460111450758 Time: 11.3678
[05/21/2022-03:14:07] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:14:07] [V] [TRT] Tactic: 1754984623894446479 Time: 13.5806
[05/21/2022-03:14:07] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:14:07] [V] [TRT] Tactic: 3611739942397549984 Time: 9.32773
[05/21/2022-03:14:07] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:14:07] [V] [TRT] Tactic: 3827454225649558724 Time: 9.72045
[05/21/2022-03:14:07] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:14:08] [V] [TRT] Tactic: 4337000649858996379 Time: 9.44367
[05/21/2022-03:14:08] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:08] [V] [TRT] Tactic: 4501471010995462441 Time: 9.33137
[05/21/2022-03:14:08] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:08] [V] [TRT] Tactic: 5137655947464784826 Time: 9.12729
[05/21/2022-03:14:08] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:08] [V] [TRT] Tactic: 5288347012147084929 Time: 9.15342
[05/21/2022-03:14:08] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:14:08] [V] [TRT] Tactic: 5921334924264294896 Time: 7.364
[05/21/2022-03:14:08] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:09] [V] [TRT] Tactic: 6645123197870846056 Time: 9.36407
[05/21/2022-03:14:09] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:09] [V] [TRT] Tactic: 7144526460361122478 Time: 12.0794
[05/21/2022-03:14:09] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:14:09] [V] [TRT] Tactic: 7852627285308570038 Time: 9.66034
[05/21/2022-03:14:09] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:14:09] [V] [TRT] Tactic: -9137461792520977713 Time: 9.39024
[05/21/2022-03:14:09] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:14:09] [V] [TRT] Tactic: -8776506421218919509 Time: 9.31239
[05/21/2022-03:14:09] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:10] [V] [TRT] Tactic: -8262349710178828730 Time: 9.27557
[05/21/2022-03:14:10] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:14:10] [V] [TRT] Tactic: -8133971918129952780 Time: 10.1538
[05/21/2022-03:14:10] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:14:10] [V] [TRT] Tactic: -6092040395344634144 Time: 11.8029
[05/21/2022-03:14:10] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:10] [V] [TRT] Tactic: -4787320710726427159 Time: 13.5463
[05/21/2022-03:14:10] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:10] [V] [TRT] Tactic: -3456450830548107839 Time: 10.2349
[05/21/2022-03:14:10] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:14:11] [V] [TRT] Tactic: -2318106587342035239 Time: 9.45151
[05/21/2022-03:14:11] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:14:11] [V] [TRT] Tactic: -1343271414618805657 Time: 6.68737
[05/21/2022-03:14:11] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:11] [V] [TRT] Tactic: -1218658103698133241 Time: 10.4516
[05/21/2022-03:14:11] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:11] [V] [TRT] Tactic: -836875257600482091 Time: 9.67717
[05/21/2022-03:14:11] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:11] [V] [TRT] Tactic: -410470605513481746 Time: 8.97768
[05/21/2022-03:14:11] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 6.68737
[05/21/2022-03:14:11] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:14:11] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:11] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:11] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:11] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:11] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:14:12] [V] [TRT] Tactic: -9153228964338181824 Time: 11.2605
[05/21/2022-03:14:12] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:14:12] [V] [TRT] Tactic: -7394439838318485025 Time: 8.85853
[05/21/2022-03:14:12] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 8.85853
[05/21/2022-03:14:12] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:14:12] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:12] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:12] [V] [TRT] Tactic: 0 Time: 15.3361
[05/21/2022-03:14:12] [V] [TRT] Tactic: 1 Time: 9.69598
[05/21/2022-03:14:12] [V] [TRT] Tactic: 2 Time: 12.4646
[05/21/2022-03:14:12] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1147797504, available: 536870912
[05/21/2022-03:14:12] [V] [TRT] Tactic: 5 skipped. Scratch requested: 573767680, available: 536870912
[05/21/2022-03:14:13] [V] [TRT] Tactic: 6 Time: 9.46503
[05/21/2022-03:14:13] [V] [TRT] Fastest Tactic: 6 Time: 9.46503
[05/21/2022-03:14:13] [V] [TRT] Setting workspace to 573767680enables more tactics for profiling
[05/21/2022-03:14:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:13] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:13] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-03:14:13] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:13] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:13] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:13] [V] [TRT] --------------- Timing Runner: 124_convolutional + 124_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:13] [V] [TRT] Tactic: 3564772625446233998 Time: 5.80944
[05/21/2022-03:14:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:14:13] [V] [TRT] Tactic: 3650389455493082349 Time: 5.98859
[05/21/2022-03:14:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:14:13] [V] [TRT] Tactic: 4772821744921268633 Time: 3.87107
[05/21/2022-03:14:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:13] [V] [TRT] Tactic: 5319956359050645452 Time: 5.11719
[05/21/2022-03:14:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:13] [V] [TRT] Tactic: 7205456024582378848 Time: 4.67676
[05/21/2022-03:14:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:14:13] [V] [TRT] Tactic: -6490690591794140522 Time: 4.74119
[05/21/2022-03:14:13] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:14:14] [V] [TRT] Tactic: -4686027666808657977 Time: 4.71395
[05/21/2022-03:14:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:14] [V] [TRT] Tactic: -4212163711445252890 Time: 4.51968
[05/21/2022-03:14:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:14] [V] [TRT] Tactic: -3898373634979201110 Time: 4.68879
[05/21/2022-03:14:14] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:14] [V] [TRT] Tactic: -2409163523992614473 Time: 4.54919
[05/21/2022-03:14:14] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 3.87107
[05/21/2022-03:14:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:14:14] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:14] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:14] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:14] [V] [TRT] Tactic: 0 Time: 0.298958
[05/21/2022-03:14:14] [V] [TRT] Tactic: 1 Time: 0.214303
[05/21/2022-03:14:14] [V] [TRT] Tactic: 2 Time: 0.187669
[05/21/2022-03:14:14] [V] [TRT] Tactic: 3 Time: 0.182526
[05/21/2022-03:14:14] [V] [TRT] Tactic: 4 Time: 0.148542
[05/21/2022-03:14:14] [V] [TRT] Tactic: 5 Time: 0.140866
[05/21/2022-03:14:14] [V] [TRT] Tactic: 6 Time: 0.180762
[05/21/2022-03:14:14] [V] [TRT] Tactic: 7 Time: 0.144251
[05/21/2022-03:14:14] [V] [TRT] Tactic: 8 Time: 0.144401
[05/21/2022-03:14:14] [V] [TRT] Tactic: 9 Time: 0.143496
[05/21/2022-03:14:14] [V] [TRT] Tactic: 28 Time: 0.291556
[05/21/2022-03:14:14] [V] [TRT] Fastest Tactic: 5 Time: 0.140866
[05/21/2022-03:14:14] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:14] [V] [TRT] Tactic: 128 Time: 0.684239
[05/21/2022-03:14:14] [V] [TRT] Tactic: 256 Time: 0.686367
[05/21/2022-03:14:14] [V] [TRT] Tactic: 512 Time: 0.690566
[05/21/2022-03:14:14] [V] [TRT] Tactic: -32 Time: 0.723424
[05/21/2022-03:14:14] [V] [TRT] Tactic: -64 Time: 0.709714
[05/21/2022-03:14:14] [V] [TRT] Tactic: -128 Time: 0.715644
[05/21/2022-03:14:14] [V] [TRT] Fastest Tactic: 128 Time: 0.684239
[05/21/2022-03:14:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:14] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:14] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:14] [V] [TRT] Tactic: 0 Time: 0.298274
[05/21/2022-03:14:14] [V] [TRT] Tactic: 1 Time: 0.214765
[05/21/2022-03:14:14] [V] [TRT] Tactic: 2 Time: 0.188281
[05/21/2022-03:14:14] [V] [TRT] Tactic: 3 Time: 0.181934
[05/21/2022-03:14:14] [V] [TRT] Tactic: 4 Time: 0.149284
[05/21/2022-03:14:14] [V] [TRT] Tactic: 5 Time: 0.141322
[05/21/2022-03:14:14] [V] [TRT] Tactic: 6 Time: 0.180241
[05/21/2022-03:14:14] [V] [TRT] Tactic: 7 Time: 0.145508
[05/21/2022-03:14:14] [V] [TRT] Tactic: 8 Time: 0.144518
[05/21/2022-03:14:14] [V] [TRT] Tactic: 9 Time: 0.143444
[05/21/2022-03:14:14] [V] [TRT] Tactic: 28 Time: 0.292018
[05/21/2022-03:14:14] [V] [TRT] Fastest Tactic: 5 Time: 0.141322
[05/21/2022-03:14:14] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:14] [V] [TRT] Tactic: 128 Time: 0.683841
[05/21/2022-03:14:14] [V] [TRT] Tactic: 256 Time: 0.686035
[05/21/2022-03:14:14] [V] [TRT] Tactic: 512 Time: 0.691309
[05/21/2022-03:14:14] [V] [TRT] Tactic: -32 Time: 0.723665
[05/21/2022-03:14:14] [V] [TRT] Tactic: -64 Time: 0.710247
[05/21/2022-03:14:14] [V] [TRT] Tactic: -128 Time: 0.715573
[05/21/2022-03:14:14] [V] [TRT] Fastest Tactic: 128 Time: 0.683841
[05/21/2022-03:14:14] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:14] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:14] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:14] [V] [TRT] Tactic: 24 Time: 0.188633
[05/21/2022-03:14:14] [V] [TRT] Tactic: 25 Time: 0.179902
[05/21/2022-03:14:14] [V] [TRT] Tactic: 26 Time: 0.180807
[05/21/2022-03:14:14] [V] [TRT] Tactic: 27 Time: 0.186914
[05/21/2022-03:14:14] [V] [TRT] Tactic: 31 Time: 0.189349
[05/21/2022-03:14:14] [V] [TRT] Fastest Tactic: 25 Time: 0.179902
[05/21/2022-03:14:14] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:14] [V] [TRT] Tactic: 128 Time: 0.684297
[05/21/2022-03:14:15] [V] [TRT] Tactic: 256 Time: 0.686243
[05/21/2022-03:14:15] [V] [TRT] Tactic: 512 Time: 0.691296
[05/21/2022-03:14:15] [V] [TRT] Tactic: -32 Time: 0.723815
[05/21/2022-03:14:15] [V] [TRT] Tactic: -64 Time: 0.710234
[05/21/2022-03:14:15] [V] [TRT] Tactic: -128 Time: 0.715137
[05/21/2022-03:14:15] [V] [TRT] Fastest Tactic: 128 Time: 0.684297
[05/21/2022-03:14:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:15] [V] [TRT] Tactic: 0 Time: 0.296738
[05/21/2022-03:14:15] [V] [TRT] Tactic: 1 Time: 0.21054
[05/21/2022-03:14:15] [V] [TRT] Tactic: 2 Time: 0.20207
[05/21/2022-03:14:15] [V] [TRT] Tactic: 3 Time: 0.164818
[05/21/2022-03:14:15] [V] [TRT] Tactic: 4 Time: 0.13265
[05/21/2022-03:14:15] [V] [TRT] Tactic: 5 Time: 0.138268
[05/21/2022-03:14:15] [V] [TRT] Tactic: 6 Time: 0.150755
[05/21/2022-03:14:15] [V] [TRT] Tactic: 7 Time: 0.10972
[05/21/2022-03:14:15] [V] [TRT] Tactic: 8 Time: 0.0992774
[05/21/2022-03:14:15] [V] [TRT] Tactic: 9 Time: 0.110814
[05/21/2022-03:14:15] [V] [TRT] Tactic: 28 Time: 0.288301
[05/21/2022-03:14:15] [V] [TRT] Fastest Tactic: 8 Time: 0.0992774
[05/21/2022-03:14:15] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:15] [V] [TRT] Tactic: 128 Time: 0.617376
[05/21/2022-03:14:15] [V] [TRT] Tactic: 256 Time: 0.614948
[05/21/2022-03:14:15] [V] [TRT] Tactic: 512 Time: 0.596224
[05/21/2022-03:14:15] [V] [TRT] Tactic: -32 Time: 0.689902
[05/21/2022-03:14:15] [V] [TRT] Tactic: -64 Time: 0.668516
[05/21/2022-03:14:15] [V] [TRT] Tactic: -128 Time: 0.674994
[05/21/2022-03:14:15] [V] [TRT] Fastest Tactic: 512 Time: 0.596224
[05/21/2022-03:14:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:15] [V] [TRT] Tactic: 0 Time: 0.192656
[05/21/2022-03:14:15] [V] [TRT] Tactic: 1 Time: 0.155462
[05/21/2022-03:14:15] [V] [TRT] Tactic: 2 Time: 0.168203
[05/21/2022-03:14:15] [V] [TRT] Tactic: 3 Time: 0.138652
[05/21/2022-03:14:15] [V] [TRT] Tactic: 4 Time: 0.142728
[05/21/2022-03:14:15] [V] [TRT] Tactic: 5 Time: 0.155006
[05/21/2022-03:14:15] [V] [TRT] Tactic: 6 Time: 0.138073
[05/21/2022-03:14:15] [V] [TRT] Tactic: 7 Time: 0.137044
[05/21/2022-03:14:15] [V] [TRT] Tactic: 8 Time: 0.14571
[05/21/2022-03:14:15] [V] [TRT] Tactic: 9 Time: 0.157227
[05/21/2022-03:14:15] [V] [TRT] Tactic: 10 Time: 0.322246
[05/21/2022-03:14:15] [V] [TRT] Tactic: 11 Time: 0.224271
[05/21/2022-03:14:15] [V] [TRT] Tactic: 12 Time: 0.216211
[05/21/2022-03:14:15] [V] [TRT] Tactic: 13 Time: 0.168366
[05/21/2022-03:14:15] [V] [TRT] Tactic: 14 Time: 0.140358
[05/21/2022-03:14:15] [V] [TRT] Tactic: 15 Time: 0.149453
[05/21/2022-03:14:15] [V] [TRT] Tactic: 16 Time: 0.153632
[05/21/2022-03:14:15] [V] [TRT] Tactic: 17 Time: 0.111321
[05/21/2022-03:14:15] [V] [TRT] Tactic: 18 Time: 0.105788
[05/21/2022-03:14:15] [V] [TRT] Tactic: 19 Time: 0.124694
[05/21/2022-03:14:15] [V] [TRT] Tactic: 28 Time: 0.188503
[05/21/2022-03:14:15] [V] [TRT] Tactic: 29 Time: 0.312461
[05/21/2022-03:14:15] [V] [TRT] Fastest Tactic: 18 Time: 0.105788
[05/21/2022-03:14:15] [V] [TRT] --------------- Timing Runner: PWN(124_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:15] [V] [TRT] Tactic: 128 Time: 0.617481
[05/21/2022-03:14:15] [V] [TRT] Tactic: 256 Time: 0.615163
[05/21/2022-03:14:15] [V] [TRT] Tactic: 512 Time: 0.597148
[05/21/2022-03:14:15] [V] [TRT] Tactic: -32 Time: 0.688327
[05/21/2022-03:14:15] [V] [TRT] Tactic: -64 Time: 0.668268
[05/21/2022-03:14:15] [V] [TRT] Tactic: -128 Time: 0.675625
[05/21/2022-03:14:15] [V] [TRT] Fastest Tactic: 512 Time: 0.597148
[05/21/2022-03:14:15] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:14:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:15] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:14:15] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:15] [V] [TRT] Tactic: 589823 Time: 0.716882
[05/21/2022-03:14:15] [V] [TRT] Tactic: 655359 Time: 0.531094
[05/21/2022-03:14:15] [V] [TRT] Tactic: 786431 Time: 0.882175
[05/21/2022-03:14:16] [V] [TRT] Tactic: 851967 Time: 0.835983
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1179647 Time: 0.819499
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1310719 Time: 1.55007
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1376255 Time: 0.577852
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1441791 Time: 0.827324
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1507327 Time: 0.683346
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1638399 Time: 0.877506
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1835007 Time: 0.831875
[05/21/2022-03:14:16] [V] [TRT] Tactic: 1900543 Time: 0.73237
[05/21/2022-03:14:16] [V] [TRT] Tactic: 2097151 Time: 0.942201
[05/21/2022-03:14:16] [V] [TRT] Tactic: 2162687 Time: 0.642507
[05/21/2022-03:14:16] [V] [TRT] Tactic: 2293759 Time: 0.518372
[05/21/2022-03:14:16] [V] [TRT] Tactic: 2359295 Time: 0.605247
[05/21/2022-03:14:16] [V] [TRT] Tactic: 2686975 Time: 0.551146
[05/21/2022-03:14:16] [V] [TRT] Tactic: 3080191 Time: 0.64056
[05/21/2022-03:14:16] [V] [TRT] Tactic: 3342335 Time: 0.769857
[05/21/2022-03:14:16] [V] [TRT] Tactic: 3407871 Time: 0.532083
[05/21/2022-03:14:16] [V] [TRT] Tactic: 3538943 Time: 0.548177
[05/21/2022-03:14:16] [V] [TRT] Tactic: 3670015 Time: 0.522025
[05/21/2022-03:14:17] [V] [TRT] Tactic: 3932159 Time: 0.641328
[05/21/2022-03:14:17] [V] [TRT] Tactic: 3997695 Time: 0.943281
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4063231 Time: 0.72821
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4194303 Time: 0.767832
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4259839 Time: 0.970273
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4325375 Time: 0.763229
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4521983 Time: 0.722181
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4587519 Time: 0.72345
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4653055 Time: 0.685703
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4915199 Time: 0.787246
[05/21/2022-03:14:17] [V] [TRT] Tactic: 4980735 Time: 0.780111
[05/21/2022-03:14:17] [V] [TRT] Tactic: 5177343 Time: 0.949134
[05/21/2022-03:14:17] [V] [TRT] Tactic: 5242879 Time: 0.613919
[05/21/2022-03:14:17] [V] [TRT] Tactic: 5373951 Time: 1.10962
[05/21/2022-03:14:17] [V] [TRT] Tactic: 5439487 Time: 1.07047
[05/21/2022-03:14:17] [V] [TRT] Tactic: 5570559 Time: 0.574531
[05/21/2022-03:14:17] [V] [TRT] Tactic: 5636095 Time: 0.727454
[05/21/2022-03:14:18] [V] [TRT] Tactic: 5701631 Time: 0.674792
[05/21/2022-03:14:18] [V] [TRT] Tactic: 5767167 Time: 1.96043
[05/21/2022-03:14:18] [V] [TRT] Tactic: 5832703 Time: 0.649316
[05/21/2022-03:14:18] [V] [TRT] Tactic: 5898239 Time: 0.64319
[05/21/2022-03:14:18] [V] [TRT] Tactic: 6029311 Time: 0.595326
[05/21/2022-03:14:18] [V] [TRT] Tactic: 6225919 Time: 0.653789
[05/21/2022-03:14:18] [V] [TRT] Tactic: 6291455 Time: 0.818203
[05/21/2022-03:14:18] [V] [TRT] Tactic: 6422527 Time: 0.620638
[05/21/2022-03:14:18] [V] [TRT] Tactic: 6750207 Time: 0.79082
[05/21/2022-03:14:18] [V] [TRT] Tactic: 6815743 Time: 0.746745
[05/21/2022-03:14:18] [V] [TRT] Tactic: 6946815 Time: 1.1929
[05/21/2022-03:14:18] [V] [TRT] Tactic: 7012351 Time: 0.941719
[05/21/2022-03:14:18] [V] [TRT] Tactic: 7077887 Time: 0.678913
[05/21/2022-03:14:18] [V] [TRT] Tactic: 7143423 Time: 1.18464
[05/21/2022-03:14:18] [V] [TRT] Tactic: 7208959 Time: 0.700618
[05/21/2022-03:14:18] [V] [TRT] Tactic: 7340031 Time: 0.714785
[05/21/2022-03:14:18] [V] [TRT] Tactic: 7405567 Time: 0.75804
[05/21/2022-03:14:19] [V] [TRT] Tactic: 7536639 Time: 0.724948
[05/21/2022-03:14:19] [V] [TRT] Tactic: 7602175 Time: 0.953079
[05/21/2022-03:14:19] [V] [TRT] Tactic: 7733247 Time: 0.705286
[05/21/2022-03:14:19] [V] [TRT] Tactic: 7798783 Time: 0.878913
[05/21/2022-03:14:19] [V] [TRT] Tactic: 8191999 Time: 1.17778
[05/21/2022-03:14:19] [V] [TRT] Tactic: 8257535 Time: 0.836055
[05/21/2022-03:14:19] [V] [TRT] Tactic: 8323071 Time: 0.767748
[05/21/2022-03:14:19] [V] [TRT] Tactic: 8650751 Time: 0.987181
[05/21/2022-03:14:19] [V] [TRT] Tactic: 8716287 Time: 0.858502
[05/21/2022-03:14:19] [V] [TRT] Tactic: 9109503 Time: 1.05695
[05/21/2022-03:14:19] [V] [TRT] Tactic: 9568255 Time: 0.781862
[05/21/2022-03:14:19] [V] [TRT] Tactic: 9895935 Time: 0.770163
[05/21/2022-03:14:19] [V] [TRT] Tactic: 10223615 Time: 0.553236
[05/21/2022-03:14:19] [V] [TRT] Tactic: 10354687 Time: 0.908366
[05/21/2022-03:14:19] [V] [TRT] Tactic: 10551295 Time: 0.720788
[05/21/2022-03:14:19] [V] [TRT] Tactic: 10747903 Time: 0.643294
[05/21/2022-03:14:19] [V] [TRT] Tactic: 10944511 Time: 0.779362
[05/21/2022-03:14:19] [V] [TRT] Fastest Tactic: 2293759 Time: 0.518372
[05/21/2022-03:14:19] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:14:19] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:19] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:19] [V] [TRT] Tactic: 0 Time: 0.613607
[05/21/2022-03:14:19] [V] [TRT] Tactic: 1 Time: 0.549935
[05/21/2022-03:14:20] [V] [TRT] Tactic: 2 Time: 0.669017
[05/21/2022-03:14:20] [V] [TRT] Tactic: 4 Time: 42.4826
[05/21/2022-03:14:20] [V] [TRT] Tactic: 5 Time: 2.94373
[05/21/2022-03:14:20] [V] [TRT] Fastest Tactic: 1 Time: 0.549935
[05/21/2022-03:14:20] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:20] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:20] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:20] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:20] [V] [TRT] Tactic: 1062367460111450758 Time: 0.412279
[05/21/2022-03:14:20] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:14:21] [V] [TRT] Tactic: 1698681053543049347 Time: 0.389492
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:21] [V] [TRT] Tactic: 4501471010995462441 Time: 0.299687
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:21] [V] [TRT] Tactic: 5137655947464784826 Time: 0.3011
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:21] [V] [TRT] Tactic: 5288347012147084929 Time: 0.304453
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:14:21] [V] [TRT] Tactic: 5326823351883942011 Time: 0.290124
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:14:21] [V] [TRT] Tactic: 5500448035057547314 Time: 0.338893
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:21] [V] [TRT] Tactic: 6645123197870846056 Time: 0.30916
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:21] [V] [TRT] Tactic: 7144526460361122478 Time: 0.41375
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:21] [V] [TRT] Tactic: -8262349710178828730 Time: 0.307695
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:14:21] [V] [TRT] Tactic: -6576203419454146580 Time: 0.355951
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:21] [V] [TRT] Tactic: -4787320710726427159 Time: 0.432129
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:21] [V] [TRT] Tactic: -3456450830548107839 Time: 0.371797
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:21] [V] [TRT] Tactic: -1218658103698133241 Time: 0.350645
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:21] [V] [TRT] Tactic: -836875257600482091 Time: 0.337494
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:21] [V] [TRT] Tactic: -410470605513481746 Time: 0.294818
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:14:21] [V] [TRT] Tactic: -377491875521947884 Time: 0.298945
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:14:21] [V] [TRT] Tactic: -37215280111360163 Time: 0.294024
[05/21/2022-03:14:21] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.290124
[05/21/2022-03:14:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:14:21] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(86528,1,3328,128) ***************
[05/21/2022-03:14:21] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:21] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:21] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:21] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:21] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:14:21] [V] [TRT] Tactic: 3886731678879822788 Time: 0.315749
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:14:21] [V] [TRT] Tactic: 6629944304117643200 Time: 0.553724
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:14:21] [V] [TRT] Tactic: -9153228964338181824 Time: 0.55485
[05/21/2022-03:14:21] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:14:21] [V] [TRT] Tactic: -7394439838318485025 Time: 0.310833
[05/21/2022-03:14:21] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 0.310833
[05/21/2022-03:14:21] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:14:21] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:14:21] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:21] [V] [TRT] Tactic: 0 Time: 0.611777
[05/21/2022-03:14:21] [V] [TRT] Tactic: 1 Time: 0.534668
[05/21/2022-03:14:21] [V] [TRT] Tactic: 2 Time: 0.628249
[05/21/2022-03:14:22] [V] [TRT] Tactic: 4 Time: 39.9819
[05/21/2022-03:14:22] [V] [TRT] Tactic: 5 Time: 2.68436
[05/21/2022-03:14:22] [V] [TRT] Fastest Tactic: 1 Time: 0.534668
[05/21/2022-03:14:22] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:22] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:22] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:22] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:14:22] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:14:22] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:22] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:22] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(43264,676:2,26,1) ***************
[05/21/2022-03:14:22] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:22] [V] [TRT] Tactic: 589823 Time: 0.356576
[05/21/2022-03:14:22] [V] [TRT] Tactic: 655359 Time: 0.34918
[05/21/2022-03:14:22] [V] [TRT] Tactic: 786431 Time: 0.532051
[05/21/2022-03:14:22] [V] [TRT] Tactic: 851967 Time: 0.389688
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1179647 Time: 0.359394
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1310719 Time: 0.769922
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1376255 Time: 0.29209
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1441791 Time: 0.400938
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1507327 Time: 0.356055
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1638399 Time: 0.451126
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1835007 Time: 0.480697
[05/21/2022-03:14:22] [V] [TRT] Tactic: 1900543 Time: 0.376374
[05/21/2022-03:14:22] [V] [TRT] Tactic: 2097151 Time: 0.570859
[05/21/2022-03:14:22] [V] [TRT] Tactic: 2162687 Time: 0.342923
[05/21/2022-03:14:22] [V] [TRT] Tactic: 2293759 Time: 0.269583
[05/21/2022-03:14:22] [V] [TRT] Tactic: 2359295 Time: 0.306556
[05/21/2022-03:14:22] [V] [TRT] Tactic: 2686975 Time: 0.475215
[05/21/2022-03:14:23] [V] [TRT] Tactic: 3080191 Time: 0.325606
[05/21/2022-03:14:23] [V] [TRT] Tactic: 3342335 Time: 0.385378
[05/21/2022-03:14:23] [V] [TRT] Tactic: 3407871 Time: 0.265202
[05/21/2022-03:14:23] [V] [TRT] Tactic: 3538943 Time: 0.272773
[05/21/2022-03:14:23] [V] [TRT] Tactic: 3670015 Time: 0.378952
[05/21/2022-03:14:23] [V] [TRT] Tactic: 3932159 Time: 0.28207
[05/21/2022-03:14:23] [V] [TRT] Tactic: 3997695 Time: 0.561335
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4063231 Time: 0.353255
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4194303 Time: 0.426426
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4259839 Time: 0.567754
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4325375 Time: 0.382767
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4521983 Time: 0.372617
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4587519 Time: 0.421296
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4653055 Time: 0.349805
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4915199 Time: 0.440723
[05/21/2022-03:14:23] [V] [TRT] Tactic: 4980735 Time: 0.384232
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5177343 Time: 0.357539
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5242879 Time: 0.296595
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5373951 Time: 0.52931
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5439487 Time: 0.567454
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5570559 Time: 0.362103
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5636095 Time: 0.352331
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5701631 Time: 0.304173
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5767167 Time: 0.920736
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5832703 Time: 0.31431
[05/21/2022-03:14:23] [V] [TRT] Tactic: 5898239 Time: 0.369284
[05/21/2022-03:14:23] [V] [TRT] Tactic: 6029311 Time: 0.30543
[05/21/2022-03:14:23] [V] [TRT] Tactic: 6225919 Time: 0.293399
[05/21/2022-03:14:23] [V] [TRT] Tactic: 6291455 Time: 0.359232
[05/21/2022-03:14:23] [V] [TRT] Tactic: 6422527 Time: 0.303607
[05/21/2022-03:14:24] [V] [TRT] Tactic: 6750207 Time: 0.424271
[05/21/2022-03:14:24] [V] [TRT] Tactic: 6815743 Time: 0.371094
[05/21/2022-03:14:24] [V] [TRT] Tactic: 6946815 Time: 0.594928
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7012351 Time: 0.570163
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7077887 Time: 0.321686
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7143423 Time: 0.598437
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7208959 Time: 0.323802
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7340031 Time: 0.38791
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7405567 Time: 0.346139
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7536639 Time: 0.38414
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7602175 Time: 0.444889
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7733247 Time: 0.34903
[05/21/2022-03:14:24] [V] [TRT] Tactic: 7798783 Time: 0.532194
[05/21/2022-03:14:24] [V] [TRT] Tactic: 8191999 Time: 0.599231
[05/21/2022-03:14:24] [V] [TRT] Tactic: 8257535 Time: 0.443913
[05/21/2022-03:14:24] [V] [TRT] Tactic: 8323071 Time: 0.418965
[05/21/2022-03:14:24] [V] [TRT] Tactic: 8650751 Time: 0.457057
[05/21/2022-03:14:24] [V] [TRT] Tactic: 8716287 Time: 0.405912
[05/21/2022-03:14:24] [V] [TRT] Tactic: 9109503 Time: 0.576647
[05/21/2022-03:14:24] [V] [TRT] Tactic: 9568255 Time: 0.440989
[05/21/2022-03:14:24] [V] [TRT] Tactic: 9895935 Time: 0.426908
[05/21/2022-03:14:24] [V] [TRT] Tactic: 10223615 Time: 0.478411
[05/21/2022-03:14:24] [V] [TRT] Tactic: 10354687 Time: 0.552461
[05/21/2022-03:14:24] [V] [TRT] Tactic: 10551295 Time: 0.352265
[05/21/2022-03:14:24] [V] [TRT] Tactic: 10747903 Time: 0.321862
[05/21/2022-03:14:24] [V] [TRT] Tactic: 10944511 Time: 0.383457
[05/21/2022-03:14:24] [V] [TRT] Fastest Tactic: 3407871 Time: 0.265202
[05/21/2022-03:14:24] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:24] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:24] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:24] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:24] [V] [TRT] --------------- Timing Runner: 128_convolutional + 128_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:24] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:14:24] [V] [TRT] Tactic: 3066127711859985668 Time: 0.189036
[05/21/2022-03:14:24] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:24] [V] [TRT] Tactic: 3564772625446233998 Time: 0.208372
[05/21/2022-03:14:24] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:24] [V] [TRT] Tactic: 5319956359050645452 Time: 0.199609
[05/21/2022-03:14:24] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:25] [V] [TRT] Tactic: 7205456024582378848 Time: 0.166328
[05/21/2022-03:14:25] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:14:25] [V] [TRT] Tactic: 8163473458334948789 Time: 0.160365
[05/21/2022-03:14:25] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:25] [V] [TRT] Tactic: -4212163711445252890 Time: 0.156231
[05/21/2022-03:14:25] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:25] [V] [TRT] Tactic: -3898373634979201110 Time: 0.159895
[05/21/2022-03:14:25] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:25] [V] [TRT] Tactic: -2409163523992614473 Time: 0.161413
[05/21/2022-03:14:25] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:14:25] [V] [TRT] Tactic: -1716393687483585322 Time: 0.15446
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.15446
[05/21/2022-03:14:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:14:25] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:25] [V] [TRT] *************** Autotuning format combination: Float(86528,676,26,1) -> Float(86528,676,26,1) ***************
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 0 Time: 0.0796486
[05/21/2022-03:14:25] [V] [TRT] Tactic: 1 Time: 0.0585484
[05/21/2022-03:14:25] [V] [TRT] Tactic: 2 Time: 0.0505924
[05/21/2022-03:14:25] [V] [TRT] Tactic: 3 Time: 0.0497396
[05/21/2022-03:14:25] [V] [TRT] Tactic: 4 Time: 0.041452
[05/21/2022-03:14:25] [V] [TRT] Tactic: 5 Time: 0.038568
[05/21/2022-03:14:25] [V] [TRT] Tactic: 6 Time: 0.0504949
[05/21/2022-03:14:25] [V] [TRT] Tactic: 7 Time: 0.0404885
[05/21/2022-03:14:25] [V] [TRT] Tactic: 8 Time: 0.0398045
[05/21/2022-03:14:25] [V] [TRT] Tactic: 9 Time: 0.0395119
[05/21/2022-03:14:25] [V] [TRT] Tactic: 28 Time: 0.0778583
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 5 Time: 0.038568
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 128 Time: 0.176283
[05/21/2022-03:14:25] [V] [TRT] Tactic: 256 Time: 0.176524
[05/21/2022-03:14:25] [V] [TRT] Tactic: 512 Time: 0.178561
[05/21/2022-03:14:25] [V] [TRT] Tactic: -32 Time: 0.204069
[05/21/2022-03:14:25] [V] [TRT] Tactic: -64 Time: 0.188112
[05/21/2022-03:14:25] [V] [TRT] Tactic: -128 Time: 0.188548
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 128 Time: 0.176283
[05/21/2022-03:14:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:25] [V] [TRT] *************** Autotuning format combination: Float(86528,1,3328,128) -> Float(86528,1,3328,128) ***************
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 0 Time: 0.079056
[05/21/2022-03:14:25] [V] [TRT] Tactic: 1 Time: 0.0582161
[05/21/2022-03:14:25] [V] [TRT] Tactic: 2 Time: 0.0511065
[05/21/2022-03:14:25] [V] [TRT] Tactic: 3 Time: 0.0501432
[05/21/2022-03:14:25] [V] [TRT] Tactic: 4 Time: 0.0413866
[05/21/2022-03:14:25] [V] [TRT] Tactic: 5 Time: 0.0386134
[05/21/2022-03:14:25] [V] [TRT] Tactic: 6 Time: 0.050332
[05/21/2022-03:14:25] [V] [TRT] Tactic: 7 Time: 0.0407748
[05/21/2022-03:14:25] [V] [TRT] Tactic: 8 Time: 0.0398113
[05/21/2022-03:14:25] [V] [TRT] Tactic: 9 Time: 0.0392643
[05/21/2022-03:14:25] [V] [TRT] Tactic: 28 Time: 0.0775196
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 5 Time: 0.0386134
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 128 Time: 0.176719
[05/21/2022-03:14:25] [V] [TRT] Tactic: 256 Time: 0.177266
[05/21/2022-03:14:25] [V] [TRT] Tactic: 512 Time: 0.178561
[05/21/2022-03:14:25] [V] [TRT] Tactic: -32 Time: 0.203535
[05/21/2022-03:14:25] [V] [TRT] Tactic: -64 Time: 0.188132
[05/21/2022-03:14:25] [V] [TRT] Tactic: -128 Time: 0.188711
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 128 Time: 0.176719
[05/21/2022-03:14:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:25] [V] [TRT] *************** Autotuning format combination: Float(2704,676:32,26,1) -> Float(2704,676:32,26,1) ***************
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 24 Time: 0.0511655
[05/21/2022-03:14:25] [V] [TRT] Tactic: 25 Time: 0.0485612
[05/21/2022-03:14:25] [V] [TRT] Tactic: 26 Time: 0.0491081
[05/21/2022-03:14:25] [V] [TRT] Tactic: 27 Time: 0.0505535
[05/21/2022-03:14:25] [V] [TRT] Tactic: 31 Time: 0.0516993
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 25 Time: 0.0485612
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 128 Time: 0.176289
[05/21/2022-03:14:25] [V] [TRT] Tactic: 256 Time: 0.176881
[05/21/2022-03:14:25] [V] [TRT] Tactic: 512 Time: 0.177982
[05/21/2022-03:14:25] [V] [TRT] Tactic: -32 Time: 0.204597
[05/21/2022-03:14:25] [V] [TRT] Tactic: -64 Time: 0.187585
[05/21/2022-03:14:25] [V] [TRT] Tactic: -128 Time: 0.188548
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 128 Time: 0.176289
[05/21/2022-03:14:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:25] [V] [TRT] *************** Autotuning format combination: Half(86528,676,26,1) -> Half(86528,676,26,1) ***************
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 0 Time: 0.0790755
[05/21/2022-03:14:25] [V] [TRT] Tactic: 1 Time: 0.0572069
[05/21/2022-03:14:25] [V] [TRT] Tactic: 2 Time: 0.0544205
[05/21/2022-03:14:25] [V] [TRT] Tactic: 3 Time: 0.0451369
[05/21/2022-03:14:25] [V] [TRT] Tactic: 4 Time: 0.0367446
[05/21/2022-03:14:25] [V] [TRT] Tactic: 5 Time: 0.0375523
[05/21/2022-03:14:25] [V] [TRT] Tactic: 6 Time: 0.0430664
[05/21/2022-03:14:25] [V] [TRT] Tactic: 7 Time: 0.0315366
[05/21/2022-03:14:25] [V] [TRT] Tactic: 8 Time: 0.0283334
[05/21/2022-03:14:25] [V] [TRT] Tactic: 9 Time: 0.0311263
[05/21/2022-03:14:25] [V] [TRT] Tactic: 28 Time: 0.076953
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 8 Time: 0.0283334
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 128 Time: 0.159987
[05/21/2022-03:14:25] [V] [TRT] Tactic: 256 Time: 0.159369
[05/21/2022-03:14:25] [V] [TRT] Tactic: 512 Time: 0.156484
[05/21/2022-03:14:25] [V] [TRT] Tactic: -32 Time: 0.195612
[05/21/2022-03:14:25] [V] [TRT] Tactic: -64 Time: 0.188125
[05/21/2022-03:14:25] [V] [TRT] Tactic: -128 Time: 0.191074
[05/21/2022-03:14:25] [V] [TRT] Fastest Tactic: 512 Time: 0.156484
[05/21/2022-03:14:25] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:14:25] [V] [TRT] *************** Autotuning format combination: Half(43264,676:2,26,1) -> Half(43264,676:2,26,1) ***************
[05/21/2022-03:14:25] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:25] [V] [TRT] Tactic: 0 Time: 0.0519012
[05/21/2022-03:14:25] [V] [TRT] Tactic: 1 Time: 0.0430926
[05/21/2022-03:14:25] [V] [TRT] Tactic: 2 Time: 0.045202
[05/21/2022-03:14:25] [V] [TRT] Tactic: 3 Time: 0.0396286
[05/21/2022-03:14:25] [V] [TRT] Tactic: 4 Time: 0.0408009
[05/21/2022-03:14:25] [V] [TRT] Tactic: 5 Time: 0.0438736
[05/21/2022-03:14:25] [V] [TRT] Tactic: 6 Time: 0.038939
[05/21/2022-03:14:25] [V] [TRT] Tactic: 7 Time: 0.0390559
[05/21/2022-03:14:25] [V] [TRT] Tactic: 8 Time: 0.0409894
[05/21/2022-03:14:25] [V] [TRT] Tactic: 9 Time: 0.043672
[05/21/2022-03:14:25] [V] [TRT] Tactic: 10 Time: 0.0854492
[05/21/2022-03:14:25] [V] [TRT] Tactic: 11 Time: 0.0604559
[05/21/2022-03:14:25] [V] [TRT] Tactic: 12 Time: 0.0581969
[05/21/2022-03:14:25] [V] [TRT] Tactic: 13 Time: 0.046595
[05/21/2022-03:14:25] [V] [TRT] Tactic: 14 Time: 0.0393035
[05/21/2022-03:14:25] [V] [TRT] Tactic: 15 Time: 0.0416667
[05/21/2022-03:14:25] [V] [TRT] Tactic: 16 Time: 0.0436589
[05/21/2022-03:14:25] [V] [TRT] Tactic: 17 Time: 0.0324414
[05/21/2022-03:14:25] [V] [TRT] Tactic: 18 Time: 0.030306
[05/21/2022-03:14:25] [V] [TRT] Tactic: 19 Time: 0.0348958
[05/21/2022-03:14:25] [V] [TRT] Tactic: 28 Time: 0.0509959
[05/21/2022-03:14:26] [V] [TRT] Tactic: 29 Time: 0.0832356
[05/21/2022-03:14:26] [V] [TRT] Fastest Tactic: 18 Time: 0.030306
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: PWN(128_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:26] [V] [TRT] Tactic: 128 Time: 0.16026
[05/21/2022-03:14:26] [V] [TRT] Tactic: 256 Time: 0.159304
[05/21/2022-03:14:26] [V] [TRT] Tactic: 512 Time: 0.155788
[05/21/2022-03:14:26] [V] [TRT] Tactic: -32 Time: 0.195749
[05/21/2022-03:14:26] [V] [TRT] Tactic: -64 Time: 0.187402
[05/21/2022-03:14:26] [V] [TRT] Tactic: -128 Time: 0.191348
[05/21/2022-03:14:26] [V] [TRT] Fastest Tactic: 512 Time: 0.155788
[05/21/2022-03:14:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:14:26] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:26] [V] [TRT] *************** Autotuning format combination: Float(86528,676,26,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 129_upsample (Resize)
[05/21/2022-03:14:26] [V] [TRT] Tactic: 0 Time: 0.298724
[05/21/2022-03:14:26] [V] [TRT] Fastest Tactic: 0 Time: 0.298724
[05/21/2022-03:14:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-03:14:26] [V] [TRT] *************** Autotuning format combination: Half(86528,676,26,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 129_upsample (Resize)
[05/21/2022-03:14:26] [V] [TRT] Tactic: 0 Time: 0.310814
[05/21/2022-03:14:26] [V] [TRT] Fastest Tactic: 0 Time: 0.310814
[05/21/2022-03:14:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: Resize Tactic: 0
[05/21/2022-03:14:26] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:26] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:26] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:14:26] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:26] [V] [TRT] Tactic: 0 Time: 3.34793
[05/21/2022-03:14:26] [V] [TRT] Tactic: 1 Time: 1.34057
[05/21/2022-03:14:26] [V] [TRT] Tactic: 2 Time: 2.14236
[05/21/2022-03:14:26] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1116078080, available: 536870912
[05/21/2022-03:14:26] [V] [TRT] Tactic: 5 Time: 5.16741
[05/21/2022-03:14:26] [V] [TRT] Fastest Tactic: 1 Time: 1.34057
[05/21/2022-03:14:26] [V] [TRT] Setting workspace to 1116078080enables more tactics for profiling
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:26] [V] [TRT] Tactic: 1062367460111450758 Time: 1.39307
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:14:26] [V] [TRT] Tactic: 1698681053543049347 Time: 1.31439
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:26] [V] [TRT] Tactic: 4501471010995462441 Time: 1.07652
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:26] [V] [TRT] Tactic: 5137655947464784826 Time: 1.05527
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:26] [V] [TRT] Tactic: 5288347012147084929 Time: 1.07499
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:14:26] [V] [TRT] Tactic: 5326823351883942011 Time: 1.0412
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:14:26] [V] [TRT] Tactic: 5500448035057547314 Time: 1.18409
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:26] [V] [TRT] Tactic: 6645123197870846056 Time: 1.07367
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:26] [V] [TRT] Tactic: 7144526460361122478 Time: 1.4851
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:26] [V] [TRT] Tactic: -8262349710178828730 Time: 1.0951
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:14:26] [V] [TRT] Tactic: -6576203419454146580 Time: 1.24812
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:26] [V] [TRT] Tactic: -4787320710726427159 Time: 1.55532
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:26] [V] [TRT] Tactic: -3456450830548107839 Time: 1.31144
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:26] [V] [TRT] Tactic: -1218658103698133241 Time: 1.21995
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:26] [V] [TRT] Tactic: -836875257600482091 Time: 1.18546
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:26] [V] [TRT] Tactic: -410470605513481746 Time: 1.05163
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:14:26] [V] [TRT] Tactic: -377491875521947884 Time: 1.06948
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:14:26] [V] [TRT] Tactic: -37215280111360163 Time: 1.02867
[05/21/2022-03:14:26] [V] [TRT] Fastest Tactic: -37215280111360163 Time: 1.02867
[05/21/2022-03:14:26] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -37215280111360163
[05/21/2022-03:14:26] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:26] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:26] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:26] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 3886731678879822788
[05/21/2022-03:14:26] [V] [TRT] Tactic: 3886731678879822788 Time: 1.10593
[05/21/2022-03:14:26] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_interior_nhwc_tn_v1 Tactic: 6629944304117643200
[05/21/2022-03:14:27] [V] [TRT] Tactic: 6629944304117643200 Time: 2.09003
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:14:27] [V] [TRT] Tactic: -9153228964338181824 Time: 2.13189
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:14:27] [V] [TRT] Tactic: -7394439838318485025 Time: 1.09855
[05/21/2022-03:14:27] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 1.09855
[05/21/2022-03:14:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:14:27] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:27] [V] [TRT] Tactic: 0 Time: 2.21847
[05/21/2022-03:14:27] [V] [TRT] Tactic: 1 Time: 1.90131
[05/21/2022-03:14:27] [V] [TRT] Tactic: 2 Time: 2.01145
[05/21/2022-03:14:27] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1116078080, available: 536870912
[05/21/2022-03:14:27] [V] [TRT] Tactic: 5 Time: 5.06874
[05/21/2022-03:14:27] [V] [TRT] Fastest Tactic: 1 Time: 1.90131
[05/21/2022-03:14:27] [V] [TRT] Setting workspace to 1116078080enables more tactics for profiling
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:27] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:14:27] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:27] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:27] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:27] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:27] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CublasConvolution)
[05/21/2022-03:14:27] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: 131_convolutional + 131_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:14:27] [V] [TRT] Tactic: 3066127711859985668 Time: 0.663783
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:27] [V] [TRT] Tactic: 3564772625446233998 Time: 0.743372
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:27] [V] [TRT] Tactic: 5319956359050645452 Time: 0.687617
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:27] [V] [TRT] Tactic: 7205456024582378848 Time: 0.565475
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:14:27] [V] [TRT] Tactic: 8163473458334948789 Time: 0.544779
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:27] [V] [TRT] Tactic: -4212163711445252890 Time: 0.547813
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:27] [V] [TRT] Tactic: -3898373634979201110 Time: 0.558776
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:27] [V] [TRT] Tactic: -2409163523992614473 Time: 0.552233
[05/21/2022-03:14:27] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:14:27] [V] [TRT] Tactic: -1716393687483585322 Time: 0.541081
[05/21/2022-03:14:27] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.541081
[05/21/2022-03:14:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:14:27] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:27] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:27] [V] [TRT] Tactic: 0 Time: 0.399635
[05/21/2022-03:14:27] [V] [TRT] Tactic: 1 Time: 0.261784
[05/21/2022-03:14:27] [V] [TRT] Tactic: 2 Time: 0.242611
[05/21/2022-03:14:27] [V] [TRT] Tactic: 3 Time: 0.192643
[05/21/2022-03:14:27] [V] [TRT] Tactic: 4 Time: 0.164792
[05/21/2022-03:14:27] [V] [TRT] Tactic: 5 Time: 0.15528
[05/21/2022-03:14:27] [V] [TRT] Tactic: 6 Time: 0.182949
[05/21/2022-03:14:27] [V] [TRT] Tactic: 7 Time: 0.146003
[05/21/2022-03:14:27] [V] [TRT] Tactic: 8 Time: 0.143594
[05/21/2022-03:14:27] [V] [TRT] Tactic: 9 Time: 0.140898
[05/21/2022-03:14:27] [V] [TRT] Tactic: 28 Time: 0.390391
[05/21/2022-03:14:27] [V] [TRT] Fastest Tactic: 9 Time: 0.140898
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:27] [V] [TRT] Tactic: 128 Time: 0.856074
[05/21/2022-03:14:27] [V] [TRT] Tactic: 256 Time: 0.858359
[05/21/2022-03:14:27] [V] [TRT] Tactic: 512 Time: 0.861914
[05/21/2022-03:14:27] [V] [TRT] Tactic: -32 Time: 0.72929
[05/21/2022-03:14:27] [V] [TRT] Tactic: -64 Time: 0.720462
[05/21/2022-03:14:27] [V] [TRT] Tactic: -128 Time: 0.735475
[05/21/2022-03:14:27] [V] [TRT] Fastest Tactic: -64 Time: 0.720462
[05/21/2022-03:14:27] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:14:27] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:14:27] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:27] [V] [TRT] Tactic: 0 Time: 0.399401
[05/21/2022-03:14:27] [V] [TRT] Tactic: 1 Time: 0.261849
[05/21/2022-03:14:27] [V] [TRT] Tactic: 2 Time: 0.242884
[05/21/2022-03:14:27] [V] [TRT] Tactic: 3 Time: 0.192995
[05/21/2022-03:14:27] [V] [TRT] Tactic: 4 Time: 0.166705
[05/21/2022-03:14:27] [V] [TRT] Tactic: 5 Time: 0.15625
[05/21/2022-03:14:28] [V] [TRT] Tactic: 6 Time: 0.235326
[05/21/2022-03:14:28] [V] [TRT] Tactic: 7 Time: 0.206015
[05/21/2022-03:14:28] [V] [TRT] Tactic: 8 Time: 0.198711
[05/21/2022-03:14:28] [V] [TRT] Tactic: 9 Time: 0.184753
[05/21/2022-03:14:28] [V] [TRT] Tactic: 28 Time: 0.390339
[05/21/2022-03:14:28] [V] [TRT] Fastest Tactic: 5 Time: 0.15625
[05/21/2022-03:14:28] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:28] [V] [TRT] Tactic: 128 Time: 0.855853
[05/21/2022-03:14:28] [V] [TRT] Tactic: 256 Time: 0.857708
[05/21/2022-03:14:28] [V] [TRT] Tactic: 512 Time: 0.861855
[05/21/2022-03:14:28] [V] [TRT] Tactic: -32 Time: 0.775475
[05/21/2022-03:14:28] [V] [TRT] Tactic: -64 Time: 0.844805
[05/21/2022-03:14:28] [V] [TRT] Tactic: -128 Time: 1.00357
[05/21/2022-03:14:28] [V] [TRT] Fastest Tactic: -32 Time: 0.775475
[05/21/2022-03:14:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:28] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:14:28] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:28] [V] [TRT] Tactic: 24 Time: 0.175312
[05/21/2022-03:14:28] [V] [TRT] Tactic: 25 Time: 0.174447
[05/21/2022-03:14:28] [V] [TRT] Tactic: 26 Time: 0.177194
[05/21/2022-03:14:28] [V] [TRT] Tactic: 27 Time: 0.178978
[05/21/2022-03:14:28] [V] [TRT] Tactic: 31 Time: 0.175937
[05/21/2022-03:14:28] [V] [TRT] Fastest Tactic: 25 Time: 0.174447
[05/21/2022-03:14:28] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:28] [V] [TRT] Tactic: 128 Time: 0.855612
[05/21/2022-03:14:28] [V] [TRT] Tactic: 256 Time: 0.857774
[05/21/2022-03:14:28] [V] [TRT] Tactic: 512 Time: 0.86211
[05/21/2022-03:14:28] [V] [TRT] Tactic: -32 Time: 0.727962
[05/21/2022-03:14:28] [V] [TRT] Tactic: -64 Time: 0.719395
[05/21/2022-03:14:28] [V] [TRT] Tactic: -128 Time: 0.735137
[05/21/2022-03:14:28] [V] [TRT] Fastest Tactic: -64 Time: 0.719395
[05/21/2022-03:14:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:28] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:14:28] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:28] [V] [TRT] Tactic: 0 Time: 0.401953
[05/21/2022-03:14:28] [V] [TRT] Tactic: 1 Time: 0.268952
[05/21/2022-03:14:28] [V] [TRT] Tactic: 2 Time: 0.252578
[05/21/2022-03:14:28] [V] [TRT] Tactic: 3 Time: 0.182572
[05/21/2022-03:14:28] [V] [TRT] Tactic: 4 Time: 0.168372
[05/21/2022-03:14:28] [V] [TRT] Tactic: 5 Time: 0.161055
[05/21/2022-03:14:28] [V] [TRT] Tactic: 6 Time: 0.161244
[05/21/2022-03:14:28] [V] [TRT] Tactic: 7 Time: 0.120365
[05/21/2022-03:14:28] [V] [TRT] Tactic: 8 Time: 0.121283
[05/21/2022-03:14:28] [V] [TRT] Tactic: 9 Time: 0.123118
[05/21/2022-03:14:28] [V] [TRT] Tactic: 28 Time: 0.397181
[05/21/2022-03:14:28] [V] [TRT] Fastest Tactic: 7 Time: 0.120365
[05/21/2022-03:14:28] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:28] [V] [TRT] Tactic: 128 Time: 0.67888
[05/21/2022-03:14:28] [V] [TRT] Tactic: 256 Time: 0.674785
[05/21/2022-03:14:28] [V] [TRT] Tactic: 512 Time: 0.642129
[05/21/2022-03:14:28] [V] [TRT] Tactic: -32 Time: 0.697226
[05/21/2022-03:14:28] [V] [TRT] Tactic: -64 Time: 0.680124
[05/21/2022-03:14:28] [V] [TRT] Tactic: -128 Time: 0.699915
[05/21/2022-03:14:28] [V] [TRT] Fastest Tactic: 512 Time: 0.642129
[05/21/2022-03:14:28] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 7
[05/21/2022-03:14:28] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:28] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:28] [V] [TRT] Tactic: 0 Time: 0.235306
[05/21/2022-03:14:28] [V] [TRT] Tactic: 1 Time: 0.16623
[05/21/2022-03:14:28] [V] [TRT] Tactic: 2 Time: 0.174316
[05/21/2022-03:14:28] [V] [TRT] Tactic: 3 Time: 0.140872
[05/21/2022-03:14:28] [V] [TRT] Tactic: 4 Time: 0.147057
[05/21/2022-03:14:28] [V] [TRT] Tactic: 5 Time: 0.16513
[05/21/2022-03:14:28] [V] [TRT] Tactic: 6 Time: 0.135924
[05/21/2022-03:14:28] [V] [TRT] Tactic: 7 Time: 0.14
[05/21/2022-03:14:28] [V] [TRT] Tactic: 8 Time: 0.150547
[05/21/2022-03:14:28] [V] [TRT] Tactic: 9 Time: 0.158704
[05/21/2022-03:14:28] [V] [TRT] Tactic: 10 Time: 0.423372
[05/21/2022-03:14:28] [V] [TRT] Tactic: 11 Time: 0.284466
[05/21/2022-03:14:28] [V] [TRT] Tactic: 12 Time: 0.268483
[05/21/2022-03:14:28] [V] [TRT] Tactic: 13 Time: 0.190137
[05/21/2022-03:14:28] [V] [TRT] Tactic: 14 Time: 0.171719
[05/21/2022-03:14:28] [V] [TRT] Tactic: 15 Time: 0.177702
[05/21/2022-03:14:28] [V] [TRT] Tactic: 16 Time: 0.161511
[05/21/2022-03:14:28] [V] [TRT] Tactic: 17 Time: 0.119499
[05/21/2022-03:14:28] [V] [TRT] Tactic: 18 Time: 0.128268
[05/21/2022-03:14:28] [V] [TRT] Tactic: 19 Time: 0.137038
[05/21/2022-03:14:28] [V] [TRT] Tactic: 28 Time: 0.231204
[05/21/2022-03:14:28] [V] [TRT] Tactic: 29 Time: 0.417305
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 17 Time: 0.119499
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(131_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 128 Time: 0.678509
[05/21/2022-03:14:29] [V] [TRT] Tactic: 256 Time: 0.673021
[05/21/2022-03:14:29] [V] [TRT] Tactic: 512 Time: 0.642207
[05/21/2022-03:14:29] [V] [TRT] Tactic: -32 Time: 0.696367
[05/21/2022-03:14:29] [V] [TRT] Tactic: -64 Time: 0.68054
[05/21/2022-03:14:29] [V] [TRT] Tactic: -128 Time: 0.699316
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 512 Time: 0.642207
[05/21/2022-03:14:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 17
[05/21/2022-03:14:29] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:14:29] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 0 Time: 0.297578
[05/21/2022-03:14:29] [V] [TRT] Tactic: 1 Time: 0.214258
[05/21/2022-03:14:29] [V] [TRT] Tactic: 2 Time: 0.188379
[05/21/2022-03:14:29] [V] [TRT] Tactic: 3 Time: 0.181511
[05/21/2022-03:14:29] [V] [TRT] Tactic: 4 Time: 0.148327
[05/21/2022-03:14:29] [V] [TRT] Tactic: 5 Time: 0.140638
[05/21/2022-03:14:29] [V] [TRT] Tactic: 6 Time: 0.178529
[05/21/2022-03:14:29] [V] [TRT] Tactic: 7 Time: 0.144967
[05/21/2022-03:14:29] [V] [TRT] Tactic: 8 Time: 0.141771
[05/21/2022-03:14:29] [V] [TRT] Tactic: 9 Time: 0.141732
[05/21/2022-03:14:29] [V] [TRT] Tactic: 28 Time: 0.291172
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 5 Time: 0.140638
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 128 Time: 0.684004
[05/21/2022-03:14:29] [V] [TRT] Tactic: 256 Time: 0.686029
[05/21/2022-03:14:29] [V] [TRT] Tactic: 512 Time: 0.690671
[05/21/2022-03:14:29] [V] [TRT] Tactic: -32 Time: 0.723314
[05/21/2022-03:14:29] [V] [TRT] Tactic: -64 Time: 0.709421
[05/21/2022-03:14:29] [V] [TRT] Tactic: -128 Time: 0.714857
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 128 Time: 0.684004
[05/21/2022-03:14:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 0 Time: 0.29778
[05/21/2022-03:14:29] [V] [TRT] Tactic: 1 Time: 0.213659
[05/21/2022-03:14:29] [V] [TRT] Tactic: 2 Time: 0.188411
[05/21/2022-03:14:29] [V] [TRT] Tactic: 3 Time: 0.182044
[05/21/2022-03:14:29] [V] [TRT] Tactic: 4 Time: 0.148808
[05/21/2022-03:14:29] [V] [TRT] Tactic: 5 Time: 0.138555
[05/21/2022-03:14:29] [V] [TRT] Tactic: 6 Time: 0.178385
[05/21/2022-03:14:29] [V] [TRT] Tactic: 7 Time: 0.143867
[05/21/2022-03:14:29] [V] [TRT] Tactic: 8 Time: 0.143412
[05/21/2022-03:14:29] [V] [TRT] Tactic: 9 Time: 0.141472
[05/21/2022-03:14:29] [V] [TRT] Tactic: 28 Time: 0.291367
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 5 Time: 0.138555
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 128 Time: 0.683509
[05/21/2022-03:14:29] [V] [TRT] Tactic: 256 Time: 0.685977
[05/21/2022-03:14:29] [V] [TRT] Tactic: 512 Time: 0.690683
[05/21/2022-03:14:29] [V] [TRT] Tactic: -32 Time: 0.723438
[05/21/2022-03:14:29] [V] [TRT] Tactic: -64 Time: 0.709316
[05/21/2022-03:14:29] [V] [TRT] Tactic: -128 Time: 0.714622
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 128 Time: 0.683509
[05/21/2022-03:14:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 24 Time: 0.184779
[05/21/2022-03:14:29] [V] [TRT] Tactic: 25 Time: 0.174303
[05/21/2022-03:14:29] [V] [TRT] Tactic: 26 Time: 0.177194
[05/21/2022-03:14:29] [V] [TRT] Tactic: 27 Time: 0.177201
[05/21/2022-03:14:29] [V] [TRT] Tactic: 31 Time: 0.184056
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 25 Time: 0.174303
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 128 Time: 0.684075
[05/21/2022-03:14:29] [V] [TRT] Tactic: 256 Time: 0.685866
[05/21/2022-03:14:29] [V] [TRT] Tactic: 512 Time: 0.690924
[05/21/2022-03:14:29] [V] [TRT] Tactic: -32 Time: 0.723359
[05/21/2022-03:14:29] [V] [TRT] Tactic: -64 Time: 0.708906
[05/21/2022-03:14:29] [V] [TRT] Tactic: -128 Time: 0.71528
[05/21/2022-03:14:29] [V] [TRT] Fastest Tactic: 128 Time: 0.684075
[05/21/2022-03:14:29] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:29] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:29] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:29] [V] [TRT] Tactic: 0 Time: 0.296387
[05/21/2022-03:14:29] [V] [TRT] Tactic: 1 Time: 0.210918
[05/21/2022-03:14:29] [V] [TRT] Tactic: 2 Time: 0.201582
[05/21/2022-03:14:29] [V] [TRT] Tactic: 3 Time: 0.164609
[05/21/2022-03:14:29] [V] [TRT] Tactic: 4 Time: 0.131764
[05/21/2022-03:14:29] [V] [TRT] Tactic: 5 Time: 0.138132
[05/21/2022-03:14:29] [V] [TRT] Tactic: 6 Time: 0.151055
[05/21/2022-03:14:29] [V] [TRT] Tactic: 7 Time: 0.109603
[05/21/2022-03:14:29] [V] [TRT] Tactic: 8 Time: 0.0985805
[05/21/2022-03:14:30] [V] [TRT] Tactic: 9 Time: 0.110722
[05/21/2022-03:14:30] [V] [TRT] Tactic: 28 Time: 0.28864
[05/21/2022-03:14:30] [V] [TRT] Fastest Tactic: 8 Time: 0.0985805
[05/21/2022-03:14:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:30] [V] [TRT] Tactic: 128 Time: 0.617044
[05/21/2022-03:14:30] [V] [TRT] Tactic: 256 Time: 0.614752
[05/21/2022-03:14:30] [V] [TRT] Tactic: 512 Time: 0.596758
[05/21/2022-03:14:30] [V] [TRT] Tactic: -32 Time: 0.688633
[05/21/2022-03:14:30] [V] [TRT] Tactic: -64 Time: 0.667852
[05/21/2022-03:14:30] [V] [TRT] Tactic: -128 Time: 0.674968
[05/21/2022-03:14:30] [V] [TRT] Fastest Tactic: 512 Time: 0.596758
[05/21/2022-03:14:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:14:30] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:14:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:30] [V] [TRT] Tactic: 0 Time: 0.193327
[05/21/2022-03:14:30] [V] [TRT] Tactic: 1 Time: 0.155182
[05/21/2022-03:14:30] [V] [TRT] Tactic: 2 Time: 0.167591
[05/21/2022-03:14:30] [V] [TRT] Tactic: 3 Time: 0.139121
[05/21/2022-03:14:30] [V] [TRT] Tactic: 4 Time: 0.142389
[05/21/2022-03:14:30] [V] [TRT] Tactic: 5 Time: 0.153503
[05/21/2022-03:14:30] [V] [TRT] Tactic: 6 Time: 0.133822
[05/21/2022-03:14:30] [V] [TRT] Tactic: 7 Time: 0.137227
[05/21/2022-03:14:30] [V] [TRT] Tactic: 8 Time: 0.144876
[05/21/2022-03:14:30] [V] [TRT] Tactic: 9 Time: 0.157774
[05/21/2022-03:14:30] [V] [TRT] Tactic: 10 Time: 0.321966
[05/21/2022-03:14:30] [V] [TRT] Tactic: 11 Time: 0.224935
[05/21/2022-03:14:30] [V] [TRT] Tactic: 12 Time: 0.216269
[05/21/2022-03:14:30] [V] [TRT] Tactic: 13 Time: 0.168216
[05/21/2022-03:14:30] [V] [TRT] Tactic: 14 Time: 0.140677
[05/21/2022-03:14:30] [V] [TRT] Tactic: 15 Time: 0.149395
[05/21/2022-03:14:30] [V] [TRT] Tactic: 16 Time: 0.152689
[05/21/2022-03:14:30] [V] [TRT] Tactic: 17 Time: 0.111589
[05/21/2022-03:14:30] [V] [TRT] Tactic: 18 Time: 0.105644
[05/21/2022-03:14:30] [V] [TRT] Tactic: 19 Time: 0.124141
[05/21/2022-03:14:30] [V] [TRT] Tactic: 28 Time: 0.187975
[05/21/2022-03:14:30] [V] [TRT] Tactic: 29 Time: 0.311999
[05/21/2022-03:14:30] [V] [TRT] Fastest Tactic: 18 Time: 0.105644
[05/21/2022-03:14:30] [V] [TRT] --------------- Timing Runner: PWN(133_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:30] [V] [TRT] Tactic: 128 Time: 0.616875
[05/21/2022-03:14:30] [V] [TRT] Tactic: 256 Time: 0.614056
[05/21/2022-03:14:30] [V] [TRT] Tactic: 512 Time: 0.596569
[05/21/2022-03:14:30] [V] [TRT] Tactic: -32 Time: 0.687728
[05/21/2022-03:14:30] [V] [TRT] Tactic: -64 Time: 0.668373
[05/21/2022-03:14:30] [V] [TRT] Tactic: -128 Time: 0.675319
[05/21/2022-03:14:30] [V] [TRT] Fastest Tactic: 512 Time: 0.596569
[05/21/2022-03:14:30] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:14:30] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:30] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:14:30] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:30] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:30] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:14:30] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:30] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:30] [V] [TRT] Tactic: 0 Time: 15.0077
[05/21/2022-03:14:30] [V] [TRT] Tactic: 1 Time: 10.3478
[05/21/2022-03:14:31] [V] [TRT] Tactic: 2 Time: 13.4035
[05/21/2022-03:14:31] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1112801280, available: 536870912
[05/21/2022-03:14:32] [V] [TRT] Tactic: 5 Time: 85.1763
[05/21/2022-03:14:32] [V] [TRT] Tactic: 6 Time: 7.1575
[05/21/2022-03:14:32] [V] [TRT] Fastest Tactic: 6 Time: 7.1575
[05/21/2022-03:14:32] [V] [TRT] Setting workspace to 1112801280enables more tactics for profiling
[05/21/2022-03:14:32] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:32] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:33] [V] [TRT] Tactic: 1062367460111450758 Time: 10.5991
[05/21/2022-03:14:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:14:33] [V] [TRT] Tactic: 1754984623894446479 Time: 11.938
[05/21/2022-03:14:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:14:33] [V] [TRT] Tactic: 3611739942397549984 Time: 8.73562
[05/21/2022-03:14:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v1 Tactic: 3827454225649558724
[05/21/2022-03:14:33] [V] [TRT] Tactic: 3827454225649558724 Time: 9.77944
[05/21/2022-03:14:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:14:33] [V] [TRT] Tactic: 4337000649858996379 Time: 8.7279
[05/21/2022-03:14:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:33] [V] [TRT] Tactic: 4501471010995462441 Time: 8.69623
[05/21/2022-03:14:33] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:34] [V] [TRT] Tactic: 5137655947464784826 Time: 8.35745
[05/21/2022-03:14:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:34] [V] [TRT] Tactic: 5288347012147084929 Time: 8.49561
[05/21/2022-03:14:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 5921334924264294896
[05/21/2022-03:14:34] [V] [TRT] Tactic: 5921334924264294896 Time: 6.91824
[05/21/2022-03:14:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:34] [V] [TRT] Tactic: 6645123197870846056 Time: 8.6415
[05/21/2022-03:14:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:34] [V] [TRT] Tactic: 7144526460361122478 Time: 10.9977
[05/21/2022-03:14:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v1 Tactic: 7852627285308570038
[05/21/2022-03:14:34] [V] [TRT] Tactic: 7852627285308570038 Time: 9.81056
[05/21/2022-03:14:34] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:14:35] [V] [TRT] Tactic: -9137461792520977713 Time: 8.71129
[05/21/2022-03:14:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148n_nt_v0 Tactic: -8776506421218919509
[05/21/2022-03:14:35] [V] [TRT] Tactic: -8776506421218919509 Time: 9.69163
[05/21/2022-03:14:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:35] [V] [TRT] Tactic: -8262349710178828730 Time: 8.70559
[05/21/2022-03:14:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:14:35] [V] [TRT] Tactic: -8133971918129952780 Time: 9.56586
[05/21/2022-03:14:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:14:35] [V] [TRT] Tactic: -6092040395344634144 Time: 10.9894
[05/21/2022-03:14:35] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:36] [V] [TRT] Tactic: -4787320710726427159 Time: 12.0426
[05/21/2022-03:14:36] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:36] [V] [TRT] Tactic: -3456450830548107839 Time: 9.71876
[05/21/2022-03:14:36] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_relu_tile148t_nt_v0 Tactic: -2318106587342035239
[05/21/2022-03:14:36] [V] [TRT] Tactic: -2318106587342035239 Time: 9.79653
[05/21/2022-03:14:36] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_winograd_128x128_ldg1_ldg4_mobile_relu_tile148t_nt_v0 Tactic: -1343271414618805657
[05/21/2022-03:14:36] [V] [TRT] Tactic: -1343271414618805657 Time: 6.46314
[05/21/2022-03:14:36] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:36] [V] [TRT] Tactic: -1218658103698133241 Time: 9.45892
[05/21/2022-03:14:36] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:37] [V] [TRT] Tactic: -836875257600482091 Time: 9.10641
[05/21/2022-03:14:37] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:37] [V] [TRT] Tactic: -410470605513481746 Time: 8.43221
[05/21/2022-03:14:37] [V] [TRT] Fastest Tactic: -1343271414618805657 Time: 6.46314
[05/21/2022-03:14:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1343271414618805657
[05/21/2022-03:14:37] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:14:37] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:37] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:37] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:37] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:14:37] [V] [TRT] Tactic: -9153228964338181824 Time: 10.9389
[05/21/2022-03:14:37] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:14:37] [V] [TRT] Tactic: -7394439838318485025 Time: 8.29925
[05/21/2022-03:14:37] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 8.29925
[05/21/2022-03:14:37] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:14:37] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:14:37] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:37] [V] [TRT] Tactic: 0 Time: 21.2608
[05/21/2022-03:14:38] [V] [TRT] Tactic: 1 Time: 16.1897
[05/21/2022-03:14:38] [V] [TRT] Tactic: 2 Time: 12.7688
[05/21/2022-03:14:38] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1112801280, available: 536870912
[05/21/2022-03:14:39] [V] [TRT] Tactic: 5 Time: 84.0974
[05/21/2022-03:14:40] [V] [TRT] Tactic: 6 Time: 8.39163
[05/21/2022-03:14:40] [V] [TRT] Fastest Tactic: 6 Time: 8.39163
[05/21/2022-03:14:40] [V] [TRT] Setting workspace to 1112801280enables more tactics for profiling
[05/21/2022-03:14:40] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:40] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:40] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 6
[05/21/2022-03:14:40] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:40] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:40] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:40] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:40] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:40] [V] [TRT] --------------- Timing Runner: 134_convolutional + 134_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:40] [V] [TRT] Tactic: 3564772625446233998 Time: 5.35365
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:14:40] [V] [TRT] Tactic: 3650389455493082349 Time: 5.56115
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:14:40] [V] [TRT] Tactic: 4772821744921268633 Time: 3.76113
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:40] [V] [TRT] Tactic: 5319956359050645452 Time: 4.85298
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:40] [V] [TRT] Tactic: 7205456024582378848 Time: 4.3337
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:14:40] [V] [TRT] Tactic: -6490690591794140522 Time: 4.39105
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:14:40] [V] [TRT] Tactic: -4686027666808657977 Time: 4.38032
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:40] [V] [TRT] Tactic: -4212163711445252890 Time: 4.21405
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:40] [V] [TRT] Tactic: -3898373634979201110 Time: 4.34798
[05/21/2022-03:14:40] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:41] [V] [TRT] Tactic: -2409163523992614473 Time: 4.24747
[05/21/2022-03:14:41] [V] [TRT] Fastest Tactic: 4772821744921268633 Time: 3.76113
[05/21/2022-03:14:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 4772821744921268633
[05/21/2022-03:14:41] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:41] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:14:41] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:41] [V] [TRT] Tactic: 0 Time: 0.587734
[05/21/2022-03:14:41] [V] [TRT] Tactic: 1 Time: 0.419232
[05/21/2022-03:14:41] [V] [TRT] Tactic: 2 Time: 0.36765
[05/21/2022-03:14:41] [V] [TRT] Tactic: 3 Time: 0.355215
[05/21/2022-03:14:41] [V] [TRT] Tactic: 4 Time: 0.289486
[05/21/2022-03:14:41] [V] [TRT] Tactic: 5 Time: 0.278659
[05/21/2022-03:14:41] [V] [TRT] Tactic: 6 Time: 0.351029
[05/21/2022-03:14:41] [V] [TRT] Tactic: 7 Time: 0.282025
[05/21/2022-03:14:41] [V] [TRT] Tactic: 8 Time: 0.278698
[05/21/2022-03:14:41] [V] [TRT] Tactic: 9 Time: 0.276706
[05/21/2022-03:14:41] [V] [TRT] Tactic: 28 Time: 0.5753
[05/21/2022-03:14:41] [V] [TRT] Fastest Tactic: 9 Time: 0.276706
[05/21/2022-03:14:41] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:41] [V] [TRT] Tactic: 128 Time: 1.36123
[05/21/2022-03:14:41] [V] [TRT] Tactic: 256 Time: 1.36531
[05/21/2022-03:14:41] [V] [TRT] Tactic: 512 Time: 1.37393
[05/21/2022-03:14:41] [V] [TRT] Tactic: -32 Time: 1.41639
[05/21/2022-03:14:41] [V] [TRT] Tactic: -64 Time: 1.40255
[05/21/2022-03:14:41] [V] [TRT] Tactic: -128 Time: 1.41794
[05/21/2022-03:14:41] [V] [TRT] Fastest Tactic: 128 Time: 1.36123
[05/21/2022-03:14:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 9
[05/21/2022-03:14:41] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:14:41] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:41] [V] [TRT] Tactic: 0 Time: 0.586738
[05/21/2022-03:14:41] [V] [TRT] Tactic: 1 Time: 0.419401
[05/21/2022-03:14:41] [V] [TRT] Tactic: 2 Time: 0.367897
[05/21/2022-03:14:41] [V] [TRT] Tactic: 3 Time: 0.357109
[05/21/2022-03:14:41] [V] [TRT] Tactic: 4 Time: 0.288438
[05/21/2022-03:14:41] [V] [TRT] Tactic: 5 Time: 0.27388
[05/21/2022-03:14:41] [V] [TRT] Tactic: 6 Time: 0.351641
[05/21/2022-03:14:41] [V] [TRT] Tactic: 7 Time: 0.282012
[05/21/2022-03:14:41] [V] [TRT] Tactic: 8 Time: 0.281172
[05/21/2022-03:14:41] [V] [TRT] Tactic: 9 Time: 0.277852
[05/21/2022-03:14:41] [V] [TRT] Tactic: 28 Time: 0.573997
[05/21/2022-03:14:41] [V] [TRT] Fastest Tactic: 5 Time: 0.27388
[05/21/2022-03:14:41] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:41] [V] [TRT] Tactic: 128 Time: 1.36
[05/21/2022-03:14:41] [V] [TRT] Tactic: 256 Time: 1.36441
[05/21/2022-03:14:41] [V] [TRT] Tactic: 512 Time: 1.37335
[05/21/2022-03:14:41] [V] [TRT] Tactic: -32 Time: 1.41538
[05/21/2022-03:14:41] [V] [TRT] Tactic: -64 Time: 1.4027
[05/21/2022-03:14:41] [V] [TRT] Tactic: -128 Time: 1.41798
[05/21/2022-03:14:41] [V] [TRT] Fastest Tactic: 128 Time: 1.36
[05/21/2022-03:14:41] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 5
[05/21/2022-03:14:41] [V] [TRT] *************** Autotuning format combination: Float(21632,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:14:41] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:41] [V] [TRT] Tactic: 24 Time: 0.359251
[05/21/2022-03:14:42] [V] [TRT] Tactic: 25 Time: 0.343886
[05/21/2022-03:14:42] [V] [TRT] Tactic: 26 Time: 0.349805
[05/21/2022-03:14:42] [V] [TRT] Tactic: 27 Time: 0.348138
[05/21/2022-03:14:42] [V] [TRT] Tactic: 31 Time: 0.365983
[05/21/2022-03:14:42] [V] [TRT] Fastest Tactic: 25 Time: 0.343886
[05/21/2022-03:14:42] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:42] [V] [TRT] Tactic: 128 Time: 1.35994
[05/21/2022-03:14:42] [V] [TRT] Tactic: 256 Time: 1.36477
[05/21/2022-03:14:42] [V] [TRT] Tactic: 512 Time: 1.37382
[05/21/2022-03:14:42] [V] [TRT] Tactic: -32 Time: 1.41639
[05/21/2022-03:14:42] [V] [TRT] Tactic: -64 Time: 1.40374
[05/21/2022-03:14:42] [V] [TRT] Tactic: -128 Time: 1.4177
[05/21/2022-03:14:42] [V] [TRT] Fastest Tactic: 128 Time: 1.35994
[05/21/2022-03:14:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 25
[05/21/2022-03:14:42] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:14:42] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:42] [V] [TRT] Tactic: 0 Time: 0.584336
[05/21/2022-03:14:42] [V] [TRT] Tactic: 1 Time: 0.411348
[05/21/2022-03:14:42] [V] [TRT] Tactic: 2 Time: 0.395111
[05/21/2022-03:14:42] [V] [TRT] Tactic: 3 Time: 0.322656
[05/21/2022-03:14:42] [V] [TRT] Tactic: 4 Time: 0.256003
[05/21/2022-03:14:42] [V] [TRT] Tactic: 5 Time: 0.267682
[05/21/2022-03:14:42] [V] [TRT] Tactic: 6 Time: 0.294622
[05/21/2022-03:14:42] [V] [TRT] Tactic: 7 Time: 0.211374
[05/21/2022-03:14:42] [V] [TRT] Tactic: 8 Time: 0.190605
[05/21/2022-03:14:42] [V] [TRT] Tactic: 9 Time: 0.214186
[05/21/2022-03:14:42] [V] [TRT] Tactic: 28 Time: 0.568646
[05/21/2022-03:14:42] [V] [TRT] Fastest Tactic: 8 Time: 0.190605
[05/21/2022-03:14:42] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:42] [V] [TRT] Tactic: 128 Time: 1.2259
[05/21/2022-03:14:42] [V] [TRT] Tactic: 256 Time: 1.21997
[05/21/2022-03:14:42] [V] [TRT] Tactic: 512 Time: 1.1862
[05/21/2022-03:14:42] [V] [TRT] Tactic: -32 Time: 1.35464
[05/21/2022-03:14:42] [V] [TRT] Tactic: -64 Time: 1.31938
[05/21/2022-03:14:42] [V] [TRT] Tactic: -128 Time: 1.33913
[05/21/2022-03:14:42] [V] [TRT] Fastest Tactic: 512 Time: 1.1862
[05/21/2022-03:14:42] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 8
[05/21/2022-03:14:42] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:42] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWiseV2)
[05/21/2022-03:14:42] [V] [TRT] Tactic: 0 Time: 0.376953
[05/21/2022-03:14:42] [V] [TRT] Tactic: 1 Time: 0.303672
[05/21/2022-03:14:42] [V] [TRT] Tactic: 2 Time: 0.330091
[05/21/2022-03:14:42] [V] [TRT] Tactic: 3 Time: 0.267344
[05/21/2022-03:14:42] [V] [TRT] Tactic: 4 Time: 0.277585
[05/21/2022-03:14:42] [V] [TRT] Tactic: 5 Time: 0.299492
[05/21/2022-03:14:42] [V] [TRT] Tactic: 6 Time: 0.258164
[05/21/2022-03:14:42] [V] [TRT] Tactic: 7 Time: 0.265886
[05/21/2022-03:14:42] [V] [TRT] Tactic: 8 Time: 0.283809
[05/21/2022-03:14:42] [V] [TRT] Tactic: 9 Time: 0.310332
[05/21/2022-03:14:42] [V] [TRT] Tactic: 10 Time: 0.635925
[05/21/2022-03:14:42] [V] [TRT] Tactic: 11 Time: 0.439681
[05/21/2022-03:14:42] [V] [TRT] Tactic: 12 Time: 0.424147
[05/21/2022-03:14:42] [V] [TRT] Tactic: 13 Time: 0.328568
[05/21/2022-03:14:42] [V] [TRT] Tactic: 14 Time: 0.272376
[05/21/2022-03:14:42] [V] [TRT] Tactic: 15 Time: 0.289883
[05/21/2022-03:14:42] [V] [TRT] Tactic: 16 Time: 0.300163
[05/21/2022-03:14:42] [V] [TRT] Tactic: 17 Time: 0.214675
[05/21/2022-03:14:42] [V] [TRT] Tactic: 18 Time: 0.20317
[05/21/2022-03:14:42] [V] [TRT] Tactic: 19 Time: 0.239668
[05/21/2022-03:14:43] [V] [TRT] Tactic: 28 Time: 0.368177
[05/21/2022-03:14:43] [V] [TRT] Tactic: 29 Time: 0.615371
[05/21/2022-03:14:43] [V] [TRT] Fastest Tactic: 18 Time: 0.20317
[05/21/2022-03:14:43] [V] [TRT] --------------- Timing Runner: PWN(134_convolutional_lrelu) (PointWise)
[05/21/2022-03:14:43] [V] [TRT] Tactic: 128 Time: 1.2261
[05/21/2022-03:14:43] [V] [TRT] Tactic: 256 Time: 1.21929
[05/21/2022-03:14:43] [V] [TRT] Tactic: 512 Time: 1.18576
[05/21/2022-03:14:43] [V] [TRT] Tactic: -32 Time: 1.35492
[05/21/2022-03:14:43] [V] [TRT] Tactic: -64 Time: 1.31992
[05/21/2022-03:14:43] [V] [TRT] Tactic: -128 Time: 1.33899
[05/21/2022-03:14:43] [V] [TRT] Fastest Tactic: 512 Time: 1.18576
[05/21/2022-03:14:43] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: PointWiseV2 Tactic: 18
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(21632,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(346112,1,6656,128) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(10816,2704:32,52,1) -> Float(10816,2704:32,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(346112,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(173056,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(692224,1,13312,256) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(21632,2704:32,52,1) -> Float(21632,2704:32,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(692224,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:43] [V] [TRT] *************** Autotuning format combination: Float(692224,2704,52,1) -> Float(689520,2704,52,1) ***************
[05/21/2022-03:14:43] [V] [TRT] --------------- Timing Runner: 139_convolutional (FusedConvActConvolution)
[05/21/2022-03:14:43] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:43] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudaDepthwiseConvolution)
[05/21/2022-03:14:43] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:43] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-03:14:43] [V] [TRT] Tactic: 0 Time: 3.86059
[05/21/2022-03:14:43] [V] [TRT] Tactic: 1 Time: 2.58445
[05/21/2022-03:14:43] [V] [TRT] Tactic: 2 Time: 3.62105
[05/21/2022-03:14:43] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2214853632, available: 536870912
[05/21/2022-03:14:43] [V] [TRT] Tactic: 5 Time: 9.08717
[05/21/2022-03:14:43] [V] [TRT] Fastest Tactic: 1 Time: 2.58445
[05/21/2022-03:14:43] [V] [TRT] Setting workspace to 2214853632enables more tactics for profiling
[05/21/2022-03:14:43] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-03:14:43] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:43] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-03:14:43] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:43] [V] [TRT] Tactic: 1062367460111450758 Time: 2.7398
[05/21/2022-03:14:43] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:14:43] [V] [TRT] Tactic: 1698681053543049347 Time: 2.5876
[05/21/2022-03:14:43] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:43] [V] [TRT] Tactic: 4501471010995462441 Time: 2.14419
[05/21/2022-03:14:43] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:43] [V] [TRT] Tactic: 5137655947464784826 Time: 2.0683
[05/21/2022-03:14:43] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:43] [V] [TRT] Tactic: 5288347012147084929 Time: 2.13105
[05/21/2022-03:14:43] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:14:44] [V] [TRT] Tactic: 5326823351883942011 Time: 2.05348
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:14:44] [V] [TRT] Tactic: 5500448035057547314 Time: 2.30334
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:44] [V] [TRT] Tactic: 6645123197870846056 Time: 2.12098
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:44] [V] [TRT] Tactic: 7144526460361122478 Time: 2.94092
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:44] [V] [TRT] Tactic: -8262349710178828730 Time: 2.17398
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:14:44] [V] [TRT] Tactic: -6576203419454146580 Time: 2.47225
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:44] [V] [TRT] Tactic: -4787320710726427159 Time: 3.14727
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:44] [V] [TRT] Tactic: -3456450830548107839 Time: 2.60738
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:44] [V] [TRT] Tactic: -1218658103698133241 Time: 2.40146
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:44] [V] [TRT] Tactic: -836875257600482091 Time: 2.3474
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:44] [V] [TRT] Tactic: -410470605513481746 Time: 2.08538
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:14:44] [V] [TRT] Tactic: -377491875521947884 Time: 2.12087
[05/21/2022-03:14:44] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:14:44] [V] [TRT] Tactic: -37215280111360163 Time: 2.05613
[05/21/2022-03:14:44] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 2.05348
[05/21/2022-03:14:44] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:14:44] [V] [TRT] *************** Autotuning format combination: Float(692224,1,13312,256) -> Float(689520,1,13260,255) ***************
[05/21/2022-03:14:44] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-03:14:44] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:44] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-03:14:44] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:44] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-03:14:44] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:44] [V] [TRT] *************** Autotuning format combination: Half(692224,2704,52,1) -> Half(689520,2704,52,1) ***************
[05/21/2022-03:14:44] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-03:14:44] [V] [TRT] Tactic: 0 Time: 3.727
[05/21/2022-03:14:44] [V] [TRT] Tactic: 1 Time: 2.56435
[05/21/2022-03:14:44] [V] [TRT] Tactic: 2 Time: 3.39976
[05/21/2022-03:14:44] [V] [TRT] Tactic: 4 skipped. Scratch requested: 2214853632, available: 536870912
[05/21/2022-03:14:45] [V] [TRT] Tactic: 5 Time: 8.76533
[05/21/2022-03:14:45] [V] [TRT] Fastest Tactic: 1 Time: 2.56435
[05/21/2022-03:14:45] [V] [TRT] Setting workspace to 2214853632enables more tactics for profiling
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-03:14:45] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-03:14:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:14:45] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(689520,2704,52,1) ***************
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-03:14:45] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] *************** Autotuning format combination: Half(346112,2704:2,52,1) -> Half(346112,2704:2,52,1) ***************
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 139_convolutional (FusedConvActConvolution)
[05/21/2022-03:14:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 139_convolutional (CudnnConvolution)
[05/21/2022-03:14:45] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 139_convolutional (CublasConvolution)
[05/21/2022-03:14:45] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 139_convolutional (CaskConvolution)
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:14:45] [V] [TRT] Tactic: 3066127711859985668 Time: 1.30842
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:45] [V] [TRT] Tactic: 3564772625446233998 Time: 1.4657
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:45] [V] [TRT] Tactic: 5319956359050645452 Time: 1.35606
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:45] [V] [TRT] Tactic: 7205456024582378848 Time: 1.11335
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:14:45] [V] [TRT] Tactic: 8163473458334948789 Time: 1.06019
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:45] [V] [TRT] Tactic: -4212163711445252890 Time: 1.08121
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:45] [V] [TRT] Tactic: -3898373634979201110 Time: 1.09631
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:45] [V] [TRT] Tactic: -2409163523992614473 Time: 1.07645
[05/21/2022-03:14:45] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:14:45] [V] [TRT] Tactic: -1716393687483585322 Time: 1.0638
[05/21/2022-03:14:45] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 1.06019
[05/21/2022-03:14:45] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:14:45] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:45] [V] [TRT] *************** Autotuning format combination: Float(346112,2704,52,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:45] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:14:45] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:45] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:45] [V] [TRT] Tactic: 0 Time: 4.02195
[05/21/2022-03:14:45] [V] [TRT] Tactic: 1 Time: 3.07973
[05/21/2022-03:14:45] [V] [TRT] Tactic: 2 Time: 3.96248
[05/21/2022-03:14:47] [V] [TRT] Tactic: 5 Time: 84.2524
[05/21/2022-03:14:47] [V] [TRT] Fastest Tactic: 1 Time: 3.07973
[05/21/2022-03:14:47] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:47] [V] [TRT] Tactic: 1062367460111450758 Time: 2.97391
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:14:47] [V] [TRT] Tactic: 1754984623894446479 Time: 3.38976
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:14:47] [V] [TRT] Tactic: 3611739942397549984 Time: 2.36279
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:14:47] [V] [TRT] Tactic: 4337000649858996379 Time: 2.38885
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:47] [V] [TRT] Tactic: 4501471010995462441 Time: 2.36464
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:47] [V] [TRT] Tactic: 5137655947464784826 Time: 2.32502
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:47] [V] [TRT] Tactic: 5288347012147084929 Time: 2.33104
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:47] [V] [TRT] Tactic: 6645123197870846056 Time: 2.35256
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:47] [V] [TRT] Tactic: 7144526460361122478 Time: 3.14096
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:14:47] [V] [TRT] Tactic: -9137461792520977713 Time: 2.39146
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:47] [V] [TRT] Tactic: -8262349710178828730 Time: 2.3773
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:14:47] [V] [TRT] Tactic: -8133971918129952780 Time: 2.60606
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:14:47] [V] [TRT] Tactic: -6092040395344634144 Time: 3.01404
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:47] [V] [TRT] Tactic: -4787320710726427159 Time: 3.38249
[05/21/2022-03:14:47] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:48] [V] [TRT] Tactic: -3456450830548107839 Time: 2.73166
[05/21/2022-03:14:48] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:48] [V] [TRT] Tactic: -1218658103698133241 Time: 2.58731
[05/21/2022-03:14:48] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:48] [V] [TRT] Tactic: -836875257600482091 Time: 2.52001
[05/21/2022-03:14:48] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:48] [V] [TRT] Tactic: -410470605513481746 Time: 2.296
[05/21/2022-03:14:48] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 2.296
[05/21/2022-03:14:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-03:14:48] [V] [TRT] *************** Autotuning format combination: Float(346112,1,6656,128) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:48] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:48] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:48] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:48] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:14:48] [V] [TRT] Tactic: -9153228964338181824 Time: 3.37877
[05/21/2022-03:14:48] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:14:48] [V] [TRT] Tactic: -7394439838318485025 Time: 2.28947
[05/21/2022-03:14:48] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.28947
[05/21/2022-03:14:48] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:14:48] [V] [TRT] *************** Autotuning format combination: Half(346112,2704,52,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:48] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:48] [V] [TRT] Tactic: 0 Time: 4.42449
[05/21/2022-03:14:48] [V] [TRT] Tactic: 1 Time: 4.31661
[05/21/2022-03:14:48] [V] [TRT] Tactic: 2 Time: 3.80286
[05/21/2022-03:14:50] [V] [TRT] Tactic: 5 Time: 83.0952
[05/21/2022-03:14:50] [V] [TRT] Fastest Tactic: 2 Time: 3.80286
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:50] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,2704:2,52,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:50] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 142_convolutional + 142_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:50] [V] [TRT] Tactic: 3564772625446233998 Time: 1.47952
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:14:50] [V] [TRT] Tactic: 3650389455493082349 Time: 1.51962
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:50] [V] [TRT] Tactic: 5319956359050645452 Time: 1.36284
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:50] [V] [TRT] Tactic: 7205456024582378848 Time: 1.20435
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:14:50] [V] [TRT] Tactic: -6490690591794140522 Time: 1.22562
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:14:50] [V] [TRT] Tactic: -4686027666808657977 Time: 1.20693
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:50] [V] [TRT] Tactic: -4212163711445252890 Time: 1.14845
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:50] [V] [TRT] Tactic: -3898373634979201110 Time: 1.18798
[05/21/2022-03:14:50] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:50] [V] [TRT] Tactic: -2409163523992614473 Time: 1.19634
[05/21/2022-03:14:50] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 1.14845
[05/21/2022-03:14:50] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(173056,1,6656,256) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(5408,676:32,26,1) -> Float(5408,676:32,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(173056,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(346112,1,13312,512) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(10816,676:32,26,1) -> Float(10816,676:32,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(346112,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(173056,676:2,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:50] [V] [TRT] *************** Autotuning format combination: Float(346112,676,26,1) -> Float(172380,676,26,1) ***************
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (FusedConvActConvolution)
[05/21/2022-03:14:50] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudaDepthwiseConvolution)
[05/21/2022-03:14:50] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-03:14:50] [V] [TRT] Tactic: 0 Time: 2.19068
[05/21/2022-03:14:50] [V] [TRT] Tactic: 1 Time: 1.82543
[05/21/2022-03:14:50] [V] [TRT] Tactic: 2 Time: 2.02061
[05/21/2022-03:14:50] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1141372928, available: 536870912
[05/21/2022-03:14:50] [V] [TRT] Tactic: 5 Time: 9.2651
[05/21/2022-03:14:50] [V] [TRT] Fastest Tactic: 1 Time: 1.82543
[05/21/2022-03:14:50] [V] [TRT] Setting workspace to 1141372928enables more tactics for profiling
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-03:14:50] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:50] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-03:14:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:50] [V] [TRT] Tactic: 1062367460111450758 Time: 1.36435
[05/21/2022-03:14:50] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:14:51] [V] [TRT] Tactic: 1698681053543049347 Time: 1.38173
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:51] [V] [TRT] Tactic: 4501471010995462441 Time: 1.09354
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:51] [V] [TRT] Tactic: 5137655947464784826 Time: 1.08044
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:51] [V] [TRT] Tactic: 5288347012147084929 Time: 1.08133
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:14:51] [V] [TRT] Tactic: 5326823351883942011 Time: 1.04617
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:14:51] [V] [TRT] Tactic: 5500448035057547314 Time: 1.22344
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:51] [V] [TRT] Tactic: 6645123197870846056 Time: 1.09985
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:51] [V] [TRT] Tactic: 7144526460361122478 Time: 1.53307
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:51] [V] [TRT] Tactic: -8262349710178828730 Time: 1.09855
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:14:51] [V] [TRT] Tactic: -6576203419454146580 Time: 1.21839
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:51] [V] [TRT] Tactic: -4787320710726427159 Time: 1.59868
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:51] [V] [TRT] Tactic: -3456450830548107839 Time: 1.30925
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:51] [V] [TRT] Tactic: -1218658103698133241 Time: 1.25563
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:51] [V] [TRT] Tactic: -836875257600482091 Time: 1.21937
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:51] [V] [TRT] Tactic: -410470605513481746 Time: 1.06416
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:14:51] [V] [TRT] Tactic: -377491875521947884 Time: 1.07163
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:14:51] [V] [TRT] Tactic: -37215280111360163 Time: 1.05779
[05/21/2022-03:14:51] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 1.04617
[05/21/2022-03:14:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:14:51] [V] [TRT] *************** Autotuning format combination: Float(346112,1,13312,512) -> Float(172380,1,6630,255) ***************
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-03:14:51] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-03:14:51] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-03:14:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] *************** Autotuning format combination: Half(346112,676,26,1) -> Half(172380,676,26,1) ***************
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-03:14:51] [V] [TRT] Tactic: 0 Time: 2.20839
[05/21/2022-03:14:51] [V] [TRT] Tactic: 1 Time: 1.90138
[05/21/2022-03:14:51] [V] [TRT] Tactic: 2 Time: 1.95557
[05/21/2022-03:14:51] [V] [TRT] Tactic: 4 skipped. Scratch requested: 1141372928, available: 536870912
[05/21/2022-03:14:51] [V] [TRT] Tactic: 5 Time: 9.45122
[05/21/2022-03:14:51] [V] [TRT] Fastest Tactic: 1 Time: 1.90138
[05/21/2022-03:14:51] [V] [TRT] Setting workspace to 1141372928enables more tactics for profiling
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-03:14:51] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-03:14:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:14:51] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(172380,676,26,1) ***************
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-03:14:51] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] *************** Autotuning format combination: Half(173056,676:2,26,1) -> Half(86528,676:2,26,1) ***************
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (FusedConvActConvolution)
[05/21/2022-03:14:51] [V] [TRT] FusedConvActConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CudnnConvolution)
[05/21/2022-03:14:51] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CublasConvolution)
[05/21/2022-03:14:51] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:51] [V] [TRT] --------------- Timing Runner: 150_convolutional (CaskConvolution)
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:14:51] [V] [TRT] Tactic: 3066127711859985668 Time: 0.652519
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:51] [V] [TRT] Tactic: 3564772625446233998 Time: 0.729909
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:51] [V] [TRT] Tactic: 5319956359050645452 Time: 0.678405
[05/21/2022-03:14:51] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:52] [V] [TRT] Tactic: 7205456024582378848 Time: 0.571686
[05/21/2022-03:14:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:14:52] [V] [TRT] Tactic: 8163473458334948789 Time: 0.544511
[05/21/2022-03:14:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:52] [V] [TRT] Tactic: -4212163711445252890 Time: 0.55362
[05/21/2022-03:14:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:52] [V] [TRT] Tactic: -3898373634979201110 Time: 0.564837
[05/21/2022-03:14:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:52] [V] [TRT] Tactic: -2409163523992614473 Time: 0.558418
[05/21/2022-03:14:52] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:14:52] [V] [TRT] Tactic: -1716393687483585322 Time: 0.544922
[05/21/2022-03:14:52] [V] [TRT] Fastest Tactic: 8163473458334948789 Time: 0.544511
[05/21/2022-03:14:52] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 8163473458334948789
[05/21/2022-03:14:52] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:52] [V] [TRT] *************** Autotuning format combination: Float(173056,676,26,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:14:52] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:52] [V] [TRT] Tactic: 458751 Time: 3.88489
[05/21/2022-03:14:52] [V] [TRT] Fastest Tactic: 458751 Time: 3.88489
[05/21/2022-03:14:52] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudaDepthwiseConvolution)
[05/21/2022-03:14:52] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:52] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:52] [V] [TRT] Tactic: 0 Time: 5.65229
[05/21/2022-03:14:52] [V] [TRT] Tactic: 1 Time: 4.36701
[05/21/2022-03:14:52] [V] [TRT] Tactic: 2 Time: 3.80602
[05/21/2022-03:14:52] [V] [TRT] Tactic: 5 skipped. Scratch requested: 574514176, available: 536870912
[05/21/2022-03:14:52] [V] [TRT] Fastest Tactic: 2 Time: 3.80602
[05/21/2022-03:14:52] [V] [TRT] Setting workspace to 574514176enables more tactics for profiling
[05/21/2022-03:14:52] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:52] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:52] [V] [TRT] Tactic: 1062367460111450758 Time: 3.93938
[05/21/2022-03:14:52] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v0 Tactic: 1754984623894446479
[05/21/2022-03:14:52] [V] [TRT] Tactic: 1754984623894446479 Time: 4.54678
[05/21/2022-03:14:52] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v0 Tactic: 3611739942397549984
[05/21/2022-03:14:52] [V] [TRT] Tactic: 3611739942397549984 Time: 3.10184
[05/21/2022-03:14:52] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v1 Tactic: 4337000649858996379
[05/21/2022-03:14:53] [V] [TRT] Tactic: 4337000649858996379 Time: 3.13307
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:53] [V] [TRT] Tactic: 4501471010995462441 Time: 3.08452
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:53] [V] [TRT] Tactic: 5137655947464784826 Time: 3.04046
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:53] [V] [TRT] Tactic: 5288347012147084929 Time: 3.05115
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:53] [V] [TRT] Tactic: 6645123197870846056 Time: 3.09633
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:53] [V] [TRT] Tactic: 7144526460361122478 Time: 4.20494
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_large_nn_v1 Tactic: -9137461792520977713
[05/21/2022-03:14:53] [V] [TRT] Tactic: -9137461792520977713 Time: 3.11466
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:53] [V] [TRT] Tactic: -8262349710178828730 Time: 3.11365
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_large_nn_v0 Tactic: -8133971918129952780
[05/21/2022-03:14:53] [V] [TRT] Tactic: -8133971918129952780 Time: 3.41171
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_large_nn_v1 Tactic: -6092040395344634144
[05/21/2022-03:14:53] [V] [TRT] Tactic: -6092040395344634144 Time: 4.13897
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:14:53] [V] [TRT] Tactic: -4787320710726427159 Time: 4.52803
[05/21/2022-03:14:53] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:14:53] [V] [TRT] Tactic: -3456450830548107839 Time: 3.5963
[05/21/2022-03:14:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:14:54] [V] [TRT] Tactic: -1218658103698133241 Time: 3.39088
[05/21/2022-03:14:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:14:54] [V] [TRT] Tactic: -836875257600482091 Time: 3.29661
[05/21/2022-03:14:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:14:54] [V] [TRT] Tactic: -410470605513481746 Time: 3.00279
[05/21/2022-03:14:54] [V] [TRT] Fastest Tactic: -410470605513481746 Time: 3.00279
[05/21/2022-03:14:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -410470605513481746
[05/21/2022-03:14:54] [V] [TRT] *************** Autotuning format combination: Float(173056,1,6656,256) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:14:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x32_sliced1x4_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -9153228964338181824
[05/21/2022-03:14:54] [V] [TRT] Tactic: -9153228964338181824 Time: 4.01863
[05/21/2022-03:14:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_scudnn_128x64_sliced1x2_ldg4_relu_exp_small_nhwc_tn_v1 Tactic: -7394439838318485025
[05/21/2022-03:14:54] [V] [TRT] Tactic: -7394439838318485025 Time: 2.99157
[05/21/2022-03:14:54] [V] [TRT] Fastest Tactic: -7394439838318485025 Time: 2.99157
[05/21/2022-03:14:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -7394439838318485025
[05/21/2022-03:14:54] [V] [TRT] *************** Autotuning format combination: Half(173056,676,26,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:54] [V] [TRT] Tactic: 0 Time: 6.25338
[05/21/2022-03:14:54] [V] [TRT] Tactic: 1 Time: 4.62748
[05/21/2022-03:14:54] [V] [TRT] Tactic: 2 Time: 3.73302
[05/21/2022-03:14:54] [V] [TRT] Tactic: 5 skipped. Scratch requested: 574140928, available: 536870912
[05/21/2022-03:14:54] [V] [TRT] Fastest Tactic: 2 Time: 3.73302
[05/21/2022-03:14:54] [V] [TRT] Setting workspace to 574140928enables more tactics for profiling
[05/21/2022-03:14:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:54] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:54] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 2
[05/21/2022-03:14:54] [V] [TRT] *************** Autotuning format combination: Half(86528,676:2,26,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:14:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (FusedConvActConvolution)
[05/21/2022-03:14:54] [V] [TRT] Tactic: 458751 Time: 3.39902
[05/21/2022-03:14:54] [V] [TRT] Fastest Tactic: 458751 Time: 3.39902
[05/21/2022-03:14:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CudnnConvolution)
[05/21/2022-03:14:54] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:54] [V] [TRT] --------------- Timing Runner: 153_convolutional + 153_convolutional_bn (CaskConvolution)
[05/21/2022-03:14:54] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:14:55] [V] [TRT] Tactic: 3564772625446233998 Time: 1.9949
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_large_nn_v1 Tactic: 3650389455493082349
[05/21/2022-03:14:55] [V] [TRT] Tactic: 3650389455493082349 Time: 2.08751
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:14:55] [V] [TRT] Tactic: 5319956359050645452 Time: 1.80638
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:14:55] [V] [TRT] Tactic: 7205456024582378848 Time: 1.5629
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_large_nn_v1 Tactic: -6490690591794140522
[05/21/2022-03:14:55] [V] [TRT] Tactic: -6490690591794140522 Time: 1.58052
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_large_nn_v1 Tactic: -4686027666808657977
[05/21/2022-03:14:55] [V] [TRT] Tactic: -4686027666808657977 Time: 1.57434
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:14:55] [V] [TRT] Tactic: -4212163711445252890 Time: 1.50877
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:14:55] [V] [TRT] Tactic: -3898373634979201110 Time: 1.55626
[05/21/2022-03:14:55] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:14:55] [V] [TRT] Tactic: -2409163523992614473 Time: 1.53373
[05/21/2022-03:14:55] [V] [TRT] Fastest Tactic: -4212163711445252890 Time: 1.50877
[05/21/2022-03:14:55] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -4212163711445252890
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(86528,1,6656,512) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(2704,169:32,13,1) -> Float(2704,169:32,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(86528,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(43264,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(86528,1,6656,512) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(43264,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(173056,1,13312,1024) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(5408,169:32,13,1) -> Float(5408,169:32,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(173056,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(86528,169:2,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] =============== Computing costs for 
[05/21/2022-03:14:55] [V] [TRT] *************** Autotuning format combination: Float(173056,169,13,1) -> Float(43095,169,13,1) ***************
[05/21/2022-03:14:55] [V] [TRT] --------------- Timing Runner: 161_convolutional (FusedConvActConvolution)
[05/21/2022-03:14:56] [V] [TRT] Tactic: 589823 Time: 1.49827
[05/21/2022-03:14:56] [V] [TRT] Tactic: 786431 Time: 1.49341
[05/21/2022-03:14:56] [V] [TRT] Tactic: 1310719 Time: 3.23607
[05/21/2022-03:14:56] [V] [TRT] Tactic: 1638399 Time: 2.24199
[05/21/2022-03:14:56] [V] [TRT] Tactic: 1835007 Time: 1.49117
[05/21/2022-03:14:56] [V] [TRT] Tactic: 2097151 Time: 1.65832
[05/21/2022-03:14:56] [V] [TRT] Tactic: 3997695 Time: 1.51934
[05/21/2022-03:14:56] [V] [TRT] Tactic: 4194303 Time: 1.40017
[05/21/2022-03:14:56] [V] [TRT] Tactic: 4259839 Time: 1.71474
[05/21/2022-03:14:57] [V] [TRT] Tactic: 4325375 Time: 1.87508
[05/21/2022-03:14:57] [V] [TRT] Tactic: 4521983 Time: 1.7762
[05/21/2022-03:14:57] [V] [TRT] Tactic: 4587519 Time: 1.7006
[05/21/2022-03:14:57] [V] [TRT] Tactic: 4915199 Time: 1.38718
[05/21/2022-03:14:57] [V] [TRT] Tactic: 4980735 Time: 1.79416
[05/21/2022-03:14:57] [V] [TRT] Tactic: 5439487 Time: 1.49874
[05/21/2022-03:14:57] [V] [TRT] Tactic: 5767167 Time: 2.15373
[05/21/2022-03:14:57] [V] [TRT] Tactic: 6750207 Time: 1.484
[05/21/2022-03:14:57] [V] [TRT] Tactic: 6946815 Time: 1.94994
[05/21/2022-03:14:57] [V] [TRT] Tactic: 7012351 Time: 1.66038
[05/21/2022-03:14:58] [V] [TRT] Tactic: 7143423 Time: 2.11895
[05/21/2022-03:14:58] [V] [TRT] Tactic: 7602175 Time: 1.8185
[05/21/2022-03:14:58] [V] [TRT] Tactic: 7798783 Time: 1.49291
[05/21/2022-03:14:58] [V] [TRT] Tactic: 8191999 Time: 2.14654
[05/21/2022-03:14:58] [V] [TRT] Tactic: 8257535 Time: 1.40992
[05/21/2022-03:14:58] [V] [TRT] Tactic: 8323071 Time: 1.35102
[05/21/2022-03:14:58] [V] [TRT] Tactic: 8650751 Time: 2.12538
[05/21/2022-03:14:58] [V] [TRT] Tactic: 9109503 Time: 1.74026
[05/21/2022-03:14:58] [V] [TRT] Tactic: 9568255 Time: 1.38593
[05/21/2022-03:14:58] [V] [TRT] Tactic: 9895935 Time: 1.41257
[05/21/2022-03:14:59] [V] [TRT] Tactic: 10354687 Time: 1.8854
[05/21/2022-03:14:59] [V] [TRT] Tactic: 10551295 Time: 1.30378
[05/21/2022-03:14:59] [V] [TRT] Tactic: 10944511 Time: 1.79472
[05/21/2022-03:14:59] [V] [TRT] Fastest Tactic: 10551295 Time: 1.30378
[05/21/2022-03:14:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudaDepthwiseConvolution)
[05/21/2022-03:14:59] [V] [TRT] CudaDepthwiseConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-03:14:59] [V] [TRT] Tactic: 0 Time: 1.24169
[05/21/2022-03:14:59] [V] [TRT] Tactic: 1 Time: 1.03643
[05/21/2022-03:14:59] [V] [TRT] Tactic: 2 Time: 1.18269
[05/21/2022-03:14:59] [V] [TRT] Tactic: 4 skipped. Scratch requested: 605024256, available: 536870912
[05/21/2022-03:14:59] [V] [TRT] Tactic: 5 Time: 17.3493
[05/21/2022-03:14:59] [V] [TRT] Fastest Tactic: 1 Time: 1.03643
[05/21/2022-03:14:59] [V] [TRT] Setting workspace to 605024256enables more tactics for profiling
[05/21/2022-03:14:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-03:14:59] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:14:59] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v1 Tactic: 1062367460111450758
[05/21/2022-03:14:59] [V] [TRT] Tactic: 1062367460111450758 Time: 0.879896
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v0 Tactic: 1698681053543049347
[05/21/2022-03:14:59] [V] [TRT] Tactic: 1698681053543049347 Time: 0.847376
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v1 Tactic: 4501471010995462441
[05/21/2022-03:14:59] [V] [TRT] Tactic: 4501471010995462441 Time: 0.701172
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v1 Tactic: 5137655947464784826
[05/21/2022-03:14:59] [V] [TRT] Tactic: 5137655947464784826 Time: 0.693711
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v0 Tactic: 5288347012147084929
[05/21/2022-03:14:59] [V] [TRT] Tactic: 5288347012147084929 Time: 0.700267
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v1 Tactic: 5326823351883942011
[05/21/2022-03:14:59] [V] [TRT] Tactic: 5326823351883942011 Time: 0.672298
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v0 Tactic: 5500448035057547314
[05/21/2022-03:14:59] [V] [TRT] Tactic: 5500448035057547314 Time: 0.745495
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v1 Tactic: 6645123197870846056
[05/21/2022-03:14:59] [V] [TRT] Tactic: 6645123197870846056 Time: 0.70707
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v0 Tactic: 7144526460361122478
[05/21/2022-03:14:59] [V] [TRT] Tactic: 7144526460361122478 Time: 1.03984
[05/21/2022-03:14:59] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_medium_nn_v0 Tactic: -8262349710178828730
[05/21/2022-03:14:59] [V] [TRT] Tactic: -8262349710178828730 Time: 0.71319
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_interior_nn_v1 Tactic: -6576203419454146580
[05/21/2022-03:15:00] [V] [TRT] Tactic: -6576203419454146580 Time: 0.770423
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_medium_nn_v0 Tactic: -4787320710726427159
[05/21/2022-03:15:00] [V] [TRT] Tactic: -4787320710726427159 Time: 1.1109
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x32_relu_small_nn_v1 Tactic: -3456450830548107839
[05/21/2022-03:15:00] [V] [TRT] Tactic: -3456450830548107839 Time: 0.814121
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_medium_nn_v0 Tactic: -1218658103698133241
[05/21/2022-03:15:00] [V] [TRT] Tactic: -1218658103698133241 Time: 0.762773
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_small_nn_v0 Tactic: -836875257600482091
[05/21/2022-03:15:00] [V] [TRT] Tactic: -836875257600482091 Time: 0.754649
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_small_nn_v1 Tactic: -410470605513481746
[05/21/2022-03:15:00] [V] [TRT] Tactic: -410470605513481746 Time: 0.694239
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x128_relu_interior_nn_v0 Tactic: -377491875521947884
[05/21/2022-03:15:00] [V] [TRT] Tactic: -377491875521947884 Time: 0.689434
[05/21/2022-03:15:00] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_scudnn_128x64_relu_interior_nn_v1 Tactic: -37215280111360163
[05/21/2022-03:15:00] [V] [TRT] Tactic: -37215280111360163 Time: 0.675117
[05/21/2022-03:15:00] [V] [TRT] Fastest Tactic: 5326823351883942011 Time: 0.672298
[05/21/2022-03:15:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: 5326823351883942011
[05/21/2022-03:15:00] [V] [TRT] *************** Autotuning format combination: Float(173056,1,13312,1024) -> Float(43095,1,3315,255) ***************
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-03:15:00] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-03:15:00] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-03:15:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:00] [V] [TRT] *************** Autotuning format combination: Half(173056,169,13,1) -> Half(43095,169,13,1) ***************
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-03:15:00] [V] [TRT] Tactic: 0 Time: 1.36038
[05/21/2022-03:15:00] [V] [TRT] Tactic: 1 Time: 1.04438
[05/21/2022-03:15:00] [V] [TRT] Tactic: 2 Time: 1.15063
[05/21/2022-03:15:00] [V] [TRT] Tactic: 4 skipped. Scratch requested: 605024256, available: 536870912
[05/21/2022-03:15:00] [V] [TRT] Tactic: 5 Time: 17.2255
[05/21/2022-03:15:00] [V] [TRT] Fastest Tactic: 1 Time: 1.04438
[05/21/2022-03:15:00] [V] [TRT] Setting workspace to 605024256enables more tactics for profiling
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-03:15:00] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-03:15:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:00] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CudnnConvolution Tactic: 1
[05/21/2022-03:15:00] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(43095,169,13,1) ***************
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-03:15:00] [V] [TRT] CaskConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:00] [V] [TRT] *************** Autotuning format combination: Half(86528,169:2,13,1) -> Half(21632,169:2,13,1) ***************
[05/21/2022-03:15:00] [V] [TRT] --------------- Timing Runner: 161_convolutional (FusedConvActConvolution)
[05/21/2022-03:15:00] [V] [TRT] Tactic: 589823 Time: 0.698216
[05/21/2022-03:15:00] [V] [TRT] Tactic: 786431 Time: 0.93362
[05/21/2022-03:15:00] [V] [TRT] Tactic: 1310719 Time: 1.71535
[05/21/2022-03:15:00] [V] [TRT] Tactic: 1638399 Time: 1.18735
[05/21/2022-03:15:00] [V] [TRT] Tactic: 1835007 Time: 0.982031
[05/21/2022-03:15:01] [V] [TRT] Tactic: 2097151 Time: 1.1447
[05/21/2022-03:15:01] [V] [TRT] Tactic: 3997695 Time: 0.984896
[05/21/2022-03:15:01] [V] [TRT] Tactic: 4194303 Time: 0.805638
[05/21/2022-03:15:01] [V] [TRT] Tactic: 4259839 Time: 1.14584
[05/21/2022-03:15:01] [V] [TRT] Tactic: 4325375 Time: 0.959948
[05/21/2022-03:15:01] [V] [TRT] Tactic: 4521983 Time: 0.997161
[05/21/2022-03:15:01] [V] [TRT] Tactic: 4587519 Time: 0.978151
[05/21/2022-03:15:01] [V] [TRT] Tactic: 4915199 Time: 0.819583
[05/21/2022-03:15:01] [V] [TRT] Tactic: 4980735 Time: 0.92265
[05/21/2022-03:15:01] [V] [TRT] Tactic: 5439487 Time: 0.828933
[05/21/2022-03:15:01] [V] [TRT] Tactic: 5767167 Time: 1.02158
[05/21/2022-03:15:01] [V] [TRT] Tactic: 6750207 Time: 0.851302
[05/21/2022-03:15:01] [V] [TRT] Tactic: 6946815 Time: 0.950183
[05/21/2022-03:15:01] [V] [TRT] Tactic: 7012351 Time: 1.14364
[05/21/2022-03:15:02] [V] [TRT] Tactic: 7143423 Time: 1.06337
[05/21/2022-03:15:02] [V] [TRT] Tactic: 7602175 Time: 0.896237
[05/21/2022-03:15:02] [V] [TRT] Tactic: 7798783 Time: 0.934245
[05/21/2022-03:15:02] [V] [TRT] Tactic: 8191999 Time: 1.07416
[05/21/2022-03:15:02] [V] [TRT] Tactic: 8257535 Time: 0.844089
[05/21/2022-03:15:02] [V] [TRT] Tactic: 8323071 Time: 0.772865
[05/21/2022-03:15:02] [V] [TRT] Tactic: 8650751 Time: 1.04846
[05/21/2022-03:15:02] [V] [TRT] Tactic: 9109503 Time: 1.20174
[05/21/2022-03:15:02] [V] [TRT] Tactic: 9568255 Time: 0.820976
[05/21/2022-03:15:02] [V] [TRT] Tactic: 9895935 Time: 0.804219
[05/21/2022-03:15:02] [V] [TRT] Tactic: 10354687 Time: 1.15154
[05/21/2022-03:15:02] [V] [TRT] Tactic: 10551295 Time: 0.668138
[05/21/2022-03:15:02] [V] [TRT] Tactic: 10944511 Time: 0.923008
[05/21/2022-03:15:02] [V] [TRT] Fastest Tactic: 10551295 Time: 0.668138
[05/21/2022-03:15:02] [V] [TRT] --------------- Timing Runner: 161_convolutional (CudnnConvolution)
[05/21/2022-03:15:02] [V] [TRT] CudnnConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:02] [V] [TRT] --------------- Timing Runner: 161_convolutional (CublasConvolution)
[05/21/2022-03:15:02] [V] [TRT] CublasConvolution has no valid tactics for this config, skipping
[05/21/2022-03:15:02] [V] [TRT] --------------- Timing Runner: 161_convolutional (CaskConvolution)
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:15:02] [V] [TRT] Tactic: 3066127711859985668 Time: 0.418776
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_medium_nn_v1 Tactic: 3564772625446233998
[05/21/2022-03:15:02] [V] [TRT] Tactic: 3564772625446233998 Time: 0.470456
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:15:02] [V] [TRT] Tactic: 5319956359050645452 Time: 0.439023
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_medium_nn_v1 Tactic: 7205456024582378848
[05/21/2022-03:15:02] [V] [TRT] Tactic: 7205456024582378848 Time: 0.375515
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:02] [V] [TRT] Tactic: 8163473458334948789 Time: 0.355801
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:15:02] [V] [TRT] Tactic: -4212163711445252890 Time: 0.353451
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_medium_nn_v1 Tactic: -3898373634979201110
[05/21/2022-03:15:02] [V] [TRT] Tactic: -3898373634979201110 Time: 0.360247
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:15:02] [V] [TRT] Tactic: -2409163523992614473 Time: 0.364674
[05/21/2022-03:15:02] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:02] [V] [TRT] Tactic: -1716393687483585322 Time: 0.34765
[05/21/2022-03:15:02] [V] [TRT] Fastest Tactic: -1716393687483585322 Time: 0.34765
[05/21/2022-03:15:02] [V] [TRT] >>>>>>>>>>>>>>> Chose Runner Type: CaskConvolution Tactic: -1716393687483585322
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 001_convolutional + 001_convolutional_bn (000_net) from Float(519168,173056,416,1) to Half(346112,173056:2,416,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(106_convolutional_lrelu) (106_convolutional_bn) from Half(43264,169:2,13,1) to Float(86528,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 107_convolutional + 107_convolutional_bn (106_convolutional_lrelu) from Float(86528,169,13,1) to Half(43264,169:2,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(108_convolutional_lrelu) (108_convolutional_bn) from Half(43264,169:2,13,1) to Float(86528,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to PWN(108_convolutional_lrelu) (108_convolutional_lrelu) from Float(86528,169,13,1) to Half(43264,169:2,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(115_convolutional_lrelu) (115_convolutional_bn) from Half(43264,169:2,13,1) to Float(86528,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 116_convolutional + 116_convolutional_bn (115_convolutional_lrelu) from Float(86528,169,13,1) to Half(43264,169:2,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 119_upsample (118_convolutional_lrelu) from Half(21632,169:2,13,1) to Float(43264,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 129_upsample (128_convolutional_lrelu) from Half(43264,676:2,26,1) to Float(86528,676,26,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to 139_convolutional (139_convolutional) from Half(346112,2704:2,52,1) to Float(689520,2704,52,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to 150_convolutional (150_convolutional) from Half(86528,676:2,26,1) to Float(172380,676,26,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(155_convolutional_lrelu) (155_convolutional_bn) from Half(43264,169:2,13,1) to Float(86528,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 156_convolutional + 156_convolutional_bn (155_convolutional_lrelu) from Float(86528,169,13,1) to Half(43264,169:2,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(157_convolutional_lrelu) (157_convolutional_bn) from Half(43264,169:2,13,1) to Float(86528,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 158_convolutional + 158_convolutional_bn (157_convolutional_lrelu) from Float(86528,169,13,1) to Half(43264,169:2,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to PWN(159_convolutional_lrelu) (159_convolutional_bn) from Half(43264,169:2,13,1) to Float(86528,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Input Tensor 0 to 160_convolutional + 160_convolutional_bn (159_convolutional_lrelu) from Float(86528,169,13,1) to Half(43264,169:2,13,1)
[05/21/2022-03:15:02] [V] [TRT] Adding reformat layer: Reformatted Output Tensor 0 to 161_convolutional (161_convolutional) from Half(21632,169:2,13,1) to Float(43095,169,13,1)
[05/21/2022-03:15:02] [V] [TRT] Formats and tactics selection completed in 780.716 seconds.
[05/21/2022-03:15:02] [V] [TRT] After reformat layers: 241 layers
[05/21/2022-03:15:02] [V] [TRT] Pre-optimized block assignment.
[05/21/2022-03:15:02] [V] [TRT] Block size 11075584
[05/21/2022-03:15:02] [V] [TRT] Block size 11075584
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 11075584
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 5537792
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 86528
[05/21/2022-03:15:02] [V] [TRT] Block size 86528
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 11075584
[05/21/2022-03:15:02] [V] [TRT] Block size 2768896
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 692224
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 1384448
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 346112
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:02] [V] [TRT] Block size 173056
[05/21/2022-03:15:03] [V] [TRT] Block size 346112
[05/21/2022-03:15:03] [V] [TRT] Block size 1384448
[05/21/2022-03:15:03] [V] [TRT] Block size 346112
[05/21/2022-03:15:03] [V] [TRT] Block size 346112
[05/21/2022-03:15:03] [V] [TRT] Block size 173056
[05/21/2022-03:15:03] [V] [TRT] Block size 346112
[05/21/2022-03:15:03] [V] [TRT] Block size 173056
[05/21/2022-03:15:03] [V] [TRT] Block size 346112
[05/21/2022-03:15:03] [V] [TRT] Block size 173056
[05/21/2022-03:15:03] [V] [TRT] Block size 86528
[05/21/2022-03:15:03] [V] [TRT] Block size 536870912
[05/21/2022-03:15:03] [V] [TRT] Total Activation Memory: 759680512
[05/21/2022-03:15:03] [I] [TRT] Detected 1 inputs and 3 output network tensors.
[05/21/2022-03:15:03] [V] [TRT] 001_convolutional + 001_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_small_nn_v1 Tactic: 5319956359050645452
[05/21/2022-03:15:03] [V] [TRT] 002_convolutional + 002_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_small_nn_v1 Tactic: -2409163523992614473
[05/21/2022-03:15:03] [V] [TRT] 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 006_convolutional + 006_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x32_relu_interior_nn_v1 Tactic: 3066127711859985668
[05/21/2022-03:15:03] [V] [TRT] 007_convolutional + 007_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 009_convolutional + 009_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 011_convolutional + 011_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 012_convolutional + 012_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:15:03] [V] [TRT] 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 016_convolutional + 016_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 017_convolutional + 017_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 019_convolutional + 019_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 020_convolutional + 020_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 022_convolutional + 022_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 024_convolutional + 024_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 025_convolutional + 025_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:15:03] [V] [TRT] 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 029_convolutional + 029_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 030_convolutional + 030_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 032_convolutional + 032_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 033_convolutional + 033_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 035_convolutional + 035_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 036_convolutional + 036_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 038_convolutional + 038_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 039_convolutional + 039_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 041_convolutional + 041_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 042_convolutional + 042_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 044_convolutional + 044_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 045_convolutional + 045_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 047_convolutional + 047_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 048_convolutional + 048_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 050_convolutional + 050_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 051_convolutional + 051_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 053_convolutional + 053_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 055_convolutional + 055_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 056_convolutional + 056_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:15:03] [V] [TRT] 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 060_convolutional + 060_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 061_convolutional + 061_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 063_convolutional + 063_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 064_convolutional + 064_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 066_convolutional + 066_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 067_convolutional + 067_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 069_convolutional + 069_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 070_convolutional + 070_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 072_convolutional + 072_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 073_convolutional + 073_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 075_convolutional + 075_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 076_convolutional + 076_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 078_convolutional + 078_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 079_convolutional + 079_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 081_convolutional + 081_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 082_convolutional + 082_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 084_convolutional + 084_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 086_convolutional + 086_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:03] [V] [TRT] 087_convolutional + 087_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:15:03] [V] [TRT] 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 091_convolutional + 091_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 092_convolutional + 092_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 094_convolutional + 094_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 095_convolutional + 095_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 097_convolutional + 097_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:03] [V] [TRT] 098_convolutional + 098_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:03] [V] [TRT] 100_convolutional + 100_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 101_convolutional + 101_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 103_convolutional + 103_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 105_convolutional + 105_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 106_convolutional + 106_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 107_convolutional + 107_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 108_convolutional + 108_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 115_convolutional + 115_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:04] [V] [TRT] 116_convolutional + 116_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 117_convolutional + 117_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 118_convolutional + 118_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 121_convolutional + 121_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 123_convolutional + 123_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 124_convolutional + 124_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 125_convolutional + 125_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 126_convolutional + 126_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 127_convolutional + 127_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 128_convolutional + 128_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 131_convolutional + 131_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 133_convolutional + 133_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 134_convolutional + 134_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 135_convolutional + 135_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 136_convolutional + 136_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 137_convolutional + 137_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 138_convolutional + 138_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 139_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:04] [V] [TRT] 142_convolutional + 142_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:15:04] [V] [TRT] 144_convolutional + 144_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 145_convolutional + 145_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 146_convolutional + 146_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 147_convolutional + 147_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 148_convolutional + 148_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:04] [V] [TRT] 149_convolutional + 149_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:04] [V] [TRT] 150_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x64_relu_interior_nn_v1 Tactic: 8163473458334948789
[05/21/2022-03:15:04] [V] [TRT] 153_convolutional + 153_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_small_nn_v1 Tactic: -4212163711445252890
[05/21/2022-03:15:04] [V] [TRT] 155_convolutional + 155_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:05] [V] [TRT] 156_convolutional + 156_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:05] [V] [TRT] 157_convolutional + 157_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:05] [V] [TRT] 158_convolutional + 158_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:05] [V] [TRT] 159_convolutional + 159_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:06] [V] [TRT] 160_convolutional + 160_convolutional_bn Set Tactic Name: maxwell_fp16x2_hcudnn_winograd_fp16x2_128x128_ldg1_ldg4_relu_tile148m_nt_v1 Tactic: 4772821744921268633
[05/21/2022-03:15:06] [V] [TRT] 161_convolutional Set Tactic Name: maxwell_fp16x2_hcudnn_fp16x2_128x128_relu_interior_nn_v1 Tactic: -1716393687483585322
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 001_convolutional + 001_convolutional_bn Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 001_convolutional + 001_convolutional_bn Host Persistent: 1664 Device Persistent: 1040896 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 002_convolutional + 002_convolutional_bn Host Persistent: 1664 Device Persistent: 296960 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn Host Persistent: 3200 Device Persistent: 276480 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 006_convolutional + 006_convolutional_bn Host Persistent: 3200 Device Persistent: 264192 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 007_convolutional + 007_convolutional_bn Host Persistent: 512 Device Persistent: 102912 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 009_convolutional + 009_convolutional_bn Host Persistent: 3200 Device Persistent: 268288 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 011_convolutional + 011_convolutional_bn Host Persistent: 3200 Device Persistent: 276480 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 012_convolutional + 012_convolutional_bn Host Persistent: 1664 Device Persistent: 212992 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn Host Persistent: 3200 Device Persistent: 98304 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 016_convolutional + 016_convolutional_bn Host Persistent: 3200 Device Persistent: 73728 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 017_convolutional + 017_convolutional_bn Host Persistent: 512 Device Persistent: 205312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 019_convolutional + 019_convolutional_bn Host Persistent: 3200 Device Persistent: 73728 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 020_convolutional + 020_convolutional_bn Host Persistent: 512 Device Persistent: 205312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 022_convolutional + 022_convolutional_bn Host Persistent: 3200 Device Persistent: 73728 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 024_convolutional + 024_convolutional_bn Host Persistent: 3200 Device Persistent: 98304 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 025_convolutional + 025_convolutional_bn Host Persistent: 1664 Device Persistent: 606720 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn Host Persistent: 3200 Device Persistent: 147968 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 029_convolutional + 029_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 030_convolutional + 030_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 032_convolutional + 032_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 033_convolutional + 033_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 035_convolutional + 035_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 036_convolutional + 036_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 038_convolutional + 038_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 039_convolutional + 039_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 041_convolutional + 041_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 042_convolutional + 042_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 044_convolutional + 044_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 045_convolutional + 045_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 047_convolutional + 047_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 048_convolutional + 048_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 050_convolutional + 050_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 051_convolutional + 051_convolutional_bn Host Persistent: 512 Device Persistent: 819712 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 053_convolutional + 053_convolutional_bn Host Persistent: 3200 Device Persistent: 49664 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 055_convolutional + 055_convolutional_bn Host Persistent: 3200 Device Persistent: 147968 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 056_convolutional + 056_convolutional_bn Host Persistent: 1664 Device Persistent: 2364416 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn Host Persistent: 3200 Device Persistent: 529408 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 060_convolutional + 060_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 061_convolutional + 061_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 063_convolutional + 063_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 064_convolutional + 064_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 066_convolutional + 066_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 067_convolutional + 067_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 069_convolutional + 069_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 070_convolutional + 070_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 072_convolutional + 072_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 073_convolutional + 073_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 075_convolutional + 075_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 076_convolutional + 076_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 078_convolutional + 078_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 079_convolutional + 079_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 081_convolutional + 081_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 082_convolutional + 082_convolutional_bn Host Persistent: 512 Device Persistent: 3277312 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 084_convolutional + 084_convolutional_bn Host Persistent: 3200 Device Persistent: 135680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 086_convolutional + 086_convolutional_bn Host Persistent: 3200 Device Persistent: 529408 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 087_convolutional + 087_convolutional_bn Host Persistent: 1664 Device Persistent: 9440256 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn Host Persistent: 3200 Device Persistent: 2100224 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 091_convolutional + 091_convolutional_bn Host Persistent: 3200 Device Persistent: 526336 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 092_convolutional + 092_convolutional_bn Host Persistent: 512 Device Persistent: 13108224 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 094_convolutional + 094_convolutional_bn Host Persistent: 3200 Device Persistent: 526336 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 095_convolutional + 095_convolutional_bn Host Persistent: 512 Device Persistent: 13108224 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 097_convolutional + 097_convolutional_bn Host Persistent: 3200 Device Persistent: 526336 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 098_convolutional + 098_convolutional_bn Host Persistent: 512 Device Persistent: 13108224 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 100_convolutional + 100_convolutional_bn Host Persistent: 3200 Device Persistent: 526336 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 101_convolutional + 101_convolutional_bn Host Persistent: 512 Device Persistent: 13108224 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut) Host Persistent: 340 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 103_convolutional + 103_convolutional_bn Host Persistent: 3200 Device Persistent: 526336 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 105_convolutional + 105_convolutional_bn Host Persistent: 3200 Device Persistent: 2100224 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 106_convolutional + 106_convolutional_bn Host Persistent: 3200 Device Persistent: 1050624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(106_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(106_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 107_convolutional + 107_convolutional_bn Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 107_convolutional + 107_convolutional_bn Host Persistent: 512 Device Persistent: 26216448 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(107_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 108_convolutional + 108_convolutional_bn Host Persistent: 3200 Device Persistent: 1050624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(108_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(108_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to PWN(108_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 109_maxpool Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 111_maxpool Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 113_maxpool Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 113_maxpool copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 111_maxpool copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 109_maxpool copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 108_convolutional_lrelu copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 115_convolutional + 115_convolutional_bn Host Persistent: 3200 Device Persistent: 2099200 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(115_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(115_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 116_convolutional + 116_convolutional_bn Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 116_convolutional + 116_convolutional_bn Host Persistent: 512 Device Persistent: 26216448 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(116_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 117_convolutional + 117_convolutional_bn Host Persistent: 3200 Device Persistent: 1050624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(117_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 118_convolutional + 118_convolutional_bn Host Persistent: 3200 Device Persistent: 263680 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(118_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 119_upsample Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 119_upsample Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 121_convolutional + 121_convolutional_bn Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(121_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 119_upsample copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 123_convolutional + 123_convolutional_bn Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(123_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 124_convolutional + 124_convolutional_bn Host Persistent: 512 Device Persistent: 6554624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(124_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 125_convolutional + 125_convolutional_bn Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(125_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 126_convolutional + 126_convolutional_bn Host Persistent: 512 Device Persistent: 6554624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(126_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 127_convolutional + 127_convolutional_bn Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(127_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 128_convolutional + 128_convolutional_bn Host Persistent: 3200 Device Persistent: 70144 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(128_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 129_upsample Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 129_upsample Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 131_convolutional + 131_convolutional_bn Host Persistent: 3200 Device Persistent: 82432 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(131_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 129_upsample copy Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 133_convolutional + 133_convolutional_bn Host Persistent: 3200 Device Persistent: 82432 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(133_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 134_convolutional + 134_convolutional_bn Host Persistent: 512 Device Persistent: 1638912 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(134_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 135_convolutional + 135_convolutional_bn Host Persistent: 3200 Device Persistent: 82432 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(135_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 136_convolutional + 136_convolutional_bn Host Persistent: 512 Device Persistent: 1638912 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(136_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 137_convolutional + 137_convolutional_bn Host Persistent: 3200 Device Persistent: 82432 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(137_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 138_convolutional + 138_convolutional_bn Host Persistent: 512 Device Persistent: 1638912 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(138_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 139_convolutional Host Persistent: 3200 Device Persistent: 147968 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to 139_convolutional Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 142_convolutional + 142_convolutional_bn Host Persistent: 1664 Device Persistent: 594432 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(142_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 144_convolutional + 144_convolutional_bn Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(144_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 145_convolutional + 145_convolutional_bn Host Persistent: 512 Device Persistent: 6554624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(145_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 146_convolutional + 146_convolutional_bn Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(146_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 147_convolutional + 147_convolutional_bn Host Persistent: 512 Device Persistent: 6554624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(147_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 148_convolutional + 148_convolutional_bn Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(148_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 149_convolutional + 149_convolutional_bn Host Persistent: 512 Device Persistent: 6554624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(149_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 150_convolutional Host Persistent: 3200 Device Persistent: 266752 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to 150_convolutional Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 153_convolutional + 153_convolutional_bn Host Persistent: 1664 Device Persistent: 2361344 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(153_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 155_convolutional + 155_convolutional_bn Host Persistent: 3200 Device Persistent: 1050624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(155_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(155_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 156_convolutional + 156_convolutional_bn Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 156_convolutional + 156_convolutional_bn Host Persistent: 512 Device Persistent: 26216448 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(156_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 157_convolutional + 157_convolutional_bn Host Persistent: 3200 Device Persistent: 1050624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(157_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(157_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 158_convolutional + 158_convolutional_bn Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 158_convolutional + 158_convolutional_bn Host Persistent: 512 Device Persistent: 26216448 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(158_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 159_convolutional + 159_convolutional_bn Host Persistent: 3200 Device Persistent: 1050624 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to PWN(159_convolutional_lrelu) Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(159_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Input Tensor 0 to 160_convolutional + 160_convolutional_bn Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 160_convolutional + 160_convolutional_bn Host Persistent: 512 Device Persistent: 26216448 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: PWN(160_convolutional_lrelu) Host Persistent: 244 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: 161_convolutional Host Persistent: 3200 Device Persistent: 525824 Scratch Memory: 0
[05/21/2022-03:15:06] [V] [TRT] Layer: Reformatting CopyNode for Output Tensor 0 to 161_convolutional Host Persistent: 0 Device Persistent: 0 Scratch Memory: 0
[05/21/2022-03:15:06] [I] [TRT] Total Host Persistent Memory: 256544
[05/21/2022-03:15:06] [I] [TRT] Total Device Persistent Memory: 294645248
[05/21/2022-03:15:06] [I] [TRT] Total Scratch Memory: 0
[05/21/2022-03:15:06] [I] [TRT] [MemUsageStats] Peak memory usage of TRT CPU/GPU memory allocators: CPU 375 MiB, GPU 768 MiB
[05/21/2022-03:15:06] [I] [TRT] [BlockAssignment] Algorithm ShiftNTopDown took 214.952ms to assign 7 blocks to 226 nodes requiring 33918976 bytes.
[05/21/2022-03:15:06] [V] [TRT] Optimized block assignment.
[05/21/2022-03:15:06] [V] [TRT] Block size 11075584
[05/21/2022-03:15:06] [V] [TRT] Block size 11075584
[05/21/2022-03:15:06] [V] [TRT] Block size 5537792
[05/21/2022-03:15:06] [V] [TRT] Block size 5537792
[05/21/2022-03:15:06] [V] [TRT] Block size 346112
[05/21/2022-03:15:06] [V] [TRT] Block size 173056
[05/21/2022-03:15:06] [V] [TRT] Block size 173056
[05/21/2022-03:15:06] [I] [TRT] Total Activation Memory: 33918976
[05/21/2022-03:15:06] [V] [TRT] Using cublas as a tactic source
[05/21/2022-03:15:06] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU -11, now: CPU 1558, GPU 3812 (MiB)
[05/21/2022-03:15:06] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-03:15:06] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +8, now: CPU 1558, GPU 3820 (MiB)
[05/21/2022-03:15:06] [V] [TRT] Engine generation completed in 790.218 seconds.
[05/21/2022-03:15:06] [V] [TRT] Deleting timing cache: 1076 entries, 5233 hits
[05/21/2022-03:15:06] [V] [TRT] Engine Layer Information:
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 001_convolutional + 001_convolutional_bn, Tactic: 0, 000_net[Float(1,3,416,416)] -> Reformatted Input Tensor 0 to 001_convolutional + 001_convolutional_bn[Half(1,3,416,416)]
Layer(CaskConvolution): 001_convolutional + 001_convolutional_bn, Tactic: 5319956359050645452, Reformatted Input Tensor 0 to 001_convolutional + 001_convolutional_bn[Half(1,3,416,416)] -> 001_convolutional_bn[Half(1,32,416,416)]
Layer(PointWiseV2): PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish), Tactic: 16, 001_convolutional_bn[Half(1,32,416,416)] -> 001_convolutional_mish[Half(1,32,416,416)]
Layer(CaskConvolution): 002_convolutional + 002_convolutional_bn, Tactic: -2409163523992614473, 001_convolutional_mish[Half(1,32,416,416)] -> 002_convolutional_bn[Half(1,64,208,208)]
Layer(PointWiseV2): PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish), Tactic: 18, 002_convolutional_bn[Half(1,64,208,208)] -> 002_convolutional_mish[Half(1,64,208,208)]
Layer(CaskConvolution): 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn, Tactic: 8163473458334948789, 002_convolutional_mish[Half(1,64,208,208)] -> 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn[Half(1,128,208,208)]
Layer(PointWiseV2): PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish), Tactic: 3, 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn[Half(1,64,208,208)] -> 010_route[Half(1,64,208,208)]
Layer(PointWiseV2): PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish), Tactic: 17, 003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn[Half(1,64,208,208)] -> 005_convolutional_mish[Half(1,64,208,208)]
Layer(CaskConvolution): 006_convolutional + 006_convolutional_bn, Tactic: 3066127711859985668, 005_convolutional_mish[Half(1,64,208,208)] -> 006_convolutional_bn[Half(1,32,208,208)]
Layer(PointWiseV2): PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish), Tactic: 18, 006_convolutional_bn[Half(1,32,208,208)] -> 006_convolutional_mish[Half(1,32,208,208)]
Layer(CaskConvolution): 007_convolutional + 007_convolutional_bn, Tactic: 4772821744921268633, 006_convolutional_mish[Half(1,32,208,208)] -> 007_convolutional_bn[Half(1,64,208,208)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut), Tactic: 12, 007_convolutional_bn[Half(1,64,208,208)], 005_convolutional_mish[Half(1,64,208,208)] -> 008_shortcut[Half(1,64,208,208)]
Layer(CaskConvolution): 009_convolutional + 009_convolutional_bn, Tactic: 8163473458334948789, 008_shortcut[Half(1,64,208,208)] -> 009_convolutional_bn[Half(1,64,208,208)]
Layer(PointWiseV2): PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish), Tactic: 17, 009_convolutional_bn[Half(1,64,208,208)] -> 010_route[Half(1,64,208,208)]
Layer(CaskConvolution): 011_convolutional + 011_convolutional_bn, Tactic: 8163473458334948789, 010_route[Half(1,128,208,208)] -> 011_convolutional_bn[Half(1,64,208,208)]
Layer(PointWiseV2): PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish), Tactic: 18, 011_convolutional_bn[Half(1,64,208,208)] -> 011_convolutional_mish[Half(1,64,208,208)]
Layer(CaskConvolution): 012_convolutional + 012_convolutional_bn, Tactic: -4212163711445252890, 011_convolutional_mish[Half(1,64,208,208)] -> 012_convolutional_bn[Half(1,128,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish), Tactic: 18, 012_convolutional_bn[Half(1,128,104,104)] -> 012_convolutional_mish[Half(1,128,104,104)]
Layer(CaskConvolution): 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn, Tactic: 8163473458334948789, 012_convolutional_mish[Half(1,128,104,104)] -> 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn[Half(1,128,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish), Tactic: 17, 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn[Half(1,64,104,104)] -> 023_route[Half(1,64,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish), Tactic: 17, 013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn[Half(1,64,104,104)] -> 015_convolutional_mish[Half(1,64,104,104)]
Layer(CaskConvolution): 016_convolutional + 016_convolutional_bn, Tactic: 8163473458334948789, 015_convolutional_mish[Half(1,64,104,104)] -> 016_convolutional_bn[Half(1,64,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish), Tactic: 18, 016_convolutional_bn[Half(1,64,104,104)] -> 016_convolutional_mish[Half(1,64,104,104)]
Layer(CaskConvolution): 017_convolutional + 017_convolutional_bn, Tactic: 4772821744921268633, 016_convolutional_mish[Half(1,64,104,104)] -> 017_convolutional_bn[Half(1,64,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut), Tactic: 16, 017_convolutional_bn[Half(1,64,104,104)], 015_convolutional_mish[Half(1,64,104,104)] -> 018_shortcut[Half(1,64,104,104)]
Layer(CaskConvolution): 019_convolutional + 019_convolutional_bn, Tactic: 8163473458334948789, 018_shortcut[Half(1,64,104,104)] -> 019_convolutional_bn[Half(1,64,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish), Tactic: 18, 019_convolutional_bn[Half(1,64,104,104)] -> 019_convolutional_mish[Half(1,64,104,104)]
Layer(CaskConvolution): 020_convolutional + 020_convolutional_bn, Tactic: 4772821744921268633, 019_convolutional_mish[Half(1,64,104,104)] -> 020_convolutional_bn[Half(1,64,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut), Tactic: 16, 020_convolutional_bn[Half(1,64,104,104)], 018_shortcut[Half(1,64,104,104)] -> 021_shortcut[Half(1,64,104,104)]
Layer(CaskConvolution): 022_convolutional + 022_convolutional_bn, Tactic: 8163473458334948789, 021_shortcut[Half(1,64,104,104)] -> 022_convolutional_bn[Half(1,64,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish), Tactic: 17, 022_convolutional_bn[Half(1,64,104,104)] -> 023_route[Half(1,64,104,104)]
Layer(CaskConvolution): 024_convolutional + 024_convolutional_bn, Tactic: 8163473458334948789, 023_route[Half(1,128,104,104)] -> 024_convolutional_bn[Half(1,128,104,104)]
Layer(PointWiseV2): PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish), Tactic: 18, 024_convolutional_bn[Half(1,128,104,104)] -> 024_convolutional_mish[Half(1,128,104,104)]
Layer(CaskConvolution): 025_convolutional + 025_convolutional_bn, Tactic: -4212163711445252890, 024_convolutional_mish[Half(1,128,104,104)] -> 025_convolutional_bn[Half(1,256,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish), Tactic: 18, 025_convolutional_bn[Half(1,256,52,52)] -> 025_convolutional_mish[Half(1,256,52,52)]
Layer(CaskConvolution): 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn, Tactic: 8163473458334948789, 025_convolutional_mish[Half(1,256,52,52)] -> 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn[Half(1,256,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish), Tactic: 17, 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn[Half(1,128,52,52)] -> 054_route[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish), Tactic: 17, 026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn[Half(1,128,52,52)] -> 028_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 029_convolutional + 029_convolutional_bn, Tactic: -1716393687483585322, 028_convolutional_mish[Half(1,128,52,52)] -> 029_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish), Tactic: 18, 029_convolutional_bn[Half(1,128,52,52)] -> 029_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 030_convolutional + 030_convolutional_bn, Tactic: 4772821744921268633, 029_convolutional_mish[Half(1,128,52,52)] -> 030_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut), Tactic: 18, 030_convolutional_bn[Half(1,128,52,52)], 028_convolutional_mish[Half(1,128,52,52)] -> 031_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 032_convolutional + 032_convolutional_bn, Tactic: -1716393687483585322, 031_shortcut[Half(1,128,52,52)] -> 032_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish), Tactic: 18, 032_convolutional_bn[Half(1,128,52,52)] -> 032_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 033_convolutional + 033_convolutional_bn, Tactic: 4772821744921268633, 032_convolutional_mish[Half(1,128,52,52)] -> 033_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut), Tactic: 18, 033_convolutional_bn[Half(1,128,52,52)], 031_shortcut[Half(1,128,52,52)] -> 034_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 035_convolutional + 035_convolutional_bn, Tactic: -1716393687483585322, 034_shortcut[Half(1,128,52,52)] -> 035_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish), Tactic: 18, 035_convolutional_bn[Half(1,128,52,52)] -> 035_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 036_convolutional + 036_convolutional_bn, Tactic: 4772821744921268633, 035_convolutional_mish[Half(1,128,52,52)] -> 036_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut), Tactic: 18, 036_convolutional_bn[Half(1,128,52,52)], 034_shortcut[Half(1,128,52,52)] -> 037_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 038_convolutional + 038_convolutional_bn, Tactic: -1716393687483585322, 037_shortcut[Half(1,128,52,52)] -> 038_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish), Tactic: 18, 038_convolutional_bn[Half(1,128,52,52)] -> 038_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 039_convolutional + 039_convolutional_bn, Tactic: 4772821744921268633, 038_convolutional_mish[Half(1,128,52,52)] -> 039_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut), Tactic: 18, 039_convolutional_bn[Half(1,128,52,52)], 037_shortcut[Half(1,128,52,52)] -> 040_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 041_convolutional + 041_convolutional_bn, Tactic: -1716393687483585322, 040_shortcut[Half(1,128,52,52)] -> 041_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish), Tactic: 18, 041_convolutional_bn[Half(1,128,52,52)] -> 041_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 042_convolutional + 042_convolutional_bn, Tactic: 4772821744921268633, 041_convolutional_mish[Half(1,128,52,52)] -> 042_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut), Tactic: 18, 042_convolutional_bn[Half(1,128,52,52)], 040_shortcut[Half(1,128,52,52)] -> 043_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 044_convolutional + 044_convolutional_bn, Tactic: -1716393687483585322, 043_shortcut[Half(1,128,52,52)] -> 044_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish), Tactic: 18, 044_convolutional_bn[Half(1,128,52,52)] -> 044_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 045_convolutional + 045_convolutional_bn, Tactic: 4772821744921268633, 044_convolutional_mish[Half(1,128,52,52)] -> 045_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut), Tactic: 18, 045_convolutional_bn[Half(1,128,52,52)], 043_shortcut[Half(1,128,52,52)] -> 046_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 047_convolutional + 047_convolutional_bn, Tactic: -1716393687483585322, 046_shortcut[Half(1,128,52,52)] -> 047_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish), Tactic: 18, 047_convolutional_bn[Half(1,128,52,52)] -> 047_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 048_convolutional + 048_convolutional_bn, Tactic: 4772821744921268633, 047_convolutional_mish[Half(1,128,52,52)] -> 048_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut), Tactic: 18, 048_convolutional_bn[Half(1,128,52,52)], 046_shortcut[Half(1,128,52,52)] -> 049_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 050_convolutional + 050_convolutional_bn, Tactic: -1716393687483585322, 049_shortcut[Half(1,128,52,52)] -> 050_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish), Tactic: 18, 050_convolutional_bn[Half(1,128,52,52)] -> 050_convolutional_mish[Half(1,128,52,52)]
Layer(CaskConvolution): 051_convolutional + 051_convolutional_bn, Tactic: 4772821744921268633, 050_convolutional_mish[Half(1,128,52,52)] -> 051_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut), Tactic: 18, 051_convolutional_bn[Half(1,128,52,52)], 049_shortcut[Half(1,128,52,52)] -> 052_shortcut[Half(1,128,52,52)]
Layer(CaskConvolution): 053_convolutional + 053_convolutional_bn, Tactic: -1716393687483585322, 052_shortcut[Half(1,128,52,52)] -> 053_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish), Tactic: 17, 053_convolutional_bn[Half(1,128,52,52)] -> 054_route[Half(1,128,52,52)]
Layer(CaskConvolution): 055_convolutional + 055_convolutional_bn, Tactic: 8163473458334948789, 054_route[Half(1,256,52,52)] -> 055_convolutional_bn[Half(1,256,52,52)]
Layer(PointWiseV2): PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish), Tactic: 18, 055_convolutional_bn[Half(1,256,52,52)] -> 055_convolutional_mish[Half(1,256,52,52)]
Layer(CaskConvolution): 056_convolutional + 056_convolutional_bn, Tactic: -4212163711445252890, 055_convolutional_mish[Half(1,256,52,52)] -> 056_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish), Tactic: 18, 056_convolutional_bn[Half(1,512,26,26)] -> 056_convolutional_mish[Half(1,512,26,26)]
Layer(CaskConvolution): 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn, Tactic: 8163473458334948789, 056_convolutional_mish[Half(1,512,26,26)] -> 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish), Tactic: 17, 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn[Half(1,256,26,26)] -> 085_route[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish), Tactic: 17, 057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn[Half(1,256,26,26)] -> 059_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 060_convolutional + 060_convolutional_bn, Tactic: -1716393687483585322, 059_convolutional_mish[Half(1,256,26,26)] -> 060_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish), Tactic: 18, 060_convolutional_bn[Half(1,256,26,26)] -> 060_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 061_convolutional + 061_convolutional_bn, Tactic: 4772821744921268633, 060_convolutional_mish[Half(1,256,26,26)] -> 061_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut), Tactic: 18, 061_convolutional_bn[Half(1,256,26,26)], 059_convolutional_mish[Half(1,256,26,26)] -> 062_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 063_convolutional + 063_convolutional_bn, Tactic: -1716393687483585322, 062_shortcut[Half(1,256,26,26)] -> 063_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish), Tactic: 18, 063_convolutional_bn[Half(1,256,26,26)] -> 063_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 064_convolutional + 064_convolutional_bn, Tactic: 4772821744921268633, 063_convolutional_mish[Half(1,256,26,26)] -> 064_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut), Tactic: 18, 064_convolutional_bn[Half(1,256,26,26)], 062_shortcut[Half(1,256,26,26)] -> 065_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 066_convolutional + 066_convolutional_bn, Tactic: -1716393687483585322, 065_shortcut[Half(1,256,26,26)] -> 066_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish), Tactic: 18, 066_convolutional_bn[Half(1,256,26,26)] -> 066_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 067_convolutional + 067_convolutional_bn, Tactic: 4772821744921268633, 066_convolutional_mish[Half(1,256,26,26)] -> 067_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut), Tactic: 18, 067_convolutional_bn[Half(1,256,26,26)], 065_shortcut[Half(1,256,26,26)] -> 068_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 069_convolutional + 069_convolutional_bn, Tactic: -1716393687483585322, 068_shortcut[Half(1,256,26,26)] -> 069_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish), Tactic: 18, 069_convolutional_bn[Half(1,256,26,26)] -> 069_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 070_convolutional + 070_convolutional_bn, Tactic: 4772821744921268633, 069_convolutional_mish[Half(1,256,26,26)] -> 070_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut), Tactic: 18, 070_convolutional_bn[Half(1,256,26,26)], 068_shortcut[Half(1,256,26,26)] -> 071_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 072_convolutional + 072_convolutional_bn, Tactic: -1716393687483585322, 071_shortcut[Half(1,256,26,26)] -> 072_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish), Tactic: 18, 072_convolutional_bn[Half(1,256,26,26)] -> 072_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 073_convolutional + 073_convolutional_bn, Tactic: 4772821744921268633, 072_convolutional_mish[Half(1,256,26,26)] -> 073_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut), Tactic: 18, 073_convolutional_bn[Half(1,256,26,26)], 071_shortcut[Half(1,256,26,26)] -> 074_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 075_convolutional + 075_convolutional_bn, Tactic: -1716393687483585322, 074_shortcut[Half(1,256,26,26)] -> 075_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish), Tactic: 18, 075_convolutional_bn[Half(1,256,26,26)] -> 075_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 076_convolutional + 076_convolutional_bn, Tactic: 4772821744921268633, 075_convolutional_mish[Half(1,256,26,26)] -> 076_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut), Tactic: 18, 076_convolutional_bn[Half(1,256,26,26)], 074_shortcut[Half(1,256,26,26)] -> 077_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 078_convolutional + 078_convolutional_bn, Tactic: -1716393687483585322, 077_shortcut[Half(1,256,26,26)] -> 078_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish), Tactic: 18, 078_convolutional_bn[Half(1,256,26,26)] -> 078_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 079_convolutional + 079_convolutional_bn, Tactic: 4772821744921268633, 078_convolutional_mish[Half(1,256,26,26)] -> 079_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut), Tactic: 18, 079_convolutional_bn[Half(1,256,26,26)], 077_shortcut[Half(1,256,26,26)] -> 080_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 081_convolutional + 081_convolutional_bn, Tactic: -1716393687483585322, 080_shortcut[Half(1,256,26,26)] -> 081_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish), Tactic: 18, 081_convolutional_bn[Half(1,256,26,26)] -> 081_convolutional_mish[Half(1,256,26,26)]
Layer(CaskConvolution): 082_convolutional + 082_convolutional_bn, Tactic: 4772821744921268633, 081_convolutional_mish[Half(1,256,26,26)] -> 082_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut), Tactic: 18, 082_convolutional_bn[Half(1,256,26,26)], 080_shortcut[Half(1,256,26,26)] -> 083_shortcut[Half(1,256,26,26)]
Layer(CaskConvolution): 084_convolutional + 084_convolutional_bn, Tactic: -1716393687483585322, 083_shortcut[Half(1,256,26,26)] -> 084_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish), Tactic: 17, 084_convolutional_bn[Half(1,256,26,26)] -> 085_route[Half(1,256,26,26)]
Layer(CaskConvolution): 086_convolutional + 086_convolutional_bn, Tactic: 8163473458334948789, 085_route[Half(1,512,26,26)] -> 086_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish), Tactic: 18, 086_convolutional_bn[Half(1,512,26,26)] -> 086_convolutional_mish[Half(1,512,26,26)]
Layer(CaskConvolution): 087_convolutional + 087_convolutional_bn, Tactic: -4212163711445252890, 086_convolutional_mish[Half(1,512,26,26)] -> 087_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish), Tactic: 18, 087_convolutional_bn[Half(1,1024,13,13)] -> 087_convolutional_mish[Half(1,1024,13,13)]
Layer(CaskConvolution): 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn, Tactic: -1716393687483585322, 087_convolutional_mish[Half(1,1024,13,13)] -> 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish), Tactic: 17, 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn[Half(1,512,13,13)] -> 104_route[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish), Tactic: 17, 088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn[Half(1,512,13,13)] -> 090_convolutional_mish[Half(1,512,13,13)]
Layer(CaskConvolution): 091_convolutional + 091_convolutional_bn, Tactic: -1716393687483585322, 090_convolutional_mish[Half(1,512,13,13)] -> 091_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish), Tactic: 18, 091_convolutional_bn[Half(1,512,13,13)] -> 091_convolutional_mish[Half(1,512,13,13)]
Layer(CaskConvolution): 092_convolutional + 092_convolutional_bn, Tactic: 4772821744921268633, 091_convolutional_mish[Half(1,512,13,13)] -> 092_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut), Tactic: 18, 092_convolutional_bn[Half(1,512,13,13)], 090_convolutional_mish[Half(1,512,13,13)] -> 093_shortcut[Half(1,512,13,13)]
Layer(CaskConvolution): 094_convolutional + 094_convolutional_bn, Tactic: -1716393687483585322, 093_shortcut[Half(1,512,13,13)] -> 094_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish), Tactic: 18, 094_convolutional_bn[Half(1,512,13,13)] -> 094_convolutional_mish[Half(1,512,13,13)]
Layer(CaskConvolution): 095_convolutional + 095_convolutional_bn, Tactic: 4772821744921268633, 094_convolutional_mish[Half(1,512,13,13)] -> 095_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut), Tactic: 18, 095_convolutional_bn[Half(1,512,13,13)], 093_shortcut[Half(1,512,13,13)] -> 096_shortcut[Half(1,512,13,13)]
Layer(CaskConvolution): 097_convolutional + 097_convolutional_bn, Tactic: -1716393687483585322, 096_shortcut[Half(1,512,13,13)] -> 097_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish), Tactic: 18, 097_convolutional_bn[Half(1,512,13,13)] -> 097_convolutional_mish[Half(1,512,13,13)]
Layer(CaskConvolution): 098_convolutional + 098_convolutional_bn, Tactic: 4772821744921268633, 097_convolutional_mish[Half(1,512,13,13)] -> 098_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut), Tactic: 18, 098_convolutional_bn[Half(1,512,13,13)], 096_shortcut[Half(1,512,13,13)] -> 099_shortcut[Half(1,512,13,13)]
Layer(CaskConvolution): 100_convolutional + 100_convolutional_bn, Tactic: -1716393687483585322, 099_shortcut[Half(1,512,13,13)] -> 100_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish), Tactic: 18, 100_convolutional_bn[Half(1,512,13,13)] -> 100_convolutional_mish[Half(1,512,13,13)]
Layer(CaskConvolution): 101_convolutional + 101_convolutional_bn, Tactic: 4772821744921268633, 100_convolutional_mish[Half(1,512,13,13)] -> 101_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut), Tactic: 18, 101_convolutional_bn[Half(1,512,13,13)], 099_shortcut[Half(1,512,13,13)] -> 102_shortcut[Half(1,512,13,13)]
Layer(CaskConvolution): 103_convolutional + 103_convolutional_bn, Tactic: -1716393687483585322, 102_shortcut[Half(1,512,13,13)] -> 103_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish), Tactic: 17, 103_convolutional_bn[Half(1,512,13,13)] -> 104_route[Half(1,512,13,13)]
Layer(CaskConvolution): 105_convolutional + 105_convolutional_bn, Tactic: -1716393687483585322, 104_route[Half(1,1024,13,13)] -> 105_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish), Tactic: 18, 105_convolutional_bn[Half(1,1024,13,13)] -> 105_convolutional_mish[Half(1,1024,13,13)]
Layer(CaskConvolution): 106_convolutional + 106_convolutional_bn, Tactic: -1716393687483585322, 105_convolutional_mish[Half(1,1024,13,13)] -> 106_convolutional_bn[Half(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to PWN(106_convolutional_lrelu), Tactic: 0, 106_convolutional_bn[Half(1,512,13,13)] -> Reformatted Input Tensor 0 to PWN(106_convolutional_lrelu)[Float(1,512,13,13)]
Layer(PointWiseV2): PWN(106_convolutional_lrelu), Tactic: 0, Reformatted Input Tensor 0 to PWN(106_convolutional_lrelu)[Float(1,512,13,13)] -> 106_convolutional_lrelu[Float(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 107_convolutional + 107_convolutional_bn, Tactic: 0, 106_convolutional_lrelu[Float(1,512,13,13)] -> Reformatted Input Tensor 0 to 107_convolutional + 107_convolutional_bn[Half(1,512,13,13)]
Layer(CaskConvolution): 107_convolutional + 107_convolutional_bn, Tactic: 4772821744921268633, Reformatted Input Tensor 0 to 107_convolutional + 107_convolutional_bn[Half(1,512,13,13)] -> 107_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(107_convolutional_lrelu), Tactic: 18, 107_convolutional_bn[Half(1,1024,13,13)] -> 107_convolutional_lrelu[Half(1,1024,13,13)]
Layer(CaskConvolution): 108_convolutional + 108_convolutional_bn, Tactic: -1716393687483585322, 107_convolutional_lrelu[Half(1,1024,13,13)] -> 108_convolutional_bn[Half(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to PWN(108_convolutional_lrelu), Tactic: 0, 108_convolutional_bn[Half(1,512,13,13)] -> Reformatted Input Tensor 0 to PWN(108_convolutional_lrelu)[Float(1,512,13,13)]
Layer(PointWiseV2): PWN(108_convolutional_lrelu), Tactic: 0, Reformatted Input Tensor 0 to PWN(108_convolutional_lrelu)[Float(1,512,13,13)] -> Reformatted Output Tensor 0 to PWN(108_convolutional_lrelu)[Float(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to PWN(108_convolutional_lrelu), Tactic: 0, Reformatted Output Tensor 0 to PWN(108_convolutional_lrelu)[Float(1,512,13,13)] -> 108_convolutional_lrelu[Half(1,512,13,13)]
Layer(TiledPooling): 109_maxpool, Tactic: 7735053, 108_convolutional_lrelu[Half(1,512,13,13)] -> 109_maxpool[Half(1,512,13,13)]
Layer(CudaPooling): 111_maxpool, Tactic: -3, 108_convolutional_lrelu[Half(1,512,13,13)] -> 111_maxpool[Half(1,512,13,13)]
Layer(CudaPooling): 113_maxpool, Tactic: -3, 108_convolutional_lrelu[Half(1,512,13,13)] -> 113_maxpool[Half(1,512,13,13)]
Layer(Reformat): 113_maxpool copy, Tactic: 0, 113_maxpool[Half(1,512,13,13)] -> 114_route[Half(1,512,13,13)]
Layer(Reformat): 111_maxpool copy, Tactic: 0, 111_maxpool[Half(1,512,13,13)] -> 114_route[Half(1,512,13,13)]
Layer(Reformat): 109_maxpool copy, Tactic: 0, 109_maxpool[Half(1,512,13,13)] -> 114_route[Half(1,512,13,13)]
Layer(Reformat): 108_convolutional_lrelu copy, Tactic: 0, 108_convolutional_lrelu[Half(1,512,13,13)] -> 114_route[Half(1,512,13,13)]
Layer(CaskConvolution): 115_convolutional + 115_convolutional_bn, Tactic: 8163473458334948789, 114_route[Half(1,2048,13,13)] -> 115_convolutional_bn[Half(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to PWN(115_convolutional_lrelu), Tactic: 0, 115_convolutional_bn[Half(1,512,13,13)] -> Reformatted Input Tensor 0 to PWN(115_convolutional_lrelu)[Float(1,512,13,13)]
Layer(PointWiseV2): PWN(115_convolutional_lrelu), Tactic: 0, Reformatted Input Tensor 0 to PWN(115_convolutional_lrelu)[Float(1,512,13,13)] -> 115_convolutional_lrelu[Float(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 116_convolutional + 116_convolutional_bn, Tactic: 0, 115_convolutional_lrelu[Float(1,512,13,13)] -> Reformatted Input Tensor 0 to 116_convolutional + 116_convolutional_bn[Half(1,512,13,13)]
Layer(CaskConvolution): 116_convolutional + 116_convolutional_bn, Tactic: 4772821744921268633, Reformatted Input Tensor 0 to 116_convolutional + 116_convolutional_bn[Half(1,512,13,13)] -> 116_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(116_convolutional_lrelu), Tactic: 18, 116_convolutional_bn[Half(1,1024,13,13)] -> 116_convolutional_lrelu[Half(1,1024,13,13)]
Layer(CaskConvolution): 117_convolutional + 117_convolutional_bn, Tactic: -1716393687483585322, 116_convolutional_lrelu[Half(1,1024,13,13)] -> 117_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(117_convolutional_lrelu), Tactic: 1, 117_convolutional_bn[Half(1,512,13,13)] -> 154_route[Half(1,512,13,13)]
Layer(CaskConvolution): 118_convolutional + 118_convolutional_bn, Tactic: -1716393687483585322, 154_route[Half(1,512,13,13)] -> 118_convolutional_bn[Half(1,256,13,13)]
Layer(PointWiseV2): PWN(118_convolutional_lrelu), Tactic: 6, 118_convolutional_bn[Half(1,256,13,13)] -> 118_convolutional_lrelu[Half(1,256,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 119_upsample, Tactic: 0, 118_convolutional_lrelu[Half(1,256,13,13)] -> Reformatted Input Tensor 0 to 119_upsample[Float(1,256,13,13)]
Layer(Resize): 119_upsample, Tactic: 0, Reformatted Input Tensor 0 to 119_upsample[Float(1,256,13,13)] -> 119_upsample[Float(1,256,26,26)]
Layer(CaskConvolution): 121_convolutional + 121_convolutional_bn, Tactic: -1716393687483585322, 086_convolutional_mish[Half(1,512,26,26)] -> 121_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(121_convolutional_lrelu), Tactic: 17, 121_convolutional_bn[Half(1,256,26,26)] -> 122_route[Half(1,256,26,26)]
Layer(Reformat): 119_upsample copy, Tactic: 0, 119_upsample[Float(1,256,26,26)] -> 122_route[Half(1,256,26,26)]
Layer(CaskConvolution): 123_convolutional + 123_convolutional_bn, Tactic: -1716393687483585322, 122_route[Half(1,512,26,26)] -> 123_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(123_convolutional_lrelu), Tactic: 18, 123_convolutional_bn[Half(1,256,26,26)] -> 123_convolutional_lrelu[Half(1,256,26,26)]
Layer(CaskConvolution): 124_convolutional + 124_convolutional_bn, Tactic: 4772821744921268633, 123_convolutional_lrelu[Half(1,256,26,26)] -> 124_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(124_convolutional_lrelu), Tactic: 18, 124_convolutional_bn[Half(1,512,26,26)] -> 124_convolutional_lrelu[Half(1,512,26,26)]
Layer(CaskConvolution): 125_convolutional + 125_convolutional_bn, Tactic: -1716393687483585322, 124_convolutional_lrelu[Half(1,512,26,26)] -> 125_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(125_convolutional_lrelu), Tactic: 18, 125_convolutional_bn[Half(1,256,26,26)] -> 125_convolutional_lrelu[Half(1,256,26,26)]
Layer(CaskConvolution): 126_convolutional + 126_convolutional_bn, Tactic: 4772821744921268633, 125_convolutional_lrelu[Half(1,256,26,26)] -> 126_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(126_convolutional_lrelu), Tactic: 18, 126_convolutional_bn[Half(1,512,26,26)] -> 126_convolutional_lrelu[Half(1,512,26,26)]
Layer(CaskConvolution): 127_convolutional + 127_convolutional_bn, Tactic: -1716393687483585322, 126_convolutional_lrelu[Half(1,512,26,26)] -> 127_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(127_convolutional_lrelu), Tactic: 17, 127_convolutional_bn[Half(1,256,26,26)] -> 143_route[Half(1,256,26,26)]
Layer(CaskConvolution): 128_convolutional + 128_convolutional_bn, Tactic: -1716393687483585322, 143_route[Half(1,256,26,26)] -> 128_convolutional_bn[Half(1,128,26,26)]
Layer(PointWiseV2): PWN(128_convolutional_lrelu), Tactic: 18, 128_convolutional_bn[Half(1,128,26,26)] -> 128_convolutional_lrelu[Half(1,128,26,26)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 129_upsample, Tactic: 0, 128_convolutional_lrelu[Half(1,128,26,26)] -> Reformatted Input Tensor 0 to 129_upsample[Float(1,128,26,26)]
Layer(Resize): 129_upsample, Tactic: 0, Reformatted Input Tensor 0 to 129_upsample[Float(1,128,26,26)] -> 129_upsample[Float(1,128,52,52)]
Layer(CaskConvolution): 131_convolutional + 131_convolutional_bn, Tactic: -1716393687483585322, 055_convolutional_mish[Half(1,256,52,52)] -> 131_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(131_convolutional_lrelu), Tactic: 17, 131_convolutional_bn[Half(1,128,52,52)] -> 132_route[Half(1,128,52,52)]
Layer(Reformat): 129_upsample copy, Tactic: 0, 129_upsample[Float(1,128,52,52)] -> 132_route[Half(1,128,52,52)]
Layer(CaskConvolution): 133_convolutional + 133_convolutional_bn, Tactic: -1716393687483585322, 132_route[Half(1,256,52,52)] -> 133_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(133_convolutional_lrelu), Tactic: 18, 133_convolutional_bn[Half(1,128,52,52)] -> 133_convolutional_lrelu[Half(1,128,52,52)]
Layer(CaskConvolution): 134_convolutional + 134_convolutional_bn, Tactic: 4772821744921268633, 133_convolutional_lrelu[Half(1,128,52,52)] -> 134_convolutional_bn[Half(1,256,52,52)]
Layer(PointWiseV2): PWN(134_convolutional_lrelu), Tactic: 18, 134_convolutional_bn[Half(1,256,52,52)] -> 134_convolutional_lrelu[Half(1,256,52,52)]
Layer(CaskConvolution): 135_convolutional + 135_convolutional_bn, Tactic: -1716393687483585322, 134_convolutional_lrelu[Half(1,256,52,52)] -> 135_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(135_convolutional_lrelu), Tactic: 18, 135_convolutional_bn[Half(1,128,52,52)] -> 135_convolutional_lrelu[Half(1,128,52,52)]
Layer(CaskConvolution): 136_convolutional + 136_convolutional_bn, Tactic: 4772821744921268633, 135_convolutional_lrelu[Half(1,128,52,52)] -> 136_convolutional_bn[Half(1,256,52,52)]
Layer(PointWiseV2): PWN(136_convolutional_lrelu), Tactic: 18, 136_convolutional_bn[Half(1,256,52,52)] -> 136_convolutional_lrelu[Half(1,256,52,52)]
Layer(CaskConvolution): 137_convolutional + 137_convolutional_bn, Tactic: -1716393687483585322, 136_convolutional_lrelu[Half(1,256,52,52)] -> 137_convolutional_bn[Half(1,128,52,52)]
Layer(PointWiseV2): PWN(137_convolutional_lrelu), Tactic: 18, 137_convolutional_bn[Half(1,128,52,52)] -> 137_convolutional_lrelu[Half(1,128,52,52)]
Layer(CaskConvolution): 138_convolutional + 138_convolutional_bn, Tactic: 4772821744921268633, 137_convolutional_lrelu[Half(1,128,52,52)] -> 138_convolutional_bn[Half(1,256,52,52)]
Layer(PointWiseV2): PWN(138_convolutional_lrelu), Tactic: 18, 138_convolutional_bn[Half(1,256,52,52)] -> 138_convolutional_lrelu[Half(1,256,52,52)]
Layer(CaskConvolution): 139_convolutional, Tactic: 8163473458334948789, 138_convolutional_lrelu[Half(1,256,52,52)] -> Reformatted Output Tensor 0 to 139_convolutional[Half(1,255,52,52)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to 139_convolutional, Tactic: 0, Reformatted Output Tensor 0 to 139_convolutional[Half(1,255,52,52)] -> 139_convolutional[Float(1,255,52,52)]
Layer(CaskConvolution): 142_convolutional + 142_convolutional_bn, Tactic: -4212163711445252890, 137_convolutional_lrelu[Half(1,128,52,52)] -> 142_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(142_convolutional_lrelu), Tactic: 17, 142_convolutional_bn[Half(1,256,26,26)] -> 143_route[Half(1,256,26,26)]
Layer(CaskConvolution): 144_convolutional + 144_convolutional_bn, Tactic: -1716393687483585322, 143_route[Half(1,512,26,26)] -> 144_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(144_convolutional_lrelu), Tactic: 18, 144_convolutional_bn[Half(1,256,26,26)] -> 144_convolutional_lrelu[Half(1,256,26,26)]
Layer(CaskConvolution): 145_convolutional + 145_convolutional_bn, Tactic: 4772821744921268633, 144_convolutional_lrelu[Half(1,256,26,26)] -> 145_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(145_convolutional_lrelu), Tactic: 18, 145_convolutional_bn[Half(1,512,26,26)] -> 145_convolutional_lrelu[Half(1,512,26,26)]
Layer(CaskConvolution): 146_convolutional + 146_convolutional_bn, Tactic: -1716393687483585322, 145_convolutional_lrelu[Half(1,512,26,26)] -> 146_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(146_convolutional_lrelu), Tactic: 18, 146_convolutional_bn[Half(1,256,26,26)] -> 146_convolutional_lrelu[Half(1,256,26,26)]
Layer(CaskConvolution): 147_convolutional + 147_convolutional_bn, Tactic: 4772821744921268633, 146_convolutional_lrelu[Half(1,256,26,26)] -> 147_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(147_convolutional_lrelu), Tactic: 18, 147_convolutional_bn[Half(1,512,26,26)] -> 147_convolutional_lrelu[Half(1,512,26,26)]
Layer(CaskConvolution): 148_convolutional + 148_convolutional_bn, Tactic: -1716393687483585322, 147_convolutional_lrelu[Half(1,512,26,26)] -> 148_convolutional_bn[Half(1,256,26,26)]
Layer(PointWiseV2): PWN(148_convolutional_lrelu), Tactic: 18, 148_convolutional_bn[Half(1,256,26,26)] -> 148_convolutional_lrelu[Half(1,256,26,26)]
Layer(CaskConvolution): 149_convolutional + 149_convolutional_bn, Tactic: 4772821744921268633, 148_convolutional_lrelu[Half(1,256,26,26)] -> 149_convolutional_bn[Half(1,512,26,26)]
Layer(PointWiseV2): PWN(149_convolutional_lrelu), Tactic: 18, 149_convolutional_bn[Half(1,512,26,26)] -> 149_convolutional_lrelu[Half(1,512,26,26)]
Layer(CaskConvolution): 150_convolutional, Tactic: 8163473458334948789, 149_convolutional_lrelu[Half(1,512,26,26)] -> Reformatted Output Tensor 0 to 150_convolutional[Half(1,255,26,26)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to 150_convolutional, Tactic: 0, Reformatted Output Tensor 0 to 150_convolutional[Half(1,255,26,26)] -> 150_convolutional[Float(1,255,26,26)]
Layer(CaskConvolution): 153_convolutional + 153_convolutional_bn, Tactic: -4212163711445252890, 148_convolutional_lrelu[Half(1,256,26,26)] -> 153_convolutional_bn[Half(1,512,13,13)]
Layer(PointWiseV2): PWN(153_convolutional_lrelu), Tactic: 1, 153_convolutional_bn[Half(1,512,13,13)] -> 154_route[Half(1,512,13,13)]
Layer(CaskConvolution): 155_convolutional + 155_convolutional_bn, Tactic: -1716393687483585322, 154_route[Half(1,1024,13,13)] -> 155_convolutional_bn[Half(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to PWN(155_convolutional_lrelu), Tactic: 0, 155_convolutional_bn[Half(1,512,13,13)] -> Reformatted Input Tensor 0 to PWN(155_convolutional_lrelu)[Float(1,512,13,13)]
Layer(PointWiseV2): PWN(155_convolutional_lrelu), Tactic: 0, Reformatted Input Tensor 0 to PWN(155_convolutional_lrelu)[Float(1,512,13,13)] -> 155_convolutional_lrelu[Float(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 156_convolutional + 156_convolutional_bn, Tactic: 0, 155_convolutional_lrelu[Float(1,512,13,13)] -> Reformatted Input Tensor 0 to 156_convolutional + 156_convolutional_bn[Half(1,512,13,13)]
Layer(CaskConvolution): 156_convolutional + 156_convolutional_bn, Tactic: 4772821744921268633, Reformatted Input Tensor 0 to 156_convolutional + 156_convolutional_bn[Half(1,512,13,13)] -> 156_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(156_convolutional_lrelu), Tactic: 18, 156_convolutional_bn[Half(1,1024,13,13)] -> 156_convolutional_lrelu[Half(1,1024,13,13)]
Layer(CaskConvolution): 157_convolutional + 157_convolutional_bn, Tactic: -1716393687483585322, 156_convolutional_lrelu[Half(1,1024,13,13)] -> 157_convolutional_bn[Half(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to PWN(157_convolutional_lrelu), Tactic: 0, 157_convolutional_bn[Half(1,512,13,13)] -> Reformatted Input Tensor 0 to PWN(157_convolutional_lrelu)[Float(1,512,13,13)]
Layer(PointWiseV2): PWN(157_convolutional_lrelu), Tactic: 0, Reformatted Input Tensor 0 to PWN(157_convolutional_lrelu)[Float(1,512,13,13)] -> 157_convolutional_lrelu[Float(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 158_convolutional + 158_convolutional_bn, Tactic: 0, 157_convolutional_lrelu[Float(1,512,13,13)] -> Reformatted Input Tensor 0 to 158_convolutional + 158_convolutional_bn[Half(1,512,13,13)]
Layer(CaskConvolution): 158_convolutional + 158_convolutional_bn, Tactic: 4772821744921268633, Reformatted Input Tensor 0 to 158_convolutional + 158_convolutional_bn[Half(1,512,13,13)] -> 158_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(158_convolutional_lrelu), Tactic: 18, 158_convolutional_bn[Half(1,1024,13,13)] -> 158_convolutional_lrelu[Half(1,1024,13,13)]
Layer(CaskConvolution): 159_convolutional + 159_convolutional_bn, Tactic: -1716393687483585322, 158_convolutional_lrelu[Half(1,1024,13,13)] -> 159_convolutional_bn[Half(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to PWN(159_convolutional_lrelu), Tactic: 0, 159_convolutional_bn[Half(1,512,13,13)] -> Reformatted Input Tensor 0 to PWN(159_convolutional_lrelu)[Float(1,512,13,13)]
Layer(PointWiseV2): PWN(159_convolutional_lrelu), Tactic: 0, Reformatted Input Tensor 0 to PWN(159_convolutional_lrelu)[Float(1,512,13,13)] -> 159_convolutional_lrelu[Float(1,512,13,13)]
Layer(Reformat): Reformatting CopyNode for Input Tensor 0 to 160_convolutional + 160_convolutional_bn, Tactic: 0, 159_convolutional_lrelu[Float(1,512,13,13)] -> Reformatted Input Tensor 0 to 160_convolutional + 160_convolutional_bn[Half(1,512,13,13)]
Layer(CaskConvolution): 160_convolutional + 160_convolutional_bn, Tactic: 4772821744921268633, Reformatted Input Tensor 0 to 160_convolutional + 160_convolutional_bn[Half(1,512,13,13)] -> 160_convolutional_bn[Half(1,1024,13,13)]
Layer(PointWiseV2): PWN(160_convolutional_lrelu), Tactic: 18, 160_convolutional_bn[Half(1,1024,13,13)] -> 160_convolutional_lrelu[Half(1,1024,13,13)]
Layer(CaskConvolution): 161_convolutional, Tactic: -1716393687483585322, 160_convolutional_lrelu[Half(1,1024,13,13)] -> Reformatted Output Tensor 0 to 161_convolutional[Half(1,255,13,13)]
Layer(Reformat): Reformatting CopyNode for Output Tensor 0 to 161_convolutional, Tactic: 0, Reformatted Output Tensor 0 to 161_convolutional[Half(1,255,13,13)] -> 161_convolutional[Float(1,255,13,13)]
[05/21/2022-03:15:06] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in building engine: CPU +123, GPU +512, now: CPU 123, GPU 512 (MiB)
[05/21/2022-03:15:07] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 1462, GPU 3872 (MiB)
[05/21/2022-03:15:07] [I] [TRT] Loaded engine size: 282 MiB
[05/21/2022-03:15:08] [V] [TRT] Using cublas as a tactic source
[05/21/2022-03:15:08] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +1, now: CPU 1473, GPU 3893 (MiB)
[05/21/2022-03:15:08] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-03:15:08] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +1, GPU +1, now: CPU 1474, GPU 3894 (MiB)
[05/21/2022-03:15:08] [V] [TRT] Deserialization required 773972 microseconds.
[05/21/2022-03:15:08] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in engine deserialization: CPU +0, GPU +280, now: CPU 0, GPU 280 (MiB)
[05/21/2022-03:15:13] [I] Engine built in 805.62 sec.
[05/21/2022-03:15:14] [I] [TRT] [MemUsageChange] Init CUDA: CPU +0, GPU +0, now: CPU 913, GPU 3458 (MiB)
[05/21/2022-03:15:14] [I] [TRT] The profiling verbosity was set to ProfilingVerbosity::kLAYER_NAMES_ONLY when the engine was built, so only the layer names will be returned. Rebuild the engine with ProfilingVerbosity::kDETAILED to get more verbose layer information.
[05/21/2022-03:15:14] [V] [TRT] Using cublas as a tactic source
[05/21/2022-03:15:14] [I] [TRT] [MemUsageChange] Init cuBLAS/cuBLASLt: CPU +0, GPU +0, now: CPU 913, GPU 3458 (MiB)
[05/21/2022-03:15:14] [V] [TRT] Using cuDNN as a tactic source
[05/21/2022-03:15:14] [I] [TRT] [MemUsageChange] Init cuDNN: CPU +0, GPU +0, now: CPU 913, GPU 3458 (MiB)
[05/21/2022-03:15:14] [V] [TRT] Total per-runner device persistent memory is 294645248
[05/21/2022-03:15:14] [V] [TRT] Total per-runner host persistent memory is 256544
[05/21/2022-03:15:14] [V] [TRT] Allocated activation device memory of size 33918976
[05/21/2022-03:15:14] [I] [TRT] [MemUsageChange] TensorRT-managed allocation in IExecutionContext creation: CPU +0, GPU +314, now: CPU 0, GPU 594 (MiB)
[05/21/2022-03:15:14] [I] Using random values for input 000_net
[05/21/2022-03:15:14] [I] Created input binding for 000_net with dimensions 1x3x416x416
[05/21/2022-03:15:14] [I] Using random values for output 139_convolutional
[05/21/2022-03:15:14] [I] Created output binding for 139_convolutional with dimensions 1x255x52x52
[05/21/2022-03:15:14] [I] Using random values for output 150_convolutional
[05/21/2022-03:15:14] [I] Created output binding for 150_convolutional with dimensions 1x255x26x26
[05/21/2022-03:15:14] [I] Using random values for output 161_convolutional
[05/21/2022-03:15:14] [I] Created output binding for 161_convolutional with dimensions 1x255x13x13
[05/21/2022-03:15:14] [I] Starting inference
[05/21/2022-03:15:18] [I] Warmup completed 0 queries over 200 ms
[05/21/2022-03:15:18] [I] Timing trace has 15 queries over 3.57194 s
[05/21/2022-03:15:18] [I] 
[05/21/2022-03:15:18] [I] === Trace details ===
[05/21/2022-03:15:18] [I] Trace averages of 10 runs:
[05/21/2022-03:15:18] [I] Average on 10 runs - GPU latency: 226.06 ms - Host latency: 255.999 ms (end to end 256.016 ms, enqueue 48.9465 ms)
[05/21/2022-03:15:18] [I] 
[05/21/2022-03:15:18] [I] === Performance summary ===
[05/21/2022-03:15:18] [I] Throughput: 4.1994 qps
[05/21/2022-03:15:18] [I] Latency: min = 202.238 ms, max = 733.047 ms, mean = 238.113 ms, median = 202.5 ms, percentile(99%) = 733.047 ms
[05/21/2022-03:15:18] [I] End-to-End Host Latency: min = 202.25 ms, max = 733.094 ms, mean = 238.128 ms, median = 202.514 ms, percentile(99%) = 733.094 ms
[05/21/2022-03:15:18] [I] Enqueue Time: min = 8.23981 ms, max = 383.329 ms, mean = 37.3019 ms, median = 13.2729 ms, percentile(99%) = 383.329 ms
[05/21/2022-03:15:18] [I] H2D Latency: min = 0.203857 ms, max = 293.833 ms, mean = 19.783 ms, median = 0.207275 ms, percentile(99%) = 293.833 ms
[05/21/2022-03:15:18] [I] GPU Compute Time: min = 201.667 ms, max = 438.842 ms, mean = 217.963 ms, median = 201.932 ms, percentile(99%) = 438.842 ms
[05/21/2022-03:15:18] [I] D2H Latency: min = 0.360474 ms, max = 0.382568 ms, mean = 0.367289 ms, median = 0.365967 ms, percentile(99%) = 0.382568 ms
[05/21/2022-03:15:18] [I] Total Host Walltime: 3.57194 s
[05/21/2022-03:15:18] [I] Total GPU Compute Time: 3.26945 s
[05/21/2022-03:15:18] [I] Explanations of the performance metrics are printed in the verbose logs.
[05/21/2022-03:15:18] [V] 
[05/21/2022-03:15:18] [V] === Explanations of the performance metrics ===
[05/21/2022-03:15:18] [V] Total Host Walltime: the host walltime from when the first query (after warmups) is enqueued to when the last query is completed.
[05/21/2022-03:15:18] [V] GPU Compute Time: the GPU latency to execute the kernels for a query.
[05/21/2022-03:15:18] [V] Total GPU Compute Time: the summation of the GPU Compute Time of all the queries. If this is significantly shorter than Total Host Walltime, the GPU may be under-utilized because of host-side overheads or data transfers.
[05/21/2022-03:15:18] [V] Throughput: the observed throughput computed by dividing the number of queries by the Total Host Walltime. If this is significantly lower than the reciprocal of GPU Compute Time, the GPU may be under-utilized because of host-side overheads or data transfers.
[05/21/2022-03:15:18] [V] Enqueue Time: the host latency to enqueue a query. If this is longer than GPU Compute Time, the GPU may be under-utilized.
[05/21/2022-03:15:18] [V] H2D Latency: the latency for host-to-device data transfers for input tensors of a single query.
[05/21/2022-03:15:18] [V] D2H Latency: the latency for device-to-host data transfers for output tensors of a single query.
[05/21/2022-03:15:18] [V] Latency: the summation of H2D Latency, GPU Compute Time, and D2H Latency. This is the latency to infer a single query.
[05/21/2022-03:15:18] [V] End-to-End Host Latency: the duration from when the H2D of a query is called to when the D2H of the same query is completed, which includes the latency to wait for the completion of the previous query. This is the latency of a query if multiple queries are enqueued consecutively.
[05/21/2022-03:15:18] [I] 
[05/21/2022-03:15:23] [I] 
[05/21/2022-03:15:23] [I] === Profile (17 iterations ) ===
[05/21/2022-03:15:23] [I]                                                                                                              Layer   Time (ms)   Avg. Time (ms)   Time %
[05/21/2022-03:15:23] [I]                               Reformatting CopyNode for Input Tensor 0 to 001_convolutional + 001_convolutional_bn       19.21           1.1299      0.5
[05/21/2022-03:15:23] [I]                                                                           001_convolutional + 001_convolutional_bn       89.65           5.2738      2.5
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(001_convolutional_softplus), PWN(001_convolutional_tanh)), 001_convolutional_mish)      103.46           6.0858      2.9
[05/21/2022-03:15:23] [I]                                                                           002_convolutional + 002_convolutional_bn      103.33           6.0781      2.9
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(002_convolutional_softplus), PWN(002_convolutional_tanh)), 002_convolutional_mish)       31.53           1.8546      0.9
[05/21/2022-03:15:23] [I]                               003_convolutional + 003_convolutional_bn || 005_convolutional + 005_convolutional_bn       55.60           3.2704      1.5
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(003_convolutional_softplus), PWN(003_convolutional_tanh)), 003_convolutional_mish)       36.67           2.1568      1.0
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(005_convolutional_softplus), PWN(005_convolutional_tanh)), 005_convolutional_mish)       33.60           1.9766      0.9
[05/21/2022-03:15:23] [I]                                                                           006_convolutional + 006_convolutional_bn       18.77           1.1040      0.5
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(006_convolutional_softplus), PWN(006_convolutional_tanh)), 006_convolutional_mish)       15.86           0.9330      0.4
[05/21/2022-03:15:23] [I]                                                                           007_convolutional + 007_convolutional_bn       74.20           4.3649      2.1
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(007_convolutional_softplus), PWN(007_convolutional_tanh)), 007_convolutional_mish), 008_shortcut)       52.39           3.0817      1.5
[05/21/2022-03:15:23] [I]                                                                           009_convolutional + 009_convolutional_bn       28.16           1.6563      0.8
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(009_convolutional_softplus), PWN(009_convolutional_tanh)), 009_convolutional_mish)       33.60           1.9763      0.9
[05/21/2022-03:15:23] [I]                                                                           011_convolutional + 011_convolutional_bn       43.67           2.5690      1.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(011_convolutional_softplus), PWN(011_convolutional_tanh)), 011_convolutional_mish)       31.55           1.8561      0.9
[05/21/2022-03:15:23] [I]                                                                           012_convolutional + 012_convolutional_bn       74.80           4.3997      2.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(012_convolutional_softplus), PWN(012_convolutional_tanh)), 012_convolutional_mish)       14.87           0.8748      0.4
[05/21/2022-03:15:23] [I]                               013_convolutional + 013_convolutional_bn || 015_convolutional + 015_convolutional_bn       21.03           1.2371      0.6
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(013_convolutional_softplus), PWN(013_convolutional_tanh)), 013_convolutional_mish)        7.95           0.4676      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(015_convolutional_softplus), PWN(015_convolutional_tanh)), 015_convolutional_mish)        7.96           0.4679      0.2
[05/21/2022-03:15:23] [I]                                                                           016_convolutional + 016_convolutional_bn        6.87           0.4039      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(016_convolutional_softplus), PWN(016_convolutional_tanh)), 016_convolutional_mish)        7.50           0.4410      0.2
[05/21/2022-03:15:23] [I]                                                                           017_convolutional + 017_convolutional_bn       29.55           1.7384      0.8
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(017_convolutional_softplus), PWN(017_convolutional_tanh)), 017_convolutional_mish), 018_shortcut)        9.42           0.5538      0.3
[05/21/2022-03:15:23] [I]                                                                           019_convolutional + 019_convolutional_bn        6.95           0.4090      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(019_convolutional_softplus), PWN(019_convolutional_tanh)), 019_convolutional_mish)        7.55           0.4439      0.2
[05/21/2022-03:15:23] [I]                                                                           020_convolutional + 020_convolutional_bn       29.49           1.7349      0.8
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(020_convolutional_softplus), PWN(020_convolutional_tanh)), 020_convolutional_mish), 021_shortcut)        9.35           0.5498      0.3
[05/21/2022-03:15:23] [I]                                                                           022_convolutional + 022_convolutional_bn        6.86           0.4035      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(022_convolutional_softplus), PWN(022_convolutional_tanh)), 022_convolutional_mish)        7.99           0.4702      0.2
[05/21/2022-03:15:23] [I]                                                                           024_convolutional + 024_convolutional_bn       20.90           1.2293      0.6
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(024_convolutional_softplus), PWN(024_convolutional_tanh)), 024_convolutional_mish)       14.84           0.8728      0.4
[05/21/2022-03:15:23] [I]                                                                           025_convolutional + 025_convolutional_bn       73.49           4.3229      2.0
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(025_convolutional_softplus), PWN(025_convolutional_tanh)), 025_convolutional_mish)        7.48           0.4402      0.2
[05/21/2022-03:15:23] [I]                               026_convolutional + 026_convolutional_bn || 028_convolutional + 028_convolutional_bn       18.76           1.1033      0.5
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(026_convolutional_softplus), PWN(026_convolutional_tanh)), 026_convolutional_mish)        3.99           0.2350      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(028_convolutional_softplus), PWN(028_convolutional_tanh)), 028_convolutional_mish)        3.84           0.2260      0.1
[05/21/2022-03:15:23] [I]                                                                           029_convolutional + 029_convolutional_bn        5.69           0.3345      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(029_convolutional_softplus), PWN(029_convolutional_tanh)), 029_convolutional_mish)        3.76           0.2212      0.1
[05/21/2022-03:15:23] [I]                                                                           030_convolutional + 030_convolutional_bn       33.47           1.9688      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(030_convolutional_softplus), PWN(030_convolutional_tanh)), 030_convolutional_mish), 031_shortcut)        4.56           0.2683      0.1
[05/21/2022-03:15:23] [I]                                                                           032_convolutional + 032_convolutional_bn        5.69           0.3345      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(032_convolutional_softplus), PWN(032_convolutional_tanh)), 032_convolutional_mish)        3.74           0.2198      0.1
[05/21/2022-03:15:23] [I]                                                                           033_convolutional + 033_convolutional_bn       32.80           1.9294      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(033_convolutional_softplus), PWN(033_convolutional_tanh)), 033_convolutional_mish), 034_shortcut)        5.31           0.3125      0.1
[05/21/2022-03:15:23] [I]                                                                           035_convolutional + 035_convolutional_bn        5.69           0.3348      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(035_convolutional_softplus), PWN(035_convolutional_tanh)), 035_convolutional_mish)        3.76           0.2213      0.1
[05/21/2022-03:15:23] [I]                                                                           036_convolutional + 036_convolutional_bn       32.83           1.9313      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(036_convolutional_softplus), PWN(036_convolutional_tanh)), 036_convolutional_mish), 037_shortcut)        4.67           0.2748      0.1
[05/21/2022-03:15:23] [I]                                                                           038_convolutional + 038_convolutional_bn        5.68           0.3344      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(038_convolutional_softplus), PWN(038_convolutional_tanh)), 038_convolutional_mish)        3.78           0.2226      0.1
[05/21/2022-03:15:23] [I]                                                                           039_convolutional + 039_convolutional_bn       33.02           1.9426      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(039_convolutional_softplus), PWN(039_convolutional_tanh)), 039_convolutional_mish), 040_shortcut)        4.66           0.2743      0.1
[05/21/2022-03:15:23] [I]                                                                           041_convolutional + 041_convolutional_bn        5.68           0.3340      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(041_convolutional_softplus), PWN(041_convolutional_tanh)), 041_convolutional_mish)        3.75           0.2208      0.1
[05/21/2022-03:15:23] [I]                                                                           042_convolutional + 042_convolutional_bn       32.83           1.9312      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(042_convolutional_softplus), PWN(042_convolutional_tanh)), 042_convolutional_mish), 043_shortcut)        4.66           0.2744      0.1
[05/21/2022-03:15:23] [I]                                                                           044_convolutional + 044_convolutional_bn        5.68           0.3340      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(044_convolutional_softplus), PWN(044_convolutional_tanh)), 044_convolutional_mish)        3.76           0.2210      0.1
[05/21/2022-03:15:23] [I]                                                                           045_convolutional + 045_convolutional_bn       32.70           1.9233      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(045_convolutional_softplus), PWN(045_convolutional_tanh)), 045_convolutional_mish), 046_shortcut)        4.69           0.2758      0.1
[05/21/2022-03:15:23] [I]                                                                           047_convolutional + 047_convolutional_bn        5.68           0.3342      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(047_convolutional_softplus), PWN(047_convolutional_tanh)), 047_convolutional_mish)        3.72           0.2190      0.1
[05/21/2022-03:15:23] [I]                                                                           048_convolutional + 048_convolutional_bn       33.18           1.9516      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(048_convolutional_softplus), PWN(048_convolutional_tanh)), 048_convolutional_mish), 049_shortcut)        4.68           0.2754      0.1
[05/21/2022-03:15:23] [I]                                                                           050_convolutional + 050_convolutional_bn        5.70           0.3356      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(050_convolutional_softplus), PWN(050_convolutional_tanh)), 050_convolutional_mish)        3.68           0.2165      0.1
[05/21/2022-03:15:23] [I]                                                                           051_convolutional + 051_convolutional_bn       33.14           1.9495      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(051_convolutional_softplus), PWN(051_convolutional_tanh)), 051_convolutional_mish), 052_shortcut)        4.68           0.2751      0.1
[05/21/2022-03:15:23] [I]                                                                           053_convolutional + 053_convolutional_bn        5.64           0.3315      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(053_convolutional_softplus), PWN(053_convolutional_tanh)), 053_convolutional_mish)        4.05           0.2381      0.1
[05/21/2022-03:15:23] [I]                                                                           055_convolutional + 055_convolutional_bn       19.68           1.1579      0.5
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(055_convolutional_softplus), PWN(055_convolutional_tanh)), 055_convolutional_mish)        7.07           0.4160      0.2
[05/21/2022-03:15:23] [I]                                                                           056_convolutional + 056_convolutional_bn       78.66           4.6268      2.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(056_convolutional_softplus), PWN(056_convolutional_tanh)), 056_convolutional_mish)        3.66           0.2156      0.1
[05/21/2022-03:15:23] [I]                               057_convolutional + 057_convolutional_bn || 059_convolutional + 059_convolutional_bn       18.86           1.1096      0.5
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(057_convolutional_softplus), PWN(057_convolutional_tanh)), 057_convolutional_mish)        2.02           0.1190      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(059_convolutional_softplus), PWN(059_convolutional_tanh)), 059_convolutional_mish)        2.00           0.1178      0.1
[05/21/2022-03:15:23] [I]                                                                           060_convolutional + 060_convolutional_bn        5.31           0.3124      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(060_convolutional_softplus), PWN(060_convolutional_tanh)), 060_convolutional_mish)        1.90           0.1120      0.1
[05/21/2022-03:15:23] [I]                                                                           061_convolutional + 061_convolutional_bn       33.47           1.9691      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(061_convolutional_softplus), PWN(061_convolutional_tanh)), 061_convolutional_mish), 062_shortcut)        2.20           0.1295      0.1
[05/21/2022-03:15:23] [I]                                                                           063_convolutional + 063_convolutional_bn        5.22           0.3073      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(063_convolutional_softplus), PWN(063_convolutional_tanh)), 063_convolutional_mish)        1.85           0.1090      0.1
[05/21/2022-03:15:23] [I]                                                                           064_convolutional + 064_convolutional_bn       33.34           1.9613      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(064_convolutional_softplus), PWN(064_convolutional_tanh)), 064_convolutional_mish), 065_shortcut)        2.26           0.1329      0.1
[05/21/2022-03:15:23] [I]                                                                           066_convolutional + 066_convolutional_bn        5.19           0.3051      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(066_convolutional_softplus), PWN(066_convolutional_tanh)), 066_convolutional_mish)        1.85           0.1090      0.1
[05/21/2022-03:15:23] [I]                                                                           067_convolutional + 067_convolutional_bn       33.58           1.9752      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(067_convolutional_softplus), PWN(067_convolutional_tanh)), 067_convolutional_mish), 068_shortcut)        2.30           0.1351      0.1
[05/21/2022-03:15:23] [I]                                                                           069_convolutional + 069_convolutional_bn        5.22           0.3070      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(069_convolutional_softplus), PWN(069_convolutional_tanh)), 069_convolutional_mish)        1.82           0.1071      0.1
[05/21/2022-03:15:23] [I]                                                                           070_convolutional + 070_convolutional_bn       33.26           1.9565      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(070_convolutional_softplus), PWN(070_convolutional_tanh)), 070_convolutional_mish), 071_shortcut)        2.33           0.1370      0.1
[05/21/2022-03:15:23] [I]                                                                           072_convolutional + 072_convolutional_bn        5.23           0.3076      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(072_convolutional_softplus), PWN(072_convolutional_tanh)), 072_convolutional_mish)        1.82           0.1072      0.1
[05/21/2022-03:15:23] [I]                                                                           073_convolutional + 073_convolutional_bn       33.34           1.9610      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(073_convolutional_softplus), PWN(073_convolutional_tanh)), 073_convolutional_mish), 074_shortcut)        2.31           0.1356      0.1
[05/21/2022-03:15:23] [I]                                                                           075_convolutional + 075_convolutional_bn        5.25           0.3085      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(075_convolutional_softplus), PWN(075_convolutional_tanh)), 075_convolutional_mish)        1.84           0.1081      0.1
[05/21/2022-03:15:23] [I]                                                                           076_convolutional + 076_convolutional_bn       33.44           1.9673      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(076_convolutional_softplus), PWN(076_convolutional_tanh)), 076_convolutional_mish), 077_shortcut)        2.34           0.1379      0.1
[05/21/2022-03:15:23] [I]                                                                           078_convolutional + 078_convolutional_bn        5.19           0.3056      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(078_convolutional_softplus), PWN(078_convolutional_tanh)), 078_convolutional_mish)        1.85           0.1088      0.1
[05/21/2022-03:15:23] [I]                                                                           079_convolutional + 079_convolutional_bn       33.35           1.9618      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(079_convolutional_softplus), PWN(079_convolutional_tanh)), 079_convolutional_mish), 080_shortcut)        2.33           0.1373      0.1
[05/21/2022-03:15:23] [I]                                                                           081_convolutional + 081_convolutional_bn        5.27           0.3099      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(081_convolutional_softplus), PWN(081_convolutional_tanh)), 081_convolutional_mish)        1.85           0.1089      0.1
[05/21/2022-03:15:23] [I]                                                                           082_convolutional + 082_convolutional_bn       33.35           1.9615      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(082_convolutional_softplus), PWN(082_convolutional_tanh)), 082_convolutional_mish), 083_shortcut)        2.36           0.1386      0.1
[05/21/2022-03:15:23] [I]                                                                           084_convolutional + 084_convolutional_bn        5.19           0.3055      0.1
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(084_convolutional_softplus), PWN(084_convolutional_tanh)), 084_convolutional_mish)        2.01           0.1185      0.1
[05/21/2022-03:15:23] [I]                                                                           086_convolutional + 086_convolutional_bn       18.55           1.0912      0.5
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(086_convolutional_softplus), PWN(086_convolutional_tanh)), 086_convolutional_mish)        3.36           0.1979      0.1
[05/21/2022-03:15:23] [I]                                                                           087_convolutional + 087_convolutional_bn      101.63           5.9780      2.8
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(087_convolutional_softplus), PWN(087_convolutional_tanh)), 087_convolutional_mish)        1.77           0.1041      0.0
[05/21/2022-03:15:23] [I]                               088_convolutional + 088_convolutional_bn || 090_convolutional + 090_convolutional_bn       23.36           1.3744      0.6
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(088_convolutional_softplus), PWN(088_convolutional_tanh)), 088_convolutional_mish)        0.98           0.0579      0.0
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(090_convolutional_softplus), PWN(090_convolutional_tanh)), 090_convolutional_mish)        1.03           0.0608      0.0
[05/21/2022-03:15:23] [I]                                                                           091_convolutional + 091_convolutional_bn        6.19           0.3641      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(091_convolutional_softplus), PWN(091_convolutional_tanh)), 091_convolutional_mish)        1.02           0.0603      0.0
[05/21/2022-03:15:23] [I]                                                                           092_convolutional + 092_convolutional_bn       30.50           1.7941      0.8
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(092_convolutional_softplus), PWN(092_convolutional_tanh)), 092_convolutional_mish), 093_shortcut)        1.19           0.0703      0.0
[05/21/2022-03:15:23] [I]                                                                           094_convolutional + 094_convolutional_bn        6.38           0.3755      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(094_convolutional_softplus), PWN(094_convolutional_tanh)), 094_convolutional_mish)        0.99           0.0581      0.0
[05/21/2022-03:15:23] [I]                                                                           095_convolutional + 095_convolutional_bn       30.50           1.7943      0.8
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(095_convolutional_softplus), PWN(095_convolutional_tanh)), 095_convolutional_mish), 096_shortcut)        1.21           0.0715      0.0
[05/21/2022-03:15:23] [I]                                                                           097_convolutional + 097_convolutional_bn        6.37           0.3745      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(097_convolutional_softplus), PWN(097_convolutional_tanh)), 097_convolutional_mish)        0.97           0.0571      0.0
[05/21/2022-03:15:23] [I]                                                                           098_convolutional + 098_convolutional_bn       30.70           1.8061      0.9
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(098_convolutional_softplus), PWN(098_convolutional_tanh)), 098_convolutional_mish), 099_shortcut)        1.23           0.0721      0.0
[05/21/2022-03:15:23] [I]                                                                           100_convolutional + 100_convolutional_bn        6.35           0.3734      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(100_convolutional_softplus), PWN(100_convolutional_tanh)), 100_convolutional_mish)        0.99           0.0584      0.0
[05/21/2022-03:15:23] [I]                                                                           101_convolutional + 101_convolutional_bn       30.57           1.7985      0.8
[05/21/2022-03:15:23] [I]  PWN(PWN(PWN(PWN(101_convolutional_softplus), PWN(101_convolutional_tanh)), 101_convolutional_mish), 102_shortcut)        1.23           0.0724      0.0
[05/21/2022-03:15:23] [I]                                                                           103_convolutional + 103_convolutional_bn        6.34           0.3728      0.2
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(103_convolutional_softplus), PWN(103_convolutional_tanh)), 103_convolutional_mish)        0.97           0.0572      0.0
[05/21/2022-03:15:23] [I]                                                                           105_convolutional + 105_convolutional_bn       22.95           1.3500      0.6
[05/21/2022-03:15:23] [I]                     PWN(PWN(PWN(105_convolutional_softplus), PWN(105_convolutional_tanh)), 105_convolutional_mish)        1.90           0.1116      0.1
[05/21/2022-03:15:23] [I]                                                                           106_convolutional + 106_convolutional_bn       11.66           0.6859      0.3
[05/21/2022-03:15:23] [I]                                           Reformatting CopyNode for Input Tensor 0 to PWN(106_convolutional_lrelu)        1.14           0.0669      0.0
[05/21/2022-03:15:23] [I]                                                                                       PWN(106_convolutional_lrelu)        1.32           0.0774      0.0
[05/21/2022-03:15:23] [I]                               Reformatting CopyNode for Input Tensor 0 to 107_convolutional + 107_convolutional_bn        1.27           0.0748      0.0
[05/21/2022-03:15:23] [I]                                                                           107_convolutional + 107_convolutional_bn       61.55           3.6204      1.7
[05/21/2022-03:15:23] [I]                                                                                       PWN(107_convolutional_lrelu)        0.92           0.0540      0.0
[05/21/2022-03:15:23] [I]                                                                           108_convolutional + 108_convolutional_bn       11.86           0.6978      0.3
[05/21/2022-03:15:23] [I]                                           Reformatting CopyNode for Input Tensor 0 to PWN(108_convolutional_lrelu)        1.14           0.0670      0.0
[05/21/2022-03:15:23] [I]                                                                                       PWN(108_convolutional_lrelu)        1.31           0.0772      0.0
[05/21/2022-03:15:23] [I]                                          Reformatting CopyNode for Output Tensor 0 to PWN(108_convolutional_lrelu)        1.28           0.0750      0.0
[05/21/2022-03:15:23] [I]                                                                                                        109_maxpool        3.68           0.2162      0.1
[05/21/2022-03:15:23] [I]                                                                                                        111_maxpool        8.96           0.5268      0.2
[05/21/2022-03:15:23] [I]                                                                                                        113_maxpool       14.89           0.8757      0.4
[05/21/2022-03:15:23] [I]                                                                                                   113_maxpool copy        0.45           0.0267      0.0
[05/21/2022-03:15:23] [I]                                                                                                   111_maxpool copy        0.42           0.0244      0.0
[05/21/2022-03:15:23] [I]                                                                                                   109_maxpool copy        0.42           0.0247      0.0
[05/21/2022-03:15:23] [I]                                                                                       108_convolutional_lrelu copy        0.42           0.0246      0.0
[05/21/2022-03:15:23] [I]                                                                           115_convolutional + 115_convolutional_bn       22.89           1.3465      0.6
[05/21/2022-03:15:23] [I]                                           Reformatting CopyNode for Input Tensor 0 to PWN(115_convolutional_lrelu)        1.12           0.0660      0.0
[05/21/2022-03:15:23] [I]                                                                                       PWN(115_convolutional_lrelu)        1.31           0.0769      0.0
[05/21/2022-03:15:23] [I]                               Reformatting CopyNode for Input Tensor 0 to 116_convolutional + 116_convolutional_bn        1.26           0.0743      0.0
[05/21/2022-03:15:23] [I]                                                                           116_convolutional + 116_convolutional_bn       61.67           3.6276      1.7
[05/21/2022-03:15:23] [I]                                                                                       PWN(116_convolutional_lrelu)        0.92           0.0542      0.0
[05/21/2022-03:15:23] [I]                                                                           117_convolutional + 117_convolutional_bn       12.03           0.7079      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(117_convolutional_lrelu)        0.77           0.0451      0.0
[05/21/2022-03:15:23] [I]                                                                           118_convolutional + 118_convolutional_bn        3.19           0.1875      0.1
[05/21/2022-03:15:23] [I]                                                                                       PWN(118_convolutional_lrelu)        0.34           0.0201      0.0
[05/21/2022-03:15:23] [I]                                                           Reformatting CopyNode for Input Tensor 0 to 119_upsample        0.58           0.0340      0.0
[05/21/2022-03:15:23] [I]                                                                                                       119_upsample        2.55           0.1499      0.1
[05/21/2022-03:15:23] [I]                                                                           121_convolutional + 121_convolutional_bn        9.30           0.5472      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(121_convolutional_lrelu)        1.07           0.0627      0.0
[05/21/2022-03:15:23] [I]                                                                                                  119_upsample copy        2.46           0.1444      0.1
[05/21/2022-03:15:23] [I]                                                                           123_convolutional + 123_convolutional_bn        9.27           0.5451      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(123_convolutional_lrelu)        0.93           0.0550      0.0
[05/21/2022-03:15:23] [I]                                                                           124_convolutional + 124_convolutional_bn       65.44           3.8492      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(124_convolutional_lrelu)        1.74           0.1024      0.0
[05/21/2022-03:15:23] [I]                                                                           125_convolutional + 125_convolutional_bn        9.47           0.5573      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(125_convolutional_lrelu)        0.95           0.0558      0.0
[05/21/2022-03:15:23] [I]                                                                           126_convolutional + 126_convolutional_bn       65.42           3.8482      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(126_convolutional_lrelu)        1.74           0.1023      0.0
[05/21/2022-03:15:23] [I]                                                                           127_convolutional + 127_convolutional_bn        9.49           0.5583      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(127_convolutional_lrelu)        1.05           0.0618      0.0
[05/21/2022-03:15:23] [I]                                                                           128_convolutional + 128_convolutional_bn        2.58           0.1520      0.1
[05/21/2022-03:15:23] [I]                                                                                       PWN(128_convolutional_lrelu)        0.51           0.0300      0.0
[05/21/2022-03:15:23] [I]                                                           Reformatting CopyNode for Input Tensor 0 to 129_upsample        1.10           0.0647      0.0
[05/21/2022-03:15:23] [I]                                                                                                       129_upsample        4.99           0.2935      0.1
[05/21/2022-03:15:23] [I]                                                                           131_convolutional + 131_convolutional_bn        9.18           0.5402      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(131_convolutional_lrelu)        2.01           0.1180      0.1
[05/21/2022-03:15:23] [I]                                                                                                  129_upsample copy        4.85           0.2853      0.1
[05/21/2022-03:15:23] [I]                                                                           133_convolutional + 133_convolutional_bn        9.12           0.5364      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(133_convolutional_lrelu)        1.77           0.1041      0.0
[05/21/2022-03:15:23] [I]                                                                           134_convolutional + 134_convolutional_bn       63.96           3.7626      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(134_convolutional_lrelu)        3.39           0.1996      0.1
[05/21/2022-03:15:23] [I]                                                                           135_convolutional + 135_convolutional_bn        9.30           0.5471      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(135_convolutional_lrelu)        1.78           0.1046      0.0
[05/21/2022-03:15:23] [I]                                                                           136_convolutional + 136_convolutional_bn       64.35           3.7855      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(136_convolutional_lrelu)        3.40           0.1998      0.1
[05/21/2022-03:15:23] [I]                                                                           137_convolutional + 137_convolutional_bn        9.26           0.5445      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(137_convolutional_lrelu)        1.77           0.1039      0.0
[05/21/2022-03:15:23] [I]                                                                           138_convolutional + 138_convolutional_bn       64.02           3.7660      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(138_convolutional_lrelu)        3.38           0.1990      0.1
[05/21/2022-03:15:23] [I]                                                                                                  139_convolutional       18.46           1.0858      0.5
[05/21/2022-03:15:23] [I]                                                     Reformatting CopyNode for Output Tensor 0 to 139_convolutional        8.38           0.4930      0.2
[05/21/2022-03:15:23] [I]                                                                           142_convolutional + 142_convolutional_bn       19.71           1.1595      0.5
[05/21/2022-03:15:23] [I]                                                                                       PWN(142_convolutional_lrelu)        1.05           0.0618      0.0
[05/21/2022-03:15:23] [I]                                                                           144_convolutional + 144_convolutional_bn        9.56           0.5622      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(144_convolutional_lrelu)        0.94           0.0553      0.0
[05/21/2022-03:15:23] [I]                                                                           145_convolutional + 145_convolutional_bn       65.02           3.8246      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(145_convolutional_lrelu)        1.74           0.1024      0.0
[05/21/2022-03:15:23] [I]                                                                           146_convolutional + 146_convolutional_bn        9.48           0.5577      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(146_convolutional_lrelu)        0.94           0.0555      0.0
[05/21/2022-03:15:23] [I]                                                                           147_convolutional + 147_convolutional_bn       65.52           3.8540      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(147_convolutional_lrelu)        1.75           0.1028      0.0
[05/21/2022-03:15:23] [I]                                                                           148_convolutional + 148_convolutional_bn        9.43           0.5549      0.3
[05/21/2022-03:15:23] [I]                                                                                       PWN(148_convolutional_lrelu)        0.94           0.0553      0.0
[05/21/2022-03:15:23] [I]                                                                           149_convolutional + 149_convolutional_bn       65.07           3.8274      1.8
[05/21/2022-03:15:23] [I]                                                                                       PWN(149_convolutional_lrelu)        1.74           0.1023      0.0
[05/21/2022-03:15:23] [I]                                                                                                  150_convolutional        9.55           0.5615      0.3
[05/21/2022-03:15:23] [I]                                                     Reformatting CopyNode for Output Tensor 0 to 150_convolutional        2.15           0.1266      0.1
[05/21/2022-03:15:23] [I]                                                                           153_convolutional + 153_convolutional_bn       25.60           1.5060      0.7
[05/21/2022-03:15:23] [I]                                                                                       PWN(153_convolutional_lrelu)        0.77           0.0450      0.0
[05/21/2022-03:15:23] [I]                                                                           155_convolutional + 155_convolutional_bn       11.89           0.6994      0.3
[05/21/2022-03:15:23] [I]                                           Reformatting CopyNode for Input Tensor 0 to PWN(155_convolutional_lrelu)        1.14           0.0668      0.0
[05/21/2022-03:15:23] [I]                                                                                       PWN(155_convolutional_lrelu)        1.30           0.0767      0.0
[05/21/2022-03:15:23] [I]                               Reformatting CopyNode for Input Tensor 0 to 156_convolutional + 156_convolutional_bn        1.27           0.0745      0.0
[05/21/2022-03:15:23] [I]                                                                           156_convolutional + 156_convolutional_bn       61.14           3.5967      1.7
[05/21/2022-03:15:23] [I]                                                                                       PWN(156_convolutional_lrelu)        0.92           0.0540      0.0
[05/21/2022-03:15:23] [I]                                                                           157_convolutional + 157_convolutional_bn       11.80           0.6943      0.3
[05/21/2022-03:15:23] [I]                                           Reformatting CopyNode for Input Tensor 0 to PWN(157_convolutional_lrelu)        1.14           0.0669      0.0
[05/21/2022-03:15:23] [I]                                                                                       PWN(157_convolutional_lrelu)        1.31           0.0768      0.0
[05/21/2022-03:15:23] [I]                               Reformatting CopyNode for Input Tensor 0 to 158_convolutional + 158_convolutional_bn        1.27           0.0749      0.0
[05/21/2022-03:15:23] [I]                                                                           158_convolutional + 158_convolutional_bn       61.17           3.5980      1.7
[05/21/2022-03:15:23] [I]                                                                                       PWN(158_convolutional_lrelu)        0.92           0.0541      0.0
[05/21/2022-03:15:23] [I]                                                                           159_convolutional + 159_convolutional_bn       11.82           0.6952      0.3
[05/21/2022-03:15:23] [I]                                           Reformatting CopyNode for Input Tensor 0 to PWN(159_convolutional_lrelu)        1.13           0.0665      0.0
[05/21/2022-03:15:23] [I]                                                                                       PWN(159_convolutional_lrelu)        1.31           0.0771      0.0
[05/21/2022-03:15:23] [I]                               Reformatting CopyNode for Input Tensor 0 to 160_convolutional + 160_convolutional_bn        1.27           0.0749      0.0
[05/21/2022-03:15:23] [I]                                                                           160_convolutional + 160_convolutional_bn       61.51           3.6182      1.7
[05/21/2022-03:15:23] [I]                                                                                       PWN(160_convolutional_lrelu)        0.92           0.0541      0.0
[05/21/2022-03:15:23] [I]                                                                                                  161_convolutional        6.01           0.3538      0.2
[05/21/2022-03:15:23] [I]                                                     Reformatting CopyNode for Output Tensor 0 to 161_convolutional        0.58           0.0343      0.0
[05/21/2022-03:15:23] [I]                                                                                                              Total     3598.31         211.6656    100.0
[05/21/2022-03:15:23] [I] 
&&&& PASSED TensorRT.trtexec [TensorRT v8201] # /usr/src/tensorrt/bin/trtexec --onnx=yolov4-416.onnx --saveEngine=yolov4-416.trt --fp16 --dumpProfile --verbose --separateProfileRun --exportProfile=yolov4-416/recordProfile.json --exportOutput=yolov4-416/recordOutput.json --exportTimes=yolov4-416/recordTimes.json --exportLayerInfo=yolov4-416/recordLayer.json --workspace=512
